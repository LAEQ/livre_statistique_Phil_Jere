--- 
title: "Introduction aux méthodes quantitatives en sciences sociales avec R"
author: "Philippe Apparicio et Jérémy Gelb"
date: "`r Sys.Date()`"
colorlinks: yes
cover-image: images/cover.png
bibliography: book.bib
description: Ce livre propose une introduction aux méthodes quantitatives en sciences
  sociales basée sur le logiciel ouvert R. Le contenu est pensé pour être accessible
  même à ceux et celles n'ayant presque aucune base en statistique ou en programmation. Les
  personnes plus expérimentées y découvriront également des sections sur des méthodes
  poussées comme les modèles généralisés additifs à effets mixtes ou les méthodes
  factorielles mixtes. Celles cherchant à passer à R et délaisser progressivement SPSS, SAS ou STATA trouveront dans cet ouvrage les éléments pour une transition en douceur. La philosophie
  de se livre est de donner toutes les clefs de compréhension et de mise en œuvre
  des méthodes abordées afin de faciliter l'assimilation par les lecteur·trices. La présentation
  des méthodes est basée sur une approche compréhensive et intuitive plutôt que mathématique
  sans pour autant que la rigueur statistique ne soit négligée. Servez-vous votre
  boisson chaude ou froide favorite, installez-vous dans votre meilleur fauteuil et
  bonne lecture !
documentclass: book
fontsize: 11pt
github-repo: LAEQ/livre_statistique_Phil_Jere
graphics: yes
link-citations: yes
lof: yes
lot: yes
mainfont: Palatino Linotype
monofont: "Source Code Pro"
monofontoptions: "Scale=0.8"
mathfontoptions: "Scale=0.1"
site: bookdown::bookdown_site
csl: StyleINRS.csl
url: https\://bookdown.org/yihui/rmarkdown/
geometry: "left=2cm,right=2cm,top=2cm,bottom=2cm"
toc-title: "Table des matières"
lang: fr
---


# Préface {-}

```{asis, echo=identical(knitr:::pandoc_to(), 'html')}

Ce livre propose une introduction aux méthodes quantitatives en sciences sociales basée sur le logiciel ouvert R. Il a d'ailleurs été écrit intégralement dans R avec **rmarkdown**. Le contenu est pensé pour être accessible même à ceux n'ayant presque aucune base en statistique ou en programmation. Les personnes plus expérimentées y découvriront également des sections sur des méthodes plus avancées comme les modèles généralisés additifs à effets mixtes ou les méthodes factorielles. Ceux cherchant à migrer progressivement d'un autre logiciel statistique vers R trouveront dans cet ouvrage les éléments pour une transition en douceur. La philosophie de ce livre est de donner toutes les clefs de compréhension et de mise en œuvre des méthodes abordées afin de facilité l'assimilation par le lecteur. La présentation des méthodes est basée sur une approche compréhensive et intuitive plutôt que mathématique sans pour autant que la rigueur statistique ne soit négligée. Servez-vous votre boisson chaude ou froide favorite, installez-vous dans votre meilleur fauteuil et bonne lecture !


::: {.bloc_notes data-latex=""}

**Ce livre est un projet en cours d'écriture !**

Il sert de matériel pour le cours **Méthodes quantitatives appliquées aux études urbaines** (EUR8219), offert au Centre Urbanisation Culture Société de l'INRS. Son contenu est amené à changer et des erreurs peuvent encore être présentes. À terme, nous espérons le publier. Par conséquent, **son contenu ne peut donc en aucun cas être partagé en dehors du cours**. Vos commentaires et suggestions sur le contenu et la forme sont bienvenus ! Si certains passages vous semblent peu clairs, n'hésitez pas à nous en faire part.

:::

```

## Comment lire ce livre {-}

Si vous googlez l'expression « comment lire un livre ? », vous trouverez une multitude de conseils et astuces. Pour ce livre, nous vous conseillons de le lire de gauche à droite et page par page! Plus sérieusement, le livre comprend plusieurs types de blocs de texte qui, on l'espère, faciliteront la lecture.


::: {.bloc_package data-latex=""}
**Bloc packages**: habituellement localisé en début du chapitre, il comprend la liste des *packages* R utilisés pour un chapitre.
:::

::: {.bloc_objectif data-latex=""}
**Bloc objectif**: comprend une description des objectifs d'un chapitre ou d'une section.
:::

::: {.bloc_notes  data-latex=""}
**Bloc notes**: comprend une information secondaire sur une notion, un élément, une idée abordée dans une section.
:::

::: {.bloc_aller_loin data-latex=""}
**Bloc pour aller plus loin** : peut comprendre des références ou des extensions d'une méthode statistique abordée dans une section.
:::

::: {.bloc_astuce data-latex=""}
**Bloc astuce**: décrit un élément qui vous facilera le vie : une propriété statistique, un *package*, une fonction, une syntaxe R.
:::

::: {.bloc_attention data-latex=""}
**Bloc attention**:  comprend une notion ou un élément important à bien maîtriser.
:::

## Structure du livre {-}

Le livre est organisé autour de cinq grandes parties.


**Partie 1. La découverte de R.** Dans cette première partie, nous discuterons brièvement de l’histoire et de la philosophie de R. Nous verrons ensuite comment installer R et RStudio. Les bases du langage R (particulièrement les principaux objets que sont le vecteur, la matrice, la liste et le *dataframe*) ainsi que la manipulation des données avec R sont aussi largement abordés dans le chapitre \@ref(chap01).

**Partie 2. Analyses univariées et représentations graphiques**.

**Partie 3. Analyses bivariées.** Cette troisième partie comprend trois chapitres dans lesquelles sont présentées les principales méthodes exploratoires et confirmatoires bivariées permettant d'évaluer la relation entre deux variables (figure \@ref(fig:fig1)). Plus spécifiquement, nous présenterons puis mettrons en œuvre dans R les méthodes permettant d'explorer les relations entre deux variables quantitatives (covariance, corrélation et régression linéaire simple dans le chapitre \@ref(chap04)), deux variables qualitatives (tableau de contingence et test du khi^2^ dans le chapitre \@ref(chap05)) et une variable qualitative avec deux modalités (tests de student, de Welch et de Wilcoxon) ou avec plus de deux modalités (ANOVA et test de Kruskal-Wallis dans le chapitre \@ref(chap06)).


```{r fig1, fig.align='center', echo=FALSE, auto_pdf = TRUE, fig.cap="Les principales méthodes bivariées",  out.width='65%'}
knitr::include_graphics('images/bivariee/figure1.jpg', dpi = NA)
```

**Partie 4. Modèles de régression**. Dans cette partie, sont présentées les principales méthodes de statistique inférentielle utilisées en sciences sociales : la **régression linéaire multiple** (chapitre \@ref(chap07)), les régressions linéaires généralisées (chapitre \@ref(chap08)), les régressions à effets mixtes (chapitre \@ref(chap09)), les régressions à effets mixtes (chapitre \@ref(chap10)), les régressions multiniveaux (chapitre \@ref(chap11)) et les modèles généralisés additifs (chapitre \@ref(chap12)).

**Partie 5. Analyses exploratoires multidimensionnelles**. Dans cette cinquième partie, sont abordées les méthodes de statistique exploratoire et descritive permettant de décrire des tableaux de données comprenant plusieurs variables. Nous décrirons d'abord les méthodes de réduction de données — les méthodes factorielles  (analyses de composantes principales, analyses factorielles de correspondances, analyses factorielles de correspondances multiples et analyses factorielles de correspondances mixte) dans le chapitre \@ref(chap12); puis, les méthodes de classification dans le chapitre \@ref(chap13) (classification ascendantes hiérachiques, k-means, k-median et leurs extensions en logique floue comme le c-means et c-median).


## Pourquoi faut-il programmer en sciences sociales ? {-}

Vous contrasterez rapidement que R est un véritable langage de programmation. Il est donc légitime de se questionner à savoir si l'apprentissage d'un tel langage est pertinent pour un·e étudiant·e ou un·e chercheur·e en sciences sociales. Il est vrai que la programmation n'est pas la compétence qui vient tout de suite à l'esprit lorsque l'on pense aux sciences sociales. Pourtant, cette compétence est de plus en plus importante, et ce, pour plusieurs raisons :

* Une part toujours plus grande des phénomènes sociaux se produisent ou peuvent s'observer au travers d'environnements numériques. Être capable d'exploiter efficacement ces outils permet d'extraire des données riches sur des phénomènes complexes, tels qu’en témoigne des études récentes sur la propagation de la désinformation sur les réseaux sociaux [@allcott2017social], la migration des personnes [@spyratos2019quantifying], la propagation et les risques de contamination de la COVID19 [@boulos2020geographical], etc. Le plus souvent, les interfaces (API par exemple) permettant d'accéder à ces données nécessitent une base en programmation.
* La quantité de données numériques ouvertes et accessibles en ligne croit chaque année sur des sujets très divers. La plupart des villes et des gouvernements ont maintenant leurs portails de données ouvertes auxquels s'ajoutent les données produites par des projets collaboratifs comme [OpenStreetMap](https://www.openstreetmap.org) ou [NoisePlanet](https://noise-planet.org/map_noisecapture/index.html). Récupérer ces données et les structurer pour les utiliser à des fins de recherche nécessite le plus souvent des compétences en programmation.
* Les méthodes d'analyse quantitative connaissent également un développement très important. Les logiciels propriétaires peinent à suivre la cadence de ce développement contrairement aux logiciels à code source ouvert qui permettent d'avoir accès aux dernières méthodes. Il est souvent long et coûteux de développer une interface graphique pour un logiciel, ce qui explique que la plupart de ces programmes en sont dépourvus et nécessitent alors de savoir programmer pour les utiliser.
* Savoir programmer donne une liberté considérable en recherche. Cette compétence permet notamment de ne plus être limité aux fonctionnalités proposées par des logiciels spécifiques. Il devient possible d'innover tant en matière de structuration, d'analyses que de représentations des résultats en écrivant vos propres fonctions. Cette flexibilité contribue directement à la production d'une recherche de meilleure qualité et plus diversifiée.
* Programmer permet également d'automatiser des tâches qui autrement seraient extrêmement répétitives. Déplacer et renommer une centaine de fichiers ? Retirer les lignes inutiles dans un ensemble de fichiers CSV et les compiler dans une seule base de données ? Tester parmi des milliers d'adresses lesquelles sont valides ? Récupérer chaque jour les messages postés sur un forum ? Autant de tâches faciles à automatiser si l'on sait programmer.
* Dans un logiciel avec une interface graphique, il est compliqué de conserver un historique des opérations effectuées. Programmer permet au contraire de garder une trace de l'ensemble des actions effectuées au cours d'un projet de recherche. En effet, le code utilisé reste disponible et permet de reproduire la méthode et les résultats obtenus ce qui est essentiel dans le monde de la recherche. À cela s'ajoute le fait que chaque ligne de code que vous écrivez vient s'ajouter à un capital de code que vous possédez, car elles pourront être réutilisées dans d'autres projets !


## Remerciements {-}

Ce livre est dédié au beau Cargo (chien Mira) qui nous a tant supporté dans l'écriture du livre !

Nous tenons aussi à remercier sincérement les étudiant·e·s du cours **Méthodes quantitatives appliquées aux études urbaines (EUR8219)** du programme de maîtrise en études urbaines de l'INRS. À compléter plus tard.

```{r cargo, fig.align='center', echo=FALSE, auto_pdf = TRUE, fig.cap="Cargo, le plus beau",  out.width='50%'}
knitr::include_graphics('images/Cargo.jpg', dpi = NA)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
## quelques parametres generaux en fonction du type de document
library(tidyverse)
library(ggpubr)

if (knitr::is_latex_output()){
  font_size_table <- 8
}else{
  font_size_table <- 14
}

# note : il ne faut changer que les caracteres en dehors des equations
clean_text <- function(string){
  if (is.na(string)){
    return (NA)
  }
  if(string == ""){
    return("")
  }
  changes <- list(
     c("`", "", F),
      c("\\^([^\"]*?)\\^","\\\\textsuperscript{\\1}",F),
      c("\\*{2}([^\"]*)\\*{2}","\\\\textbf{\\1}", F),
      c("\\*{2}([^\"]*)\\*{2}","\\\\textbf{\\1}", F),
      c("\\%", "\\\\%", F),
      c("&", "\\\\&", F),
      #c("\\^(?=(?:[^$]*$[^$]*$)*[^$]*$)", "\\\\textasciicircum{}", F),
      c("\\*{2}", "doublestars", F),
      c("\\*([^\"]*?)\\*", "\\\\textit{\\1}", F),
      c("doublestars", "**", F),
      c("\\\\@ref\\(([^\"]*?)\\)", "\\\\ref{\\1}", F),
      c("\\(\\%\\)", "(\\\\%)", F),
      c("_", "\\_", TRUE),
      c("beta\\_", "beta_", TRUE),
      c("alpha\\_", "alpha_", TRUE)
      )
  parts <- strsplit(string, "$", fixed = T)[[1]]
  new_strings <- sapply(1:length(parts), function(i){
    thisstring <- parts[[i]]
    if (thisstring != ""){
      parts2 <- strsplit(thisstring, "`", fixed = T)[[1]]
      new_strings2 <- sapply(1:length(parts2), function(j){
        thisstring2 <- parts2[[j]]
        if (j %% 2 ==0){
          thisstring2 <- gsub("^","\\textasciicircum{}",thisstring2, fixed = T)
          return(thisstring2)
        }else{
          return(thisstring2)
        }
      })
      thisstring <- paste(new_strings2, collapse="")
    }
    
    
    if (i %% 2 ==0){
      return(paste("$",thisstring,"$",sep=""))
    }else{
      for (ch in changes){
          if(ch[[3]]){
            thisstring <- gsub(ch[[1]],ch[[2]],thisstring, fixed = T)
          }else{
            thisstring <- gsub(ch[[1]],ch[[2]],thisstring, perl = T)
          }
          
      }
      return(thisstring)
    }
  })
  fullstring <- paste(new_strings, collapse = "")
  return (fullstring)
  
}

clean_df_latex <- function(df){
  if(inherits(df, "list") == F){
    df <- list(df)
  }
  df2 <- lapply(df, function(i){
    i <- data.frame(i)
    for(col in names(i)){
      if(is.character(i[[col]])){
       i[[col]] <- sapply(i[[col]], clean_text)
      }
    }
    return(i)
  })
  return(df2)
}

show_table <- function(df, col.names = NA, caption = NULL, col.to.resize = NULL, 
                       col.width = NULL, digits = getOption("digits"),
                       align = NULL, row.names = FALSE, position = NULL, ...){
  options(knitr.kable.NA = '')
  if(is.null(position)){
    position <- "basic"
  }
  ## dans le cas d'un tableau LATEX
  if (knitr::is_latex_output()){
    #etape1 : supprimer les caracteres speciaux, echapper les gras et italic
    df2 <- clean_df_latex(df)
    if (is.null(col.names) == F){
      if(is.na(col.names)==F){
        #col.names <- gsub("\\(\\%\\)","(\\\\%)",col.names)
        col.names <- gsub("\\%","\\\\%",col.names)
        col.names <- gsub("\\^([^\"]*?)\\^","\\\\textasciicircum{\\1}",col.names,fixed = F)
      }
    }

    if(is.null(caption)==F){
      caption <- gsub("\\*{2}([^\"]*)\\*{2}","\\\\textbf{\\1}", caption)
      caption <- gsub("\\*([^\"]*?)\\*","\\\\textit{\\1}", caption)
    }
    if(length(df2) == 1){
      df2 <- df2[[1]]
    }
    table1 <- knitr::kable(
      df2, booktabs = TRUE,
      format = "latex",
      digits = digits,
      format.args = list(decimal.mark = ",", big.mark = " "),
      valign = 't', row.names = row.names,
      align = align,
      col.names = col.names,
      caption = caption,
      escape = FALSE, ...) %>% 
      kableExtra::kable_styling(font_size = 8,protect_latex = T, latex_options = position)
    if (is.null(col.to.resize) == FALSE){
      table1 <- table1 %>% 
        kableExtra::column_spec(col.to.resize, width=col.width)
    }
  ## dans le cas d'un tableau HTLM
  }else{
    
    # gerer les newline
    if(class(df) != "list"){
      df <- data.frame(df)
      for(col in names(df)){
        if(is.character(df[[col]])){
          df[[col]] <- gsub("\\newline","<br/>",df[[col]], fixed = T)
        }
      }
    }else {
      df <- lapply(df, function(i){
        i <- data.frame(i)
        i <- i %>% mutate_if(~is.character(.), funs(str_replace_all(., "\\newline", "<br/>")))
        return(i)
      })
    }
    table1 <- knitr::kable(
      df, booktabs = TRUE,
      format.args = list(decimal.mark = ",", big.mark = " "),
      col.names = col.names,
      align = align,
      valign = 't', row.names = row.names,
      digits = digits,
      caption = caption,
      escape = FALSE, ...)
    ## gerer le padding
    table1 <- gsub(pattern = "NApadding", replacement = "padding",x = table1, fixed = T)
  }
  return(table1)
}

tofr <- function(float){
  return(gsub(".",",",as.character(float),fixed = T))
}


# a simple function to show a more simple figure when a lot of details are given
show_as_png <- function(gplot, out, dpi = 250){
  invisible({capture.output({this_file <- ggsave(plot = gplot,
                      filename = out, 
                      device = "png",
                      dpi = dpi)})})
  knitr::include_graphics(out, dpi = dpi)
}


print_number <- function(x, digits = NULL){
  if(is.null(digits) == FALSE){
    x <- round(x, digits = digits)
  }
  parts <- strsplit(as.character(x), split = ".", fixed = TRUE)[[1]]
  part1 <- strsplit(parts[[1]], "")[[1]]
  i<-1
  elems <- sapply(rev(part1), function(y){
    if(i == 3){
      i <<- 1
      return(paste0(" ",y))
    }else{
      i <<- i+1
      return(y)
    }
  })
  part1 <- paste(rev(elems), collapse = "")
  x2 <- paste0(part1, ",",parts[[2]])
  cat(x2)
}

```


```{r message=FALSE, warning=FALSE, include=FALSE}
source("code_complementaire/JG_helper.R")
source("code_complementaire/QuizzFunctions.R")
```
