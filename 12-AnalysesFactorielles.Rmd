# (PART) Analyses exploratoires multivariées{-}

# Méthodes factorielles {#chap12}

::: {.bloc_attention data-latex=""}
Ce chapitre n'a pas encore fait l'objet d'une révision linguistique. Il comprend certainement plusieurs coquilles... Une version révisée sera mise à jour prochainement.
:::


Dans le cadre de ce chapitre, nous présentons les trois méthodes factorielles les plus utilisées en sciences sociales&nbsp;: l'analyse en composantes principales (ACP, section \@ref(sect122)), l'analyse factorielle des correspondances (AFC, section \@ref(sect123)) et l'analyse factorielle des correspondances multiples (ACM, section \@ref(sect124)). Ces méthodes qui permettent d'explorer et de synthétiser l'information de différents tableaux de données relèvent de la statistique exploratoire multidimensionnelle.

::: {.bloc_package data-latex=""}
Dans ce chapitre, nous utilisons les *packages* suivants&nbsp;: 

* Pour créer des graphiques&nbsp;:
  - `ggplot2`, le seul, l'unique!
  - `ggpubr` pour combiner des graphiques.
* Pour les analyses factorielles&nbsp;:
  - `FactoMineR` pour réaliser des ACP, AFC et ACM.
  - `factoextra` pour réaliser des graphiques à partir des résultats d'une analyse factorielle.
  - `explor` pour les résultats d'une ACP, d'une AFC ou d'une ACM avec une interface Web interactive.
* Autre *package*&nbsp;:
  - `geocmeans` pour un jeu de données utilisé pour calculer une ACP.
  - `ggplot2`, `ggpubr`, `stringr` et `corrplot` pour réaliser des graphiques personnalisés sur les résultats d'une analyse factorielle.
  - `tmap` et `RColorBrewer` pour cartographier les coordonnées factorielles.
  - `Hmisc` pour l'obtention d'une matrice de corrélation.
:::

::: {.bloc_objectif data-latex=""}
**Réduction de données et identification de variables latentes**

Les méthodes factorielles sont souvent dénommées des **méthodes de réduction de données**, en raison de leur objectif principal&nbsp;: résumer l'information d'un tableau en quelques nouvelles variables synthétiques (figure&nbsp;\@ref(fig:AnalysesFactoriellesFig)). Ainsi, elles permettent de réduire l'information d'un tableau volumineux —&nbsp;comprenant par exemple 1000&nbsp;observations et 100&nbsp;variables&nbsp;— en *p* nouvelles variables (par exemple cinq avec toujours 1000&nbsp;observations) résumant *X* % de l'information contenue dans le tableau initial. Formulée plus mathématiquement, Lebart et al. [-@lebart1995statistique, p.13] signalent qu'avec les méthodes factorielles, «&nbsp;on cherche à réduire les dimensions du tableau de données en représentant les associations entre individus et entre variables dans des espaces de faibles dimensions&nbsp;».

```{r AnalysesFactoriellesFig, fig.align='center', echo=FALSE, auto_pdf = TRUE, fig.cap="Principe de base des analyses factorielles",  fig.pos="H", out.width='50%'}
knitr::include_graphics('images/analysesfactorielles/AnalysesFactorielles.png', dpi = NA)
```

Ces nouvelles variables synthétiques peuvent être considérées comme des **variables latentes** puisqu’elles ne sont directement observées, mais plutôt produites par la méthode factorielle utilisée afin de résumer les relations/associations entre plusieurs variables mesurées initialement.
:::

## Aperçu des méthodes factorielles {#sect121}

### Méthodes factorielles et types de données {#sect1211}

En analyse factorielle, la nature même des données du tableau à traiter détermine la méthode à employer&nbsp;: l’analyse en composantes principales (ACP) est adaptée aux tableaux avec des variables continues (idéalement normalement distribuées), l’analyse factorielle des correspondances (AFC) s’applique à des tableaux de contingence tandis que l’analyse des correspondances multiples (ACM) permet de résumer des tableaux avec des données qualitatives (issues d'un sondage par exemple) (tableau&nbsp;\@ref(tab:typesanalysesfactorielles)). Sachez toutefois qu'il existe d'autres méthodes factorielles qui ne sont pas abordées dans ce chapitre, notamment&nbsp;: l'analyse factorielle de données mixtes (AFDM) permettant d'explorer des tableaux avec à la fois des variables continues et des variables qualitatives, l'analyse factorielle multiple hiérarchique (AFMH) permettant de traiter des tableaux avec une structure hiérarchique. Pour s'initier à ces deux autres méthodes factorielles plus récentes, consultez notamment l'excellent ouvrage de Jérôme Pagès [-@pages2013analyse].

```{r typesanalysesfactorielles, echo=FALSE, message=FALSE, warning=FALSE, out.width='75%'}

typesaf <- data.frame(Metho= c("Analyse en composantes principales",
                             "Analyse factorielle des correspondances", 
                             "Analyse factorielle des correspondances multiples"), 
                      Abr = c("ACP", "AFC", "ACM"),
                      type = c("Variables continues", "Tableau de contingence", "Variables qualitatives"),
                      dist = c("Distance euclidienne", "Distance du khi-deux", "Distance du khi-deux")
                    )
show_table(typesaf,
           caption = "Trois principales méthodes factorielles",
           col.names=c("Méthode factorielle","Abr.","Type de données", "Type de distance"),
           align= c("l", "l", "l", "l"),
           position = "HOLD_position"
           )
```

### Bref historique des méthodes factorielles {#sect1212}

Il existe une longue tradition de l'utilisation des méthodes factorielles dans le monde universitaire francophone puisque plusieurs d'entre elles ont été proposées par des statisticiens et des statisticiennes francophones à partir des années 1960. L’analyse en composantes principales (ACP) a été proposée dès les années 1930 par le statisticien américain Harold Hotelling [-@hotelling1933analysis]. En revanche, l’analyse des correspondances (AFC) et son extension (l’analyse des correspondances multiples, ACM) ont été proposées par le statisticien français Jean-Paul Benzécri [-@benzecri1973analyse], tandis que l’analyse factorielle de données mixtes (AFDM) a été proposée par Brigitte Escofier et Jérôme Pagès [@escofier1979traitement; @pages2002analyse].

Ainsi, plusieurs ouvrages de statistique  sur les méthodes factorielles, désormais classiques, ont été publiés en français [@benzecri1973analyse; @escofier1998analyses; @lebart1995statistique; @pages2013analyse]. Ils méritent grandement d'être consultés, notamment pour mieux comprendre les formulations mathématiques (matricielles et géométriques) de ces méthodes. À cela, s'ajoutent plusieurs ouvrages visant à «&nbsp;vulgariser ces méthodes&nbsp;» en sciences sociales; c'est notamment le cas de l'excellent ouvrage de Léna Sanders [-@sanders1989analyse] en géographie.


## Analyses en composantes principales (ACP) {#sect122}

D'emblée, notez qu'il existe deux types d'analyse en composantes principales (ACP) (*Principal Component Analysis, PCA* en anglais)&nbsp;: 

- **l'ACP non normée** dans laquelle les variables quantitatives du tableau sont uniquement centrées (moyenne&nbsp;=&nbsp;0).
- **l'ACP normée** dans laquelle les variables quantitatives du tableau sont préalablement centrées réduites (moyenne&nbsp;=&nbsp;0 et variance&nbsp;=&nbsp;1; section \@ref(sect02552)).

Puisque les variables d'un tableau sont souvent exprimées dans des unités de mesure différentes ou avec des ordres de grandeur différents (intervalles et écarts-types bien différents), l'utilisation de l'ACP normée est bien plus courante. Elle est d'ailleurs l'option par défaut dans les fonctions R permettant de calculer une ACP. Par conséquent, nous détaillons dans cette section uniquement l'ACP normée.

Autrement dit, le recours à une ACP non normée est plus rare et s'applique uniquement à la situation suivante&nbsp;: toutes les variables du tableau sont mesurées dans la même unité (par exemple, en pourcentage); il pourrait alors être ainsi judicieux de conserver leurs variances respectives.

### Recherche d'une simplification {#sect1221}

L’ACP permet d'explorer et de résumer un tableau constitué uniquement de variables quantitatives (figure&nbsp;\@ref(fig:AnalysesFactoriellesTabACPFig)), et ce, de trois façons&nbsp;: 1) en montrant les ressemblances entre les individus (observations), 2) en révélant les liaisons entre les variables quantitatives et 3) en résumant l’ensemble des variables du tableau par des variables synthétiques nommées composantes principales.

```{r AnalysesFactoriellesTabACPFig, fig.align='center', echo=FALSE, auto_pdf = TRUE, fig.cap="Tableau pour une ACP", out.width='60%'}
knitr::include_graphics('images/analysesfactorielles/AnalysesFactoriellesTabACP.png', dpi = NA)
```


**Ressemblance entre les individus**. Concrètement deux individus se ressemblent si leurs valeurs respectives pour les *p* variables du tableau sont similaires. Cette proximité/ressemblance est évaluée à partir de la distance euclidienne&nbsp; (équation \@ref(eq:ACPdistEuc)). La notion de distance fait l'objet d'une section à part entière (section \@ref(sect132)) que vous pouvez consulter dès à présent si elle ne vous est pas familière.

\footnotesize
\begin{equation}
d^2(a,b) = \sum_{j=1}^p(x_{aj}-x_{bj})^2
(\#eq:ACPdistEuc)
\end{equation}
\normalsize

Prenons un exemple fictif avec trois individus (*i*, *j* et *k*) ayant des valeurs pour trois variables préalablement centrées réduites (V1 à V3) (tableau&nbsp;\@ref(tab:distanceACPindi)). La proximité entre les paires de points est évaluée comme suit&nbsp;: 

$$d^2(i,j)=(-\mbox{1,15}-\mbox{0,49})^2+(-\mbox{1,15}-\mbox{0,58})^2+(\mbox{0,83}+\mbox{1,11})^2=\mbox{9,44}$$
$$d^2(i,k)=(-\mbox{1,15}+\mbox{0,66})^2+(-\mbox{1,15}-\mbox{0,58})^2+(\mbox{0,83}-\mbox{0,28})^2=\mbox{5,98}$$

$$d^2(j,k)= (\mbox{0,49}+\mbox{0,66})^2+(\mbox{0,58}-\mbox{0,58})^2+(-\mbox{1,11}-\mbox{0,28})^2=\mbox{1,97}$$

Nous pouvons en conclure que *i* est plus proche de *k* que de *j*, mais aussi que la paire de points les plus proches est (*i*,*k*). En d'autres termes, les deux observations *i* et *k* sont les plus similaires du jeu de données selon la distance euclidienne.

```{r distanceACPindi, echo=FALSE, message=FALSE, warning=FALSE, out.width='75%'}
library(kableExtra)
df1 <- data.frame(Ind=c("i", "j", "k"),
                  V1=c(100,150,155),
                  V2=c(20,22,22),
                  V3=c(25,18,23))

df1$V1 <- round(scale(df1$V1),2)
df1$V2 <- round(scale(df1$V2),2)
df1$V3 <- round(scale(df1$V3),2)

my_table <- show_table(df1,
             caption = "Données fictives",
             col.names = c("Individu","V1","V2", "V3"),
             align= c("c", "c", "c", "c")
             )
add_header_above(my_table, c(" " = 1, "Variables centrées réduites" = 3))
```


**Liaisons entre les variables**. Dans une ACP normée, les liaisons entre les variables deux à deux sont évaluées avec le coefficient de corrélation (section \@ref(sect0431)), soit la moyenne du produit des deux variables centrées réduites (équation \@ref(eq:ACPcor)). Notez que dans une ACP non normée, plus rarement utilisée, les liaisons sont alors évaluées avec la covariance puisque les variables sont uniquement centrées (équation \@ref(eq:ACPcov)).

\footnotesize
\begin{equation}
r_{xy} = \frac{\sum_{i=1}^n (x_{i}-\bar{x})(y_{i}-\bar{y})}{n\sqrt{\sum_{i=1}^n(x_i - \bar{x})^2(y_i - \bar{y})^2}}=\sum_{i=1}^n\frac{Zx_iZy_i}{n}
(\#eq:ACPcor)
\end{equation}
\normalsize

\footnotesize
\begin{equation}
cov(x,y) = \frac{\sum_{i=1}^n (x_{i}-\bar{x})(y_{i}-\bar{y})}{n}
(\#eq:ACPcov)
\end{equation}
\normalsize

**Composantes principales**. Au chapitre&nbsp;4, nous avons abordé deux méthodes pour identifier des relations linéaires entre des variables continues normalement distribuées&nbsp;: 

* la corrélation de Pearson (section \@ref(sect043)), qu'il est possible d'illustrer graphiquement à partir d'un nuage de points;
* la régression linéaire simple (section \@ref(sect044)), permettant de résumer la relation linéaire entre deux variables avec une droite de régression de type $Y=a+bX$. 

Brièvement, plus deux variables sont corrélées (positivement ou négativement), plus le nuage de points qu'elles forment est allongé et plus les points sont proches de la droite de régression (figure&nbsp;\@ref(fig:liaisons2Vars), partie&nbsp;**a**). À l'inverse, plus la liaison entre les deux variables normalement distribuées est faible, plus le nuage prend la forme d'un cercle et plus les points du nuage sont éloignés de la droite de régression (figure&nbsp;\@ref(fig:liaisons2Vars), partie&nbsp;**b**). Puisqu'en ACP normée, les variables sont centrées réduites, le centre de gravité du nuage de points est (*x*=0, *y*=0) et il est toujours traversé par la droite de régression. Finalement, nous avons vu que la méthode des moindres carrés ordinaires (MCO) permet de déterminer cette droite en minimisant les distances entre les valeurs observées et celles projetées orthogonalement sur cette droite (valeurs prédites). Dans le cas de deux variables uniquement, l'axe factoriel principal/la composante principale est donc la droite qui résume le mieux la liaison entre les deux variables (en rouge). L'axe&nbsp;2 représente la seconde plus importante composante (axe, dimension) et il est orthogonal (perpendiculaire) au premier axe (en bleu).

```{r liaisons2Vars, fig.align='center', echo=FALSE, auto_pdf = TRUE, fig.cap="Corrélation, allongement du nuage de points et axes factoriels", out.width='100%'}
knitr::include_graphics('images/analysesfactorielles/bivariePlanFacto.png', dpi = NA)
# library("MASS")
# library("ggplot2")
# library("ggpubr")
# library("FactoMineR")
# N <- 500      # nombre d'observations
# moy_x <- 50   # moyenne de x
# moy_y <- 40   # moyenne de y
# sd_x <- 10    # écart-type de x
# sd_y <- 8     # écart-type de y
# rxy <- c(.90,-.85,0.01) # corrélation entre X et Y
# # Matrice de covariance
# cov1 <- matrix(c(sd_x^2,  rxy[1]*sd_x*sd_y, rxy[1]*sd_x*sd_y, sd_y^2), nrow=2)
# cov2 <- matrix(c(sd_x^2,  rxy[2]*sd_x*sd_y, rxy[2]*sd_x*sd_y, sd_y^2), nrow=2) 
# cov3 <- matrix(c(sd_x^2,  rxy[3]*sd_x*sd_y, rxy[3]*sd_x*sd_y, sd_y^2), nrow=2) 
# data1 <-  as.data.frame(mvrnorm(N, c(moy_x, moy_y), cov1))
# data2 <-  as.data.frame(mvrnorm(N, c(moy_x, moy_y), cov2))
# data3 <-  as.data.frame(mvrnorm(N, c(moy_x, moy_y), cov3))
# data1$V1 <- scale(data1$V1)
# data1$V2 <- scale(data1$V2)
# data2$V1 <- scale(data2$V1)
# data2$V2 <- scale(data2$V2)
# data3$V1 <- scale(data3$V1)
# data3$V2 <- scale(data3$V2)
# cor1 <- round(cor(data1)[1,2],3)
# cor2 <- round(cor(data2)[1,2],3)
# cor3 <- round(cor(data3)[1,2],3)
# 
# lm1 <- lm(V1 ~ V2, data = data1)
# coef1 <- round(lm1$coefficients,3)[2]
# y1 <-lm1$coefficients[1]+(lm1$coefficients[2]*3)
# y2 <-lm1$coefficients[1]+(lm1$coefficients[2]*-3)
# plot1 <- ggplot(data1, aes(x=V1,y=V2))+
#   xlim(-3,3)+
#   ylim(-3,3)+
#   geom_point(size = 1, color="steelblue")+
#   ggtitle("a. Forte relation linéaire positive", subtitle = paste0("Corrélation = ", tofr(cor1)))+
#   geom_hline(yintercept=0, size = .2, color="black")+
#   geom_vline(xintercept=0, size = .2, color="black")+
#   xlab("Variable 1")+ylab("Variable 2")+
#   stat_ellipse( size = 1, color="black")+
#   annotate(geom="text", x =3, y= 3, label="Axe 1", color="red", hjust = 1, size = 5)+
#   annotate(geom="text", x =-2.5, y=  3, label="Axe 2", color="steelblue", hjust = 0, size = 5)+
#   geom_segment(aes(x = 3, y = y1, xend = -3, yend = y2), size=1, color='red')+
#   geom_segment(aes(x = -y1, y = 3, xend = -y2, yend = -3), size=1, color='steelblue')+
#   coord_fixed()
# plot1
# 
# lm3 <- lm(V1 ~ V2, data = data3)
# coef3 <- round(lm3$coefficients,3)[2]
# y1 <-lm3$coefficients[1]+(lm3$coefficients[2]*3)
# y2 <-lm3$coefficients[1]+(lm3$coefficients[2]*-3)
# plot3 <- ggplot(data3, aes(x=V1,y=V2))+
#   xlim(-3,3)+
#   ylim(-3,3)+
#   geom_point(size = 1, color="steelblue")+
#   ggtitle("b. Absence de relation linéaire", subtitle = paste0("Corrélation = ", tofr(cor3)))+
#   xlab("Variable 1")+ylab("Variable 2")+
#   geom_hline(yintercept=0, size = .2, color="black")+
#   geom_vline(xintercept=0, size = .2, color="black")+
#   stat_ellipse( size = 1, color="black")+
#   annotate(geom="text", x =3, y= -.2, label="Axe 1", color="red", hjust = 1, size = 5)+
#   annotate(geom="text", x =.2, y= 2.8, label="Axe 2", color="blue", hjust = 0, size = 5)+
#   geom_segment(aes(x = 3, y = y1, xend = -3, yend = y2), size=1, color='red')+
#   geom_segment(aes(x = -y1, y = 3, xend = -y2, yend = -3), size=1, color='blue')+
#   coord_fixed()
# plot3
  
```

Imaginez maintenant trois variables pour lesquelles vous désirez identifier un axe, une droite qui résume le mieux les liaisons entre elles. Visuellement, vous passez d'un nuage de points en deux dimensions (2D) à trois dimensions (3D). Si les corrélations entre les trois variables sont très faibles, alors le nuage prendra la forme d'un ballon de football (soccer en Amérique du Nord). Par contre, plus ces liaisons seront fortes, plus la forme sera allongée comme un ballon de rugby (ou football américain) et plus les points seront proches de l'axe traversant le ballon.

Ajouter une autre variable revient alors à ajouter une quatrième dimension qu'il est impossible de visualiser, même pour les plus fervents adaptes de science-fiction. Pourtant le problème reste le même, identifier dans dans un plan en *p* dimensions (variables), les axes factoriels, les composantes principales qui concourent le plus à résumer liaisons entre les variables continues préalablement centrées réduites, et ce, en utilisation la méthode des moindres carrés ordinaires.

::: {.bloc_attention data-latex=""}
Les termes **composantes principales** et **axes factoriels** sont des synonymes employés pour référer aux nouvelles variables synthétiques produites par l'ACP et résumant l'information du tableau intitial.
:::


### Aides à l'interprétation {#sect1222}

Pour illustrer les aides à l'interprétation de l'ACP, nous utilisons un jeu de données spatiales tiré d'un article sur l'agglomération lyonnaise en France [@2021_4]. Ce jeu de données comprend dix variables, dont quatre environnementales (EN) et six socioéconomiques (SE),  pour les îlots regroupés pour l'information statistique (IRIS) de l'agglomération lyonnaise (tableau&nbsp;\@ref(tab:dataacp) et figure&nbsp;\@ref(fig:datacartoacp)). Sur ces dix variables, nous calculons une **ACP normée**.

\newpage

```{r dataacp, echo=FALSE, message=FALSE, warning=FALSE, out.width='75%'}
library(geocmeans)
data(LyonIris)
Data <- LyonIris@data[c("Lden","NO2","PM25","VegHautPrt",
                        "Pct0_14","Pct_65","Pct_Img",
                        "TxChom1564","Pct_brevet","NivVieMed")]

intitule <- c("Bruit routier (Lden dB(A))",
              "Dioxyde d'azote (ug/m^3^)",
              "Particules fines (PM$_{2,5}$)",
              "Canopée (%)",
              "Moins de 15 ans (%)",
              "65 ans et plus (%)",
              "Immigrants (%)",
              "Taux de chômage",
              "Personnes à faible scolarité (%)",
              "Médiane du niveau de vie (Euros)" )

stats <- data.frame(variable = names(Data),
                    nom = intitule,
                    type = c("EN","EN","EN","EN","SE","SE","SE","SE","SE","SE"),
                    moy = round(sapply(Data, mean),2),
                    et = round(sapply(Data, sd),2), 
                    minimum =round(sapply(Data, min),2), 
                    maximum =round(sapply(Data, max),2)
                    )
show_table(stats,
           digits = 1,
            caption = "Statistiques descriptives pour le jeu de données utilisé pour l'ACP",
           col.names=c("Nom","Intitulé","Type","Moy.", "E.-T.", "Min.", "Max."),
           align= c("l","l", "c","r", "r", "r", "r"),
           position = "HOLD_position"
           )
```

```{r datacartoacp, fig.align='center', echo=FALSE, auto_pdf = TRUE, fig.cap="Cartographie des dix variables utilisées pour l'ACP",  out.width='100%'}
knitr::include_graphics('images/analysesfactorielles/Figure3Data.png', dpi = NA)
```

::: {.bloc_objectif data-latex=""}
**Trois étapes pour bien analyser une ACP et comprendre la signification des axes factoriels&nbsp;:**

1. Interprétation des résultats des valeurs propres pour identifier le nombre d'axes (de composantes principales) à retenir. L'enjeu est de garder un nombre d'axes limité qui résume le mieux le tableau initial (réduction des données).
2. Analyse des résultats pour les variables (coordonnées factorielles, cosinus carrés et contributions sur les axes retenus).
3. Analyse des résultats pour les individus (coordonnées factorielles, cosinus carrés et contributions sur les axes retenus).

Les deux dernières étapes permettent de comprendre la signification des axes retenus et de les qualifier. Cette étape d'interprétation est essentielle en sciences sociales. En effet, nous avons vu dans l'introduction du chapitre que les méthodes factorielles permettent de résumer l'information d'un tableau en quelques nouvelles variables synthétiques, souvent considérées comme des variables latentes dans le jeu de données. Il convient alors de bien comprendre ces variables synthétiques (latentes), si nous souhaitons les utiliser dans une autre analyse subséquente (par exemple, les introduire dans une régression).
:::


#### Résultats de l'ACP pour les valeurs propres {#sect12221}

À titre de rappel, une ACP normée est réalisée sur des variables préalablement centrées réduites (équation \@ref(eq:scorezacpnormee)), ce qui signifie que pour chaque variable&nbsp;:

- Nous soustrayons à chaque valeur la moyenne de la variable correspondante (centrage); la moyenne est donc égale à&nbsp;0.
- Nous divisons cette différence par l’écart-type de la variable correspondante (réduction); la variance est égale à&nbsp;1.
	
\footnotesize
\begin{equation}  
z= \frac{x_i-\mu}{\sigma}
(\#eq:scorezacpnormee)
\end{equation}
\normalsize
	
Par conséquent, la variance totale (ou inertie totale) d’un tableau sur lequel est calculée une ACP normée est égale au nombre de variables qu'il comprend. Puisque nous l'appliquons ici à dix variables, la variance totale du tableau à réduire – c'est-à-dire à résumer en *K* nouvelles variables synthétiques, composantes principales, axes factoriels – est donc égale à 10. Trois mesures reportées au tableau&nbsp;\@ref(tab:dataacpValeurPropres) permettent d'analyser les valeurs propres&nbsp;: 

- $\mbox{VP}_k$, la valeur propre (*eigenvalue* en anglais) de l'axe *k* c'est-à-dire la quantité de variance du tableau initial résumé par l'axe.
- $\mbox{VP}_k / \mbox{P}$ avec *P* étant le nombre de variables que comprend le tableau initial. Cette mesure représente ainsi le pourcentage de la variance totale du tableau résumé par l’axe *k*, autrement dit, la quantité d’informations du tableau initial résumée par l’axe, la composante principale *k*. Cela nous permet ainsi d’évaluer le pouvoir explicatif de l’axe.
- Le pourcentage cumulé pour les axes.

```{r dataacpValeurPropres, echo=FALSE, message=FALSE, warning=FALSE, out.width='75%'}
library(FactoMineR)

# Calcul de l'ACP
res.acp <- PCA(Data, ncp=5, scale.unit=TRUE, graph=F)

# Construction d'un DataFrame pour les valeurs propres
dfACPvp <- data.frame(res.acp$eig)
names(dfACPvp) <- c("VP","VP_pct","VP_cumupct")
dfACPvp$Composante <- factor(1:nrow(dfACPvp), levels=rev(1:nrow(dfACPvp)))
dfACPvp <- dfACPvp[,c(4,1:3)]

show_table(dfACPvp,
           digits = 3,
            caption = "Résultats de l'ACP pour les valeurs propres",
           col.names=c("Composante","Valeur propre","Pourcentage", "Pourc. cumulé"),
           align= c("r", "r", "r", "r")
           )
```

Avant d'analyser en détail le tableau&nbsp;\@ref(tab:dataacpValeurPropres), notez que la somme des valeurs propres de toutes les composantes de l'ACP est toujours  égale au nombre de variables du tableau initial. Aussi, la quantité de variance expliquée (les valeurs propres) décroît de de la composante&nbsp;1 à la composante&nbsp;*K*.

**Combien d'axes d'une ACP faut-il retenir?** Pour ce faire, deux approches sont possibles&nbsp;:

- **Approche statistique** (avec le critère de Kaiser [-@kaiser1960application]). Nous retenons uniquement les composantes qui présentent une valeur propre supérieure à&nbsp;1. Rappelez-vous qu'en ACP normée, les variables sont préalablement centrées réduites et donc que leur variance respective est égale à&nbsp;1. Par conséquent, une composante ayant une valeur propre inférieure à&nbsp;1 a un pouvoir explicatif inférieur à celui d'une variable. À la lecture du tableau, nous retenons les trois premières composantes si nous appliquons ce critère.
- **Approche empirique** basée sur la lecture des pourcentages et des pourcentages cumulés. Nous pourrons retenir uniquement les deux premières composantes. En effet, ces deux premiers facteurs résument près des deux tiers de la variance totale du tableau (63,02&nbsp;%). Cela démontre bien que l'ACP, comme les autres méthodes factorielles, est bien une méthode de réduction de données puisque nous résumons dix variables avec deux nouvelles variables synthétiques (axes, composantes principales). Pour faciliter le choix du nombre d'axes, il est fortement conseillé de construire des histogrammes à partir des valeurs propres, des pourcentages et des pourcentages cumulés (figure&nbsp;\@ref(fig:acpgraphvp)). Or, à la lecture de ces graphiques, nous constatons que la variance expliquée chute drastiquement après les deux premières composantes. Par conséquent, nous pouvons retenir uniquement les deux premiers axes.

::: {.bloc_astuce data-latex=""}
**Lecture du diagramme des valeurs propres** 

Plus les variables incluses dans l'ACP sont corrélées entre elles, plus l'ACP sera intéressante&nbsp;: plus les valeurs propres des premiers axes sont fortes et plus il y a des sauts importants dans le diagramme des valeurs propres. À l'inverse, lorsque les variables incluses dans l'ACP sont peu corrélées entre elles, il n'y aura pas de sauts importants dans l'histogramme, autrement dit, les valeurs propres sont uniformément décroissantes.
:::

```{r acpgraphvp, echo=FALSE, fig.align='center', fig.cap="Graphiques personnalisés pour les valeurs propres pour l'ACP", auto_pdf=TRUE, dev="png", dpi=300, out.width='75%'}
library(ggplot2)
library(ggpubr)
library(stringr)

dfACPvp <- data.frame(res.acp$eig)
names(dfACPvp) <- c("VP","VP_pct","VP_cumupct")
dfACPvp$Composante <- factor(1:nrow(dfACPvp), levels=rev(1:nrow(dfACPvp)))

couleursAxes <- c("steelblue","skyblue2")
vpsup1 <-  tofr(round(sum(subset(dfACPvp, VP >= 1)$VP),2))
vpsup1cumul <- tofr(round(sum(subset(dfACPvp, VP >= 1)$VP_pct),2))

plotVP1 <- ggplot(dfACPvp,aes(x=VP, y=Composante,fill=VP<1))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black")+
  geom_vline(xintercept=1, linetype="dashed", color = "azure4", size=1)+
  scale_fill_manual(name="Valeur\npropre",values=couleursAxes,labels = c(">= 1","< 1"))+
  labs(x="Valeur propre", y="Composante principale")

plotVP2 <- ggplot(dfACPvp, aes(x=VP_pct, y=Composante,fill=VP<1))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black")+
  scale_fill_manual(name="Valeur\npropre",values=couleursAxes,labels = c(">= 1","< 1"))+
  theme(legend.position="none")+
  labs(x="Variance expliquée (%)", y="")

plotVP3 <- ggplot(dfACPvp, aes(x=VP_cumupct, y=Composante,fill=VP<1, group=1))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black")+
  scale_fill_manual(name="Valeur\npropre",values=couleursAxes,labels = c(">= 1","< 1"))+
  geom_line(colour="brown", linetype="solid", size=.8) +
  geom_point(size=3, shape=21, color="brown", fill="brown")+
  theme(legend.position="none")+
  labs(x="Variance expliquée (% cumulé)", y="")

  annotate_figure(ggarrange(plotVP1, plotVP2, plotVP3, ncol=2, nrow=2),
                  text_grob("Graphiques pour les valeurs propres", color = "black", face = "bold", size = 12),
                  bottom = text_grob(
                          paste0("Somme des valeurs propres supérieures à 1 : ", vpsup1,
                                 ".\nPourcentage cumulé des valeurs propres supérieures à 1 : ", vpsup1cumul, " %."),
                           color = "black", hjust = 1, x = 1, size = 10))
```

#### Résultats de l'ACP pour les variables {#sect12222}

Pour qualifier les axes, quatre mesures sont disponibles pour les variables&nbsp;:

- **Les coordonnées factorielles des variables**  sont simplement les coefficients de corrélation de Pearson des variables sur l’axe *k* et varient ainsi de -1 à 1 (relire au besoin la section \@ref(sect043)). Pour qualifier un axe, il convient alors de repérer les variables les plus corrélées positivement et négativement sur l’axe, autrement dit, de repérer les variables situées aux extrémités l'axe. 
- **Les cosinus carrés des variables** (Cos^2^) (appelées aussi les qualités de représentation des variables sur un axe) permettent de repérer le ou les axes qui concourent le plus à donner un sens à la variable. Elles sont en fait les coordonnées des variables mises au carré. La somme des cosinus carrés d’une variable sur tous les axes de l’ACP est donc égale à&nbsp;1 (sommation en ligne).
**La qualité de représentation d'une variable sur les _n_ premiers axes** est simplement la somme des cosinus carrés d'une variable sur les axes retenus. Par exemple, pour la variable `Lden`, la qualité de représentation de la variable  sur le premier axe est égale&nbsp;: $\mbox{0,42}^2=\mbox{0,17}$. Pour cette même variable, la qualité de la `Lden` sur les trois premiers axes est égale à&nbsp;: $\mbox{0,17}+\mbox{0,32}+\mbox{0,26}=\mbox{0,75}$.
- **Les contributions des variables** permettent de repérer celles qui participent le plus à la formation d’un axe. Elles s'obtiennent en divisant les cosinus carrés par la valeur propre de l’axe multiplié par 100. La somme des contributions des variables pour un axe donné est donc égale à 100 (sommation en colonne). Par exemple, pour la variable `Lden`, la contribution sur le premier axe est égale&nbsp;: $\mbox{0,174} / \mbox{3,543} \times \mbox{100}= \mbox{4,920 }%$.

Les résultats de l'ACP pour les variables sont présentés au tableau&nbsp;\@ref(tab:dataacpCoordVars).

```{r dataacpCoordVars, echo=FALSE, message=FALSE, warning=FALSE, out.width='75%'}
library(kableExtra)
nComp <- 3
# Variance expliquée par les axes retenus
vppct <- round(dfACPvp[1:nComp,"VP_pct"],1)
# Dataframe des résultats pour les variables
CoordsVar <- res.acp$var$coord[, 1:nComp]
Cos2Var   <- res.acp$var$cos2[, 1:nComp]
CtrVar   <- res.acp$var$contrib[, 1:nComp]
dfACPVars <- data.frame(Variable =  row.names(res.acp$var$coord[, 1:nComp]),
                        Coord = CoordsVar,
                        Cos2 = Cos2Var,
                        Qualite = rowSums(Cos2Var),
                        Ctr = CtrVar)
row.names(dfACPVars) <- NULL
names(dfACPVars) <- str_replace(names(dfACPVars), ".Dim.", "Comp")

my_table <- show_table(dfACPVars,
                   digits = 2,
                   caption = "Résultats de l'ACP pour les variables",
                   col.names=c("Variable","1","2","3","1","2","3","Qualité","1","2","3"),
                   align= c("l","r","r","r","r","r","r","r","r","r","r")
                   )
add_header_above(my_table, c(" " = 1, "Coordonnées" = 3, "Cosinus carrés" = 4, "Contributions" = 3))
```

**Analyse de la première composante principale (valeur propre de 3,54, 35,43&nbsp;%)**

- À la lecture des contributions, il est clair que quatre variables contribuent grandement à la formation de l'axe&nbsp;1&nbsp;: `NivVieMed` (22,06&nbsp;%), 
`Pct_Img` (21,56&nbsp;%), `TxChom1564` (16,89&nbsp;%) et `Pct_brevet` (14,94&nbsp;%). Il convient alors d'analyser en détail leurs coordonnées factorielles et leurs cosinus carrés.

- À la lecture des coordonnées factorielles, nous constatons que trois variables socioéconomiques sont fortement corrélées positivement avec l’axe&nbsp;1, soit le *pourcentage d’immigrants* (0,87), le *taux de chômage* (0,77) le *pourcentage de personnes avec une faible scolarité* (0,73). À l’autre extrémité, la *médiane du niveau de vie* (en Euros) est négativement corrélée avec l’axe&nbsp;1. Comment interpréter ce résultat? Premièrement, cela signifie que plus la valeur de l’axe 1 est positive et élevée, plus celles des trois variables (`Pct_Img`,`TxChom1564` et `Pct_brevet`) sont aussi élevées (corrélations positives) et plus la valeur de `NivVieMed` est faible (corrélation négative). Inversement, plus la valeur de l’axe&nbsp;1 est négative et faible, les valeurs de `Pct_Img`, `TxChom1564` et `Pct_brevet` sont faibles et plus celle de `NivVieMed` est forte. Deuxièmement, cela signifie que les trois variables (`Pct_Img`,`TxChom1564` et `Pct_brevet`) sont fortement corrélées positivement entre elles puisqu’elles se situent sur la même extrémité de l’axe et qu’elles sont toutes trois négativement corrélées avec la variable `NivVieMed`. Cela peut être rapidement confirmé avec la matrice de corrélation entre les dix variables (tableau&nbsp;\@ref(tab:dataacpMatriceCorr)). 
- À la lecture des cosinus carrés de l'axe&nbsp;1, nous constatons que plus des trois quarts de la dispersion/de l'information des variables `NivVieMed` (0,78) et `Pct_Img` (0,76) est concentrée sur l'axe&nbsp;1.


```{r dataacpMatriceCorr, echo=FALSE, message=FALSE, warning=FALSE, out.width='75%'}
library(Hmisc)

DataZ <-  scale(Data)
MatriceCorr <- as.data.frame(rcorr(Data %>% as.matrix())$r)
MatriceCorr$Variable <- c("A. Lden",  "B. NO2", "C. PM25", "D. VegHautPrt", "E. Pct0_14", 
                          "F. Pct_65", "G. Pct_Img", "H. TxChom1564", "I. Pct_brevet", "J. NivVieMed")
MatriceCorr <- MatriceCorr[, c(11,1:10)]
names(MatriceCorr) <- c("Variable", "A", "B", "C", "D", "E", "F", "G", "H", "I", "J")
for (e in 2:11){
  MatriceCorr[[e]] <- ifelse(MatriceCorr[[e]] == 1.00, NA, MatriceCorr[[e]])
}
show_table(MatriceCorr,
                   digits = 2,
                   caption = "Matrice de corrélation de Pearson entre les variables utilisées pour l'ACP",
                   align= c("l","r","r","r","r","r","r","r","r","r","r","r")
                   )
```

**Analyse de la deuxième composante principale (valeur propre de 2,76, 27,60&nbsp;%)**

- À la lecture des contributions, trois variables environnementales contribuent à la formation de l'axe&nbsp;2&nbsp;: principalement, celles sur la pollution de l'air (`NO2`&nbsp;=&nbsp;31,07&nbsp;% et `PM25`&nbsp;=&nbsp;30,36&nbsp;%) et secondairement, sur le bruit routier (`Lden`&nbsp;=&nbsp;11,64&nbsp;%).
- À la lecture des coordonnées factorielles, ces trois variables sont fortement corrélées positivement avec l'axe 2&nbsp;: `NO2` (0,93), `PM25` (0,92) et `Lden` (0,57). À l'autre extrémité de l'axe, la variable `Pct0_14` est négativement, mais pas fortement corrélée négativement (-0,53). La lecture de la matrice de corrélation au tableau&nbsp;\@ref(tab:dataacpMatriceCorr) confirme que ces trois variables environnementales sont fortement corrélées positivement entre elles (par exemple, un coefficient de corrélation de Pearson de 0,90 entre `NO2` et `PM25`).
- À la lecture des cosinus carrés de l'axe&nbsp;2, nous constatons que près de 90&nbsp;% de la dispersion/de l'information des variables `NO2` (0,86) et `PM25` (0,84) est concentré sur l'axe&nbsp;2.


**Analyse de la troisième composante principale (valeur propre de 1,042, 10,42&nbsp;%)**

- Le *pourcentage de personnes âgées* (`Pct_65`) contribue principalement à la formation de l'axe&nbsp;3 avec lequel il est corrélée positivement (contribution de 49,26&nbsp;% et coordonnée factorielle de 0,72). S'en suit, la variable `Lden` qui joue un rôle beaucoup moins important (contribution de 24,80&nbsp;% et coordonnée factorielle de 0,51).

::: {.bloc_astuce data-latex=""}
**Lien entre la valeur propre d'un axe et le nombre de variables contribuant à sa formation**

Vous auvez compris que plus la valeur propre d'un axe est forte, plus il y a potentiellement de variables qui concourent à sa formation. Cela explique que pour la troisième composante qui a une faible valeur propre (1,042), seule une variable contribue significativement à sa formation. 
:::

**Analyse de la qualité de représentation des variables sur les premiers axes de l'ACP**

À titre de rappel, la qualité est simplement la somme des cosinus carrés d’une variable sur les axes retenus. Si nous retenons trois axes, les six variables qui sont le mieux résumées –&nbsp;et qui ont donc le plus d'influence sur les résultats de l'ACP&nbsp;– sont &nbsp;:`NO2` (0,92), `PM25` (0,87), `NivVieMed` (0,79), `Pct_Img` (0,78), `Pct_brevet` (0,77) et`Lden` (0,75).

**Qualification, dénomination d'axes factoriels**

L'analyse des coordonnées, contributions et cosinus carrés doit vous permettre de formuler un intitulé pour chacun des axes retenus. Nous vous proposons les intitulés suivants&nbsp;: 

- *Niveau de défavorisation socioéconomique* (axe&nbsp;1). Plus la valeur de l'axe est élevé, plus le niveau de défavorisation de l'entité spatiale (IRIS) est élevé.
- *Qualité environnementale* (axe&nbsp;2). Plus la valeur de l'axe est forte, plus les niveaux de pollution atmosphérique (dioxyde d'azote et particules fines) et de bruit (Lden) sont élevés.

**Recours à des graphiques pour analyser les résultats de l'ACP pour des variables**

Plus le nombre de variables utilisées pour calculer l'ACP est important, plus l'analyse des coordonnées factorielles, des cosinus carrés et des contributions reportés dans un tableau devient fastidieuse. Puisque l’ACP a été calculée sur dix variables, l’analyse des valeurs du tableau&nbsp;\@ref(tab:dataacpCoordVars) a donc été assez facile et rapide. Imaginez maintenant que nous réalisons une ACP sur une centaine de variables, la taille du tableau des résultats pour les variables sera considérable... Par conséquent, il est recommandé de construire plusieurs graphiques qui facilitent l’analyse des résultats pour les variables. 

Par exemple, à la figure&nbsp;\@ref(fig:acpgraphvarscoords), nous avons construit des graphiques avec les coordonnées factorielles sur les trois premiers axes de l’ACP. En un coup d’œil, il est facile de repérer les variables les plus corrélées positivement ou négativement avec chacun d’entre eux.
Aussi, il est fréquent de construire un nuage de points avec les coordonnées des variables sur les deux premiers axes factoriels, soit un graphique communément appelé **nuage de points des variables sur le premier plan factoriel** sur lequel est représenté le cercle des corrélations (figure&nbsp;\@ref(fig:acp1erplanfactVars)). Bien entendu, cet exercice peut être fait avec d’autres axes factoriels (les axes 3 et 4 par exemple).

```{r acpgraphvarscoords, echo=FALSE, fig.align='center', fig.cap="Coordonnées factorielles des variables", auto_pdf=TRUE, dev="png", dpi=300, out.width='100%'}
# Variance expliquée par les axes retenus
vppct <- round(dfACPvp[1:nComp,"VP_pct"],1)
# Dataframe des résultats pour les variables
CoordsVar <- res.acp$var$coord[, 1:nComp]
Cos2Var   <- res.acp$var$cos2[, 1:nComp]
CtrVar   <- res.acp$var$contrib[, 1:nComp]
dfACPVars <- data.frame(Variable =  row.names(res.acp$var$coord[, 1:nComp]),
                        Coord = CoordsVar,
                        Cos2 = Cos2Var,
                        Qualite = rowSums(Cos2Var),
                        Ctr = CtrVar)
row.names(dfACPVars) <- NULL
names(dfACPVars) <- str_replace(names(dfACPVars), ".Dim.", "Comp")

# Histogrammes pour les coordonnées
couleursCoords <- c("lightsalmon","steelblue")
plotCoordF1 <- ggplot(dfACPVars,
                      aes(y = reorder(Variable, CoordComp1),
                          x = CoordComp1, fill=CoordComp1<0))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black")+
  geom_vline(xintercept=0, color = "black", size=1)+
  scale_fill_manual(name="Coordonnée",values=couleursCoords,labels = c("Positive","Négative"))+
  labs(x=paste0("Axe 1 (", tofr(vppct[1]),"%)"), y="Variable")+
  theme(legend.position="none")

plotCoordF2 <- ggplot(dfACPVars,
                      aes(y = reorder(Variable, CoordComp2),
                          x = CoordComp2, fill=CoordComp2<0))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black")+
  geom_vline(xintercept=0, color = "black", size=1)+
  scale_fill_manual(name="Coordonnée",values=couleursCoords,labels = c("Positive","Négative"))+
  labs(x=paste0("Axe 2 (", tofr(vppct[2]),"%)"), y="Variable")+
  theme(legend.position="none")

plotCoordF3 <- ggplot(dfACPVars,
                      aes(y = reorder(Variable, CoordComp3),
                          x = CoordComp3, fill=CoordComp3<0))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black")+
  geom_vline(xintercept=0, color = "black", size=1)+
  scale_fill_manual(name="Coordonnée", values=couleursCoords,labels = c("Positive","Négative"))+
  labs(x=paste0("Axe 3 (", tofr(vppct[3]),"%)"), y="Variable")

annotate_figure(ggarrange(plotCoordF1, plotCoordF2, plotCoordF3, nrow = nComp),
                text_grob("Coordonnées des variables sur les axes factoriels",
                          color = "black", face = "bold", size = 12))
```

```{r acp1erplanfactVars, echo=FALSE, fig.align='center', fig.cap="Premier plan factoriel de l'ACP pour les variables", message=FALSE, auto_pdf=TRUE, dev="png", dpi=300, out.width='75%', quietly=TRUE, warn.conflicts=TRUE}
library(factoextra)
library(ggplot2)
library(ggpubr)

fviz_pca_var(res.acp,
             geom = c("point", "text","arrow"),
             col.var="black",
             col.circle = "red",
             title = "Premier plan factoriel pour les variables")+
  theme_minimal()
```

#### Résultats de l'ACP pour les individus {#sect12223}

Comme pour les variables, nous retrouvons les mêmes mesures pour les individus&nbsp;: les coordonnées factorielles, les cosinus carrés et les contributions. Les coordonnées factorielles des individus sont les projections orthogonales des observations sur l'axe. Puisqu'en ACP normée, les variables utilisées pour l'ACP sont centrées réduites, la moyenne des coordonnées factorielles des individus pour un axe est toujours égale à zéro. En revanche, contrairement aux coordonnées factorielles pour les variables, les coordonnées pour les individus ne varient pas de -1 à 1! Les cosinus carrés quantifient à quel point chaque axe représente chaque individu. Enfin, les contributions quantifient l'apport de chaque individu à la formation d'un axe.

Si le jeu de données comprend peu d'observations, il est toujours possible de créer un **nuage de points des individus sur le premier plan factoriel** sur lequel vous pouvez ajouter les étiquettes permettant d'identifier les observations (figure&nbsp;\@ref(fig:acp1erplanfactIndiv)). Ce graphique est rapidement illisible lorsque le nombre d'observations est important. Il peut rester utile si certaines des observations du jeu de données doivent faire l'objet d'une analyse spécifique.

```{r acp1erplanfactIndiv, echo=FALSE, fig.align='center', fig.cap="Premier plan factoriel pour les individus", message=FALSE, auto_pdf=TRUE, dev="png", dpi=300, out.width='75%', quietly=TRUE, warn.conflicts=TRUE}
library(factoextra)
library(ggplot2)
library(ggpubr)

fviz_pca_ind(res.acp,
             geom = c("point", "text"),
             col.var="black",
             col.circle = "red",
             title="")+
  theme_minimal()
```

Lorsque les observations sont des unités spatiales, il est très intéressant de cartographier les coordonnées factorielles des individus (figure&nbsp;\@ref(fig:acp1erplanfactIndiv)). À la lecture de la carte choroplèthe de gauche (axe 1), nous pouvons constater que le niveau de défavorisation socioéconomique est élevé dans l'est (IRIS en vert), et inversement, très faible à l'ouest de l'agglomération (IRIS en rouge). À la lecture de la carte de droite (axe 2), sans surprise, la partie centrale de l'agglomération est caractérisée par des niveaux de pollution atmosphérique et de bruit routier bien plus élevés qu'en périphérie.

```{r acpcartoindiv, echo=FALSE, fig.align='center', fig.cap="Cartographie des coordonnées factorielles des individus", auto_pdf=TRUE, dev="png", dpi=300, out.width='100%'}
library("tmap")
library("RColorBrewer")

CoordsInd <- res.acp$ind$coord[, 1:nComp]
Cos2Ind   <- res.acp$ind$cos2[, 1:nComp]
CtrInd    <- res.acp$ind$contrib[, 1:nComp]
dfACPInd <- data.frame(Coord = CoordsInd, Cos2 = Cos2Ind, Ctr = CtrInd)
names(dfACPInd) <- str_replace(names(dfACPInd), ".Dim.", "Comp")
CartoACP <- cbind(LyonIris, dfACPInd)

Carte1 <- tm_shape(CartoACP) +
          tm_polygons(col = "CoordComp1", style = "cont",
                      midpoint = 0, title = 'Coordonnées')+
          tm_layout(main.title = "Axe 1 : Défavorisation socioéco.",
                    main.title.size = 1, attr.outside = TRUE, frame = FALSE)

Carte2 <- tm_shape(CartoACP) +
          tm_polygons(col = "CoordComp2", style = "cont",
                      midpoint = 0, title = 'Coordonnées')+
          tm_layout(main.title = "Axe 2 : Qualité environnementale",
                    main.title.size = 1, attr.outside = TRUE, frame = FALSE)

tmap_arrange(Carte1, Carte2)
```


::: {.bloc_aller_loin data-latex=""}

Nous n'avons pas abordé plusieurs autres éléments intéressants de l'ACP.

**Ajout de variables ou d'individus supplémentaires** 

Premièrement, il est possible d'ajouter des variables continues ou des individus supplémentaires qui n'ont pas été pris en compte dans le calcul de l'ACP (figure&nbsp;\@ref(fig:acpvarindcorrsuppl)). Concernant les variables continues supplémentaires, il s'agit simplement de calculer leurs corrélations avec les axes retenus de l'ACP. Concernant les individus, il s'agit de les projeter sur les axes factoriels. Pour plus d'informations sur le sujet, consultez les excellents ouvrages de Ludovic Lebart, Alain Morineau et Marie Piron [-@lebart1995statistique, p.42-45] ou encore Jérôme Pagès [-@pages2013analyse, p.22-24].

```{r acpvarindcorrsuppl, fig.align='center', echo=FALSE, auto_pdf = TRUE, fig.cap="Variables et individus supplémentaires pour l'ACP",  out.width='28%', fig.pos = "H", out.extra = ""}
knitr::include_graphics('images/analysesfactorielles/AcpIndVarSuppl.png', dpi = NA)
```

**Pondération des individus et des variables**

Deuxièmement, il est possible de pondérer à la fois les individus et plus rarement les variables lors du calcul de l'ACP.

**Analyse en composantes principales non paramétrique**

Troisièmement, il est possible de calculer une ACP sur des variables préalablement transformées en rangs (section \@ref(sect02552)). Cela peut être justifié lorsque les variables sont très anormalement distribuées en raison de valeurs extrêmes. Les coordonnées factorielles pour les variables sont alors le coefficient de Spearman (section \@ref(sect0433)) et non de Pearson. Aussi, les variables sont centrées non pas sur leurs moyennes respectives, mais sur leurs médianes. Pour plus d'informations sur cette approche, consultez de nouveau Lebart et al. [-@lebart1995statistique, p.51-52].

**Analyse en composantes principales robuste**

D'autres méthodes plus avancées qu'une ACP non paramétrique peuvent être utilisées afin d'obtenir des composantes principales qui ne sont pas influencées par des valeurs extrêmes&nbsp;: les ACP robustes [@rivest1988analyse; @hubert2005robpca] qui peuvent être mises en œuvre, entre autres, avec le *package* `roscpca`.
:::


### Mise en œuvre dans R {#sect1223}

Plusieurs *packages* permettent de calculer une ACP dans R, notamment `psych` (fonction `principal`), `ade4` (fonction `dudi.pca`) et `FactoMineR` (fonction `PCA`). Ce dernier est certainement le plus abouti. De plus, il permet également de calculer une analyse des correspondances (AFC), une analyse des correspondances multiples (ACM) et une analyse factorielle de données mixtes (AFDM). Nous utilisons donc `FactoMineR` pour mettre en œuvre les trois types de méthodes factorielles abordées dans ce chapitre (ACP, AFC et ACM). Pour l'ACP, nous exploitons un jeu de données issu du *package* `geocmeans` qu'il faut préalablement charger à l'aide des lignes de code suivantes.

```{r echo=TRUE}
library(geocmeans)
data(LyonIris)
Data <- LyonIris@data[c("CODE_IRIS","Lden","NO2","PM25","VegHautPrt",
                        "Pct0_14","Pct_65","Pct_Img",
                        "TxChom1564","Pct_brevet","NivVieMed")]
```

#### Calcul et exploration d'une ACP avec `FactoMineR` {#sect12231}

Pour calculer l'ACP, il suffit d'utiliser la fonction `PCA` de `FactoMineR`, puis la fonction `summary(MonACP)` qui renvoie les résultats de l'ACP pour&nbsp;: 

- Les valeurs propres (section `Eigenvalues`) pour les composantes principales (`Dim.1` à `Dim.n`) avec leur variance expliquée brute (`Variance`), en pourcentage (`% of var.`) et en pourcentage cumulé (`Cumulative % of var.`).
- Les dix premières observations (section `Individuals`) avec les coordonnées factorielles (`Dim.1` à `Dim.n`), les contributions (`ctr`) et les cosinus carrés (`cos2`). Pour accéder aux résultats pour toutes les observations, utilisez les fonctions `res.acp$ind` ou encore `res.acp$ind$coord` (uniquement les coordonnées factorielles), `res.acp$ind$contrib` (uniquement les contributions) et `res.acp$ind$cos2` (uniquement les cosinus carrés).
- Les variables (section `Variables`) avec les coordonnées factorielles (D`im.1` à `Dim.n`), les contributions (`ctr`) et les cosinus carrés (`cos2`).

```{r echo=TRUE}
library(FactoMineR)
# Version classique avec FactoMineR
# Construction d'une ACP sur les colonnes 2 à 11 du DataFrame Data
res.acp <- PCA(Data[,2:11], scale.unit=TRUE, graph=F)
# Affichage des résultats de la fonction PCA
print(res.acp)
# Résumé des résultats (valeurs propres, individus, variables)
summary(res.acp)
```

Avec les fonctions de base `barplot` et `plot`, il est possible de construire rapidement des graphiques pour explorer les résultats de l'ACP pour les valeurs propres, les variables et les individus.

```{r echo=TRUE}
# Graphiques pour les valeurs propres
barplot(res.acp$eig[,1], main="Valeurs propres", names.arg=1:nrow(res.acp$eig))
barplot(res.acp$eig[,2], main="Variance expliquée (%)", names.arg=1:nrow(res.acp$eig))
barplot(res.acp$eig[,3], main="Variance expliquée cumulée (%)",
        names.arg=1:nrow(res.acp$eig))
# Nuage du points du premier plan factoriel pour les variables et les individus
plot(res.acp, graph.type = "classic", choix="var", axes = 1:2, 
     title = "Premier plan factoriel (variables)")
plot(res.acp, graph.type = "classic", choix="ind", axes = 1:2, 
     title = "Premier plan factoriel (individus)")
```



::: {.bloc_aller_loin data-latex=""}
Nous avons vu dans un encadré ci-dessus qu'il est possible d'ajouter des variables et des individus supplémentaires dans une ACP, ce que permet la fonction `PCA` de `FactoMineR` avec les paramètres `ind.sup` et `quanti.sup`. Aussi, pour ajouter des pondérations aux individus ou aux variables, utilisez les paramètres `row.w` et `col.w`. Pour plus d'informations sur ces paramètres, consulter l'aide de la fonction en tapant `?PCA` dans la console de Rstudio.
:::

#### Exploration graphique des résultats de l'ACP avec `factoextra` {#sect12232}

Visuellement, vous avez pu constater que les graphiques ci-dessus (pour les valeurs propres et pour le premier plan factoriel pour les variables et les individus) réalisés avec les fonctions de base `barplot` et `plot` sont peu attrayants. Avec le *package* `factoextra`, quelques lignes de code suffissent pour construire des graphiques bien plus esthétiques. 

Premièrement, la syntaxe ci-dessous renvoie deux graphiques pour analyser les résultats des valeurs propres (figure&nbsp;\@ref(fig:factoextra1)).

```{r factoextra1, echo=TRUE, fig.align='center', fig.cap="Graphiques pour les valeurs propres de l'ACP avec factoextra", quietly = TRUE, warn.conflicts = TRUE,   message=FALSE, auto_pdf=TRUE, out.width='75%', dev="png", dpi=300}
library(factoextra)
library(ggplot2)
library(ggpubr)

# Graphiques pour les variables propres avec factoextra
G1 <- fviz_screeplot(res.acp, choice ="eigenvalue", addlabels = TRUE,
                     x="Composantes",
                     y="Valeur propre",
                    title="")
G2 <- fviz_screeplot(res.acp, choice ="variance", addlabels = TRUE,
                     x="Composantes",
                     y="Pourcentage de la variance expliquée",
                     title="")
ggarrange(G1, G2)
```

Deuxièmement, la syntaxe ci-dessous renvoie trois graphiques pour analyser les contributions de chaque variable aux deux premiers axes de l'ACP (figures \@ref(fig:factoextra2) et \@ref(fig:factoextra3)) et la qualité de représentation des variables sur les trois premiers axes (figure&nbsp;\@ref(fig:factoextra4)), c'est-à-dire la somme des cosinus carrés sur les trois axes retenus.

```{r eval=FALSE, include=TRUE}
# Contributions des variables aux deux premières composantes avec factoextra
fviz_contrib(res.acp, choice = "var", axes = 1, top = 10,
             title = "Contributions des variables à la première composante")
fviz_contrib(res.acp, choice = "var", axes = 2, top = 10,
             title = "Contributions des variables à la première composante")
fviz_cos2(res.acp, choice = "var", axes = 1:3)+
  labs(x="", y="Somme des cosinus carrés sur les 3 axes retenus",
       title ="Qualité de représentation des variables sur les axes retenus de l'ACP")
```


```{r factoextra2, echo=FALSE, fig.align='center', fig.cap="Contributions des variables à la première composante avec factoextra", auto_pdf=TRUE, dev="png", dpi=300, out.width='85%'}
# Contributions des variables aux deux premières composantes
fviz_contrib(res.acp, choice = "var", axes = 1, top = 10,
             title = "Contributions des variables à la première composante")
```

```{r factoextra3, echo=FALSE, fig.align='center', fig.cap="Contributions des variables à la deuxième composante avec factoextra", auto_pdf=TRUE, dev="png", dpi=300, out.width='85%'}
# Contributions des variables aux deux premières composantes
fviz_contrib(res.acp, choice = "var", axes = 2, top = 10,
             title = "Contributions des variables à la deuxième composante")
```

```{r factoextra4, echo=FALSE, fig.align='center', fig.cap="Qualité des variables sur les trois premières composantes avec factoextra", auto_pdf=TRUE, dev="png", dpi=300, out.width='85%'}
fviz_cos2(res.acp, choice = "var", axes = 1:3)+
  labs(x="", y="Somme des cosinus carrés sur les 3 axes retenus",
       title ="Qualité de représentation des variables sur les axes retenus de l'ACP")
```


Troisièmement, le code ci-dessous renvoie un nuage de points pour le premier plan factoriel de l'ACP (axes 1 et 2) pour les variables (figure&nbsp;\@ref(fig:factoextra5)) et les individus (figure&nbsp;\@ref(fig:factoextra6)).

```{r eval=FALSE, include=TRUE}
# Premier plan factoriel pour les variables avec factoextra
fviz_pca_var(res.acp, col.var="contrib",
             title = "Premier plan factoriel pour les variables")+
  scale_color_gradient2(low="#313695", mid="#ffffbf", high="#a50026",
                        midpoint=mean(res.acp$var$contrib[,1]))
# Premier plan factoriel pour les individus avec factoextra
fviz_pca_ind(res.acp, label="none", title="ACP. Individus")
fviz_pca_ind(res.acp, col.ind="cos2", title="ACP. Individus") +
  scale_color_gradient2(low="blue", mid="white", high="red", midpoint=0.50)
```

```{r factoextra5, echo=FALSE, fig.align='center', fig.cap="Premier plan factoriel de l'ACP pour les variables avec factoextra", auto_pdf=TRUE, dev="png", dpi=300, out.width='100%'}
fviz_pca_var(res.acp, col.var="contrib",
             title = "")+
  scale_color_gradient2(low="#313695", mid="#ffffbf", high="#a50026",
                        midpoint=mean(res.acp$var$contrib[,1]))
```

```{r factoextra6, echo=FALSE, fig.align='center', fig.cap="Premier plan factoriel de l'ACP pour les individus avec factoextra", auto_pdf=TRUE, dev="png", dpi=300, out.width='75%'}
fviz_pca_ind(res.acp, col.ind="cos2", title="") +
  scale_color_gradient2(low="blue", mid="white", high="red", midpoint=0.50)+coord_fixed()
```

#### Personnalisation des graphiques avec les résultats de l'ACP {#sect12233}

Avec un peu plus de code et l'utilisation d'autres *packages* (`ggplot2`, `ggpubr`, `stringr`, `corrplot`), vous pouvez aussi construire des graphiques personnalisés.

Premièrement, la syntaxe ci-dessous permet de réaliser trois graphiques pour analyser les valeurs propres (figure&nbsp;\@ref(fig:acpmesgraphs1)). Notez que, d'un coup d'œil, nous pouvons identifier les composantes principales avec une valeur propre égale ou supérieure à 1. 

```{r eval=FALSE, include=TRUE}
library(ggplot2)
library(ggpubr)
library(stringr)
library(corrplot)

# Calcul de l'ACP
res.acp <- PCA(Data[,2:11], ncp=5, scale.unit=TRUE, graph=F)
print(res.acp)

# Construction d'un DataFrame pour les valeurs propres
dfACPvp <- data.frame(res.acp$eig)
names(dfACPvp) <- c("VP","VP_pct","VP_cumupct")
dfACPvp$Composante <- factor(1:nrow(dfACPvp), levels=rev(1:nrow(dfACPvp)))
couleursAxes <- c("steelblue","skyblue2")
vpsup1 <- round(sum(subset(dfACPvp, VP >= 1)$VP),2)
vpsup1cumul <- round(sum(subset(dfACPvp, VP >= 1)$VP_pct),2)

plotVP1 <- ggplot(dfACPvp,aes(x=VP, y=Composante,fill=VP<1))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black")+
  geom_vline(xintercept=1, linetype="dashed", color = "azure4", size=1)+
  scale_fill_manual(name="Valeur\npropre",values=couleursAxes,labels = c(">= 1","< 1"))+
  labs(x="Valeur propre", y="Composante principale")
plotVP2 <- ggplot(dfACPvp, aes(x=VP_pct, y=Composante,fill=VP<1))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black")+
  scale_fill_manual(name="Valeur\npropre",values=couleursAxes,labels = c(">= 1","< 1"))+
  theme(legend.position="none")+
  labs(x="Pourcentage de la variance expliquée", y="")
plotVP3 <- ggplot(dfACPvp, aes(x=VP_cumupct, y=Composante,fill=VP<1, group=1))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black")+
  scale_fill_manual(name="Valeur\npropre",values=couleursAxes,labels = c(">= 1","< 1"))+
  geom_line(colour="brown", linetype="solid", size=.8) +
  geom_point(size=3, shape=21, color="brown", fill="brown")+
  theme(legend.position="none")+
  labs(x="Pourcentage cumulé de la variance expliquée", y="")

text1 <- paste0("Somme des valeurs propres supérieures à 1 : ",
                vpsup1,
                ".\nPourcentage cumulé des valeurs propres supérieures à 1 : ",
                vpsup1cumul, "%.")
annotate_figure(ggarrange(plotVP1, plotVP2, plotVP3, ncol=2),
                text_grob("Analyse des valeurs propres", 
                         color = "black", face = "bold", size = 12),
                bottom = text_grob(text1,
                           color = "black", hjust = 1, x = 1, size = 10))
```

```{r acpmesgraphs1, echo=FALSE, fig.align='center', fig.cap="Graphiques personnalisés pour les valeurs propres", auto_pdf=TRUE, dev="png", dpi=300, out.width='75%'}
library(ggplot2)
library(ggpubr)
library(stringr)

# Calcul de l'ACP
res.acp <- PCA(Data[,2:11], ncp=5, scale.unit=TRUE, graph=F)

# Construction d'un DataFrame pour les valeurs propres
dfACPvp <- data.frame(res.acp$eig)
names(dfACPvp) <- c("VP","VP_pct","VP_cumupct")
dfACPvp$Composante <- factor(1:nrow(dfACPvp), levels=rev(1:nrow(dfACPvp)))

couleursAxes <- c("steelblue","skyblue2")
vpsup1 <- round(sum(subset(dfACPvp, VP >= 1)$VP),2)
vpsup1cumul <- round(sum(subset(dfACPvp, VP >= 1)$VP_pct),2)
plotVP1 <- ggplot(dfACPvp,aes(x=VP, y=Composante,fill=VP<1))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black")+
  geom_vline(xintercept=1, linetype="dashed", color = "azure4", size=1)+
  scale_fill_manual(name="Valeur\npropre",values=couleursAxes,labels = c(">= 1","< 1"))+
  labs(x="Valeur propre", y="Composante principale")
plotVP2 <- ggplot(dfACPvp, aes(x=VP_pct, y=Composante,fill=VP<1))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black")+
  scale_fill_manual(name="Valeur\npropre",values=couleursAxes,labels = c(">= 1","< 1"))+
  theme(legend.position="none")+
  labs(x="Variance expliquée (%)", y="")
plotVP3 <- ggplot(dfACPvp, aes(x=VP_cumupct, y=Composante,fill=VP<1, group=1))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black")+
  scale_fill_manual(name="Valeur\npropre",values=couleursAxes,labels = c(">= 1","< 1"))+
  geom_line(colour="brown", linetype="solid", size=.8) +
  geom_point(size=3, shape=21, color="brown", fill="brown")+
  theme(legend.position="none")+
  labs(x="Variance expliquée (% cumulé)", y="")
  annotate_figure(ggarrange(plotVP1, plotVP2, plotVP3, ncol=2, nrow=2),
                  text_grob("Analyse des valeurs propres", color = "black", face = "bold", size = 12),
                  bottom = text_grob(
                          paste0("Somme des valeurs propres supérieures à 1 : ", vpsup1,
                                 ".\nPourcentage cumulé des valeurs propres supérieures à 1 : ", vpsup1cumul, "%."),
                           color = "black", hjust = 1, x = 1, size = 10))
```

Deuxièmement, la syntaxe ci-dessous permet de&nbsp;: 

- Construire un *DataFrame* avec les résultats des variables.
- Construire des histogrammes avec les coordonnées des variables sur les axes factoriels (figure&nbsp;\@ref(fig:acpmesgraphs2)). Notez que les coordonnées négatives sont indiquées avec des barres bleues et celles positives avec des barres de couleur saumon.
- Un graphique avec les contributions des variables sur les axes retenus (figure&nbsp;\@ref(fig:acpmesgraphs3)).
- Un graphique avec les cosinus carrés des variables sur les axes retenus (figure&nbsp;\@ref(fig:acpmesgraphs4)). 
- Un histogramme avec la qualité des variables sur les axes retenus (figure&nbsp;\@ref(fig:acpmesgraphs5)), soit la sommation de leurs cosinus carrés sur les axes retenus.

```{r eval=FALSE, include=TRUE}
# Analyse des résultats de L'ACP pour les variables
library(corrplot)
library(stringr)
library(ggplot2)
library(ggpubr)

# Indiquer le nombre d'axes à conserver suite à l'analyse des valeurs propres
nComp <- 3
# Variance expliquée par les axes retenus
vppct <- round(dfACPvp[1:nComp,"VP_pct"],1)
# Dataframe des résultats pour les variables
CoordsVar <- res.acp$var$coord[, 1:nComp]
Cos2Var   <- res.acp$var$cos2[, 1:nComp]
CtrVar   <- res.acp$var$contrib[, 1:nComp]
dfACPVars <- data.frame(Variable =  row.names(res.acp$var$coord[, 1:nComp]),
                        Coord = CoordsVar,
                        Cos2 = Cos2Var,
                        Qualite = rowSums(Cos2Var),
                        Ctr = CtrVar)
row.names(dfACPVars) <- NULL
names(dfACPVars) <- str_replace(names(dfACPVars), ".Dim.", "Comp")
dfACPVars

# Histogrammes pour les coordonnées
couleursCoords <- c("lightsalmon","steelblue")
plotCoordF1 <- ggplot(dfACPVars,
                      aes(y = reorder(Variable, CoordComp1),
                          x = CoordComp1, fill=CoordComp1<0))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black")+
  geom_vline(xintercept=0, color = "black", size=1)+
  scale_fill_manual(name="Coordonnée",values=couleursCoords,
                    labels = c("Positive","Négative"))+
  labs(x=paste0("Axe 1 (", vppct[1],"%)"), y="Variable")+
  theme(legend.position="none")
plotCoordF2 <- ggplot(dfACPVars,
                      aes(y = reorder(Variable, CoordComp2),
                          x = CoordComp2, fill=CoordComp2<0))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black")+
  geom_vline(xintercept=0, color = "black", size=1)+
  scale_fill_manual(name="Coordonnée",values=couleursCoords,
                    labels = c("Positive","Négative"))+
  labs(x=paste0("Axe 2 (", vppct[2],"%)"), y="Variable")+
  theme(legend.position="none")
plotCoordF3 <- ggplot(dfACPVars,
                      aes(y = reorder(Variable, CoordComp3),
                          x = CoordComp3, fill=CoordComp3<0))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black")+
  geom_vline(xintercept=0, color = "black", size=1)+
  scale_fill_manual(name="Coordonnée", values=couleursCoords,
                    labels = c("Positive","Négative"))+
  labs(x=paste0("Axe 3 (", vppct[3],"%)"), y="Variable")

annotate_figure(ggarrange(plotCoordF1, plotCoordF2, plotCoordF3, nrow=nComp),
                text_grob("Coordonnées des variables sur les axes factoriels",
                          color = "black", face = "bold", size = 12))

# Contributions des variables à la formation des axes
corrplot(CtrVar, is.corr=FALSE, method ="square",
         addCoef.col = 1, cl.pos = FALSE)

# La qualité des variables sur les composantes retenues : cosinus carrés
corrplot(Cos2Var, is.corr=FALSE, method ="square",
         addCoef.col = 1, cl.pos = FALSE)

ggplot(dfACPVars)+
  geom_bar(aes(y=reorder(Variable, Qualite), x=Qualite),
            stat="identity", width = .6, alpha=.8, fill="steelblue")+
  labs(x="", y="Somme des cosinus carrés sur les axes retenus",
       title ="Qualité de représentation des variables sur les axes retenus de l'ACP",
       subtitle = paste0("Variance expliquée par les ", nComp, 
                         " composantes : ", sum(vppct), "%"))
```


```{r acpmesgraphs2, echo=FALSE, fig.align='center', fig.cap="Histogrammes personnalisés avec les coordonnées factorielles pour les variables", auto_pdf=TRUE, dev="png", dpi=300, out.width='75%'}
# Indiquer le nombre d'axes à conserver suite à l'analyse des valeurs propres
nComp <- 3
# Variance expliquée par les axes retenus
vppct <- round(dfACPvp[1:nComp,"VP_pct"],1)
# Dataframe des résultats pour les variables
CoordsVar <- res.acp$var$coord[, 1:nComp]
Cos2Var   <- res.acp$var$cos2[, 1:nComp]
CtrVar   <- res.acp$var$contrib[, 1:nComp]
dfACPVars <- data.frame(Variable =  row.names(res.acp$var$coord[, 1:nComp]),
                        Coord = CoordsVar,
                        Cos2 = Cos2Var,
                        Qualite = rowSums(Cos2Var),
                        Ctr = CtrVar)
row.names(dfACPVars) <- NULL
names(dfACPVars) <- str_replace(names(dfACPVars), ".Dim.", "Comp")

# Histogrammes pour les coordonnées
couleursCoords <- c("lightsalmon","steelblue")
plotCoordF1 <- ggplot(dfACPVars,
                      aes(y = reorder(Variable, CoordComp1),
                          x = CoordComp1, fill=CoordComp1<0))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black")+
  geom_vline(xintercept=0, color = "black", size=1)+
  scale_fill_manual(name="Coordonnée",values=couleursCoords,labels = c("Positive","Négative"))+
  labs(x=paste0("Axe 1 (", vppct[1],"%)"), y="Variable")+
  theme(legend.position="none")
plotCoordF2 <- ggplot(dfACPVars,
                      aes(y = reorder(Variable, CoordComp2),
                          x = CoordComp2, fill=CoordComp2<0))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black")+
  geom_vline(xintercept=0, color = "black", size=1)+
  scale_fill_manual(name="Coordonnée",values=couleursCoords,labels = c("Positive","Négative"))+
  labs(x=paste0("Axe 2 (", vppct[2],"%)"), y="Variable")+
  theme(legend.position="none")
plotCoordF3 <- ggplot(dfACPVars,
                      aes(y = reorder(Variable, CoordComp3),
                          x = CoordComp3, fill=CoordComp3<0))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black")+
  geom_vline(xintercept=0, color = "black", size=1)+
  scale_fill_manual(name="Coordonnée", values=couleursCoords,labels = c("Positive","Négative"))+
  labs(x=paste0("Axe 3 (", vppct[3],"%)"), y="Variable")

annotate_figure(ggarrange(plotCoordF1, plotCoordF2, plotCoordF3, nrow = nComp),
                text_grob("Coordonnées des variables sur les axes factoriels",
                          color = "black", face = "bold", size = 12))
```

```{r acpmesgraphs3, echo=FALSE, fig.align='center', fig.cap="Graphiques personnalisés avec les contributions des variables", message=FALSE, auto_pdf=TRUE, dev="png", dpi=300, out.width='75%'}
library(corrplot)
# couleurs <- colorRampPalette(c("#ffffd4","#993404"))
corrplot(CtrVar, is.corr=FALSE, method ="square", addCoef.col = 1, cl.pos = FALSE)
```

```{r acpmesgraphs4, echo=FALSE, fig.align='center', fig.cap="Graphiques personnalisés avec les cosinus carrés des variables", auto_pdf=TRUE, dev="png", dpi=300, out.width='75%'}
corrplot(Cos2Var, is.corr=FALSE, method ="square", addCoef.col = 1, cl.pos = FALSE)
```

```{r acpmesgraphs5, echo=FALSE, fig.align='center', fig.cap="Graphique personnalisé avec la qualité des variables sur les axes retenus de l'ACP", auto_pdf=TRUE, dev="png", dpi=300, out.width='75%'}
ggplot(dfACPVars)+
  geom_bar(aes(y=reorder(Variable, Qualite), x=Qualite),
            stat="identity", width = .6, alpha=.8, fill="steelblue")+
  labs(x="", y="Somme des cosinus carrés sur les axes retenus",
       title ="Qualité de représentation des variables sur les axes",
       subtitle = paste0("Variance expliquée par les ", nComp, 
                         " composantes : ", sum(vppct), "%"))
```

Troisièmement, lorsque les observations sont des unités spatiales, il convient de cartographier les coordonnées factorielles des individus. Dans le jeu de données utilisé, les observations sont des polygones délimitant les îlots regroupés pour l'information statistique (IRIS) pour l'agglomération de Lyon (France). Nous utilisons les *packages* `tmap` et `RColorBrewer` pour réaliser des cartes choroplèthes avec les coordonnées deux premières composantes (figure&nbsp;\@ref(fig:acpmesgraphs6)).


```{r acpmesgraphs6, echo=TRUE, fig.align='center', fig.cap="Cartographie des coordonnées factorielles des individus", auto_pdf=TRUE, dev="png", dpi=300, out.width='75%'}
library("tmap")
library("RColorBrewer")
# Analyse des résultats de l'ACP pour les individus
# Dataframe des résultats pour les individus
CoordsInd <- res.acp$ind$coord[, 1:nComp]
Cos2Ind   <- res.acp$ind$cos2[, 1:nComp]
CtrInd    <- res.acp$ind$contrib[, 1:nComp]
dfACPInd <- data.frame(Coord = CoordsInd, Cos2 = Cos2Ind, Ctr = CtrInd)
names(dfACPInd) <- str_replace(names(dfACPInd), ".Dim.", "Comp")
# Fusion du tableau original avec les résultats de l'ACP pour les individus
CartoACP <- cbind(LyonIris, dfACPInd)
# Cartographie des coordonnées factorielles pour les individus pour les
# deux premières composantes
Carte1 <- tm_shape(CartoACP) +
          tm_polygons(col = "CoordComp1", style = "cont",
                      midpoint = 0, title = 'Coordonnées')+
          tm_layout(main.title = paste0("Axe 1 (", vppct[1],"%)"),
             attr.outside = TRUE, frame = FALSE, main.title.size = 1)
Carte2 <- tm_shape(CartoACP) +
          tm_polygons(col = "CoordComp2", style = "cont",
                      midpoint = 0, title = 'Coordonnées')+
  tm_layout(main.title = paste0("Axe 2 (", vppct[2],"%)"),
             attr.outside = TRUE, frame = FALSE, main.title.size = 1)
tmap_arrange(Carte1, Carte2)
```


::: {.bloc_aller_loin data-latex=""}
**Exploration interactive des résultats d'une ACP avec le _package_ `explor`**. 

Vous avez compris qu'il ne suffit pas de calculer une ACP, il faut retenir les *n* premiers axes de l'ACP qui nous semblent les plus pertinents, puis les interpréter à la lecture des coordonnées factorielles, les cosinus carrés et les contributions des variables et des individus sur les axes. Il faut donc bien explorer les résultats à l’aide de tableaux et de graphiques! Cela explique que nous avons mobilisé de nombreux graphiques dans les deux sections précédentes (\@ref(sect12232) et \@ref(sect12233)). 
L’exploration des données d’une ACP peut aussi être réalisée avec des graphiques interactifs. Or, un superbe *package* dénommé `explor` (https://juba.github.io/explor/), reposant sur `Shiny` (https://shiny.rstudio.com/), permet d’explorer de manière interactive les résultats de plusieurs méthodes factorielles calculés avec `FactorMinerR`. Pour cela, il vous suffit de lancer les deux lignes de code suivantes&nbsp;:

`library(explor)`

`explor(res.acp)`

Finalement, `explor` permet également d'explorer les résultats d'une analyse des correspondances (AFC) et d'une analyse des correspondances multiples (ACM).
:::

## Analyse factorielle des correspondances (AFC) {#sect123}

::: {.bloc_notes  data-latex=""}
Pour bien comprendre l'AFC, il est essentiel de bien maîtriser les notions de tableau de contingence (marges du tableau, fréquences observées et théoriques, pourcentages en ligne et en colonne, contributions au khi-deux) et de distance du khi-deux. Si ce n'est pas le cas, il est conseillé de (re)lire le chapitre \@ref(chap05). 
:::

Dans le chapitre \@ref(chap05), nous avons vu comment construire un tableau de contingence (figure&nbsp;\@ref(fig:AnalysesFactoriellesTabAFCFig)) à partir deux variables qualitatives comprenant plusieurs modalités, puis comment vérifier s’il y a dépendance entre les deux variables qualitatives avec le test du khi-deux. Or, s’il y a bien dépendance, il est peut-être judicieux de résumer l’information que contient le tableau de contingence en quelques nouvelles variables synthétiques, objectif auquel répond l’analyse factorielle des correspondances (AFC).

```{r AnalysesFactoriellesTabAFCFig, fig.align='center', echo=FALSE, auto_pdf = TRUE, fig.cap="Tableau de contingence pour une AFC", out.width='70%'}
knitr::include_graphics('images/analysesfactorielles/AnalysesFactoriellesTabAFC.png', dpi = NA)
```

À titre de rappel (section \@ref(sect1212)), l’AFC a été développée par le statisticien français Jean-Paul Benzécri [-@benzecri1973analyse]. Cela explique qu’elle est souvent enseignée et utilisée en sciences sociales dans les universités francophones, mais plus rarement dans les universités anglophones. Pourtant, les applications de l’AFC sont nombreuses dans différentes disciplines des sciences sociales comme illustrées avec les exemples suivants&nbsp;:

-	En géographie, les modalités de la première variable du tableau de contingence sont souvent des entités spatiales (par exemple, régions, municipalités, quartiers, etc.) croisées avec les modalités d'une autre variable qualitative (catégories socioprofessionnelles, modes de transport, tranches de revenu des ménages ou des individus, etc.).
- En économie régionale, nous pourrions vouloir explorer un tableau de contingence croisant des entités spatiales (par exemple, MRC au Québec, départements en France) et les effectifs d'emplois pour différents secteurs d’activité.
- En sciences politiques, le recours à l’AFC peut être intéressant pour explorer les résultats d’une élection. Les deux variables qualitatives pourraient être les *circonscriptions électorales* et les *partis politiques*. Le croisement des lignes et des colonnes du tableau de contingence représenterait le nombre de votes obtenus par un parti politique *j* dans la circonscription électorale *i*. Appliquer une AFC sur un tel tableau de contingence permettrait de révéler les ressemblances entre les différents partis politiques et celles entre les circonscriptions électorales. 

::: {.bloc_attention data-latex=""}
**Application d'une ACP sur un tableau de contingence transformé en un tableau avec les pourcentages en ligne&nbsp;: un bien mauvais calcul...**

Il pourrait être tentant de transformer le tableau de contingence initial (tableau&nbsp;\@ref(tab:encadreAFCACP1)) en un tableau avec les pourcentages en lignes (tableau&nbsp;\@ref(tab:encadreAFCACP2)) afin de lui appliquer une analyse en composantes principales. Une telle démarche a deux inconvénients majeurs&nbsp;: chacune des modalités de la première variable qualitative (*I*) aurait alors le même poids; chacune des modalités de la deuxième variable (*J*) aurait aussi le même poids. Or, à la lecture des marges en ligne et en colonne au tableau&nbsp;\@ref(tab:encadreAFCACP1), il est clair que la modalité `j1` et `i1` comprennent plus bien d'individus que les autres modalités respectives.

Si nous reprenons le dernier exemple applicatif, cela signifierait que le même poids sera accordé à chaque parti puisque les variables sont centrées réduites en ACP (moyenne&nbsp;=&nbsp;0 et variance&nbsp;=&nbsp;1). Autrement dit, les grands partis traditionnels seraient ainsi sur le pied d’égalité que les autres partis. Aussi, chaque circonscription électorale aurait le même poids bien que certaines comprennent bien plus d’électeurs et d’électrices que d’autres.

```{r encadreAFCACP1, echo=FALSE, message=FALSE, warning=FALSE}
dataAFCex <- data.frame(Véhicule = c(357060, 427530, 147500, 128520),
                        VehPass = c(22010,26400 , 6545, 6405),
                        TranspC = c(276625,295860, 34545, 42925),
                        Apied = c(65000,69410, 4415, 6565),
                        Velo = c(29415,30645 , 1040, 2670))

dataafex1 <- dataAFCex
dataafex1[nrow(dataafex1)+1,] <- colSums(dataafex1)
dataafex1$MargeJ <- rowSums(dataafex1)
rownames(dataafex1) <- c("i1", "i2", "i3", "i4","Marge (colonne)")
colnames(dataafex1) <- c("j1", "j2", "j3", "j4", "j5","MargeJ")
show_table(dataafex1,
           caption = "Exemple de tableau de contingence pour l'AFC",
           row.names = TRUE,
           col.names=c("j1", "j2", "j3", "j4", "j5", "Marge (ligne)"),
           align= c("r", "r", "r", "r", "r", "r"),
           position = 'HOLD_position'
           )
```


```{r encadreAFCACP2, echo=FALSE, message=FALSE, warning=FALSE}
dataafex2 <- dataAFCex
rownames(dataafex2) <- c("i1", "i2", "i3", "i4")
colnames(dataafex2) <- c("V1", "V2", "V3", "V4", "V5")
dataafex2$MargeJ <- rowSums(dataafex2)
dataafex2$V1  <- round(dataafex2$V1 / dataafex2$MargeJ *100, 1)
dataafex2$V2  <- round(dataafex2$V2 / dataafex2$MargeJ *100, 1)
dataafex2$V3  <- round(dataafex2$V3 / dataafex2$MargeJ *100, 1)
dataafex2$V4  <- round(dataafex2$V4 / dataafex2$MargeJ *100, 1)
dataafex2$V5  <- round(dataafex2$V5 / dataafex2$MargeJ *100, 1)
dataafex2$MargeJ <- NULL
show_table(dataafex2,
           caption = "Exemple d'un tableau de contingence transformé (pourcentage en ligne) pour l'ACP",
           row.names = TRUE,
          align= c("r", "r", "r", "r", "r"),
          position = 'HOLD_position'
           )
```
:::

### Recherche d'une simplification basée sur la distance du khi-deux {#sect1231}

Sur le plan mathématique et des objectifs visés, l'AFC est similaire à l'ACP puisqu'elle permet d'explorer un tableau de trois façons&nbsp;: 1) en montrant les ressemblances entre un ensemble d'individus (*I*), 2) en révélant les liaisons entre les variables (*J*) et 3) en résumant le tout avec des variables synthétiques. Toutefois avec l'AFC, les ensembles *I* et *J* sont les modalités de deux variables qualitatives (dont le croisement forme un tableau de contingence) et elle est basée sur la distance du khi-deux (et non sur la distance euclidienne comme en ACP).

Ainsi, avec la distance du khi-deux, la proximité (ressemblance) entre deux lignes (*i* et *l*) et deux colonnes (*j* et *k*) est mesurée comme suit&nbsp;:

\footnotesize
\begin{equation}
d_{\chi_{il}^2} = \sum_j \frac{1}{f_{.j}}(\frac{f_{ij}}{f_{i.}}-\frac{f_{lj}}{f_{l.}})^2
(\#eq:khideuxlignes)
\end{equation}
\normalsize

\footnotesize
\begin{equation}
d_{\chi_{jk}^2} = \sum_i \frac{1}{f_{i.}}(\frac{f_{ij}}{f_{.j}}-\frac{f_{ik}}{f_{.k}})^2
(\#eq:khideuxcolonnes)
\end{equation}
\normalsize

Prenons un exemple fictif pour calculer ces deux distances. Le tableau \@ref(tab:afcdataex1) comprend trois modalités en ligne (*I*) et trois autres en colonnes (*J*). Le total des effectifs de ce tableau de contingence est égal à 1&nbsp;665.

À partir des données brutes, il est facile de construire deux tableaux&nbsp;: le profil des lignes et le profil des colonnes (tableau \@ref(tab:afcProfilsLignesCols)), c'est-à-dire les proportions en ligne et en colonne.

\newpage

```{r afcdataex1, echo=FALSE, message=FALSE, warning=FALSE}
# Fréquences brutes
dfAFC1 <- data.frame(j1 = c(360, 420, 145),
                     j2 = c(65, 70, 5),
                     j3 = c(275,290, 35))
# Fréquences relatives
nt <- sum(dfAFC1)
ni <- nrow(dfAFC1)
nj <- ncol(dfAFC1)
dfAFC1fij <- dfAFC1 / nt

# Tableau des profils des lignes
profilligne <- data.frame(round(dfAFC1 / rowSums(dfAFC1),3))
profilligne$Total <- 1
names(profilligne) <- c("j1","j2","j3","Total")
rownames(profilligne) <- c("i1", "i2", "i3")

# Tableau des profils des colonnes
profilcol <- dfAFC1
profilcol$j1 <- round(profilcol$j1 / sum(profilcol$j1),3)
profilcol$j2 <- round(profilcol$j2 / sum(profilcol$j2),3)
profilcol$j3 <- round(profilcol$j3 / sum(profilcol$j3),3)
profilcol[ni+1,] <- 1
rownames(profilcol) <- c("j1", "j2", "j3", "Total")

# Calcul des marges
dfAFC1$fi <- rowSums(dfAFC1)
dfAFC1[ni+1,] <- colSums(dfAFC1)
dfAFC1fij$fi <- rowSums(dfAFC1fij)
dfAFC1fij[ni+1,] <- colSums(dfAFC1fij)
rownames(dfAFC1) <- c("i1", "i2", "i3", "Total (colonne)")
show_table(dfAFC1,
           row.names = TRUE,
           col.names = c("j1","j2","j3","Total (ligne)"),
           caption = "Données brutes du tableau de contingence",
           align= c("c","c","c","c"),
           position = "HOLD_position"
           )
```


```{r afcProfilsLignesCols, echo=FALSE, message=FALSE, warning=FALSE}
profilcol$Total <- NA
profils <- rbind(profilligne, profilcol)
rownames(profils)  <- NULL
profils$ind <- c("i1","i2","i3","i1","i2","i3","Total")
profils <- profils[, c(5,1:4)]

montableau <- show_table(profils,
               row.names = FALSE,
               digits = 3,
               col.names = c("","j1","j2","j3","Total"),
               caption = "Profils des lignes et des colonnes",
               align= c("c","c","c","c","c"),
               position = "HOLD_position"
               )
group_rows(montableau,
           index = c("Profil des lignes" = 3,
                  "Profils des colonnes" = 4)
          )
```

En divisant les valeurs du tableau \@ref(tab:afcdataex1) par le grand total (1&nbsp;665), nous obtenons tous les termes utilisés dans les équations \@ref(eq:khideuxlignes) et \@ref(eq:khideuxcolonnes) au tableau \@ref(tab:afcdataex2)&nbsp;:

- Les fréquences relatives dénommées $f_{ij}$. 
- La marge $fi.$ est égale à la somme des fréquences relatives en ligne.
- La marge $f.j$ est égale à la somme des fréquences relatives en colonne.
- La somme de toutes les fréquences relatives est donc égale à 1, soit $\sum{f_{i.}}$ ou $\sum{f_{.j}}$.


```{r afcdataex2, echo=FALSE, message=FALSE, warning=FALSE}
rownames(dfAFC1fij) <- c("i1", "i2", "i3", "Total (f.j)")
show_table(dfAFC1fij,
           digits = 3,
           row.names = TRUE,
           col.names = c("j1","j2","j3","Total (fi.)"),
           caption = "Données relatives du tableau de contingence (fij)",
           align= c("r","r","r","r"),
           position = "HOLD_position"
           )
```

Il est possible de calculer les distances entre les différentes modalités  de *I* en appliquant l'équation \@ref(eq:khideuxlignes); par exemple, la distance entre les observations `i1` et `i2` est égale à&nbsp;:

$$d_{(i1,i2)}=\frac{\mbox{1}}{\mbox{0,556}}(\mbox{0,216}-\mbox{0,252})^2+\frac{\mbox{1}}{\mbox{0,084}}(\mbox{0,039}-\mbox{0,042})^2+
\frac{\mbox{1}}{\mbox{0,360}}(\mbox{0,165}-\mbox{0,174})^2=\mbox{0,003}$$

Avec l'équation \@ref(eq:khideuxcolonnes), la distance entre les modalités `j1` et `j2` de *J* est égale à&nbsp;:

$$d_{(j1,j2)}=\frac{\mbox{1}}{\mbox{0,420}}(\mbox{0,216}-\mbox{0,039})^2+ \frac{\mbox{1}}{\mbox{0,468}}(\mbox{0,252}-\mbox{0,042})^2 + \frac{\mbox{1}}{\mbox{0,111}}(\mbox{0,087}-\mbox{0,003})^2=\mbox{0,233}$$


À la lecture du tableau \@ref(tab:MatriceDistKhi), les modalités les plus sont semblables sont 
`i1` et `i2` (0,003) pour *I* et `j1` et `j3` (0,058) pour *J*.

```{r MatriceDistKhi, echo=FALSE, message=FALSE, warning=FALSE}
MatriceI <- matrix(1:9, nrow = 3, ncol = 3)
MatriceJ <- matrix(1:9, nrow = 3, ncol = 3)
dfij <- dfAFC1fij

# Matrice de distances des lignes I
for (i in 1:ni){
   for (l in 1:ni){
     dil <- (1/dfij[4,1])*(dfij[i,1]-dfij[l,1])^2 +
            (1/dfij[4,2])*(dfij[i,2]-dfij[l,2])^2 + 
            (1/dfij[4,3])*(dfij[i,3]-dfij[l,3])^2
    MatriceI[i,l] <- round(dil,3)
   }
}
# Matrice de distances des colonnes J
for (i in 1:ni){
   for (l in 1:ni){
     dil <- (1/dfij[1,4])*(dfij[1,i]-dfij[1,l])^2 +
            (1/dfij[2,4])*(dfij[2,i]-dfij[2,l])^2 + 
            (1/dfij[3,4])*(dfij[3,i]-dfij[3,l])^2
    MatriceJ[i,l] <- round(dil,3)
   }
}
Matrices <- data.frame(Ind. =c("i1","i2","i3"),
                       MatriceI,
                       Col.=c("j1","j2","j3"),
                       MatriceJ)
colnames(Matrices) <- c("Ind.","i1","i2","i3", "Col.","j1","j2","j3")

show_table(Matrices,
           digits = 5,
           caption = "Distances du khi-deux entre les modalités I et les modalités J",
           align= c("c","c","c","c","c","c","c","c")
           )
```

Finalement, l'approche pour déterminer les axes factoriels de l'AFC est similaire à celle de l'ACP&nbsp;: les axes factoriels sont les droites orthogonales qui minimisent les distances aux points du profil des lignes, excepté que la métrique pour mesurer ces distances est celle du khi-deux (et non celle la distance euclidienne comme ACP). Pour plus détail sur le calcul de ces axes (notamment les formulations matricielles), consultez notamment Benzécri [-@benzecri1973analyse], Escofier et Pagès [-@escofier1998analyses] et Lebart et al. [-@lebart1995statistique].


### Aides à l'interprétation {#sect1232}

Pour illustrer les aides à l’interprétation de l’AFC, nous utilisons un jeu de données spatiales extrait du [profil du recensement de 2016 de Statistique Canada](https://www12.statcan.gc.ca/census-recensement/2016/dp-pd/prof/index.cfm?Lang=F){target='_blank'} pour les secteurs de recensement de l'île de Montréal. La liste des modalités des variables qu'il comprend est reportée au tableau \@ref(tab:dataAfc). L'AFC est calculée sur un tableau de contingence croisant les secteurs de recensement (lignes) et les modalités d'une variable relative au mode de transport utilisé pour les déplacements domicile-travail (colonnes). Ces modalités sont cartographiées à la figure \@ref(fig:cartovarAFC).

```{r dataAfc, echo=FALSE, message=FALSE, warning=FALSE}
library(sf)
library(kableExtra)
load("data/analysesfactorielles/DonneesAFC.Rdata")

Dimensions <- c("Mode de transport", "Durée du trajet")
MesVarLongs <- c("Véhicule motorisé (conducteur·trice)",
                 "Véhicule motorisé (passager·ère)",
                 "Transport en commun",
                 "À pied",
                 "Bicyclette",
                 "Autre moyen",
                 "Moins de 15 minutes",
                 "15 à 29 minutes",
                 "30 à 44 minutes",
                 "45 à 59 minutes",
                 "60 minutes et plus")
stats <- data.frame(variable = names(dfDonneesAFC),
                    nom = MesVarLongs,
                    somme = sapply(dfDonneesAFC, sum)
                    )
montableau <- show_table(stats,
           digits = 1,
            caption = "Jeu de données utilisé pour l'analyse factorielle des correspondances",
           col.names=c("Nom","Intitulé","Somme"),
           align= c("l","l", "r"),
           position = "HOLD_position"
           )
group_rows(montableau,
           index = c("Modalités de la variable utilisée dans l'AFC (mode de transport)" = 6,
                  "Modalités de la variable supplémentaire (durée du trajet)" = 5)
          )
```

```{r cartovarAFC, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center', fig.cap="Cartographie des modalités de la variable mode de transport utilisée pour l'AFC", auto_pdf=TRUE, dev="png", dpi=300, out.width='100%'}
library(tmap)
library(viridis)
Carte1 <- tm_shape(sfDonneesAFC) + tm_fill("VehCond", style="cont", pal=viridis(10, direction=-1, option="G"), title ='Véhicule (conducteur·trice)')
Carte2 <- tm_shape(sfDonneesAFC) + tm_fill("VehPass", style="cont", pal=viridis(10, direction=-1, option="G"), title='Véhicule (passager·ère)')
Carte3 <- tm_shape(sfDonneesAFC) + tm_fill("TranspC", style="cont", pal=viridis(10, direction=-1, option="G"), title='Transport en commun')
Carte4 <- tm_shape(sfDonneesAFC) + tm_fill("Apied", style="cont", pal=viridis(10, direction=-1, option="G"), title = 'À pied')
Carte5 <- tm_shape(sfDonneesAFC) + tm_fill("Velo", style="cont", pal=viridis(10, direction=-1, option="G"), title = 'Bicyclette')
Carte6 <- tm_shape(sfDonneesAFC) + tm_fill("AutreMoyen", style="cont", pal=viridis(10, direction=-1, option="G"), title = 'Autre moyen')
tmap_arrange(Carte1, Carte2, Carte3, Carte4, Carte5, Carte6, ncol = 2, nrow = 3)
```

#### Résultats de l'AFC pour les valeurs propres {#sect12321}

Avant de calculer l'AFC, il convient de vérifier s'il y a bien dépendance entre les modalités des deux variables qualitatives. En effet, si les deux variables sont indépendantes, il n'est pas nécessaire de résumer le tableau de contingence avec une AFC. Pour ce faire, nous utilisons le test du khi-deux largement décrit à la section \@ref(sect052). Les résultats de ce test signalent qu’il existe des associations entre les modalités des deux variables ($\chi$&nbsp;=&nbsp;203&nbsp;971, p&nbsp;<&nbsp;0,001, tableau \@ref(tab:dataafckhi2)). Nous pouvons donc appliquer une AFC sur ce tableau de contingence.

```{r dataafckhi2, echo=FALSE, message=FALSE, warning=FALSE, out.width='75%'}
load("data/analysesfactorielles/DonneesAFC.Rdata")
chideux <- chisq.test(dfDonneesAFC[,1:6])
ni <-  nrow(dfDonneesAFC)
nj <-  ncol(dfDonneesAFC[,1:6])
nij <- sum(dfDonneesAFC[,1:6])
# cat("\n Modalités I (secteurs de recensement) :", nrow(dfDonneesAFC),
#     "\n Modalités J (variable mode de transport) :", ncol(dfDonneesAFC[,1:5]),
#     "\n Somme nij :", nij,
#     "\n chi-deux :", chideux$statistic,
#     "\n valeur de p :", round(chideux$p.value,3),
#     "\nphi2 (khi-deux / nij) : ", round(chideux$statistic / nij, 5))

dfkhi <- data.frame(Mesure= c("Modalités *I* (secteurs de recensement)",
                              "Modalités *J* (variable mode de transport)",
                              "Somme des données brutes ($n_{ij}$)",
                              "Khi-deux ($\\chi^2$)",
                              "Degrés de liberté, soit $(c-1)\\times(l-1)$",
                              "Valeur de *p*",
                              "Coefficient Phi au carré ($\\phi^2=\\chi^2 / n_{ij})$"),
                    Valeur = c(ni,
                                nj,
                                nij,
                                round(chideux$statistic,2),
                                (ni-1)*(nj-1),
                                round(chideux$p.value,3),
                                round(chideux$statistic / nij, 2))
                    )
show_table(dfkhi,
            caption = "Résultats du test du khi-deux sur le tableau de contingence",
           align= c("l", "r")
           )
```

Nous avons vu qu'en ACP normée (section \@ref(sect12221)), la somme des valeurs propres est égale au nombre de variables puisqu'elles sont centrées réduites. Par contre, en AFC, cette somme est égale à l'inertie totale du tableau de contingence, c'est-à-dire à la valeur du khi-deux divisée par le nombre total des effectifs bruts (soit le coefficient phi au carré, $\phi^2$) (section \@ref(sect052)). Le tableau \@ref(tab:dataafcValeurPropres) permet de vérifier que la somme des valeurs propres est bien égale au coefficient phi au carré&nbsp;: 

$$\mbox{0,156}+\mbox{0,046}+\mbox{0,031}+\mbox{0,004}+\mbox{0,004} = \mbox{0,24}$$

$$\phi^2 = \chi^2 / n_{ij}=\mbox{203 971}/ \mbox{849 795} = \mbox{0,24}$$

```{r dataafcValeurPropres, echo=FALSE, message=FALSE, warning=FALSE, out.width='75%'}
library(FactoMineR)
# Calcul de l'AFC
res.afc <- CA(dfDonneesAFC[,1:6], graph=F)
# Construction d'un DataFrame pour les valeurs propres
dfAFCvp <- data.frame(res.afc$eig)
names(dfAFCvp) <- c("VP","VP_pct","dfAFCvp")
dfAFCvp$Composante <- factor(1:nrow(dfAFCvp), levels=rev(1:nrow(dfAFCvp)))
dfAFCvp <- dfAFCvp[,c(4,1:3)]

show_table(dfAFCvp,
           digits = 3,
            caption = "Résultats de l'AFC pour les valeurs propres",
           col.names=c("Axe factoriel","Valeur propre","Pourcentage", "Pourc. cumulé"),
           align= c("r", "r","r", "r")
           )
```

\newpage

**Combien d'axes d'une AFC faut-il retenir?**

- **Approche statistique**. Mike Bendixen [-@bendixen1995compositional], cité dans l'excellent site [STHDA](http://www.sthda.com/french/articles/38-methodes-des-composantes-principales-dans-r-guide-pratique/74-afc-analyse-factorielle-des-correspondances-avec-r-l-essentiel/#valeurs-propres-variances){target='_blank'}, propose deux critères pour sélectionner les premiers axes d'une AFC&nbsp;: $c_1= 1 / (l-1) \times 100$ et $c_2= 1 / (c-1) \times 100$ avec *l* et *c* étant respectivement les nombres de modalités en ligne et en colonne. Autrement dit, lorsque les données sont distribuées aléatoirement, la valeur propre en pourcentage devrait être égale à $c_1$ et celle de l'axe factoriel moyen à $c_2$. Par conséquent, nous pourrions retenir uniquement les axes dont les valeurs propres en pourcentage excèdent&nbsp;: $c_1 = \mbox{1}/(\mbox{521}-\mbox{1})\times \mbox{100}=\mbox{0,19 }%$ et $c_2=\mbox{1}/(\mbox{6}-\mbox{1})\times \mbox{100}=\mbox{20 }%$. En appliquant ces deux critères, seul le premier axe factoriel qui résume 65,6&nbsp;% mériterait d'être retenu.

- **Approche empirique** basée sur la lecture des pourcentages et des pourcentages cumulés. Nous retenons uniquement les deux premières composantes qui résument 85&nbsp;% de la variance totale. Pour faciliter le choix du nombre d'axes avec cette approche empirique, il est fortement conseillé de construire un histogramme à partir des valeurs propres, soit brutes, soit en pourcentages, soit en pourcentages cumulés (figure&nbsp;\@ref(fig:afcGraphVP)).

```{r afcGraphVP, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center', fig.cap="Histogramme des valeurs propres de l'AFC", auto_pdf=TRUE, dev="png", dpi=300, out.width='80%'}
library(factoextra)
c2 <- 1/(ncol(dfDonneesAFC[,1:6])-1)*100
texte <- tofr(round(c2, 2))
texte <- paste0("Critère pour le profil moyen : ", as.character(texte), " %")
fviz_screeplot(res.afc, choice="variance", addlabels = TRUE, ylim = c(0, 70),
                     ylab="Variance expliquée (%)",
                     xlab="Axes factoriels",
                     main="")+
  geom_hline(yintercept = c2, linetype = 1, color = "red", size=1)+
 annotate(geom="text", x =5.5, y= c2+3, label=texte, color="red", hjust = 1, size = 4)
```

#### Résultats de l'AFC pour les variables et les individus {#sect12322}
Comme pour l'ACP, nous retrouvons les trois mêmes mesures pour les variables et les individus&nbsp;: 1)&nbsp;les coordonnées factorielles, 2)&nbsp;les contributions et 3)&nbsp;les cosinus carrés. 

::: {.bloc_objectif data-latex=""}
**Compréhension des axes factoriels de l'AFC&nbsp;: une étape essentielle, incontournable...**

Comme en ACP, l'analyse des trois mesures (coordonnées, contributions et cosinus carrés) pour les variables et les individus doit vous permettre de comprendre la signification des axes factoriels retenus de l'AFC. Cette étape d'interprétation est essentielle afin de qualifier les variables latentes (axes factoriels, variables synthétiques) produites par l'AFC.
:::

- **Les coordonnées factorielles** sont simplement les projections des points-lignes et de points-colonnes sur les axes de l'AFC. Tant pour les lignes que pour les colonnes, ces coordonnées bénéficient de deux propriétés intéressantes. Premièrement pour chaque axe factoriel *k*, la somme du produit des marges des variables ($f.j$, colonnes) ou des individus ($fi.$, lignes) avec leurs coordonnées respectives ($C^k_j$ et $C^k_i$) est égale à 0 (équation&nbsp;\@ref(eq:CoordPropr1)). Deuxièmement, pour chaque axe factoriel *k*, la somme des produits entre les marges (en ligne et en colonne) et les coordonnées au carré (en ligne et en colonne) est égale à la valeur propre de l'axe (équation&nbsp;\@ref(eq:CoordPropr2)).

\footnotesize
\begin{equation}
\sum{f.j (C^k_j)}= 0 \text{ et} \sum{fi. (C^k_i)}= 0
(\#eq:CoordPropr1)
\end{equation}
\normalsize

\footnotesize
\begin{equation}
\sum{fi. (C^k_i)^2}= \mu_k \text{ et} \sum{f.j (C^k_j)^2}= \mu_k
(\#eq:CoordPropr2)
\end{equation}
\normalsize

En guise d'exemple, le tableau \@ref(tab:dataafcCoordVars2) permet de vérifier les deux propriétés des coordonnées pour les variables. Les sommes de ${f.j (C^k_j)}$ pour les axes&nbsp;1 et&nbsp;2 sont bien égales à 0; et les sommes de ${f.j (C^k_j)^2}$ pour les axes&nbsp;1 et&nbsp;2 sont bien égales aux valeurs propres de ces deux axes, soit 0,156 et 0,046 (comparez ces valeurs avec celles reportées au tableau \@ref(tab:dataafcValeurPropres) plus haut).

```{r dataafcCoordVars2, echo=FALSE, message=FALSE, warning=FALSE, out.width='75%'}
fj <- colSums(dfDonneesAFC[,1:6]) / sum(dfDonneesAFC[,1:6])
nAxes <- 2
CoordsVar <- res.afc$col$coord[, 1:nAxes]
dfAFCVars2 <- data.frame(Modalite =  row.names(CoordsVar),
                        Coord = res.afc$col$coord[, 1:nAxes])
dfAFCVars2$fj <- fj
dfAFCVars2 <- dfAFCVars2[, c(1,4,2,3)]
names(dfAFCVars2) <- c("Modalite", "fj", "CoordAxe1", "CoordAxe2")
ni <- nrow(dfAFCVars2)
dfAFCVars2$fiCoord1 <- dfAFCVars2$CoordAxe1*dfAFCVars2$fj
dfAFCVars2$fiCoord2 <- dfAFCVars2$CoordAxe2*dfAFCVars2$fj
dfAFCVars2$fiCoord1b <- dfAFCVars2$CoordAxe1^2*dfAFCVars2$fj
dfAFCVars2$fiCoord2b <- dfAFCVars2$CoordAxe2^2*dfAFCVars2$fj
dfAFCVars2[ni+1,] <- NA
dfAFCVars2[ni+1,1] <- "Somme"
for (i in c(2,5:ncol(dfAFCVars2))){
    dfAFCVars2[ni+1,i] <- round(sum(dfAFCVars2[[i]], na.rm = TRUE),4)
}
montableau <- show_table(dfAFCVars2,
                   digits = 3,
                   caption = "Vérification des deux propriétés des coordonnées factorielles pour les variables",
                   col.names=c("Modalité","f.j","1","2","1","2","1","2"),
                   align= c("l","r","r","r","r","r","r","r"),
                   position = "HOLD_position"
                   )
add_header_above(montableau, c(" " = 2, "Coord." = 2, "f.j x Coord." = 2, "f.j x Coord2" = 2))
```


::: {.bloc_attention data-latex=""}
Contrairement à l'ACP, les coordonnées factorielles pour les variables en ACF ne sont pas les coefficients de corrélation de Pearson des variables sur les axes!
:::

- **Les contributions** des colonnes ou des lignes en AFC permettent des repérer celles qui contribuent le plus à la formation des axes factoriels (de manière analogue à l'ACP). Pour un axe donné, leur sommation est égale à&nbsp;100&nbsp;%. Elles s'obtiennent en multipliant la coordonnée au carré avec la marge et en divisant le tout par la valeur propre de l'axe (équations&nbsp;\@ref(eq:CtrAFCVar) et&nbsp;\@ref(eq:CtrAFCInd)).

\footnotesize
\begin{equation}
\mbox{Ctr}_j^k =\frac{f.j(C^k_j)^2}{\mu_{k}}\times 100
(\#eq:CtrAFCVar)
\end{equation}
\normalsize

\footnotesize
\begin{equation}
\mbox{Ctr}_i^k =\frac{fi.(C^k_i)^2}{\mu_{k}}\times 100
(\#eq:CtrAFCInd)
\end{equation}
\normalsize

- **Les cosinus carrés** (Cos^2^) (appelés aussi les qualités de représentation sur un axe) permettent de repérer le ou les axes qui concourent le plus à donner un sens aux colonnes(variables) et aux lignes (individus), de manière analogue à l'ACP). Pour une variable ou un individu, la sommation des Cos^2^ pour tous les axes de l'AFC est aussi égale à 1.

**Interprétation des résultats pour les colonnes (variables)**

Analysons maintenant, ces trois statistiques pour les variables pour les deux premiers axes de l'AFC (tableau&nbsp;\@ref(tab:dataafcCoordVars) et figure&nbsp;\@ref(fig:afc1erplanfactVars)).

Pour l'axe&nbsp;1, résumant 65&nbsp;% de la variance, trois modalités concourent à sa formation&nbsp;: `VehCond` (34,69&nbsp;%), `Apied` (34,25&nbsp;%) et `Velo` (20,13&nbsp;%). À la lecture des coordonnées factorielles sur cet axe, les modes de transport relatifs aux véhicules motorisés (`VehCond`&nbsp;=&nbsp;-0,33 et `VehPass`&nbsp;=&nbsp;-0,25) s'opposent clairement aux modes actifs (`Apied`&nbsp;=&nbsp;0,81 et `Velo`&nbsp;=&nbsp;0,94), constat qu'il est possible de confirmer visuellement avec la figure&nbsp;\@ref(fig:afc1erplanfactVars)). La modalité `VehCond` a d'ailleurs la plus forte valeur de Cos^2^ sur cet axe (0,92), ce qui signale, sans l'ombre d'un doute, que l'axe&nbsp;1 est celui qui donne le plus de sens à cette modalité. 

Puisque l'axe&nbsp;2 résume une partie beaucoup plus limitée de la variance du tableau (19,25&nbsp;%), il n'est pas étonnant qu'un nombre plus limité de modalités concourent à sa formation&nbsp;: seules les contributions de la modalité `Apied` (51,68&nbsp;%) et secondairement `VehPass` (38,81&nbsp;%) sont importantes. Leurs coordonnées factorielles s'opposent d'ailleurs sur cet axe (respectivement 0,81 et 0,21).


```{r dataafcCoordVars, echo=FALSE, message=FALSE, warning=FALSE, out.width='75%'}
library(kableExtra)
library(stringr)
nAxes <- 2
dfAFCVars <- data.frame(Modalite =  row.names(CoordsVar),
                        Coord = res.afc$col$coord[, 1:nAxes],
                        Cos2 =  res.afc$col$cos2[, 1:nAxes],
                        Ctr =   res.afc$col$contrib[, 1:nAxes])
row.names(dfAFCVars) <- NULL
names(dfAFCVars) <- str_replace(names(dfAFCVars), ".Dim.", "Axe")

montableau <- show_table(dfAFCVars,
                   digits = 2,
                   caption = "Résultats de l'AFC pour les variables",
                   col.names=c("Modalité","1","2","1","2","1","2"),
                   align= c("l","r","r","r","r","r","r"),
                   position = "HOLD_position"
                   )
add_header_above(montableau, c(" " = 1, "Coordonnées" = 2, "Cosinus carrés" = 2, "Contributions (%)" = 2))
```

```{r afc1erplanfactVars, echo=FALSE, fig.align='center', fig.cap="Premier plan factoriel de l'AFC pour les variables", message=FALSE, auto_pdf=TRUE, dev="png", dpi=300, out.width='75%', quietly=TRUE, warn.conflicts=TRUE}
VP1pct <- tofr(round(res.afc$eig[1,2],2))
VP2pct <- tofr(round(res.afc$eig[2,2],2))
fviz_ca_col(res.afc,
            repel = TRUE,
            geom= c("text","point"),
            col.col = "steelblue",
            gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
            title = "",
            xlab=paste0("Axe 1 (", VP1pct, " %)"),
            ylab=paste0("Axe 2 (", VP2pct, " %)"))
```          
            
            
**Interprétation des résultats pour les individus**

::: {.bloc_notes  data-latex=""}
**Premier plan factoriel pour les variables et les individus**

Lorsque le jeu de données comprend à la fois peu de modalités en lignes et en colonnes, il est judicieux de les représenter simultanément sur le premier plan factoriel (axe&nbsp;1 et&nbsp;2). Pour ce faire, vous pouvez utiliser la fonction `fviz_ca_biplot` du *package* `factoextra`.
:::

Étant donné que notre jeu de données comprend 521&nbsp;secteurs de recensement, nous proposons ici de cartographier les coordonnées factorielles des individus pour les deux premiers axes de l'AFC (figure&nbsp;\@ref(fig:afc1erplanfactInds2)). Pour l'axe&nbsp;1, les secteurs de recensement à l'est et l'ouest de l'île de Montréal présentent les coordonnées les plus fortement négatives (en rouge); dans ces zones, l'usage des véhicules motorisés pour des déplacements domicile-travail est certainement surreprésenté, comparativement aux modes actifs. À l'inverse, dans les secteurs de recensement du centre de l'île présentant de fortes valeurs positives (en rouge), le recours aux modes de transports actifs (marche et vélo) est bien plus important, toutes proportions gardées. Quant à la cartographie des coordonnées pour l'axe&nbsp;2, elle permet surtout de repérer quelques secteurs de recensement autour du centre-ville (très fortes valeurs positives en vert foncé) où les déplacements domicile-travail à pied sont plus fréquents, toutes proportions gardées.

En résumé, suite à l'analyse des coordonnées factorielles des variables et des individus, nous pouvons conclure que le premier axe est certainement le plus intéressant puisqu’il permet d'opposer l’usage des modes de transports motorisés versus les modes de transports actifs pour les déplacements domicile-travail sur l'île de Montréal. Cette nouvelle variable synthétique (variable latente) pourrait ainsi être introduite des analyses subséquentes (par exemple, dans un modèle de régression). Cela démontre, qu’au même titre que l’ACP, l’AFC est une méthode de réduction de données puisque nous sommes passés d’un tableau comprenant 512 secteurs de recensement et six modalités à un tableau comprend une seule variable synthétique (axe&nbsp;1).

```{r afc1erplanfactInds2, echo=FALSE, fig.align='center', fig.cap="Cartographie de coordonnées factorielles des individus pour l'ACF", message=FALSE, auto_pdf=TRUE, dev="png", dpi=300, out.width='85%', quietly=TRUE, warn.conflicts=TRUE}
library(tmap)
library(stringr)
dfAFCInd <- data.frame(Coord = res.afc$row$coord, 
                       Cos2 = res.afc$row$cos2, 
                       Ctr = res.afc$row$contrib)
names(dfAFCInd) <- str_replace(names(dfAFCInd), ".Dim.", "Comp")
CartoAFC <- cbind(sfDonneesAFC, dfAFCInd)
VP1pct <- tofr(round(res.afc$eig[1,2],2))
VP2pct <- tofr(round(res.afc$eig[2,2],2))
Carte1 <- tm_shape(CartoAFC) +
  tm_fill(col = "CoordComp1", style = "cont", midpoint = 0, title = 'Coordonnées')+
  tm_layout(title = paste0("Axe 1 (", VP1pct,"%)"), attr.outside = TRUE, frame = FALSE)
Carte2 <- tm_shape(CartoAFC) +
  tm_fill(col = "CoordComp2", style = "cont", midpoint = 0, title = 'Coordonnées')+
  tm_layout(title = paste0("Axe 2 (", VP2pct,"%)"), attr.outside = TRUE, frame = FALSE)
tmap_arrange(Carte1, Carte2, nrow = 1)
```          



::: {.bloc_aller_loin data-latex=""}
**Ajout de modalités supplémentaires dans une analyse des correspondances (AFC)**

Comme pour l'ACP, il est possible d'ajouter des variables et des individus supplémentaires une fois l'AFC calculée. En guise d'illustration, nous avons ajouté à l'AFC précédemment analysée des modalités relatives à la durée des temps de déplacements&nbsp;:	moins de 15 minutes, 15 à 29, 30 à 44, 45 à 59, 60 minutes et plus. Sans surprise, sur le premier plan factoriel à la figure&nbsp;\@ref(fig:afc1erplanfactInds2), cette dernière modalité, représentant les trajets les plus longs, est la plus proche des modalités relatives à l'usage des véhicules motorisés (`VehCond` et `VehPass`).

```{r afcAjoutModalites, echo=FALSE, fig.align='center', fig.cap="Ajout de modalités supplémentaires sur le premier plan factoriel de l'AFC", message=FALSE, auto_pdf=TRUE, dev="png", dpi=300, out.width='75%', quietly=TRUE, warn.conflicts=TRUE, fig.pos ="H"}
res.afc2 <- CA(dfDonneesAFC, col.sup = 7:11, graph = FALSE)
VP1pct <- tofr(round(res.afc2$eig[1,2],2))
VP2pct <- tofr(round(res.afc2$eig[2,2],2))
fviz_ca_col(res.afc2,
            repel = TRUE,
            geom= c("text","point"),
            col.col = "steelblue",
            title = "",
            xlab=paste0("Axe 1 (", VP1pct, " %)"),
            ylab=paste0("Axe 2 (", VP2pct, " %)"))
``` 

:::

### Mise en œuvre dans R {#sect1233}

#### Calcul d’une AFC avec `FactoMineR` {#sect12331}

Plusieurs *packages* permettent de calculer une AFC dans R, notamment `ca` (fonction `ca`), `MASS` (fonction `corresp`), `ade4` (fonction `dudi.coa`) et `FactoMineR` (fonction `CA`). De nouveau, nous utilisons `FactoMineR` couplé au *package* `factoextra` pour réaliser rapidement des graphiques avec les résultats pour les variables et les coordonnées.

Pour calculer l'AFC, il suffit d'utiliser la fonction `CA` de `FactoMineR`, puis la fonction `summary(res.afc)` qui renvoie les résultats de l'AFC pour&nbsp;: 

- Les valeurs propres (section `Eigenvalues`) pour les axes factoriels (`Dim.1` à `Dim.n`) avec leur variance expliquée brute (`Variance`), en pourcentage (`% of var.`) et en pourcentage cumulé (`Cumulative % of var.`).
- Les dix premières observations (section `Rows`) avec les coordonnées factorielles (`Dim.1` à `Dim.n`), les contributions (`ctr`) et les cosinus carrés (`cos2`). Pour accéder aux résultats pour toutes les observations, utilisez les fonctions `res.afc$row` ou encore `res.afc$row$coord` (uniquement les coordonnées factorielles), `res.afc$row$contrib` (uniquement les contributions) et `res.afc$row$cos2` (uniquement les cosinus carrés).
- Les colonnes (section `Columns`) avec les coordonnées factorielles (D`im.1` à `Dim.n`), les contributions (`ctr`) et les cosinus carrés (`cos2`).

```{r calculAFC, echo=TRUE, message=FALSE, warning=FALSE, out.width='75%'}
# Chargement des packages
library(FactoMineR)
library(factoextra)
# Chargement des données
load("data/analysesfactorielles/DonneesAFC.Rdata")
# Avant de calculer l'AFC, il convient de vérifier si les deux variables
# qualitatives sont dépendantes avec le test du khi-deux
khideux <- chisq.test(dfDonneesAFC[,1:6])
print(khideux)
if(khideux$p.value <=0.05){
  cat("La valeur de p < 0,05. Les variables sont dépendantes. Calculer l'AFC.")
}else {
    cat("La valeur de p > 0,05. Les variables sont indépendantes. Inutile de calculer l'AFC")
}

# Calcul de l'analyse des correspondances sur les six premières variables
res.afc <- CA(dfDonneesAFC[,1:6], graph=F)
# Affichage des résultats de la fonction CA
print(res.afc)
# Visualisation des marges en colonnes
round(res.afc$call$marge.col,4)
# Visualisation des marges en lignes. Étant donnée que nous avons 521 individus, 
# la ligne ci-dessous est en commentaire
# round(res.afc$call$marge.row,4)

# Sommaire des résultats de l'AFC
# Remarquez que la première ligne de ce sommaire est le résultat du khi-deux
summary(res.afc)

```

#### Exploration graphique des résultats de l'AFC avec `factoextra` {#sect12332}

Comme pour l'ACP, `factoextra` dispose de plusieurs fonctions très intéressantes pour construire rapidement des graphiques avec les résultats de l'AFC. Premièrement, la syntaxe ci-dessous (avec la fonction `fviz_screeplot`) renvoie deux graphiques pour analyser les résultats des valeurs propres de l'AFC (figure&nbsp;\@ref(fig:factoextraAFC1)).

```{r factoextraAFC1, echo=TRUE, fig.align='center', fig.cap="Graphiques pour les valeurs propres de l'AFC avec factoextra", quietly = TRUE, warn.conflicts = TRUE,   message=FALSE, auto_pdf=TRUE, out.width='65%', dev="png", dpi=300, fig.pos = "H"}
library(factoextra)
library(ggplot2)
library(ggpubr)

# Nombre de modalités en lignes et en colonnes
ModalitesLig <- nrow(dfDonneesAFC)
ModalitesCol <- ncol(dfDonneesAFC[,1:6])
# Critère statistique du profil moyen
critere2 <- round(1/(ModalitesCol-1)*100,2)
texte <- paste0("Critère pour le profil moyen : ", as.character(critere2), " %")
# Graphique avec les valeurs propres
G1 <- fviz_screeplot(res.afc, choice="eigenvalue",
               ylab="Valeurs propres",
               xlab="Axes factoriels",
               main="Valeurs propres")
G2 <- fviz_screeplot(res.afc, choice="variance", addlabels = TRUE, ylim = c(0, 70),
                     ylab="Variance expliquée (%)",
                     xlab="Axes factoriels",
                     main="Valeurs propres (%)")+
  geom_hline(yintercept = c2, linetype = 1, color = "red", size=1)+
  annotate(geom="text", x = ModalitesCol-.5,
          y= critere2+3, label=texte, 
          color="red", hjust = 1, size = 4)
ggarrange(G1, G2)
```

Avec les fonctions `fviz_contrib` et `fviz_cos2`, il est très facile de réaliser des histogrammes pour les contributions et les cosinus carrés pour les variables (colonnes) ou les individus (lignes), et ce avec le paramètre `choice = c("row", "col")` (figure&nbsp;\@ref(fig:acp1erplanfactVars2a)).

```{r acp1erplanfactVars2a, echo=TRUE, fig.align='center', fig.cap="Contributions des variables avec factoextra", message=FALSE, auto_pdf=TRUE, dev="png", dpi=300, out.width='65%', quietly=TRUE, warn.conflicts=TRUE, fig.pos = "H"}
library(factoextra)
library(ggplot2)
library(ggpubr)
VP1pct <- round(res.afc$eig[1,2],2)
VP2pct <- round(res.afc$eig[2,2],2)
G1 <- fviz_contrib (res.afc, choice = "col", axes = 1, title="Axe 1")
G2 <- fviz_contrib (res.afc, choice = "col", axes = 2, title="Axe 2")
ggarrange(G1, G2, ncol = 2, nrow = 1)
```

Quant aux fonctions `fviz_ca_col` et `fviz_ca_row`, elles permettent rapidement de construire le premier plan factoriel pour les colonnes (variables) et les lignes (individus) (figure&nbsp;\@ref(fig:afc1erplanfactVars2b)). Aussi, la fonction `fviz_ca_biplot` permet de construire un plan factoriel, mais avec les lignes et les colonnes simultanément.
 
```{r afc1erplanfactVars2b, echo=TRUE, fig.align='center', fig.cap="Premier plan factoriel de l'AFC pour les variables et les individus avec factoextra", message=FALSE, auto_pdf=TRUE, dev="png", dpi=300, out.width='65%', quietly=TRUE, warn.conflicts=TRUE, fig.pos = "H"}
G3 <- fviz_ca_col(res.afc,
            repel = TRUE,
            geom= c("text","point"),
            col.col = "steelblue",
            title = "Mode de transport",
            xlab=paste0("Axe 1 (", VP1pct, " %)"),
            ylab=paste0("Axe 2 (", VP2pct, " %)"))
G4 <- fviz_ca_row(res.afc,
            repel = TRUE,
            geom= c("point"),
            col.row = "steelblue",
            title = "Secteurs de recensement",
            xlab=paste0("Axe 1 (", VP1pct, " %)"),
            ylab=paste0("Axe 2 (", VP2pct, " %)"))
ggarrange(G3, G4, ncol = 2, nrow = 1)
```


La syntaxe ci-dessous permet d'ajouter des modalités supplémentaires dans l'AFC et de constuire le graphique du premier plan factoriel (figure&nbsp;\@ref(fig:afcAjoutModalites2)).

```{r afcAjoutModalites2, echo=TRUE, fig.align='center', fig.cap="Ajout de modalités supplémentaires sur le premier plan factoriel l'AFC avec factoextra", fig.pos="H", message=FALSE, auto_pdf=TRUE, dev="png", dpi=300, out.width='65%', quietly=TRUE, warn.conflicts=TRUE, fig.pos = "H"}
# Les colonnes 7 à 11 sont mises comme des variables supplémentaires dans l'AFC
res.afc2 <- CA(dfDonneesAFC, col.sup = 7:11, graph = FALSE)
VP1pct <- round(res.afc2$eig[1,2],2)
VP2pct <- round(res.afc2$eig[2,2],2)
fviz_ca_col(res.afc2,
            repel = TRUE,
            geom= c("text","point"),
            col.col = "steelblue",
            title = "",
            xlab=paste0("Axe 1 (", VP1pct, " %)"),
            ylab=paste0("Axe 2 (", VP2pct, " %)"))
``` 

Finalement, la syntaxe ci-dessous permet de cartographier les coordonnées factorielles des individus de l’ACF avec le *package* `tmap` (figure&nbsp;\@ref(fig:afc1erplanfactInds2B)).
 

```{r afc1erplanfactInds2B, echo=TRUE, fig.align='center', fig.cap="Cartographie de coordonnées factorielles des individus pour l'ACF", message=FALSE, auto_pdf=TRUE, dev="png", dpi=300, out.width='85%', quietly=TRUE, warn.conflicts=TRUE, fig.pos = "H"}
library(tmap)
library(stringr)
dfAFCInd <- data.frame(Coord = res.afc$row$coord, 
                       Cos2 = res.afc$row$cos2, 
                       Ctr = res.afc$row$contrib)
names(dfAFCInd) <- str_replace(names(dfAFCInd), ".Dim.", "Comp")
CartoAFC <- cbind(sfDonneesAFC, dfAFCInd)
VP1pct <- tofr(round(res.afc$eig[1,2],2))
VP2pct <- tofr(round(res.afc$eig[2,2],2))
Carte1 <- tm_shape(CartoAFC) +
  tm_fill(col = "CoordComp1", style = "cont", midpoint = 0, title = 'Coordonnées')+
  tm_layout(title = paste0("Axe 1 (", VP1pct,"%)"), attr.outside = TRUE, frame = FALSE)
Carte2 <- tm_shape(CartoAFC) +
  tm_fill(col = "CoordComp2", style = "cont", midpoint = 0, title = 'Coordonnées')+
  tm_layout(title = paste0("Axe 2 (", VP2pct,"%)"), attr.outside = TRUE, frame = FALSE)
tmap_arrange(Carte1, Carte2, nrow = 1)
```          


## Analyse de correspondances multiples (ACM) {#sect124}

L'analyse des correspondances multiples (ACM) est particulièrement adaptée à l'exploration de données issues d'une enquête par sondage, puisqu'elle permet de résumer/synthétiser l'information d'un tableau comprenant uniquement des variables qualitatives (figure&nbsp;\@ref(fig:AnalysesFactoriellesTabACMFig)). 

```{r AnalysesFactoriellesTabACMFig, fig.align='center', echo=FALSE, auto_pdf = TRUE, fig.cap="Tableau pour une ACM", out.width='60%'}
knitr::include_graphics('images/analysesfactorielles/AnalysesFactoriellesTabACM.png', dpi = NA)
```

Par exemple, une enquête sur la mobilité d'une population donnée pourrait comprend plusieurs variables qualitatives dont celles reportées au tableau&nbsp;\@ref(tab:TabACM1).

```{r TabACM1, echo=FALSE, message=FALSE, warning=FALSE, out.width='75%'}
library(kableExtra)
tabacm <- data.frame(Modalite = c("Homme","Femme", 
                                   "Moins de 20 ans", "20 à 39 ans", "40 à 59 ans", "60 ans et plus",
                                   "Automobile", "Transport en commun", "Marche", "Vélo"),
                    Code = c(1,2,1,2,3,4,1,2,3,4))
montableau <- show_table(tabacm, 
               caption = "Exemple de variables qualitatives issues d'une enquête",
               col.names=c("Modalités des variables","Codage"), align= c("l", "c") )

group_rows(montableau,
           index = c("Sexe" = 2,
                    "Groupe d'âge" = 4,
                    "Mode de transport"= 4))
```

Pour analyser de telles données, il suffit de transformer le tableau condensé (de données brutes) en un tableau disjonctif complet dans lequel chaque modalité des variables qualitatives devient une variable binaire prenant les valeurs de&nbsp;0 ou&nbsp;1 (tableaux \@ref(tab:TabACM2) et \@ref(tab:TabACM3)). Notez que la somme de chaque ligne est alors égale au nombre de variables qualitatives.

```{r TabACM2, echo=FALSE, message=FALSE, warning=FALSE, out.width='75%'}
library(kableExtra)
tabs <- data.frame(V1 = c(1,1,2,1,2,1),
                   V2 = c(1,2,3,2,4,4),
                   V3 = c(2,3,1,1,2,4))
# Sexe
tabs$Homme <- ifelse(tabs$V1 == 1, 1, 0)
tabs$Femme <- ifelse(tabs$V1 == 2, 1, 0)
# Age
tabs$A20m  <- ifelse(tabs$V2 == 1, 1, 0)
tabs$A2039 <- ifelse(tabs$V2 == 2, 1, 0)
tabs$A4059 <- ifelse(tabs$V2 == 3, 1, 0)
tabs$A60p  <- ifelse(tabs$V2 == 4, 1, 0)
# Mode de transport
tabs$Auto  <- ifelse(tabs$V3 == 1, 1, 0)
tabs$TC    <- ifelse(tabs$V3 == 2, 1, 0)
tabs$Apied <- ifelse(tabs$V3 == 3, 1, 0)
tabs$Velo  <- ifelse(tabs$V3 == 4, 1, 0)
rownames(tabs) <- paste0("Ind. ", c(1:nrow(tabs)))
tabCond <- tabs[,1:3]
show_table(tabCond, 
           row.names = TRUE,
           caption = "Tableau condensé (données brutes)",
           col.names=c("Sexe","Groupe d'âge", "Mode de transport"), 
           align= c("c","c","c"),
           position = "HOLD_position")
```

```{r TabACM3, echo=FALSE, message=FALSE, warning=FALSE, out.width='75%'}
library(kableExtra)
tabDisjComplet <- tabs[,4:13]
tabDisjComplet$Ind <- row.names(tabDisjComplet)
tabDisjComplet <- tabDisjComplet[,c(11,1:10)]

montableau <-show_table(tabDisjComplet,
               caption = "Tableau disjonctif complet",
               col.names=c("Individu", "Homme","Femme", 
                           "Moins de 20 ans", "20 à 39 ans", "40 à 59 ans", "60 ans et plus",
                           "Auto.", "T.C.", "Marche", "Vélo"), 
                align= c("c","c","c","c",
                         "c","c","c","c"),
               position = "HOLD_position")
add_header_above(montableau, c(" " = 1,"Sexe" = 2, "Groupe d'âge" = 4, "Mode de transport" = 4))
```

::: {.bloc_astuce data-latex=""}
**ACM versus AFC**

Nous avons vu que l'AFC permet d'analyser un tableau de contingence avec deux variables qualitatives. En ACM, les colonnes sont alors les différentes modalités des variables qualitatives et les lignes sont les observations (par exemple, les individus ayant répondu à une enquête par sondage). En résumé, l'analyse des correspondances multiples (ACM) est simplement **une analyse des correspondances (AFC) appliquée sur un tableau disjonctif complet**. 

L'ACM permet ainsi de révéler les ressemblances entre les différentes modalités des variables qualitatives et les ressemblances entre les différents individus. Par conséquent, elle produit également des variables synthétiques (axes factoriels) résumant l'information contenue dans le tableau initial. L'évaluation de ces ressemblances et la détermination des axes factoriels sont aussi basées sur la **distance du khi-deux**.

::: 


### Aides à l'interprétation {#sect1241}

Puisque l'ACM est une extension de l'AFC, nous retrouvons les mêmes aides à l'interprétation&nbsp;: les valeurs propres pour les axes, les coordonnées factorielles, les contributions et les cosinus carrés pour les variables et les individus. 

Pour présenter l'ACM, nous utilisons des données ouvertes de la Ville de Montréal et plus particulièrement un [sondage auprès de la population de l’île de Montréal sur l'agriculture urbaine](https://www.donneesquebec.ca/recherche/dataset/vmtl-agriculture-urbaine-sondage){target='_blank'}. Pour ce faire, nous avons conservé uniquement les personnes pratiquant l'agriculture urbaine (n&nbsp;=&nbsp;352). Les variables qualitatives extraites pour l'ACM sont reportées au tableau&nbsp;\@ref(tab:dataACM) avec la description des questions, leurs modalités respectives avec les effectifs bruts et en pourcentage. Au final, l'ACM est calculée de la manière suivante&nbsp;:

- Neuf variables qualitatives relatives à la pratique de l'agriculture urbaine sont retenues (`q3`, `q4`, `q5`, `q8`, `q9`, `q10`, `q11`, `q12` et `q13`).
- Quatre variables relatives au profil socioéconomique des personnes répondantes sont introduites comme variables supplémentaires (`q15`, `q16`, `q17`, `q21`).
- Chaque ligne est pondérée avec la variable `pond`.

L'objectif est de cette ACM double&nbsp;: 

1. Montrer les ressemblances entre les différentes modalités relatives à la pratique de l'agriculture urbaine. L'analyse des axes factoriels devrait nous permettre d'identifier différents profils des personnes pratiquant l'agriculture urbaine.
2. Projeter les modalités des variables socioéconomiques afin de vérifier si elles sont ou non associées aux axes factoriels, c'est-à-dire aux différents profils révélés par les axes.

::: {.bloc_attention data-latex=""}

L'analyse du sondage sur l'agriculture urbaine réalisée ici est purement exploratoire&nbsp;: elle vise uniquement à démonter que l'ACM est un outil particulièrement intéressant pour analyser les données d'un sondage. Par contre, cette analyse n'a aucune prétention scientifique puisque nous ne sommes pas des spécialistes de l'agriculture urbaine. Dans ce champ de recherche très fertile qu'est l'agriculture urbaine (surement pas la meilleure blague du livre...), vous pourrez consulter plusieurs études montréalaises [@mcclintock2018urban; @audate2021motivations; @bhatt2016cultivating].

:::


```{r dataACM, echo=FALSE, message=FALSE, warning=FALSE, out.width='75%'}
library(kableExtra)
load("data/analysesfactorielles/DonneesACM.Rdata")
dfACM <- dfenquete[,c("q3", "q4", "q5", "q8", "q9", "q10", "q11", "q12", "q13",
                      "q15", "q16", "q17", "q21")]
questions <- c(
"Q3.  Depuis combien de temps cultivez-vous des fruits, des fines herbes ou des légumes?",
"Q4.  Selon vous, quelle proportion des fruits, des fines herbes et des légumes que vous consommez durant l'été provient de votre propre production?",
"Q5.  Utilisez-vous du compost provenant de vos déchets verts ou de vos déchets alimentaires pour faire pousser des fruits, des fines herbes ou des légumes?",
"Q8.  Récupérez-vous l'eau de pluie pour irriguer vos cultures de fruits, de fines herbes ou des légumes ou encore votre jardin?",
"Q9.  Combien de sortes de fruits, de fines herbes ou des légumes cultivez-vous?",
"Q10. Cultivez-vous suffisamment de fruits, de fines herbes ou des légumes pour partager avec d'autres personnes?",
"Q11. Échangez-vous vos semis ou vos récoltes de fruits, de fines herbes ou des légumes avec d'autres personnes?",
"Q12. Selon vous, l'agriculture urbaine contribue-t-elle à améliorer les rapports entre les gens?",
"Q13. Saviez-vous que la Ville de Montréal encourage et soutient l'agriculture urbaine sur l'île de Montréal?",
"Q15. À quel groupe d'âge appartenez-vous?",
"Q16. Quelle est votre occupation principale?",
"Q17. Quel est le plus haut niveau de scolarité que vous avez complété?",
"Q21. Êtes-vous propriétaire ou locataire de votre résidence ?"
)

modalites <- c()
nmodalites <- c()
nimodalites <- c()
i <- 0
for (e in names(dfACM)){
  # Nombre de modalités par questions
  i <- i + 1
  nmodalites[i] <- length(unique(dfACM[[e]]))
  nimodalites <- append(nimodalites, table(dfACM[[e]]))
  modalites <- append(modalites, levels(dfACM[[e]]))
}

DesTabACM <- data.frame(Modalite=modalites, N=nimodalites, Pct=round(nimodalites/nrow(dfACM)*100,1))

montableau <-show_table(DesTabACM,
               caption = "Variables qualitatives extraites du sondage sur l'agriculture urbaine de la Ville de Montréal",
               col.names=c("Modalité", "N","%"),
               align= c("l","r","r"))

group_rows(montableau,
           index = c(
  "Q3.  Depuis combien de temps cultivez-vous des fruits, des fines herbes ou des légumes?" = nmodalites[1],
  "Q4.  Selon vous, quelle proportion des fruits, des fines herbes et des légumes que vous consommez durant l'été provient de votre propre production?" = nmodalites[2],
  "Q5.  Utilisez-vous du compost provenant de vos déchets verts ou de vos déchets alimentaires pour faire pousser des fruits, des fines herbes ou des légumes?" = nmodalites[3],
  "Q8.  Récupérez-vous l'eau de pluie pour irriguer vos cultures de fruits, de fines herbes ou des légumes ou encore votre jardin?" = nmodalites[4],
  "Q9.  Combien de sortes de fruits, de fines herbes ou des légumes cultivez-vous?" = nmodalites[5],
  "Q10. Cultivez-vous suffisamment de fruits, de fines herbes ou des légumes pour partager avec d'autres personnes?" = nmodalites[6],
  "Q11. Échangez-vous vos semis ou vos récoltes de fruits, de fines herbes ou des légumes avec d'autres personnes?" = nmodalites[7],
  "Q12. Selon vous, l'agriculture urbaine contribue-t-elle à améliorer les rapports entre les gens?" = nmodalites[8],
  "Q13. Saviez-vous que la Ville de Montréal encourage et soutient l'agriculture urbaine sur l'île de Montréal?" = nmodalites[9],
  "Q15. À quel groupe d'âge appartenez-vous?" = nmodalites[10],
  "Q16. Quelle est votre occupation principale?" = nmodalites[11],
  "Q17. Quel est le plus haut niveau de scolarité que vous avez complété?" = nmodalites[12],
  "Q21. Êtes-vous propriétaire ou locataire de votre résidence ?" = nmodalites[13]
))
```
  
  
#### Résultats de l'ACM pour les valeurs propres {#sect12411}

Les résultats pour les valeurs propres sont reportés au tableau&nbsp;\@ref(tab:ACMValeursPropresTab) et à la figure&nbsp;\@ref(fig:ACMValeursPropresFig).
En ACM, l'inertie totale du tableau des variables qualitatives est égale au nombre moyen de modalités par variable moins un, soit $\frac{K}{J}-1$ avec *K* et *J* étant respectivement les nombres de modalités et de variables. Aussi, le nombre d'axes produits par l'ACM est égal à $K - J$. Pour notre tableau, l'inertie est donc égale à $\mbox{25} / \mbox{9} = \mbox{1,77}$ avec $\mbox{25}-\mbox{9} = \mbox{16}$ axes. Le nombre d'axes à retenir est souvent plus difficile à déterminer puisque tel que signalé judicieusement par Jérôme Pagès [-@pages2002analyse, p.53] : «&nbsp;en pratique, comparée à l'ACP, l'ACM conduit, dans l'ensemble à&nbsp;: des pourcentages d'inertie plus petits; une décroissance de ces pourcentages plus douce&nbsp;».

L'histogramme des valeurs propres (figure&nbsp;\@ref(fig:ACMValeursPropresFig)) révèle plusieurs sauts importants dans les valeurs propres qui pourraient justifier le choix du nombre d'axes factoriels, soit aux axes&nbsp;1, 2, 3 et&nbsp;6. Pour l'exercice, nous retenons les trois premiers axes qui résument 30&nbsp;% de l'inertie du tableau initial.

```{r ACMValeursPropresTab, echo=FALSE, message=FALSE, warning=FALSE, out.width='75%'}
library(FactoMineR)
# Calcul de l'AFC
res.acm <-  MCA(dfACM, ncp = 5, quali.sup=10:13, graph = FALSE, row.w = dfenquete$pond)

# Construction d'un DataFrame pour les valeurs propres
dfACMvp <- data.frame(res.acm$eig)
names(dfACMvp) <- c("VP","VP_pct","VP_pctCumul")
dfACMvp$Axe <- factor(1:nrow(dfACMvp), levels=rev(1:nrow(dfACMvp)))
dfACMvp <- dfACMvp[,c(4,1:3)]

show_table(dfACMvp,
           digits = 3,
            caption = "Résultats de l'ACM pour les valeurs propres",
           col.names=c("Axe factoriel","Valeur propre","Pourcentage", "Pourc. cumulé"),
           align= c("r", "r","r", "r")
           )
```

```{r ACMValeursPropresFig, echo=FALSE, fig.align='center', fig.cap="Graphiques pour les valeurs propres pour l'ACM", auto_pdf=TRUE, dev="png", dpi=300, out.width='75%'}
library(ggplot2)
library(ggpubr)
g1 <- ggplot(dfACMvp,aes(x=VP, y=Axe))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black", fill="skyblue2")+
  labs(x="Valeur propre", y="Axe factoriel")
g2 <- ggplot(dfACMvp, aes(x=VP_pct, y=Axe))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black", fill="skyblue2")+
  theme(legend.position="none")+
  labs(x="Variance expliquée (%)", y="")
g3 <- ggplot(dfACMvp, aes(x=VP_pctCumul, y=Axe, group=1))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black", fill="skyblue2")+
  geom_line(colour="brown", linetype="solid", size=.8) +
  geom_point(size=3, shape=21, color="brown", fill="brown")+
  theme(legend.position="none")+
  labs(x="Variance expliquée (% cumulé)", y="Axe factoriel")
ggarrange(g2, g3,  nrow = 2)
```

#### Résultats de l'ACM pour les modalités des variables {#sect12412}

À titre de rappel, comme pour l’ACP et l'AFC, nous retrouvons les trois mêmes mesures pour les variables et les individus (coordonnées factorielles, contributions et cosinus carrés). Plus les variables qualitatives du jeu données comprennent de modalités, plus la taille du tableau des résultats des modalités sera importante et plus il est fastidieux de l'analyser. Il est donc recommandé de construire des histogrammes avec les coordonnées factorielles et les contributions des modalités, mais aussi un nuage de points avec les coordonnées des modalités des variables qualitatives sur le premier voire le deuxième plan factoriel.

::: {.bloc_objectif data-latex=""}
**Compréhension des axes factoriels de l'ACM&nbsp;: une étape essentielle, incontournable...**

Comme en ACP et en AFC, l'analyse des trois mesures (coordonnées, contributions et cosinus carrés) pour les variables et les individus doit vous permettre de comprendre la signification des axes factoriels retenus de l'ACM. Prenez le temps de bien réaliser cette étape d'interprétation souvent plus fastidieuse qu'en ACP et ACM, en raison du nombre élevé de modalités. Cette étape est en effet essentielle afin de qualifier les variables latentes (axes factoriels, variables synthétiques) produites par l'ACM.
:::

Les résultats pour les variables sont reportés 1) au tableau&nbsp;\@ref(tab:ACMValeursCoordTab), 2) aux figure&nbsp;\@ref(fig:ACMValeursCoordFig1), \@ref(fig:ACMValeursCoordFig2) et \@ref(fig:ACMValeursCoordFig3) pour les coordonnées et les contributions et à la figure&nbsp;\@ref(fig:ACMValeursPlanFacto1) pour le premier plan factoriel.


**Interprétation des résultats de l'axe&nbsp;1 pour les variables**

Sept modalités concourent le plus à la formation de l'axe&nbsp;1 résumant 13,9&nbsp;% de la variance&nbsp;: `Q9. 10 à 14 sortes` (10,35&nbsp;%), `Q10. Oui`	(9,99&nbsp;%), `Q9. Moins de 5 sortes` (9,71&nbsp;%), `Q5. Oui`	(9,19&nbsp;%), `Q11. Oui` (8,20&nbsp;%), `Q4. Moins de 10%`	(7,87&nbsp;%) et `Q10. Non` (7,10&nbsp;%). Aussi, les modalités suivantes sont aux deux extrémités de cet axe&nbsp;:

* **Coordonnées négatives**&nbsp;:  `Q12. Non` (-0,84), `Q3. Moins de 1 an`  (-0,73), `Q9. Moins de 5 sortes` (-0,67), `Q4. Moins de 10%` (-0,56), `Q10. Non` (-0,521). Cela signifie que lorsque les coordonnées des individus sont fortement négatives sur cet axe, les personnes pratiquant l'agriculture urbaine&nbsp;: 
    + *ne pensent pas que l'agriculture urbaine contribue à améliorer les rapports entre les gens* (`Q12`);
    + *cultivent des fruits, des fines herbes ou des légumes depuis moins d'un an* (`Q3`);
    + *cultivent moins de cinq sortes de fruits, de fines herbes ou de légumes* (`Q9`);
    + *moins de 10&nbsp;% de leur proportion des fruits, des fines herbes et des légumes consommés durant l’été provient de votre propre production *(`Q4`);
    + *ne cultivent pas suffisamment pour partager avec d'autres personnes* (`Q10`).
    
* **Coordonnées positives**&nbsp;: `Q9. 15 sortes ou plus` (1,36), `Q9. 10 à 14 sortes` (1,28), `Q5. Oui` (0,95) et `Q11. Oui` (0,85). Cela signifie que lorsque les coordonnées des individus sont fortement positives sur cet axe, les personnes pratiquant l'agriculture urbaine&nbsp;:
    + *cultivent plus de dix sortes de fruits, de fines herbes ou de légumes* (`Q9`);
    + *utilisent du compost provenant de leurs déchets verts ou de leurs déchets alimentaires pour faire pousser des fruits, des fines herbes ou des légumes* (`Q5`);
    + *échangent leurs semis ou leurs récoltes de fruits, de fines herbes ou des légumes avec d’autres personnes* (`Q11`).

En résumé, l'axe&nbsp;1 oppose clairement les **«&nbsp;néophytes en agriculture&nbsp;»** versus les **personnes expérimentées** cultivant des fruits et légumes variés avec leur propre compost et échangeant leurs semis ou récoltes.


```{r ACMValeursCoordTab, echo=FALSE, message=FALSE, warning=FALSE, out.width='75%'}
library(kableExtra)
library(stringr)
nAxes <- 3
dfmodalites <- data.frame(Modalite =rownames(res.acm$var$coord),
                           Coord = round(res.acm$var$coord[, 1:nAxes],2),
                           ctr = round(res.acm$var$contrib[, 1:nAxes],2),
                           Cos2 = round(res.acm$var$cos2[, 1:nAxes],2))
rownames(dfmodalites) <- 1:nrow(dfmodalites)
names(dfmodalites) <- str_replace(names(dfmodalites), ".Dim.", "F")

montableau <- show_table(dfmodalites,
                   digits = 2,
                   caption = "Résultats de l'ACM pour les modalités des variables",
                   col.names=c("Modalité","1","2","3","1","2","3","1","2","3"),
                   align= c("l","r","r","r","r","r","r","r","r","r")
                   )
add_header_above(montableau, c(" " = 1, "Coordonnées" = 3, "Cosinus carrés" = 3, "Contributions (%)" = 3))
```

```{r ACMValeursCoordFig1, echo=FALSE, fig.align='center', fig.cap="Graphiques pour les résultats des modalités de l'axe 1 de l'ACM", auto_pdf=TRUE, dev="png", dpi=300, fig.pos="H", out.width='90%'}
# Histogrammes pour les coordonnées des modalités
couleursCoords <- c("lightsalmon","steelblue")
plotCoordF1 <- ggplot(dfmodalites,
                      aes(y = reorder(Modalite, CoordF1),
                          x = CoordF1, fill=CoordF1<0))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black")+
  geom_vline(xintercept=0, color = "black", size=1)+
  scale_fill_manual(name="Coordonnée",values=couleursCoords,
                    labels = c("Positive","Négative"))+
  labs(x="Coordonnées sur l'axe 1", y="Modalité")+
  theme(legend.position="none", axis.text.y = element_text(size = 7))

plotCoordF2 <- ggplot(dfmodalites,
                      aes(y = reorder(Modalite, CoordF2),
                          x = CoordF2, fill=CoordF2<0))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black")+
  geom_vline(xintercept=0, color = "black", size=1)+
  scale_fill_manual(name="Coordonnée",values=couleursCoords,
                    labels = c("Positive","Négative"))+
  labs(x="Coordonnées sur l'axe 2", y="Modalité")+
  theme(legend.position="none", axis.text.y = element_text(size = 7))

plotCoordF3 <- ggplot(dfmodalites,
                      aes(y = reorder(Modalite, CoordF3),
                          x = CoordF3, fill=CoordF3<0))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black")+
  geom_vline(xintercept=0, color = "black", size=1)+
  scale_fill_manual(name="Coordonnée", values=couleursCoords,
                    labels = c("Positive","Négative"))+
  labs(x="Coordonnées sur l'axe 3", y="Modalité")+
  theme(legend.position="none", axis.text.y = element_text(size = 7))


plotCtrF1 <- ggplot(dfmodalites, aes(y = reorder(Modalite, ctrF1), x = ctrF1))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black", fill="steelblue")+
  labs(x="Contributions sur l'axe 1", y="Modalité")+
  theme(legend.position="none", axis.text.y = element_text(size = 7))

plotCtrF2 <- ggplot(dfmodalites, aes(y = reorder(Modalite, ctrF2), x = ctrF2))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black", fill="steelblue")+
  labs(x="Contributions sur l'axe 2", y="Modalité")+
  theme(legend.position="none",
        axis.text.y = element_text(size = 7))

plotCtrF3 <- ggplot(dfmodalites, aes(y = reorder(Modalite, ctrF3), x = ctrF3))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black", fill="steelblue")+
  labs(x="Contributions sur l'axe 3", y="Modalité")+
  theme(legend.position="none", axis.text.y = element_text(size = 7))

ggarrange(plotCoordF1, plotCtrF1, ncol = 1, nrow = 2)
```


**Interprétation des résultats de l'axe&nbsp;2 pour les variables**

Quatre modalités concourent le plus à la formation de l'axe&nbsp;2 résumant 8,8&nbsp;% de la variance&nbsp;: `Q3. De 1 à 4 ans` (15,30&nbsp;%), `Q9. 15 sortes ou plus`	(14,42&nbsp;%), `Q11. Oui`	(12,45&nbsp;%) et `Q9. 10 à 14 sortes`	(9,42&nbsp;%). Les modalités suivantes sont présentes aux deux extrémités de l'axe&nbsp;2&nbsp;:

- **Coordonnées négatives**&nbsp;:  `Q9. 10 à 14 sortes` (-0,97), `Q11. Oui` (-0,83), `Q3. De 1 à 4 ans` (-0,79), `Q4. 10 à 25%` (-0,76). Cela signifie que lorsque les coordonnées des individus sont fortement négatives sur cet axe, les personnes pratiquant l'agriculture urbaine&nbsp;:  
    + *cultivent de 10 à 14 sortes de fruits, de fines herbes ou de légumes* (`Q9`); 
    + *échangent leurs semis ou leurs récoltes de fruits, de fines herbes ou des légumes avec d’autres personnes* (`Q11`);
    + *cultivent des fruits, des fines herbes ou des légumes depuis 1 à 4 ans* (`Q3`);
    + *de 10 à 25&nbsp;% de leur proportion des fruits, des fines herbes et des légumes consommés durant l’été provient de votre propre production *(`Q4`).

- **Coordonnées positives**&nbsp;: seule la modalité `Q9. 15 sortes ou plus` (2,15) présente une forte coordonnée positive.

**En résumé, l'axe&nbsp;2** permet surtout d'identifier des personnes pratiquant l'agriculture urbaine depuis quelques années (de 1 à 4 ans), mais cultivant déjà de nombreuses sortes de fruits et légumes et partageant aussi leurs semis ou récoltes.


```{r ACMValeursCoordFig2, echo=FALSE, fig.align='center', fig.cap="Graphiques pour les résultats des modalités de l'axe 2 de l'ACM", auto_pdf=TRUE, dev="png", dpi=300, out.width='90%'}
# Histogrammes pour les coordonnées des modalités
ggarrange(plotCoordF2, plotCtrF2, ncol = 1, nrow = 2)
```

```{r ACMValeursPlanFacto1, echo=FALSE, fig.align='center', fig.cap="Premier plan factoriel de l'ACM pour les modalités", auto_pdf=TRUE, dev="png", dpi=300, out.width='75%'}
res.acm2 <-  MCA(dfACM[1:9], ncp = 3, graph = FALSE, row.w = dfenquete$pond)
fviz_mca_var(res.acm2, repel = TRUE,
             choice="var.cat",
             axes = c(1, 2),
             # col.var = "black",
             title="", xlab="Axe 1", ylab="Axe 2",
             ggtheme = theme_minimal ())
```

**Interprétation des résultats de l'axe&nbsp;3 pour les variables**

Trois modalités concourent le plus à la formation de l'axe&nbsp;3 résumant 7,6&nbsp;% de la variance&nbsp;: `Q8. Oui`  (23,31), `Q3. De 5 à 9 ans`  (19,43) et `Q9. 5 à 9 sortes`  (17,31). Les modalités suivantes sont présentes aux deux extrémités de l'axe&nbsp;3&nbsp;:

- **Coordonnées négatives**&nbsp;: `Q3. De 5 à 9 ans` (-1,11), `Q9. 5 à 9 sortes` (-0,79). 
- **Coordonnées positives**&nbsp;: seule la modalité `Q8. Oui` présente une coordonnée fortement positive (1,21).

Par conséquent, cet axe semble plus complexe à analyser et surtout moins intéressant que les deux premiers.


```{r ACMValeursCoordFig3, echo=FALSE, fig.align='center', fig.cap="Graphiques pour les résultats des modalités de l'axe 3 de l'ACM", auto_pdf=TRUE, dev="png", dpi=300, out.width='100%'}
# Histogrammes pour les coordonnées des modalités
ggarrange(plotCoordF3, plotCtrF3, ncol = 1, nrow = 2)
```


**Analyse des variables supplémentaires dans l'ACM**

Il est ensuite possible de projeter les modalités supplémentaires sur les axes de l'ACM retenus (tableau&nbsp;\@ref(tab:ACMValeursCoordSupplTab) et figure&nbsp;\@ref(fig:ACMValeursPlanFactoSupp1)). Les faibles valeurs des coordonnées factorielles des modalités supplémentaires sur les deux axes semblent indiquer que le profil socioéconomique des personnes pratiquant l'agriculture urbaine ne semble pas (ou peu) relié aux profils identifiés par les axes factoriels.

```{r ACMValeursCoordSupplTab, echo=FALSE, message=FALSE, warning=FALSE, out.width='75%'}
library(kableExtra)
library(stringr)
nAxes <- 2
dfmodalsuppl <- data.frame(Modalite =rownames(res.acm$quali.sup$coord),
                           Coord = round(res.acm$quali.sup$coord[, 1:nAxes],2),
                           cos2 = round(res.acm$quali.sup$cos2[, 1:nAxes],2))
rownames(dfmodalsuppl) <- 1:nrow(dfmodalsuppl)
names(dfmodalsuppl) <- str_replace(names(dfmodalsuppl), ".Dim.", "F")

montableau <- show_table(dfmodalsuppl,
                   digits = 2,
                   caption = "Résultats de l'ACM pour les modalités des variables supplémentaires",
                   col.names=c("Modalité","1","2","1","2"),
                   align= c("l","r","r","r","r")
                   )
add_header_above(montableau, c(" " = 1, "Coordonnées" = 2, "Cosinus carrés" = 2))
```

```{r ACMValeursPlanFactoSupp1, echo=FALSE, fig.align='center', fig.cap="Premier plan factoriel de l'ACM avec toutes les modalités incluant celles supplémentaires", message=FALSE, warning=FALSE, auto_pdf=TRUE, dev="png", dpi=300, out.width='100%'}
fviz_mca_var(res.acm, repel = TRUE,
             choice="var.cat",
             axes = c(1, 2),
             col.var = "gray23",
             col.quali.sup = "darkred",
             labelsize = 3,
             title="", xlab="Axe 1", ylab="Axe 2", 
             ggtheme = theme_minimal ())
```

::: {.bloc_astuce data-latex=""}
**Visualisation de variables qualitatives ordinales sur un plan factoriel**

Lorsque les variables qualitatives sont ordinales et non nominales, il peut être intéressant de relier les différentes modalités avec une ligne. Cela permet de comprendre en un coup d'œil la trajectoire que suivent les modalités sur les deux axes factoriels. En guise d'exemple, nous réalisons cet exercice pour les variables `Q3` et `Q9` (figure&nbsp;\@ref(fig:ACMordinaleTrajectoire)).

```{r ACMordinaleTrajectoire, echo=FALSE, fig.align='center', fig.cap="Trajectoires des variables ordinales sur le premier plan factoriel de l'ACM ", auto_pdf=TRUE, dev="png", dpi=300, fig.pos="H",out.width='70%'}
library(ggpubr)
Q3 <- dfmodalites[1:4, 1:3]
Q9 <- dfmodalites[13:16, 1:3]
G1 <- ggplot(Q3, aes(x=CoordF1, y=CoordF2, label=Modalite))+
  xlim(-1, .75)+ylim(-1, 1)+
  labs(title = "Q3. Depuis combien de temps cultivez-vous \ndes fruits, des fines herbes ou des légumes?",
       x="Axe 1", y="Axe 2")+
  geom_label(nudge_x=0, nudge_y=0.07) +
  geom_line( color="black", size=.2)+
  geom_point(shape=21, color="black", fill="steelblue", size=4)
G2 <- ggplot(Q9, aes(x=CoordF1, y=CoordF2, label=Modalite))+
  xlim(-1, 1.75)+ylim(-1, 2.3)+
  labs(title = "Q9. Combien de sortes de fruits, de fines \nherbes ou des légumes cultivez-vous?",
       x="Axe 1", y="Axe 2")+
  geom_label(nudge_x=0, nudge_y=0.07) +
  geom_line( color="black", size=.2)+
  geom_point(shape=21, color="black", fill="steelblue", size=4)
ggarrange(G1, G2, nrow=2)
```

:::

#### Résultats de l'ACM pour les individus {#sect12413}

Comme toute méthode factorielle, les coordonnées factorielles, les cosinus carrés et les contributions sont aussi disponibles pour les individus en ACM. Nous proposons ici simplement de réaliser le premier plan factoriel pour les individus en attribuant un dégradé de couleurs avec les cosinus carrés (figure&nbsp;\@ref(fig:ACMValeursPlanFactoSupp1)). Il est aussi possible d'attribuer des couleurs aux différentes modalités d'une variable. Par exemple, sur le premier plan factoriel, nous avons utilisé la variable `Q12. Selon vous, l’agriculture urbaine contribue-t-elle à améliorer les rapports entre les gens?`. Cela permet de repérer visuellement que les personnes ayant répondu négativement à cette question ont surtout des coordonnées négatives sur l'axe&nbsp;1.

```{r ACMPlanFacto12Ind1, echo=FALSE, fig.align='center', fig.cap="Premier plan factoriel de l'ACM pour les individus", message=FALSE, warning=FALSE, auto_pdf=TRUE, dev="png", dpi=300, out.width='100%'}
fviz_mca_ind(res.acm, col.ind = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE,
             xlab="Axe 1", ylab="Axe 2", title="",
             ggtheme = theme_minimal())
```

```{r ACMPlanFacto12Ind2, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center', fig.cap="Premier plan factoriel de l'ACM pour les individus avec coloration d'une variable", auto_pdf=TRUE, dev="png", dpi=300, out.width='100%'}
fviz_mca_ind (res.acm,
              label = "none",
              habillage = "q12", # colorer par groupes
             xlab="Axe 1", ylab="Axe 2", title="",
              palette = c ("darkred", "steelblue", "gray23"),
              ggtheme = theme_minimal ())
```

### Mise en œuvre dans R {#sect1242}

#### Calcul d’une ACM avec `FactoMineR` {#sect12421}

Plusieurs *packages* permettent de calculer une ACM dans R, notamment `ExPosition` (fonction `epMCA`), `ade4` (fonction `dudi.mca`) et `FactoMineR` (fonction `MCA`). De nouveau, nous utilisons `FactoMineR` couplé au *package* `factoextra` pour réaliser rapidement des graphiques.

Pour calculer l'ACM, il suffit d'utiliser la fonction `MCA` de `FactoMineR`, puis la fonction `summary(res.acm)` qui renvoie les résultats de l'AFC pour&nbsp;: 

- Les valeurs propres (section `Eigenvalues`) pour les axes factoriels (`Dim.1` à `Dim.n`) avec leur variance expliquée brute (`Variance`), en pourcentage (`% of var.`) et en pourcentage cumulé (`Cumulative % of var.`).
- Les dix premières observations (section `Individuals`) avec les coordonnées factorielles (`Dim.1` à `Dim.n`), les contributions (`ctr`) et les cosinus carrés (`cos2`). Pour accéder aux résultats pour toutes les observations, utilisez les fonctions `res.acm$ind` ou encore `res.acm$ind$coord` (uniquement les coordonnées factorielles), `res.acm$ind$contrib` (uniquement les contributions) et `res.acm$ind$cos2` (uniquement les cosinus carrés).
- Les dix premières modalités des variables (section `Categories`) avec les coordonnées factorielles (D`im.1` à `Dim.n`), les contributions (`ctr`) et les cosinus carrés (`cos2`).

La syntaxe ci-dessous permet dans un premier temps de calculer l'ACM, puis de créer un *DataFrame* pour les résultats des valeurs propres.

```{r ACMCodePartie1VPa, echo=TRUE, message=FALSE, warning=FALSE, out.width='75%'}
library(FactoMineR)
# Calcul de l'AFC
res.acm <-  MCA(dfACM,            # Nom du DataFrame
                ncp = 3,          # Nombre d'axes retenus
                quali.sup=10:13,  # Variables supplémentaires
                graph = FALSE, 
                row.w = dfenquete$pond) # Variables pour la pondération des lignes
# Affichage des résultats
print(res.acm)
summary(res.acm)
# Construction d'un DataFrame pour les valeurs propres
dfACMvp <- data.frame(res.acm$eig)
names(dfACMvp) <- c("VP","VP_pct","VP_pctCumul")
dfACMvp$Axe <- factor(1:nrow(dfACMvp), levels=rev(1:nrow(dfACMvp)))
dfACMvp <- dfACMvp[,c(4,1:3)]
```

#### Exploration graphique des résultats de l'ACM pour les valeurs propres {#sect124212}

Pour créer un histogramme des valeurs propres de l'ACM, vous pouvez utiliser la fonction `fviz_screeplot` de `factoextra`.

```{r ACMCodePartie1VPb, echo=TRUE, fig.align='center', fig.cap="Graphiques pour les valeurs propres de l'ACM avec factoextra", quietly = TRUE, warn.conflicts = TRUE,   message=FALSE, auto_pdf=TRUE, out.width='75%', dev="png", dpi=300}
library(factoextra)
library(ggplot2)

fviz_screeplot(res.acm, addlabels = TRUE,
               x="Composantes", y="Valeur propre", title="")
```

Avec un peu plus de lignes de code, il est relativement facile d'exploiter le *DataFrame* des valeurs propres créé précédemment (`dfACMvp`), pour construire des graphiques plus personnalisés.

```{r ACMCodePartie1VPc, echo=TRUE, fig.align='center', fig.cap="Graphiques pour les valeurs propres de l'ACM avec factoextra", quietly = TRUE, warn.conflicts = TRUE,   message=FALSE, auto_pdf=TRUE, out.width='75%', dev="png", dpi=300}
library(factoextra)
library(ggplot2)

couleursAxes <- c("steelblue","skyblue2")
g1 <- ggplot(dfACMvp,aes(x=VP, y=Axe))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black", fill="skyblue2")+
  labs(x="Valeur propre", y="Axe factoriel")
g2 <- ggplot(dfACMvp, aes(x=VP_pct, y=Axe))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black", fill="skyblue2")+
  theme(legend.position="none")+
  labs(x="Variance expliquée (%)", y="")
g3 <- ggplot(dfACMvp, aes(x=VP_pctCumul, y=Axe, group=1))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black", fill="skyblue2")+
  geom_line(colour="brown", linetype="solid", size=.8) +
  geom_point(size=3, shape=21, color="brown", fill="brown")+
  theme(legend.position="none")+
  labs(x="Variance expliquée (% cumulé)", y="Axe factoriel")
ggarrange(g2, g3,  nrow = 2)
```

La syntaxe ci-dessous permet de construire un tableau avec les coordonnées factorielles, les cosinus carrés et les contributions pour les modalités des variables qualitatives.


```{r ACMCodePartie2a, echo=TRUE, message=FALSE, warning=FALSE, out.width='75%'}
library(stringr)
nAxes <- 3
dfmodalites <- data.frame(Modalite =rownames(res.acm$var$coord),
                           Coord = round(res.acm$var$coord[, 1:nAxes],3),
                           Cos2 = round(res.acm$var$cos2[, 1:nAxes],3),
                           ctr = round(res.acm$var$contrib[, 1:nAxes],3))
rownames(dfmodalites) <- 1:nrow(dfmodalites)
names(dfmodalites) <- str_replace(names(dfmodalites), ".Dim.", "F")
```


#### Exploration graphique des résultats de l'ACM pour les modalités {#sect124213}

Avant d'explorer graphiquement les résultats pour les modalités, il est judicieux de construire un *DataFrame* avec les coordonnées factorielles, les contributions et les cosinus carrés des modalités (voir la syntaxe ci-dessous).

```{r echo=TRUE, message=FALSE, warning=FALSE, out.width='75%'}
library(kableExtra)
library(stringr)
nAxes <- 3
dfmodalites <- data.frame(Modalite =rownames(res.acm$var$coord),
                           Coord = round(res.acm$var$coord[, 1:nAxes],2),
                           ctr = round(res.acm$var$contrib[, 1:nAxes],2),
                           Cos2 = round(res.acm$var$cos2[, 1:nAxes],2))
rownames(dfmodalites) <- 1:nrow(dfmodalites)
names(dfmodalites) <- str_replace(names(dfmodalites), ".Dim.", "F")
```

Plusieurs fonctions très faciles à utiliser de `factoextra` permettent de construire rapidement des graphiques&nbsp;: `fviz_mca_var` pour un nuage de points d'un plan factoriel, `fviz_cos2`et `fviz_contrib` (en utilisant le paramètre `choice=var.cat`) pour des histogrammes avec les cosinus carrés et les contributions des modalités. N'hésitez à consulter l'aide de ces fonctions ou encore cette section du site de [STHDA](de http://www.sthda.com/french/articles/38-methodes-des-composantes-principales-dans-r-guide-pratique/75-acm-analyse-des-correspondances-multiples-avec-r-l-essentiel/#graphique-des-variables).

Il est aussi possible de créer vos propres graphiques avec `ggplot2` en utilisant le *DataFrame* créé précédemment avec les modalités. Par exemple, la syntaxe ci-dessous renvoie deux histogrammes pour l'axe&nbsp;1&nbsp;: l'un avec les coordonnées, l'autre avec les contributions. Dans la syntaxe, repérez le terme `CoordF1`. Dupliquez la syntaxe et changez ce terme pour `CoordF2` et `CoordF3` pour réaliser les graphiques des axes&nbsp;2 et&nbsp;3.

```{r ACMMiseEnOeuvreVars1, echo=TRUE, fig.align='center', fig.cap="Exemple de graphiques pour les résultats des modalités", auto_pdf=TRUE, dev="png", dpi=300, out.width='100%'}
# Histogrammes pour les coordonnées des modalités
couleursCoords <- c("lightsalmon","steelblue")
plotCoordF1 <- ggplot(dfmodalites,
                      aes(y = reorder(Modalite, CoordF1),
                          x = CoordF1, fill=CoordF1<0))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black")+
  geom_vline(xintercept=0, color = "black", size=1)+
  scale_fill_manual(name="Coordonnée",values=couleursCoords,
                    labels = c("Positive","Négative"))+
  labs(x="Coordonnées sur l'axe 1", y="Modalité")+
  theme(legend.position="none", axis.text.y = element_text(size = 7))

plotCtrF1 <- ggplot(dfmodalites, aes(y = reorder(Modalite, ctrF1), x = ctrF1))+
  geom_bar(stat="identity", width = .6, alpha=.8, color="black", fill="steelblue")+
  labs(x="Contributions sur l'axe 1", y="Modalité")+
  theme(legend.position="none", axis.text.y = element_text(size = 7))

ggarrange(plotCoordF1, plotCtrF1, ncol = 1, nrow = 2)
```

La syntaxe suivante permet de construire le premier plan factoriel pour les modalités avec la fonction `fviz_mca_var` de `factoextra` (figure&nbsp;\@ref(fig:ACMMiseEnOeuvreVars2)).

```{r ACMMiseEnOeuvreVars2, echo=TRUE, fig.align='center', fig.cap="Premier plan factoriel de l'ACM pour les modalités", auto_pdf=TRUE, dev="png", dpi=300, out.width='75%'}
res.acm2 <-  MCA(dfACM[1:9], ncp = 3, graph = FALSE, row.w = dfenquete$pond)
fviz_mca_var(res.acm2, repel = TRUE,
             choice="var.cat",
             axes = c(1, 2),
             # col.var = "black",
             title="", xlab="Axe 1", ylab="Axe 2",
             ggtheme = theme_minimal ())
```

La syntaxe suivante permet de construire le premier plan factoriel pour les modalités avec la fonction `fviz_mca_var` de `factoextra` (figure&nbsp;\@ref(fig:ACMMiseEnOeuvreVars3)).

```{r ACMMiseEnOeuvreVars3, echo=TRUE, fig.align='center', fig.cap="Premier plan factoriel de l'ACM pour les modalités supplémentaires", message=FALSE, warning=FALSE, auto_pdf=TRUE, dev="png", dpi=300, out.width='75%'}
fviz_mca_var(res.acm, repel = TRUE,
             choice="var.cat",
             axes = c(1, 2),
             col.var = "gray23",
             col.quali.sup = "darkred",
             labelsize = 3,
             title="", xlab="Axe 1", ylab="Axe 2", 
             ggtheme = theme_minimal ())
```

Finalement, la syntaxe ci-dessous renvoie un graphique avec la trajectoire la variable `Q3` (figure&nbsp;\@ref(fig:ACMMiseEnOeuvreVars4)).

```{r ACMMiseEnOeuvreVars4, echo=TRUE, fig.align='center', fig.cap="Trajectoires des variables ordinales sur le premier plan factoriel de l'ACM ", auto_pdf=TRUE, dev="png", dpi=300, out.width='70%'}
library(ggpubr)
Q3 <- dfmodalites[1:4, 1:3]
ggplot(Q3, aes(x=CoordF1, y=CoordF2, label=Modalite))+
  xlim(-1, .75)+ylim(-1, 1)+
  labs(title = "Q3. Depuis combien de temps cultivez-vous \n
        des fruits, des fines herbes ou des légumes?",
       x="Axe 1", y="Axe 2")+
  geom_label(nudge_x=0, nudge_y=0.07) +
  geom_line( color="black", size=.2)+
  geom_point(shape=21, color="black", fill="steelblue", size=4)
```

#### Exploration graphique des résultats de l'ACM pour les individus {#sect124214}

D'autres fonctions de `factoextra` produisent rapidement des graphiques pour les individus&nbsp;:

- `fviz_cos2` et `fviz_contrib` (en utilisant le paramètre `choice=ind`) pour construire des histogrammes pour les cosinus carrés et les contributions des individus.
- `fviz_mca_ind` pour un nuage de points d'un plan factoriel (axes 1 et 2 habituellement).

La syntaxe ci-dessous produit le premier axe factoriel pour les individus (figure&nbsp;\@ref(fig:ACMPlanFactoInd1Facto)).

```{r ACMPlanFactoInd1Facto, echo=TRUE, fig.align='center', fig.cap="Premier plan factoriel de l'ACM pour les individus avec factoextra", message=FALSE, warning=FALSE, auto_pdf=TRUE, dev="png", dpi=300, out.width='70%'}
fviz_mca_ind(res.acm, col.ind = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE,
             xlab="Axe 1", ylab="Axe 2", title="",
             ggtheme = theme_minimal())
```

La syntaxe ci-dessous produit aussi le premier plan factoriel pour les individus, mais attribuant une couleur différente aux modalités de la variable `q12` (figure&nbsp;\@ref(fig:ACMPlanFactoInd2Facto)).

```{r ACMPlanFactoInd2Facto, echo=TRUE, fig.align='center', fig.cap="Premier plan factoriel de l'ACM pour les individus avec coloration d'une variable avec factoextra", message=FALSE, warning=FALSE, auto_pdf=TRUE, dev="png", dpi=300, out.width='70%'}
fviz_mca_ind (res.acm,
              label = "none",
              habillage = "q12", # colorer par groupes
             xlab="Axe 1", ylab="Axe 2", title="",
              palette = c ("darkred", "steelblue", "gray23"),
              ggtheme = theme_minimal ())
```

\newpage

## Quiz de révision du chapitre {#sect125}

```{r quizChapitre12, echo=FALSE, warning=FALSE, results="asis"}
Chapitre12_AnalysesFacto <- quizz("quizzs/Chapitre12_AnalysesFacto.yml", "Chapitre12_AnalysesFacto")
render_quizz(Chapitre12_AnalysesFacto)
```

