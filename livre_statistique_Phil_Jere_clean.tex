% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames*,x11names*}{xcolor}
%
\documentclass[
  11pt,
  french,
]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
  \setmainfont[]{Palatino Linotype}
  \setmonofont[Scale=0.8]{Source Code Pro}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Introduction aux méthodes quantitatives en sciences sociales avec R},
  pdfauthor={Philippe Apparicio et Jérémy Gelb},
  colorlinks=true,
  linkcolor=Maroon,
  filecolor=Maroon,
  citecolor=Blue,
  urlcolor=Blue,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage[bf,singlelinecheck=off]{caption}
\usepackage[justification=centering]{caption}

\usepackage{framed,color}
\definecolor{shadecolor}{RGB}{248,248,248}
\definecolor{shadebluecolor}{RGB}{224,244,255}

\renewcommand{\textfraction}{0.05}
\renewcommand{\topfraction}{0.8}
\renewcommand{\bottomfraction}{0.8}
\renewcommand{\floatpagefraction}{0.75}

\renewenvironment{quote}{\begin{VF}}{\end{VF}}
\let\oldhref\href
\renewcommand{\href}[2]{#2\footnote{\url{#1}}}

\ifxetex
  \usepackage{letltxmacro}
  \setlength{\XeTeXLinkMargin}{1pt}
  \LetLtxMacro\SavedIncludeGraphics\includegraphics
  \def\includegraphics#1#{% #1 catches optional stuff (star/opt. arg.)
    \IncludeGraphicsAux{#1}%
  }%
  \newcommand*{\IncludeGraphicsAux}[2]{%
    \XeTeXLinkBox{%
      \SavedIncludeGraphics#1{#2}%
    }%
  }%
\fi

\makeatletter
\newenvironment{kframe}{%
\medskip{}
\setlength{\fboxsep}{.8em}
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\makeatletter
\newenvironment{kframev}{%
\medskip{}
\setlength{\fboxsep}{.8em}
 \def\at@end@of@kframev{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframev{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadebluecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframev}
\makeatother

\renewenvironment{Shaded}{\begin{kframe}}{\end{kframe}}

\usepackage{makeidx}
\makeindex

\urlstyle{tt}

\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}

% Definition des environnements pour les blocks pdf---------------------------
\newenvironment{rmdblock}[1]
  {
  \begin{itemize}
  \renewcommand{\labelitemi}{
    \raisebox{-.7\height}[0pt][0pt]{
      {\setkeys{Gin}{width=3em,keepaspectratio}\includegraphics{images/#1}}
    }
  }
  \setlength{\fboxsep}{1em}
  \begin{kframev}
  \small
  \item
  }
  {
  \end{kframev}
  \end{itemize}
  }


\newenvironment{bloc_notes}
  {\begin{rmdblock}{notes}}
  {\end{rmdblock}}


\newenvironment{bloc_aller_loin}
  {\begin{rmdblock}{aller_loin}}
  {\end{rmdblock}}


\newenvironment{bloc_astuce}
  {\begin{rmdblock}{astuce}}
  {\end{rmdblock}}


\newenvironment{bloc_attention}
  {\begin{rmdblock}{attention}}
  {\end{rmdblock}}


\newenvironment{bloc_package}
  {\begin{rmdblock}{package}}
  {\end{rmdblock}}

\newenvironment{bloc_objectif}
  {\begin{rmdblock}{objectif}}
  {\end{rmdblock}}


% -------------------------------------------------------------------

% -------------------modifying existing environments-----------------

% changing font size of code chunks
\let\oldShaded\Shaded
\def\Shaded{\oldShaded\small}

%insuring adding a line break for level 5
\makeatletter
\renewcommand\paragraph{\@startsection{paragraph}{4}{\z@}%
   {-3.25ex\@plus -1ex \@minus -.2ex}%
   {1.5ex \@plus .2ex}%
   {\normalfont\normalsize\bfseries}}
\makeatother
% -------------------------------------------------------------------

\makeatother
\usepackage{flafter}
\usepackage{float}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\ifxetex
  % Load polyglossia as late as possible: uses bidi with RTL langages (e.g. Hebrew, Arabic)
  \usepackage{polyglossia}
  \setmainlanguage[]{french}
\else
  \usepackage[shorthands=off,main=french]{babel}
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{Introduction aux méthodes quantitatives en sciences sociales avec R}
\author{Philippe Apparicio et Jérémy Gelb}
\date{2020-09-18}

\begin{document}
\maketitle

%\cleardoublepage\newpage\thispagestyle{empty}\null
%\cleardoublepage\newpage\thispagestyle{empty}\null
%\cleardoublepage\newpage
%\thispagestyle{empty}
%\begin{center}
%\Large{To Jung Jae-sung (1982 -- 2018),}

%\large{a remarkably hard-working badminton player with a remarkably simple playing style}
%\includegraphics{images/dedication.pdf}
%\end{center}

%\setlength{\abovedisplayskip}{-5pt}
%\setlength{\abovedisplayshortskip}{-5pt}

\renewcommand*\contentsname{Table des matières}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\listoftables
\listoffigures
\hypertarget{pruxe9face}{%
\chapter*{Préface}\label{pruxe9face}}
\addcontentsline{toc}{chapter}{Préface}

\hypertarget{comment-lire-ce-livre}{%
\section*{Comment lire ce livre}\label{comment-lire-ce-livre}}
\addcontentsline{toc}{section}{Comment lire ce livre}

Si vous googlez l'expression « comment lire un livre ? », vous trouverez une multitude de conseils et astuces. Pour ce livre, nous conseillons de le lire de gauche à droite et page par page. Plus sérieusement, il comprend plusieurs types de blocs de texte qui, on l'espère, faciliteront la lecture.

\begin{bloc_package}

\textbf{Bloc packages}: habituellement localisé en début du chapitre, il comprend la liste des packages R utilisés pour un chapitre.

\end{bloc_package}

\begin{bloc_objectif}

\textbf{Bloc objectif}: comprend une description des objectifs d'une section.

\end{bloc_objectif}

\begin{bloc_notes}

\textbf{Bloc notes}: comprend une information secondaire sur une notion, un élément, une idée abordée dans une section.

\end{bloc_notes}

\begin{bloc_aller_loin}

\textbf{Bloc pour aller plus loin} : peut comprendre des références ou des extensions d'une méthode statistique abordée dans une section.

\end{bloc_aller_loin}

\begin{bloc_astuce}

\textbf{Bloc astuce}: décrit un élément qui vous facilera le vie : une propriété statistique, un \emph{package}, une fonction, une syntaxe R.

\end{bloc_astuce}

\begin{bloc_attention}

\textbf{Bloc attention}: comprend une notion ou un élément important à bien maîtriser.

\end{bloc_attention}

\hypertarget{structure-du-livre}{%
\section*{Structure du livre}\label{structure-du-livre}}
\addcontentsline{toc}{section}{Structure du livre}

À écrire plus tard.

\hypertarget{remerciements}{%
\section*{Remerciements}\label{remerciements}}
\addcontentsline{toc}{section}{Remerciements}

Note au beau Cargo (chien Mira) qui nous supporte dans l'écriture du livre !

\begin{figure}

{\centering \includegraphics[width=0.5\linewidth]{images/Cargo} 

}

\caption{Cargo, le plus beau}\label{fig:cargo}
\end{figure}

\hypertarget{auteurs}{%
\chapter*{À propos des auteurs}\label{auteurs}}
\addcontentsline{toc}{chapter}{À propos des auteurs}

\textbf{Philippe Apparicio} (\url{http://www.ucs.inrs.ca/philippe-apparicio}) est professeur titulaire au Centre Urbanisation Culture Société de l'INRS (\url{http://www.ucs.inrs.ca/}). Il enseigne au programme de maîtrise en études urbaines (\url{http://www.ucs.inrs.ca/ucs/etudier/programmes/etudes-urbaines}) les cours \emph{méthodes quantitatives appliquées aux études urbaines} et \emph{analyses spatiales appliquées aux études urbaines}. Il a aussi créé et enseigné, il y a plusieurs années, le cours \emph{systèmes d'information géographique appliqués aux études urbaines}. Durant les dernières années, il a offert plusieurs formations aux Écoles d'été du Centre interuniversitaire québécois de statistiques sociales (CIQSS, \url{https://www.ciqss.org/}). Titulaire de la Chaire de recherche du Canada (niveau 2) sur l'équité environnementale et la ville, il est le directeur du \textbf{laboratoire d'équité environnementale} (\url{http://laeq.ucs.inrs.ca}). Géographe de formation, ses intérêts de recherche actuels incluent la justice et l'équité environnementale, la pollution atmosphérique et le bruit et le vélo en ville. Il a publié une centaine d'articles dans différents domaines des études urbaines et de la géographie.

\textbf{Jérémy Gelb} est candidat au doctorat en études urbaines à l'INRS (sous la supervision de Philippe Apparicio) et membre du \textbf{laboratoire d'équité environnementale} (\url{http://laeq.ucs.inrs.ca}). Son sujet de thèse porte sur l'exposition des cyclistes aux pollutions atmosphériques et sonores en milieu urbain. Il utilise quotidiennement des systèmes d'information géographique (SIG) et est tombé dans la marmite de l'\emph{open source} avec le triptyque QGIS, R et Python au début de sa maîtrise. Il a récemment développé deux packages R : \textbf{geocmeans} et \textbf{spNetwork}, permettant respectivement d'effectuer des analyses de classification floue non-supervisée pondérée spatialement et des estimations de densité par kernel sur réseau.

Philippe et Jérémy travaillent étroitement ensemble depuis déjà plusieurs années. Avec d'autres collègues, ils ont copubliés plusieurs articles \citep{2020_1, 2020_2, 2020_3, 2019_1, 2019_2, 2019_3, 2020_1, 2020_2, 2018_1, 2017_1, 2016_1}. Tous deux s'intéressent à l'exposition des cyclistes à la pollution atmosphérique et sonore dans plusieurs villes à travers le monde : Philippe ayant une préférence pour les collectes dans les villes du Sud Global (notamment indiennes, africaines et latino-américaines) et Jérémy dans les villes du Nord (européennes et nord-américaines).

\hypertarget{part-duxe9couverte-de-r}{%
\part{Découverte de R}\label{part-duxe9couverte-de-r}}

\hypertarget{chap01}{%
\chapter{Prise en main de R}\label{chap01}}

Dans ce chapitre, nous reviendrons brièvement sur l'histoire de R et la philosophie qui entoure le logiciel. Nous donnerons quelques conseils pour son installation et la mise en place d'un environnement de développement. Nous présenterons les principaux objets qui sous-tendent le travail effectué avec R (dataframe, vecteur, matrice, etc.) et comment les manipuler avec des exemples appliqués. Enfin, nous terminerons cette section avec un tour d'horizon des capacités graphiques de R . Si vous maîtrisez déjà R , nullement besoin de lire ce chapitre !

\begin{bloc_package}

Dans cette section, nous utiliserons principalement les \emph{packages} suivants :

\begin{itemize}
\tightlist
\item
  Pour importer des fichiers externes :

  \begin{itemize}
  \tightlist
  \item
    \textbf{foreign} pour entre autres les fichiers \emph{dbase} et ceux des logiciels SPSS et Stata
  \item
    \textbf{sas7bdat} pour les fichiers du logiciel SAS
  \item
    \textbf{xlsx} pour les fichiers Excel
  \end{itemize}
\item
  Pour manipuler des chaînes de caractères et des dates :

  \begin{itemize}
  \tightlist
  \item
    \textbf{stringr} pour les chaînes de caractères
  \item
    \textbf{lubridate} pour les dates
  \end{itemize}
\item
  Pour manipuler des données :

  \begin{itemize}
  \tightlist
  \item
    \textbf{dplyr } du \textbf{tidyverse} propose une grammaire pour manipuler et structurer des données.
  \end{itemize}
\end{itemize}

\end{bloc_package}

\hypertarget{sect011}{%
\section{Histoire et philosophie de R}\label{sect011}}

R est à la fois un langage de programmation et un logiciel libre (sous la licence publique générale GNU) dédié à l'analyse statistique et supporté par une fondation : \emph{R foundation for Statistical computing}. Il est principalement écrit en C et Fortran.

R a été créé par Ross Ihaka et Robert Gentleman à l'Université d'Auckland en Nouvelle-Zélande. Si vous avez un jour l'occasion de passer dans le coin, une plaque est affichée dans le département de statistique de l'université, ça mérite le détour (figure \ref{fig:fig01}). Une première version a été publiée en 1996, mais la première version stable ne date que de 2000, il s'agit donc d'un logiciel relativement récent si on le compare à ses concurrents SAS (1976), SPSS (1968) et Stata (1984).

\begin{figure}

{\centering \includegraphics[width=0.4\linewidth]{images/introduction/plaque} 

}

\caption{Lieu de pélerinage de R}\label{fig:fig01}
\end{figure}

R a cependant réussi à s'imposer tant dans la milieu de la recherche que dans le secteur privé. Pour s'en convaincre, il suffit de lire l'excellent article concernant la popularité des logiciels d'analyse de données tiré du site \href{http://r4stats.com/articles/popularity}{r4stats.com} (figure \ref{fig:fig02}).

\begin{figure}

{\centering \includegraphics[width=0.5\linewidth]{images/introduction/r_citations} 

}

\caption{Nombre d'articles trouvés sur Google Scholar (Source : Robert A. Muenchen)}\label{fig:fig02}
\end{figure}

Les nombreux atouts de R justifient largement sa popularité sans cesse croissante :

\begin{itemize}
\tightlist
\item
  R est un logiciel à code source ouvert (\emph{open source}) et ainsi accessible à tous gratuitement.
\item
  Le développement du langage R est centralisé, mais la communauté peut créer et partager facilement des \emph{packages}. Les nouvelles méthodes sont ainsi rapidement implémentées comparativement aux logiciels propriétaires.
\item
  R est un logiciel multi-plateforme, fonctionnant sur Linux, Unix, Windows et Mac.
\item
  Comparativement à ses concurrents, R dispose d'excellentes solutions pour manipuler des données et réaliser des graphiques.
\item
  R dispose de nombreuses interfaces lui permettant de communiquer, notamment avec des systèmes de bases de données SQL et non SQL (MySQL, PostgresSQL, MongoDB, etc.), à des systèmes de \emph{big data} (Spark, Hadoop), à des systèmes d'information géographique (QGIS, ArcGIS) et même à des services en ligne comme Microsoft Azure ou Amazon AWS.
\item
  R est un langage de programmation à part entière, ce qui lui donne plus de flexibilité que ses concurrents dans le domaine privé (SPSS, SAS, STATA). Avec R , vous pouvez accomplir des tâches aussi variées que : monter un site web, créer un robot collectant des données en ligne, effectuer des analyses qualitatives, combiner des fichiers PDF, composer des diapositives pour une présentation ou même éditer un livre (comme celui-ci), mais aussi, réaliser des analyses statistiques.
\end{itemize}

Un des principaux attrait de R est la quantité astronomique de \emph{packages} actuellement disponibles. Un \emph{package} est un ensemble de nouvelles fonctionnalités développées par un ou plusieurs utilisateurs de R et mises à disposition de l'ensemble de la communauté. Par exemple, le \emph{package} \textbf{ggplot2} est dédié à la réalisation de graphiques; les \emph{packages} \textbf{data.table} et \textbf{plyr} permettent de manipuler des tableaux de données; le \emph{package} \textbf{car} apporte de nombreux outils pour faciliter l'analyse de modèles de régressions, etc. Ce partage des \emph{packages} rend accessible à tous des méthodes d'analyses complexes et récentes et favorise grandement la reproductibilité de la recherche. Cependant, ce fonctionnement implique quelques désavantages :

\begin{itemize}
\tightlist
\item
  il existe généralement plusieurs \emph{packages} pour effectuer le même type d'analyse, ce qui peut devenir une source de confusion;
\item
  certains \emph{packages} cessent d'être mis à jour au fil des années, ce qui nécessite de leur trouver d'autres alternatives (et ainsi apprendre la syntaxe des nouveaux \emph{packages});
\item
  il est impératif de s'assurer de la fiabilité des \emph{packages} que vous souhaitez utiliser, car n'importe qui peut proposer un \emph{package}.
\end{itemize}

Il nous semble important de relativiser d'emblée la portée du dernier point. Il est rarement nécessaire de lire et analyser le code source d'un \emph{package} pour s'assurer de sa fiabilité. Nous ne sommes pas des spécialistes de tous les sujets et il peut être extrêmement ardu de comprendre la logique d'un code écrit par quelqu'un d'autre. Nous vous recommandons donc de privilégier l'utilisation de \emph{packages} qui :

\begin{itemize}
\tightlist
\item
  ont fait l'objet d'une publication dans une revue à comité de lecture ou qui ont déjà été cités dans des études ayant fait l'objet d'une publication revue par les pairs;
\item
  font partie de projets comme \href{https://ropensci.github.io/reproducibility-guide/sections/introduction/}{ROpensci} prônant la vérification par les pairs ou subventionnés par des organisations comme \href{https://www.r-consortium.org/}{R Consortium}.
\item
  sont disponibles sur l'un des deux principaux répertoires de \emph{packages} R \href{https://cran.r-project.org/}{CRAN} ou \href{https://www.bioconductor.org/}{Bioconductor}.
\end{itemize}

Toujours pour nuancer notre propos, il convient de distinguer \emph{package} de \emph{package}! Certains d'entre eux sont des ensembles très complexes de fonctions permettant de réaliser des analyses poussées alors que d'autres sont des projets plus modestes dont l'objectif principal est de simplifier le travail des utilisateurs. Ces derniers ressemblent à des petites boites à outils et font généralement moins l'objet d'une vérification intensive.

Pour conclure cette section, l'illustration partagée sur Twitter par Darren L Dahly résume avec humour la force du logiciel R et de sa communauté (\ref{fig:fig03}) : R apparait clairement comme une communauté hétéroclyte, mais diversifiée et adaptable.

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{images/introduction/softwares_and_cars} 

}

\caption{Métaphore sur les langages et programmes d'analyse statistique}\label{fig:fig03}
\end{figure}

Dans ce livre, nous détaillerons les \textbf{packages} utilisés dans chaque section avec un encadré spécifique, accompagné de l'icône suivant :

\begin{figure}

{\centering \includegraphics[width=0.2\linewidth]{css/images/package} 

}

\caption{Icône des encadrés dédiés aux packages}\label{fig:fig04}
\end{figure}

\hypertarget{sect012}{%
\section{Environnement de travail}\label{sect012}}

Dans cette section, nous vous proposons une visite de l'environnement de travail classique R .

\hypertarget{sect0121}{%
\subsection{Installer R}\label{sect0121}}

La première étape pour travailler avec R est bien sûr de l'installer. Pour ce faire, il suffit de visiter le site web de \href{https://cran.r-project.org/}{CRAN} et de télécharger la dernière version de R en fonction de votre système d'exploitation : Windows, Linux ou Mac. Une fois installé, si vous démarrez R immédiatement, vous aurez alors accès à une console, plutôt rudimentaire, attendant sagement vos instructions (figure \ref{fig:fig05}).

\begin{figure}

{\centering \includegraphics[width=0.85\linewidth]{images/introduction/r_console} 

}

\caption{La console de base de R}\label{fig:fig05}
\end{figure}

Notez que vous pouvez aussi télécharger des version plus anciennes de R en allant sur ce \href{https://cran.r-project.org/bin/windows/base/old/}{lien}. Ceci peut être intéressant lorsque vous voulez reproduire des résultats d'une autre étude ou que certains \emph{packages} ne sont plus disponibles dans les nouvelles versions.

\hypertarget{sect0122}{%
\subsection{L'environnement RStudio}\label{sect0122}}

Rares sont les utilisateurs de R qui préfèrent travailler directement avec la console classique. Nous vous recommandons vivement d'utiliser RStudio, soit un environnement de développement dédié à R , offrant une intégration très intéressante d'une console, d'un éditeur de texte, d'une fenêtre de visualisation des données, d'une autre pour les graphiques, d'un accès à la documentation, etc. En d'autres termes, si R est un vélo minimaliste, RStudio permet d'y rajouter des freins, des vitesses, un porte-bagage, des gardes-boues et une selle confortable. Vous pouvez \href{https://rstudio.com/products/rstudio/download}{télécharger} et installer RStudio sur Windows, Linux et Mac. La version de base est gratuite, mais l'entreprise qui développe ce logiciel propose aussi des versions commerciales du logiciel qui assurent essentiellement un support technique. Il existe d'autres environnements de développement pour travailler avec R (VisualStudio, Jupyter, Tinn-R, Radiant, RIDE, etc.), mais RStudio offre à ce jour la meilleure option en terme de facilité d'installation, de prise en main et de fonctionnalités proposées (voir l'interface de RStudio à la figure \ref{fig:fig06}).

\begin{figure}

{\centering \includegraphics[width=0.85\linewidth]{images/introduction/r_studio_01} 

}

\caption{Environnement de base de RStudio}\label{fig:fig06}
\end{figure}

Avant d'aller plus loin, notez que :

\begin{itemize}
\tightlist
\item
  La console actuellement ouverte dans RStudio vous informe de la version de R que vous utilisez. Vous pouvez en effet avoir plusieurs versions de R installées sur votre ordinateur et passer de l'une à l'autre avec RStudio. Pour cela, naviguez dans l'onglet \emph{Tools / Global Options} et dans le volet \emph{General}, vous pouvez sélectionner la version de R que vous souhaitez utiliser.
\item
  L'aspect de RStudio peut être modifié en navigant dans l'onglet \emph{Tools / Global Options} et dans le volet \emph{Appearance}. Nous avons une préférence pour le mode sombre avec le style \emph{pastel on dark}, mais libre à chacun de choisir le style qui lui convient.
\end{itemize}

\begin{figure}

{\centering \includegraphics[width=0.85\linewidth]{images/introduction/r_studio_02} 

}

\caption{RStudio avec le style pastel on dark}\label{fig:fig07}
\end{figure}

Une fois ces détails réglés, vous pouvez ouvrir votre première feuille de code en allant dans l'onglet \emph{File / New File/ R Script}, votre environnement est maintenant découpé en quatre fenêtres (figure \ref{fig:fig08}) :

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  L'éditeur de code, vous permettant d'écrire le script que vous voulez exécuter et permettant de garder une trace de votre travail. Ce script peut être enregistré sur votre ordinateur avec l'extension \textbf{.R}, mais ce n'est qu'un simple fichier texte.
\item
  La console vous permettant d'exécuter votre code R et de voir les résultats s'afficher au fur et à mesure.
\item
  La fenêtre d'environnement vous montrant les objets, fonctions et jeux de données actuellement disponibles dans votre session (chargés dans la mémoire vive).
\item
  La fenêtre de l'aide, des graphiques et de l'explorateur de fichiers. Vous pouvez accéder ici à la documentation de R et des \emph{packages} que vous utilisez, aux sorties graphiques que vous produisez et aux dossier de votre environnement de travail.
\end{enumerate}

\begin{figure}

{\centering \includegraphics[width=0.85\linewidth]{images/introduction/r_studio_03} 

}

\caption{Les quatre fenêtres de RStudio}\label{fig:fig08}
\end{figure}

Prenons un bref exemple, tapez la syntaxe suivante dans l'éditeur de code (fenêtre 1 à la figure \ref{fig:fig08}) :

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ma_somme <-}\StringTok{ }\DecValTok{4}\OperatorTok{+}\DecValTok{4}
\end{Highlighting}
\end{Shaded}

Sélectionnez ensuite cette syntaxe (mettre en surbrillance avec votre souris), quand vous utilisez le raccourci \emph{Ctrl+Enter} ou cliquez sur le bouton \emph{Run} (avec la flèche verte), cette syntaxe est envoyée à la console qui l'exécute immédiatement. Notez que rien ne se passe tant que le code n'est pas envoyé à la console. Il s'agit donc de deux étapes distinctes : écrire son code, puis l'envoyer à la console. Vous constaterez également qu'un objet \emph{ma\_somme} est apparu dans votre environnement et que sa valeur est bien 8. Votre console se ``souvient'' de cette valeur, elle est actuellement stockée dans votre mémoire vive sous le nom de \emph{ma\_somme} (figure \ref{fig:fig09}).

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{images/introduction/r_studio_04} 

}

\caption{Les quatre fenêtres de RStudio}\label{fig:fig09}
\end{figure}

Pour conclure cette section, nous vous invitons à enregistrer votre première syntaxe R (\emph{File / Save As}) dans un fichier \textbf{.R} que vous pouvez appeler par exemple ``mon\_premier\_script.R''. Fermez ensuite RStudio, redémarrez le et ouvrez (\emph{File / Open File}) votre fichier ``mon\_premier\_script.R''. Vous pouvez constater que votre code est toujours présent, mais que votre environnement est vide tant que vous n'exécutez pas votre syntaxe. En effet, lorsque vous fermez RStudio, l'environnement est vidé pour libérer de la mémoire vive. Ceci peut poser problème lorsque certains codes sont très longs à exécuter, nous verrons donc plus tard comment enregistrer l'environnement en cours pour le recharger par la suite.

\hypertarget{sect0123}{%
\subsection{\texorpdfstring{Installer et charger un \emph{package}}{Installer et charger un package}}\label{sect0123}}

Dans la section sur la Philosophie de R , nous avons souligné la place centrale jouée par les \emph{packages}. Voyons ensemble comment installer un \emph{package} intitulé \textbf{lubridate}, qui nous permettra plus tard de manipuler des données temporelles.

\hypertarget{sect01231}{%
\subsubsection{\texorpdfstring{Installer un \emph{package} depuis CRAN}{Installer un package depuis CRAN}}\label{sect01231}}

Pour installer un \emph{package}, vous devez être connecté à internet; en effet, R va accéder au répertoire de \emph{packages} \emph{CRAN} pour télécharger le \emph{package} et l'installer sur votre machine. Cette opération est réalisée avec la fonction \texttt{install.packages}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{install.packages}\NormalTok{(}\StringTok{"lubridate"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Notez qu'une fois que le \emph{package} est installé, vous n'aurez plus besoin de le refaire. Le \emph{package} est disponible localement sur votre ordinateur, à moins de le désinstaller explicitement avec la fonction \texttt{remove.packages}.

\hypertarget{sect01232}{%
\subsubsection{\texorpdfstring{Installer un \emph{package} depuis GitHub}{Installer un package depuis GitHub}}\label{sect01232}}

\emph{CRAN} est le répertoire officiel des \emph{packages} de R . Vous pouvez cependant télécharger des \emph{packages} provenant d'autres sources. Très souvent, les \emph{packages} sont disponibles sur le site web \href{https://github.com/}{GitHub} et l'on peut même y trouver des versions en développement avec des fonctionnalités encore non intégrées dans la version sur \emph{CRAN}. Reprenons le cas de \textbf{lubridate}, sur GitHub, il est disponible à la page \href{https://github.com/tidyverse/lubridate}{suivante}. Pour l'installer nous devons d'abord installer un autre \emph{package} appelé \textbf{devtools} (depuis \emph{CRAN}).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{install.packages}\NormalTok{(}\StringTok{"devtools"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Maintenant que nous disposons de \textbf{devtools}, nous pouvons utiliser la fonction d'installation \texttt{devtools::install\_github} pour directement télécharger \textbf{lubridate} depuis GitHub.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{devtools}\OperatorTok{::}\KeywordTok{install_github}\NormalTok{(}\StringTok{"tidyverse/lubridate"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{sect01233}{%
\subsubsection{\texorpdfstring{Charger un \emph{package}}{Charger un package}}\label{sect01233}}

Maintenant que \textbf{lubridate} est installé, nous pouvons le charger dans notre session actuelle de R et accéder aux fonctions qu'il propose. Pour cela, suffit d'utiliser la fonction \texttt{library}. Notez que conventionnellement, l'appel des \emph{packages} se fait au tout début du script que vous rédigez. Rien ne vous empêche de le faire au fur et à mesure de votre code mais vous perdez alors en lisibilité.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(lubridate)}
\end{Highlighting}
\end{Shaded}

Si vous obtenez un message d'erreur du type :

{Error in library(mon\_package) : aucun \emph{package} nommé `mon\_package' n'est trouvé}

C'est que le \emph{package} que vous tentez de charger n'est pas encore installé sur votre ordinateur. Dans ce cas, réessayer de l'installer avec la fonction \texttt{install.packages}. Si le problème persiste, vérifiez que vous n'avez pas fait de faute de frappe dans le nom du \emph{package.} Vous pouvez également redémarrer RStudio et réessayer d'installer le \emph{package}.

\hypertarget{obtenir-de-laide}{%
\subsection{Obtenir de l'aide}\label{obtenir-de-laide}}

Lorsque vous installez des \emph{packages} dans R , vous téléchargez aussi leur documentation. Tous les \emph{packages} de \emph{CRAN} disposent d'une documentation, mais ceci n'est pas forcément vrai pour \emph{GitHub}. Dans RStudio, vous pouvez accéder à la documentation des \emph{packages} dans l'onglet \textbf{Packages} (figure \ref{fig:fig010}). Vous pouvez utiliser la barre de recherche pour retrouver rapidement un \emph{package} installé. Si vous cliquez sur le nom du \emph{package}, vous accédez directement à sa documentation dans cette fenêtre.

\begin{figure}

{\centering \includegraphics[width=0.45\linewidth]{images/introduction/rstudio_packages} 

}

\caption{Description des packages}\label{fig:fig010}
\end{figure}

Vous pouvez également accéder à ces informations en utilisant la syntaxe suivante dans votre console :

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{help}\NormalTok{(}\DataTypeTok{package =} \StringTok{'lubridate'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Souvent, vous aurez besoin d'accéder à la documentation d'une fonction spécifique d'un \emph{package}. Affichons la documentation de la fonction \texttt{now} de \textbf{lubridate} :

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{help}\NormalTok{(now, }\DataTypeTok{package =} \StringTok{'lubridate'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

ou plus simplement :

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{?lubridate}\OperatorTok{::}\NormalTok{now}
\end{Highlighting}
\end{Shaded}

Vous pouvez aussi utiliser le raccourci suivant :

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{?now}
\end{Highlighting}
\end{Shaded}

Si vous connaissez le nom d'une fonction, mais vous ne vous souvenez plus à quel \emph{package} elle appartient, lancez une recherche en utilisant un double point d'interrogation :

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{??now}
\end{Highlighting}
\end{Shaded}

Vous allez ainsi découvrir que la fonction \texttt{now} n'existe pas que dans \textbf{lubridate}, ce qui souligne l'importance de bien connaître les \emph{packages} que l'on installe et que l'on charge dans notre session !

Maintenant que nous avons fait le tour de l'environnement de travail, nous allons pouvoir entamer les choses sérieuses avec les bases du langage R .

\hypertarget{sect013}{%
\section{Les bases du langage R}\label{sect013}}

R est un langage de programmation. Il vous permet de communiquer avec votre ordinateur pour lui donner des tâches à accomplir. Dans cette section, nous aborderons les bases du langage. Ce type de section introductive à R est présente dans tous les manuels sur R ; elle est donc incontournable. À la première lecture, elle vous semblera probablement aride, et ce, d'autant plus que nous ne réalisons pas d'analyse à proprement parler. Gardez en tête que l'analyse de données requiert au préalable une phase de structuration de ces dernières, opération qui nécessite la maîtrise des notions abordées dans cette section. Nous vous recommandons une première lecture de ce chapitre pour comprendre quelles manipulations vous pouvez effectuer avec R , la lecture des chapitres suivants dédiés aux statistiques, puis de consulter à nouveau cette section au besoin. Notez aussi que la maîtrise des différents objets et opérations de base de R ne s'acquiert qu'en pratiquant. Vous gagnerez cette expertise au fil de vos prochains codes R , période durant laquelle vous pourrez consulter ce chapitre tel un guide de références des différents objets et notions fondamentales de R .

\hypertarget{sect0131}{%
\subsection{Hello World !}\label{sect0131}}

Une introduction à un langage de programmation se doit de commencer par le rite de passage \textbf{Hello World}. Il s'agit d'une forme de tradition consistant à montrer aux nouveaux utilisateurs comment afficher le message ``Hello World'' à l'écran avec le langage en question.

En C, cela donne :

\begin{verbatim}
#include <stdio.h>

main()
{
    printf("hello, world\n");
}
\end{verbatim}

En COBOL :

\begin{verbatim}
IDENTIFICATION DIVISION.
PROGRAM-ID. HELLO-WORLD.

ENVIRONMENT DIVISION.

DATA DIVISION.

PROCEDURE DIVISION.
    DISPLAY "Hello, world!".
    STOP RUN.
\end{verbatim}

et plus simplement en R :

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(}\StringTok{"Hello World"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Hello World"
\end{verbatim}

Bravo ! Vous venez officiellement de faire votre premier pas dans R !

\hypertarget{sect0132}{%
\subsection{Objets et expressions}\label{sect0132}}

Dans R , nous passons notre temps à manipuler des \textbf{objets} à l'aide d'\textbf{expressions}. Prenons un exemple concret, si vous tapez la syntaxe \texttt{4\ +\ 3}, vous manipulez deux objets (4 et 3) au travers d'une expression indiquant que vous souhaitez obtenir la somme des deux objets.

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{4} \OperatorTok{+}\StringTok{ }\DecValTok{3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 7
\end{verbatim}

Cette expression est correcte, R comprends vos indications et effectue le calcul.

Il est possible d'enregistrer le résultat d'une expression et de la conserver dans un nouvel objet. On appelle cette opération déclarer une variable.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ma_somme <-}\StringTok{ }\DecValTok{4} \OperatorTok{+}\StringTok{ }\DecValTok{3}
\end{Highlighting}
\end{Shaded}

Concrêtement, nous venons de demander à R d'enregistrer le résultat de \texttt{4\ +\ 3} dans un espace spécifique de notre mémoire vive. Si vous regardez dans votre fenêtre \textbf{Environment}, vous verrez en effet qu'un objet appelé ma\_somme est actuellement en mémoire et a pour valeur 7.

Notez ici que le nom des variables ne peut être composé que de lettres, de chiffres, de points (.) et de tiret bas (\_) et doit commencer par une lettre. R est sensible à la case, en d'autre termes, les variables \texttt{Ma\_somme}, \texttt{ma\_sommE}, \texttt{ma\_SOMME}, et \texttt{MA\_SOMME} renvoient toutes à un objet différent. Attention donc aux fautes de frappes. Si vous déclarez une variable en utilisant le nom d'une variable existante, la première est écrasée par la seconde :

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{age <-}\StringTok{ }\DecValTok{35}
\NormalTok{age}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 35
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{age <-}\StringTok{ }\DecValTok{45}
\NormalTok{age}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 45
\end{verbatim}

Attention donc aux noms de variables que vous utilisez et réutilisez.

Réutilisons notre objet \texttt{ma\_somme} dans une nouvelle expression :

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ma_somme2 <-}\StringTok{ }\NormalTok{ma_somme }\OperatorTok{+}\StringTok{ }\NormalTok{ma_somme}
\end{Highlighting}
\end{Shaded}

Avec cette nouvelle expression, nous indiquons à R que nous souhaitons déclarer une nouvelle variable appelée \texttt{ma\_somme2}, et que cette variable aura pour valeur \texttt{ma\_somme\ +\ ma\_somme}, soit \texttt{7\ +\ 7}. Sans surprise, \texttt{ma\_somme2} a pour valeur 14.

Notez que la mémoire vive (l'environnement) est vidée lorsque vous fermez R . En d'autres termes, R perd complètement la mémoire lorsque vous le fermez. Vous pouvez bien sûr recréer vos objets en relançant les mêmes syntaxes. C'est pourquoi vous devez conserver vos feuilles de codes et ne pas seulement travailler dans la console. La console ne garde aucune trace de votre travail. Pensez donc à bien enregistrer votre code !

Nous verrons dans un autre chapitre comment sauvegarder des objets et les recharger dans une session ultérieure de R (LIEN SECTION). Ce type d'opération est pertinent quand le temps de calcul nécessaire à la production de certains objets est très long.

\hypertarget{sect0_133}{%
\subsection{Fonctions et arguments}\label{sect0_133}}

Dans R , nous manipulons le plus souvent nos objets avec des \textbf{fonctions}. Une fonction est elle-même un objet, mais qui a la particularité de pouvoir effectuer des opérations sur d'autres objets. Par exemple, déclarons l'objet \texttt{taille} avec une valeur de 175.897 :

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{taille <-}\StringTok{ }\FloatTok{175.897}
\end{Highlighting}
\end{Shaded}

Nous allons utiliser la fonction \texttt{round} dont l'objectif est d'arrondir un nombre à virgule pour obtenir un nombre entier.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{round}\NormalTok{(taille)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 176
\end{verbatim}

Pour effectuer leurs opérations, les fonctions ont généralement besoin d'\textbf{arguments}. Ici, \texttt{taille} est un argument passé à la fonction \texttt{round}. Si nous regardons la documentation de \texttt{round} avec \texttt{help(round)}, nous constatons que cette fonction prend en réalité deux argments : \emph{x} et \emph{digits}. Le premier est le nombre que nous souhaitons arrondir et le second le nombre de décimales à conserver. On peut lire dans la documentation que la valeur par défaut de \emph{digits} est 0, ce qui explique que \texttt{round(taille)} a produit le résultat de 176.

\begin{figure}

{\centering \includegraphics[width=0.45\linewidth]{images/introduction/help_round} 

}

\caption{Arguments de la fonction round}\label{fig:fig011}
\end{figure}

Réutilisons maintenant la fonction \texttt{round} mais en gardant une décimale :

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{round}\NormalTok{(taille, }\DataTypeTok{digits =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 175.9
\end{verbatim}

Il est aussi possible que certaines fonctions ne requièrent pas d'arguments. Par exemple, la fonction \texttt{now} va indiquer la date précise (avec l'heure) et n'a besoin d'aucun argument pour le faire :

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{now}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "2020-09-18 09:38:13 EDT"
\end{verbatim}

Par contre, si nous essayons de lancer la fonction \texttt{round} sans argument, nous obtiendrons une erreur :

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{round}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

{Erreur : 0 arguments passed to `round' which requires 1 or 2 arguments}

Le message est très clair, \texttt{round} a besoin d'au moins un argument pour fonctionner. Si au lieu d'un nombre, nous avions donné du texte à la fonction \texttt{round}, nous aurions aussi obtenu une erreur :

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{round}\NormalTok{(}\StringTok{"Hello World"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

{Error in round(``Hello World'') :
non-numeric argument to mathematical function}

À nouveau le message est très explicite : nous avons passé un argument non-numérique à une fonction mathématique. Lisez toujours vos messages d'erreurs qui vous permettront d'identifier des coquilles et de corriger votre code !

Une fonction essentielle est la fonction \texttt{print} qui permet d'afficher la valeur d'une variable.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(ma_somme)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 7
\end{verbatim}

\hypertarget{sect0134}{%
\subsection{Principaux types de données}\label{sect0134}}

Depuis le début de ce chapitre, nous avons déclaré plusieurs variables et essentiellement des données numériques. Dans R , il existe trois principaux types de données de base :

\begin{itemize}
\tightlist
\item
  Les données numériques, qui peuvent être des nombres entiers (appelés \emph{integers}), ou des nombres décimaux (appelés \emph{floats}), \texttt{15} et \texttt{15.3}.
\item
  Les données textuelles, qui sont des chaînes de caratères (appelées \emph{strings}) et déclarées entre guillemets \texttt{"abcdefg"}
\item
  Les données booléennes (\emph{booleans}) qui représentent les concepts de vrai (\texttt{TRUE}) ou de faux (\texttt{FALSE}).
\end{itemize}

Déclarons une variable pour chacun de ces types :

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{age <-}\StringTok{ }\DecValTok{35}
\NormalTok{taille <-}\StringTok{ }\FloatTok{175.5}
\NormalTok{adresse <-}\StringTok{ '4225 rue de la gauchetiere'}
\NormalTok{proprietaire <-}\StringTok{ }\OtherTok{TRUE}
\end{Highlighting}
\end{Shaded}

Notez également qu'il existe des types pour représenter l'absence de données :

\begin{itemize}
\tightlist
\item
  pour représenter un objet vide, on utilisera l'objet \texttt{NULL},
\item
  pour représenter une données manquante, on utilisera l'objet \texttt{NA},
\item
  pour représenter un texte vide, on utilisera une chaîne de caractère de longueur 0 \texttt{""}.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{age2 <-}\StringTok{ }\OtherTok{NULL}
\NormalTok{taille2 <-}\StringTok{ }\OtherTok{NA}
\NormalTok{adresse2 <-}\StringTok{ ''}
\end{Highlighting}
\end{Shaded}

\hypertarget{sect0135}{%
\subsection{Opérateurs}\label{sect0135}}

Nous avons vu que les fonctions nous permettent de manipuler des objets. Nous pouvons également effectuer un grand nombre d'opérations avec des opérateurs.

\hypertarget{sect01351}{%
\subsubsection{Opérateurs mathématiques}\label{sect01351}}

Les opérateurs mathématiques permettent d'effectuer du calcul avec des données de type numérique.

\begin{table}

\caption{\label{tab:tableOperateurMath}Opérateurs mathématiques}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{lllr}
\toprule
Opérateur & Description & Syntaxe & Résultat\\
\midrule
+ & Addition & 4 + 4 & 8.0\\
- & Soustraction & 4 - 3 & 1.0\\
* & Multiplication & 4 * 3 & 12.0\\
/ & Division & 12 / 4 & 3.0\\
\textasciicircum{} & Exponentiel & 4 \textasciicircum{} 3 & 64.0\\
\addlinespace
** & Exponentiel & 4 ** 3 & 64.0\\
\%\% & Reste de division & 15.5 \%\% 2 & 1.5\\
\%/\% & Division entière & 15.5 \%/\% 2 & 7.0\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{sect01352}{%
\subsubsection{Opérateurs relationnels}\label{sect01352}}

Les opérateurs relationnels permettent de vérifier des conditions dans R . Ils renvoient un booléen, \texttt{TRUE} si la condition est vérifiée et \texttt{FALSE} si ce n'est pas le cas.

\begin{table}

\caption{\label{tab:tableOperateurRela}Opérateurs relationnels}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{llll}
\toprule
Opérateur & Description & Syntaxe & Résultat\\
\midrule
== & Égalité & 4 == 4 & TRUE\\
!= & Différence & 4 != 4 & FALSE\\
> & Est supérieur & 5 > 4 & TRUE\\
< & Est inférieur & 5 < 4 & FALSE\\
>= & Est supérieur ou égal & 5 >= 4 & TRUE\\
\addlinespace
<= & Est inférieur ou égal & 5 <= 4 & FALSE\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{sect01353}{%
\subsubsection{Opérateurs logiques}\label{sect01353}}

Les opérateurs logiques permettent de combiner plusieurs conditions :

\begin{itemize}
\item
  L'opérateur \textbf{ET} permet de vérifier que deux conditions (l'une ET l'autre) sont TRUE. Si l'une des deux est FALSE, il renvoie FALSE.
\item
  L'opérateur \textbf{OU} permet de vérifier que l'une des deux conditions est TRUE (l'une OU l'autre). Si les deux sont FALSE, alors il renvoit FALSE.
\item
  L'opérateur \textbf{NOT} permet d'inverser une condition. Ainsi NOT TRUE est FALSE et NOT FALSE est TRUE.
\end{itemize}

\begin{table}

\caption{\label{tab:tableOperateurLogi}Opérateurs relationnels}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{llll}
\toprule
Opérateur & Description & Syntaxe & Résultat\\
\midrule
\& & ET & TRUE \& FALSE & FALSE\\
| & OU & TRUE | FALSE & TRUE\\
! & NOT & ! TRUE & FALSE\\
\bottomrule
\end{tabular}
\end{table}

Prenons le temps pour un rapide exemple :

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a <-}\StringTok{ }\DecValTok{4} 
\NormalTok{b <-}\StringTok{ }\DecValTok{10}
\NormalTok{c <-}\StringTok{ }\DecValTok{-5}

\CommentTok{# produit TRUE car a est bien plus petit que b et c est bien plus petit que a}
\NormalTok{a }\OperatorTok{<}\StringTok{ }\NormalTok{b }\OperatorTok{&}\StringTok{ }\NormalTok{c }\OperatorTok{<}\StringTok{ }\NormalTok{a}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# produit FALSE car si a est bien plus petit que b, }
\CommentTok{# b est en revanche plus grand que c}
\NormalTok{a }\OperatorTok{<}\StringTok{ }\NormalTok{b }\OperatorTok{&}\StringTok{ }\NormalTok{b }\OperatorTok{<}\StringTok{ }\NormalTok{c}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# produit TRUE car la seconde condition est inversée}
\NormalTok{a }\OperatorTok{<}\StringTok{ }\NormalTok{b }\OperatorTok{&}\StringTok{  }\OperatorTok{!}\StringTok{ }\NormalTok{b }\OperatorTok{<}\StringTok{ }\NormalTok{c}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# produit TRUE car au moins une des deux conditions est juste}
\NormalTok{a }\OperatorTok{<}\StringTok{ }\NormalTok{b }\OperatorTok{|}\StringTok{  }\NormalTok{b }\OperatorTok{<}\StringTok{ }\NormalTok{c}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

Notez que l'opérateur \textbf{ET} est prioritaire sur l'opérateur \textbf{OU} et que les parenthèses sont prioritaires sur tous les opérateurs :

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# produit TRUE car on va commencer par tester a < b ET b < c ce qui donne FALSE}
\CommentTok{# on obtient ensuite}
\CommentTok{# FALSE |  a > c}
\CommentTok{# enfin, a est bien supérieur à c, donc l'une des deux conditions est vraie}
\NormalTok{a }\OperatorTok{<}\StringTok{ }\NormalTok{b }\OperatorTok{&}\StringTok{ }\NormalTok{b }\OperatorTok{<}\StringTok{ }\NormalTok{c }\OperatorTok{|}\StringTok{  }\NormalTok{a }\OperatorTok{>}\StringTok{ }\NormalTok{c}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

Notez qu'en arrière-plan, les opérateurs sont en réalité des fonctions déguisées. Il est donc possible de définir de nouveau comportements pour les opérateurs. Il est par exemple possible d'additionner ou comparer des objets spéciaux comme des dates, des géométries, des graphes, etc.

\hypertarget{sect0136}{%
\subsection{Structures de données}\label{sect0136}}

Jusqu'ici, nous avons travaillé avec des objets ne comprenant qu'une seule valeur. Lors d'une analyse statistique, nous allons travailler avec des volumes de données bien plus conséquents. Pour stocker plusieurs valeurs, nous allons travailler avec les structures de données que sont les vecteurs, les matrices, les \emph{dataframes} et les listes.

\hypertarget{sect01361}{%
\subsubsection{Vecteurs}\label{sect01361}}

Les vecteurs sont la brique élémentaire de R . Ils permettent de stocker une série de valeur du même type dans une seule variable. Pour déclarer un vecteur, on utilise la fonction \emph{c()} :

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ages <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{35}\NormalTok{,}\DecValTok{45}\NormalTok{,}\DecValTok{72}\NormalTok{,}\DecValTok{56}\NormalTok{,}\DecValTok{62}\NormalTok{)}
\NormalTok{tailles <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\FloatTok{175.5}\NormalTok{,}\FloatTok{180.3}\NormalTok{,}\FloatTok{168.2}\NormalTok{,}\FloatTok{172.8}\NormalTok{,}\FloatTok{167.6}\NormalTok{)}
\NormalTok{adresses <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'4225 rue de la gauchetiere'}\NormalTok{,}
              \StringTok{'4223 rue de la gauchetiere'}\NormalTok{,}
              \StringTok{'4221 rue de la gauchetiere'}\NormalTok{,}
              \StringTok{'4219 rue de la gauchetiere'}\NormalTok{,}
              \StringTok{'4217 rue de la gauchetiere'}\NormalTok{)}
\NormalTok{proprietaires <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\OtherTok{TRUE}\NormalTok{,}\OtherTok{TRUE}\NormalTok{,}\OtherTok{FALSE}\NormalTok{,}\OtherTok{TRUE}\NormalTok{,}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Nous venons ainsi de déclarer quatre nouvelles variables étant chacune un vecteur de longueur cinq (comprenant chacun cinq valeurs). Ces vecteurs représentent, par exemple, les réponses de plusieurs répondants à un questionnaire.

\begin{bloc_attention}

Il existe dans R une subtilité à l'origine de nombreux malentendus : la distinctions entre un vecteur de type texte et un vecteur de type facteur. Dans l'exemple précédent, le vecteur \emph{adresses} est un vecteur de type texte. Chaque nouvelle valeur ajoutée dans le vecteur peut être n'importe quelle nouvelle adresse. Déclarons un nouveau vecteur qui contiendrait cette fois-ci la couleur des yeux de personnes ayant répondu au questionnaire.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{couleurs_yeux <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'marron'}\NormalTok{,}\StringTok{'marron'}\NormalTok{,}\StringTok{'bleu'}\NormalTok{,}\StringTok{'bleu'}\NormalTok{,}\StringTok{'marron'}\NormalTok{,}\StringTok{'vert'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Contrairement aux adresses, il y a un nombre limité de couleurs que nous pouvons mettre dans ce vecteur. Il serait intéressant de fixer les valeurs possibles du vecteur pour s'assurer que de nouvelles ne soient pas ajoutées par erreur. Pour cela, nous pouvons convertir ce vecteur texte en vecteur de type facteur avec la fonction \texttt{as.factor}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{couleurs_yeux_facteur <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(couleurs_yeux)}
\end{Highlighting}
\end{Shaded}

Notez que à présent, nous pouvons ajouter une nouvelle couleur dans le 1er vecteur, mais pas dans le second.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{couleurs_yeux[}\DecValTok{7}\NormalTok{] <-}\StringTok{ "rouge"}
\NormalTok{couleurs_yeux_facteur[}\DecValTok{7}\NormalTok{] <-}\StringTok{ "rouge"}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in `[<-.factor`(`*tmp*`, 7, value = "rouge"): invalid factor level, NA
## generated
\end{verbatim}

Le message d'erreur nous informe que nous avons tenté d'introduire une valeur invalide dans le facteur.

Les facteurs peuvent sembler restrictifs et très régulièrement, on préfère travailler avec de simples vecteurs de type texte plutôt que des facteurs. Cependant, de nombreuses fonctions d'analyse nécessitent d'utiliser des facteurs car ils assurent une certaine cohérence dans les données. Il est donc essentiel de savoir passer du texte au facteur avec la fonction \texttt{as.factor}. À l'inverse, il est parfois nécessaire de revenir à une variable de type texte avec la fonction \texttt{as.character}.

Notez que des vecteurs numériques peuvent aussi être convertis en facteurs :

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tailles_facteur <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(tailles)}
\end{Highlighting}
\end{Shaded}

Cependant, si vous souhaitez reconvertir ce facteur en format numérique, il faudra passer dans un premier temps par le format texte :

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{as.numeric}\NormalTok{(tailles_facteur)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4 5 2 3 1
\end{verbatim}

Comme vous pouvez le voir, convertir un facteur en valeur numérique renvoie des nombres entiers. Ceci est dû au fait que les valeurs dans un facteur sont recodées sous forme de nombres entiers, chaque nombre correspondant à une des valeurs originales (appelées niveaux). Si on convertit un facteur en valeurs numériques, on obtient donc ces nombres entiers.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{as.numeric}\NormalTok{(}\KeywordTok{as.character}\NormalTok{(tailles_facteur))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 175.5 180.3 168.2 172.8 167.6
\end{verbatim}

Moralité de l'histoire, ne confondez pas les données de type texte et de type facteur. Dans le doute, vous pouvez demander à R quel est le type d'un vecteur avec la fonction \texttt{class}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{class}\NormalTok{(tailles)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "numeric"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{class}\NormalTok{(tailles_facteur)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "factor"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{class}\NormalTok{(couleurs_yeux)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "character"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{class}\NormalTok{(couleurs_yeux_facteur)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "factor"
\end{verbatim}

\end{bloc_attention}

Quasiment toutes les fonctions utilisent des vecteurs. Par exemple, on pourrait calculer la moyenne du vecteur \emph{ages} en utilisant la fonction \emph{mean} présente de base dans R .

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{mean}\NormalTok{(ages)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 54
\end{verbatim}

Quand nous disons que le vecteur est la brique élémentaire de R , ce n'est pas juste une façon de parler. Toutes les variables que nous avons déclarés dans les sections précédentes sont aussi des vecteurs, mais de longueur 1 !

\hypertarget{sect01362}{%
\subsubsection{Matrices}\label{sect01362}}

Il est possible de combiner des vecteurs pour former des matrices. Une matrice est un tableau en deux dimensions (colonnes et lignes) généralement utilisé pour représenter certaines structures de données comme des images (pixels), effectuer du calcul matriciel ou plus simplement présenter des matrices de corrélations. Vous aurez rarement à travailler directement avec des matrices, mais il est bon de savoir ce qu'elles sont. Créons deux matrices à partir de nos précédents vecteurs.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{matrice1 <-}\StringTok{ }\KeywordTok{cbind}\NormalTok{(ages,tailles)}
\CommentTok{# afficher la matrice 1}
\KeywordTok{print}\NormalTok{(matrice1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      ages tailles
## [1,]   35   175.5
## [2,]   45   180.3
## [3,]   72   168.2
## [4,]   56   172.8
## [5,]   62   167.6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# afficher les dimensions de la matrice 1}
\KeywordTok{print}\NormalTok{(}\KeywordTok{dim}\NormalTok{(matrice1))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 5 2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{matrice2 <-}\StringTok{ }\KeywordTok{rbind}\NormalTok{(ages, tailles)}
\CommentTok{# afficher la matrice 2}
\KeywordTok{print}\NormalTok{(matrice2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          [,1]  [,2]  [,3]  [,4]  [,5]
## ages     35.0  45.0  72.0  56.0  62.0
## tailles 175.5 180.3 168.2 172.8 167.6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# afficher les dimensions de la matrice 2}
\KeywordTok{print}\NormalTok{(}\KeywordTok{dim}\NormalTok{(matrice2))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2 5
\end{verbatim}

Comme vous pouvez le constater, la fonction \texttt{cbind} permet de concaténer des vecteurs comme s'ils étaient les colonnes d'une matrice, alors que \texttt{rbind} les combine comme s'ils étaient des lignes d'une matrice. La figure \ref{fig:fig012} présente graphiquement le passage du vecteur à la matrice.

\begin{figure}

{\centering \includegraphics[width=0.3\linewidth]{images/introduction/vecteur_to_matrix} 

}

\caption{Du vecteur à la matrice}\label{fig:fig012}
\end{figure}

Notez que vous pouvez transposer une matrice avec la fonction \texttt{t}. Si nous essayons maintenant de comparer la matrice 1 et la matrice 2 nous allons avoir une erreur car elles n'ont pas les mêmes dimensions.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{matrice1 }\OperatorTok{==}\StringTok{ }\NormalTok{matrice2}
\end{Highlighting}
\end{Shaded}

{Error in matrice1 == matrice2 : non-conformable arrays}

En revanche, on pourrait transposer la matrice 1 et refaire cette comparaison :

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{t}\NormalTok{(matrice1) }\OperatorTok{==}\StringTok{ }\NormalTok{matrice2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         [,1] [,2] [,3] [,4] [,5]
## ages    TRUE TRUE TRUE TRUE TRUE
## tailles TRUE TRUE TRUE TRUE TRUE
\end{verbatim}

Le résultat souligne bien que l'on a les mêmes valeurs dans les deux matrices. Il est aussi possible de construire des matrices directement avec la fonction \texttt{matrix}, ce que nous montrons dans la prochaine section.

\hypertarget{sect01363}{%
\subsubsection{\texorpdfstring{\emph{Arrays}}{Arrays}}\label{sect01363}}

S'il est rare de travailler directement avec des matrices, il est encore plus rare de travailler avec des \emph{arrays}. Un \emph{array} est une matrice spéciale qui peut avoir plus que deux dimensions. Un cas simple serait un \emph{array} en trois dimensions : lignes, colonnes, profondeur, que l'on pourrait se représenter comme un cube divisé en sous cubes. Au delà de trois dimensions, il devient difficile de se les représenter. Cette structure de données peut être utilisée pour représenter les différentes bandes spectrales d'une image satellitaire. Les lignes et les colonnes délimiteraient les pixels de l'image, la profondeur quant à elle délimiterait les différents bandes composant l'image (figure \ref{fig:fig012}).

\begin{figure}

{\centering \includegraphics[width=0.15\linewidth]{images/introduction/array} 

}

\caption{Un array avec trois dimension}\label{fig:fig013}
\end{figure}

Créons un array en combinant trois matrices avec la fonction \texttt{array}. Chacune de ces matrices sera composée respectivement de 1, de 2 et de 3 et aura une dimension de 5 x 5. L'array final aura donc des dimensions de 5 x 5 x 3.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mat1 <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DataTypeTok{nrow =} \DecValTok{5}\NormalTok{, }\DataTypeTok{ncol =} \DecValTok{5}\NormalTok{)}
\NormalTok{mat2 <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DataTypeTok{nrow =} \DecValTok{5}\NormalTok{, }\DataTypeTok{ncol =} \DecValTok{5}\NormalTok{)}
\NormalTok{mat3 <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DataTypeTok{nrow =} \DecValTok{5}\NormalTok{, }\DataTypeTok{ncol =} \DecValTok{5}\NormalTok{)}

\NormalTok{mon_array <-}\StringTok{ }\KeywordTok{array}\NormalTok{(}\KeywordTok{c}\NormalTok{(mat1, mat2, mat3), }\DataTypeTok{dim =} \KeywordTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{3}\NormalTok{))}

\KeywordTok{print}\NormalTok{(mon_array)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## , , 1
## 
##      [,1] [,2] [,3] [,4] [,5]
## [1,]    1    1    1    1    1
## [2,]    1    1    1    1    1
## [3,]    1    1    1    1    1
## [4,]    1    1    1    1    1
## [5,]    1    1    1    1    1
## 
## , , 2
## 
##      [,1] [,2] [,3] [,4] [,5]
## [1,]    2    2    2    2    2
## [2,]    2    2    2    2    2
## [3,]    2    2    2    2    2
## [4,]    2    2    2    2    2
## [5,]    2    2    2    2    2
## 
## , , 3
## 
##      [,1] [,2] [,3] [,4] [,5]
## [1,]    3    3    3    3    3
## [2,]    3    3    3    3    3
## [3,]    3    3    3    3    3
## [4,]    3    3    3    3    3
## [5,]    3    3    3    3    3
\end{verbatim}

\hypertarget{sect01364}{%
\subsubsection{\texorpdfstring{\emph{DataFrames}}{DataFrames}}\label{sect01364}}

S'il est rare de manipuler des matrices et des \emph{arrays}, le \emph{DataFrame} (tableau de données en français) est la structure de données avec laquelle vous travaillerez le plus souvent.
Dans cette structure, chaque ligne du tableau représente un individu et chaque colonne représente une caractéristique de ces individus. Ces colonnes ont des noms, ce qui permet facilement d'accéder à leurs valeurs. Créons ensemble un \emph{DataFrame} à partir de nos quatres vecteurs et de la fonction \texttt{data.frame}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}
  \StringTok{"age"}\NormalTok{ =}\StringTok{ }\NormalTok{ages,}
  \StringTok{"taille"}\NormalTok{ =}\StringTok{ }\NormalTok{tailles,}
  \StringTok{"adresse"}\NormalTok{ =}\StringTok{ }\NormalTok{adresses,}
  \StringTok{"proprietaire"}\NormalTok{ =}\StringTok{ }\NormalTok{proprietaires}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:tabfirsttable}Un premier DataFrame}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{rrll}
\toprule
age & taille & adresse & proprietaire\\
\midrule
35 & 175.5 & 4225 rue de la gauchetiere & TRUE\\
45 & 180.3 & 4223 rue de la gauchetiere & TRUE\\
72 & 168.2 & 4221 rue de la gauchetiere & FALSE\\
56 & 172.8 & 4219 rue de la gauchetiere & TRUE\\
62 & 167.6 & 4217 rue de la gauchetiere & TRUE\\
\bottomrule
\end{tabular}
\end{table}

Dans Rstudio, vous pouvez visualiser votre tableau de données avec la fonction \texttt{View(df)}. Comme vous pouvez le constater, chaque vecteur est devenu une colonne de votre tableau de données \emph{df}. La figure \ref{fig:fig014} résume ce passage d'une simple donnée à un DataFrame en passant par un vecteur.

\begin{figure}

{\centering \includegraphics[width=0.25\linewidth]{images/introduction/vecteur_to_dataframe} 

}

\caption{De la donnée au DataFrame}\label{fig:fig014}
\end{figure}

Plusieurs fonctions de base de R fournissent des informations importantes sur un \emph{DataFrame} :

\begin{itemize}
\tightlist
\item
  \texttt{names} renvoie les noms des colonnes du DataFrame;
\item
  \texttt{nrow} renvoie le nombre de lignes;
\item
  \texttt{ncol} renvoie le nombre de colonnes.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{names}\NormalTok{(df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "age"          "taille"       "adresse"      "proprietaire"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{nrow}\NormalTok{(df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ncol}\NormalTok{(df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4
\end{verbatim}

Vous pouvez accéder à chaque colonne de \emph{df} en utilisant le symbole \texttt{\$} ou \texttt{{[}{[}"nom\_de\_la\_colonne"{]}{]}}. Recalculons ainsi la moyenne des âges :

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{mean}\NormalTok{(df}\OperatorTok{$}\NormalTok{age)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 54
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{mean}\NormalTok{(df[[}\StringTok{"age"}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 54
\end{verbatim}

\hypertarget{sect01365}{%
\subsubsection{Listes}\label{sect01365}}

La dernière structure de données à connaître est la liste. Elle ressemble à un vecteur, au sens où elle permet de stocker un ensemble d'objets les uns à la suite des autres. Cependant, une liste peut contenir n'importe quel type d'objets. Vous pouvez ainsi construire des listes de matrices, des listes d'\emph{arrays}, des listes mixant des vecteurs, des graphiques, des \emph{DataFrames}, des listes de listes\ldots{}

Créons ensemble une liste qui va contenir des vecteurs et des matrices à l'aide de la fonction \texttt{list.}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ma_liste <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{),}
                 \KeywordTok{matrix}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DataTypeTok{ncol =} \DecValTok{3}\NormalTok{, }\DataTypeTok{nrow =} \DecValTok{5}\NormalTok{),}
                 \KeywordTok{matrix}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DataTypeTok{ncol =} \DecValTok{3}\NormalTok{, }\DataTypeTok{nrow =} \DecValTok{7}\NormalTok{),}
                 \StringTok{'A'}
\NormalTok{                 )}
\end{Highlighting}
\end{Shaded}

Il est possible d'accéder aux éléments de la liste par leur position dans cette dernière en utilisant les doubles crochets \texttt{{[}{[}\ {]}{]}}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(ma_liste[[}\DecValTok{1}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 2 3 4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(ma_liste[[}\DecValTok{4}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "A"
\end{verbatim}

Il est aussi possible de donner des noms aux éléments de la liste et d'utiliser le symbole \texttt{\$} pour y accéder. Créons une nouvelle liste de vecteurs et donnons leurs des noms avec la fonction \texttt{names}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{liste2 <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{35}\NormalTok{,}\DecValTok{45}\NormalTok{,}\DecValTok{72}\NormalTok{,}\DecValTok{56}\NormalTok{,}\DecValTok{62}\NormalTok{), }
               \KeywordTok{c}\NormalTok{(}\FloatTok{175.5}\NormalTok{,}\FloatTok{180.3}\NormalTok{,}\FloatTok{168.2}\NormalTok{,}\FloatTok{172.8}\NormalTok{,}\FloatTok{167.6}\NormalTok{),}
               \KeywordTok{c}\NormalTok{(}\OtherTok{TRUE}\NormalTok{,}\OtherTok{TRUE}\NormalTok{,}\OtherTok{FALSE}\NormalTok{,}\OtherTok{TRUE}\NormalTok{,}\OtherTok{TRUE}\NormalTok{)}
\NormalTok{)}
\KeywordTok{names}\NormalTok{(liste2) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{,}\StringTok{'taille'}\NormalTok{,}\StringTok{'proprietaire'}\NormalTok{)}

\KeywordTok{print}\NormalTok{(liste2}\OperatorTok{$}\NormalTok{age)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 35 45 72 56 62
\end{verbatim}

Si vous avez bien suivi, vous devez avoir compris qu'un \emph{DataFrame} n'est en fait rien d'autre qu'une liste de vecteurs avec des noms !

Bravo ! Vous venez de faire le tour des bases du langage R . Nous allons pouvoir passer à la suite et apprendre à manipuler des données dans des \emph{DataFrames} !

\hypertarget{sect014}{%
\section{Manipuler des données}\label{sect014}}

Dans cette section, vous apprendrez à charger et manipuler des \emph{DataFrames} en vue d'effectuer des opérations classiques de gestion de données.

\hypertarget{sect0141}{%
\subsection{\texorpdfstring{Charger un \emph{DataFrame} depuis un fichier}{Charger un DataFrame depuis un fichier}}\label{sect0141}}

Il sera rarement nécessaire de créer vos \emph{DataFrames} manuellement comme réalisé dans la section précédente. Le plus souvent, vous disposerez de fichiers contenant vos données et utiliserez des fonctions pour les importer dans R sous forme d'un \emph{DataFrame}. Les formats à importer les plus répandus sont :

\begin{itemize}
\tightlist
\item
  \emph{.csv}, soit un fichier texte dont chaque ligne représente une ligne du tableau de données dont les colonnes sont séparées par un délimiteur (généralement une virgule ou un point-virgule).
\item
  \emph{.dbf}, ou fichier \emph{dBase}, souvent associés à des fichiers d'information géographique au format \emph{ShapeFile}.
\item
  \emph{.xls} et \emph{.xlsx}, soit des fichiers générés par Excel.
\item
  \emph{.json}, soit un fichier texte utilisant la norme d'écriture propre au langage JavaScript.
\end{itemize}

Plus rarement, il se peut que vous aillez à charger des fichiers provenant de logiciels propriétaires :

\begin{itemize}
\tightlist
\item
  \emph{.sas7bdat} (SAS),
\item
  \emph{.sav} (SPSS) et
\item
  \emph{.dta} (STATA).
\end{itemize}

Pour lire la plupart de ces fichiers, nous allons utiliser le \emph{package} \textbf{foreign} dédié à l'importation d'une multitude de formats. Commencez donc par l'installer (\texttt{install.packages("foreign")}). Nous allons charger cinq fois le même jeu de données enregistré dans des formats différents (\emph{csv}, \emph{dbf}, \emph{dta}, \emph{sas7bdat} et \emph{xlsx}). Aussi, nous mesurerons le temps nécessaire pour importer chacun de ces fichiers avec la fonction \texttt{Sys.time}.

\hypertarget{sect01411}{%
\subsubsection{\texorpdfstring{Lire un fichier \emph{csv}}{Lire un fichier csv}}\label{sect01411}}

Pour le format \emph{csv}, il n'y a pas besoin d'utiliser un \emph{package} puisque R dispose d'une fonction de base pour lire ce format.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{t1 <-}\StringTok{ }\KeywordTok{Sys.time}\NormalTok{()}
\NormalTok{df1 <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/priseenmain/SR_MTL_2016.csv"}\NormalTok{, }
         \DataTypeTok{header =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{sep =} \StringTok{","}\NormalTok{, }\DataTypeTok{dec =} \StringTok{"."}\NormalTok{,}
         \DataTypeTok{stringsAsFactors =} \OtherTok{FALSE}\NormalTok{)}
\NormalTok{t2 <-}\StringTok{ }\KeywordTok{Sys.time}\NormalTok{()}
\NormalTok{d1 <-}\StringTok{ }\KeywordTok{difftime}\NormalTok{(t2,t1,}\DataTypeTok{units=}\StringTok{"secs"}\NormalTok{)}

\KeywordTok{cat}\NormalTok{(}\StringTok{'le dataframe df1 a '}\NormalTok{,}\KeywordTok{nrow}\NormalTok{(df1),}\StringTok{' observations'}\NormalTok{,}
    \StringTok{'et '}\NormalTok{,}\KeywordTok{ncol}\NormalTok{(df1),}\StringTok{"colonnes}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## le dataframe df1 a  951  observations et  48 colonnes
\end{verbatim}

Rien de bien compliqué ! Notez tout de même que :

\begin{itemize}
\tightlist
\item
  Lorsque vous chargez un fichier \emph{csv}, vous devez connaître le \textbf{séparateur}, soit le caractère utilisé pour délimiter les colonnes. Dans le cas présent, il s'agit d'une virgule (spécifiez avec l'argument \texttt{sep\ =\ ","}), mais il pourrait tout aussi bien être un point virgule (\texttt{sep\ =\ ";"}) une tabulation (\texttt{sep\ =\ "\ \ \ \ "}), etc.
\item
  Vous devez également spécifier le caractère utilisé comme séparateur de décimales. Le plus souvent, ce sera le point (\texttt{dec\ =\ "."}), mais certains logiciels avec des paramètres régionaux de langue française (notamment Excel) exportent des fichiers \emph{csv} avec des virgules comme séparateur de décimales (utilisez alors \texttt{dec\ =\ ","}).
\item
  L'argument \texttt{header} indique si la première ligne (l'entête) du fichier comprend ou non les noms des colonnes du jeu de données (avec les valeurs \texttt{TRUE} ou \texttt{FALSE}). Il arrive que certains fichiers \emph{csv} soient fournis sans entête et que les noms et descriptions des colonnes soient fournis dans un autre fichier.
\item
  L'argument \emph{stringsAsFactors} permet d'indiquer à R que les colonnes comportant du texte doivent être chargées comme des vecteurs de type texte et nom de type facteur.
\end{itemize}

\hypertarget{sect01412}{%
\subsubsection{\texorpdfstring{Lire un fichier \emph{dbase}}{Lire un fichier dbase}}\label{sect01412}}

Pour lire un fichier \emph{dbase} (.dbf), nous utilisons la fonction \texttt{read.dbf} du \emph{package} \textbf{foreign} installé précédemment :

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(foreign)}

\NormalTok{t1 <-}\StringTok{ }\KeywordTok{Sys.time}\NormalTok{()}
\NormalTok{df2 <-}\StringTok{ }\KeywordTok{read.dbf}\NormalTok{(}\StringTok{"data/priseenmain/SR_MTL_2016.dbf"}\NormalTok{)}
\NormalTok{t2 <-}\StringTok{ }\KeywordTok{Sys.time}\NormalTok{()}
\NormalTok{d2 <-}\StringTok{ }\KeywordTok{difftime}\NormalTok{(t2,t1,}\DataTypeTok{units=}\StringTok{"secs"}\NormalTok{)}

\KeywordTok{cat}\NormalTok{(}\StringTok{'le dataframe df2 a '}\NormalTok{,}\KeywordTok{nrow}\NormalTok{(df2),}\StringTok{' observations'}\NormalTok{,}
    \StringTok{'et '}\NormalTok{,}\KeywordTok{ncol}\NormalTok{(df2),}\StringTok{"colonnes}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## le dataframe df2 a  951  observations et  48 colonnes
\end{verbatim}

Comme vous pouvez le constater, nous obtenons les mêmes résultats qu'avec le fichier \emph{csv}.

\hypertarget{sect01413}{%
\subsubsection{\texorpdfstring{Lire un fichier \emph{dta} (Stata)}{Lire un fichier dta (Stata)}}\label{sect01413}}

Si vous travaillez avec des collègues utilisant le logiciel Stata, il se peut que ces derniers vous partagent des fichiers \emph{dta}. Toujours en utilisant le \emph{package} \textbf{foreign}, vous serez en mesure de les charger directement dans R .

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{t1 <-}\StringTok{ }\KeywordTok{Sys.time}\NormalTok{()}
\NormalTok{df3 <-}\StringTok{ }\KeywordTok{read.dta}\NormalTok{(}\StringTok{"data/priseenmain/SR_MTL_2016.dta"}\NormalTok{)}
\NormalTok{t2 <-}\StringTok{ }\KeywordTok{Sys.time}\NormalTok{()}
\NormalTok{d3 <-}\StringTok{ }\KeywordTok{difftime}\NormalTok{(t2,t1,}\DataTypeTok{units=}\StringTok{"secs"}\NormalTok{)}

\KeywordTok{cat}\NormalTok{(}\StringTok{'le dataframe df3 a '}\NormalTok{,}\KeywordTok{nrow}\NormalTok{(df3),}\StringTok{' observations'}\NormalTok{,}
    \StringTok{'et '}\NormalTok{,}\KeywordTok{ncol}\NormalTok{(df3),}\StringTok{"colonnes}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, }\DataTypeTok{sep =} \StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## le dataframe df3 a 951 observationset 48colonnes
\end{verbatim}

\hypertarget{sect01414}{%
\subsubsection{\texorpdfstring{Lire un fichier \emph{sav} (SPSS)}{Lire un fichier sav (SPSS)}}\label{sect01414}}

SPSS est encore utilisé dans le milieu académique, surtout au premier cycle, bien que de moins en moins. Pour importer un fichier \emph{sav}, vous pourrez utiliser la fonction \texttt{read.spss} \emph{package} \textbf{foreign}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{t1 <-}\StringTok{ }\KeywordTok{Sys.time}\NormalTok{()}
\NormalTok{df4 <-}\StringTok{ }\KeywordTok{as.data.frame}\NormalTok{(}\KeywordTok{read.spss}\NormalTok{(}\StringTok{"data/priseenmain/SR_MTL_2016.sav"}\NormalTok{))}
\NormalTok{t2 <-}\StringTok{ }\KeywordTok{Sys.time}\NormalTok{()}
\NormalTok{d4 <-}\StringTok{ }\KeywordTok{difftime}\NormalTok{(t2,t1,}\DataTypeTok{units=}\StringTok{"secs"}\NormalTok{)}

\KeywordTok{cat}\NormalTok{(}\StringTok{'le dataframe df4 a '}\NormalTok{,}\KeywordTok{nrow}\NormalTok{(df4),}\StringTok{' observations'}\NormalTok{,}
    \StringTok{'et '}\NormalTok{,}\KeywordTok{ncol}\NormalTok{(df4),}\StringTok{"colonnes}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, }\DataTypeTok{sep =} \StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## le dataframe df4 a 951 observationset 48colonnes
\end{verbatim}

\hypertarget{sect01415}{%
\subsubsection{\texorpdfstring{Lire un fichier \emph{sas7bdat} (SAS)}{Lire un fichier sas7bdat (SAS)}}\label{sect01415}}

SAS est encore utilisé dans les milieux académiques, gouvernementaux et privés. Pour importer un fichier \emph{sas7bdat}, vous pourrez utiliser le \emph{package} \textbf{sas7bdat} que vous devrez préalablement installer (\texttt{install.packages("sas7bdat")}) et charger (\texttt{library(sas7bdat)}).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(sas7bdat)}

\NormalTok{t1 <-}\StringTok{ }\KeywordTok{Sys.time}\NormalTok{()}
\NormalTok{df5 <-}\StringTok{ }\KeywordTok{read.sas7bdat}\NormalTok{(}\StringTok{"data/priseenmain/SR_MTL_2016.sas7bdat"}\NormalTok{)}
\NormalTok{t2 <-}\StringTok{ }\KeywordTok{Sys.time}\NormalTok{()}
\NormalTok{d5 <-}\StringTok{ }\KeywordTok{difftime}\NormalTok{(t2,t1,}\DataTypeTok{units=}\StringTok{"secs"}\NormalTok{)}

\KeywordTok{cat}\NormalTok{(}\StringTok{'le dataframe df5 a '}\NormalTok{,}\KeywordTok{nrow}\NormalTok{(df5),}\StringTok{' observations'}\NormalTok{,}
    \StringTok{'et '}\NormalTok{,}\KeywordTok{ncol}\NormalTok{(df5),}\StringTok{"colonnes}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, }\DataTypeTok{sep =}\StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## le dataframe df5 a 951 observationset 48colonnes
\end{verbatim}

\hypertarget{sect01416}{%
\subsubsection{\texorpdfstring{Lire un fichier \emph{xlsx} (Excel)}{Lire un fichier xlsx (Excel)}}\label{sect01416}}

Lire un fichier Excel dans R n'est pas toujours une tâche facile. Généralement, nous recommandons d'exporter les fichiers en question au format \emph{csv} dans un premier temps, puis de le lire avec la fonction \texttt{read.csv} dans un second temps (LIEN SECTION).
Il est néanmoins possible de lire directement un fichier \emph{xlsx} avec le \emph{package} \textbf{xlsx}. Ce dernier requiert que le logiciel JAVA soit installé sur votre ordinateur (Windows, Mac ou Linux). Si vous utilisez la version 64 bit de R , vous devrez télécharger et installer la version 64 bit de JAVA. Une fois que ce logiciel tiers est installé, il ne vous restera plus qu'à installer (\texttt{install.packages("xlsx")}) et charger (\texttt{library(xlsx)}) le \emph{package} \textbf{xlsx}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(xlsx)}

\NormalTok{t1 <-}\StringTok{ }\KeywordTok{Sys.time}\NormalTok{()}
\NormalTok{df6 <-}\StringTok{ }\KeywordTok{read.xlsx}\NormalTok{(}\DataTypeTok{file=}\StringTok{"data/priseenmain/SR_MTL_2016.xlsx"}\NormalTok{,}
                 \DataTypeTok{sheetIndex =} \DecValTok{1}\NormalTok{,}
                 \DataTypeTok{as.data.frame =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{t2 <-}\StringTok{ }\KeywordTok{Sys.time}\NormalTok{()}
\NormalTok{d6 <-}\StringTok{ }\KeywordTok{difftime}\NormalTok{(t2,t1,}\DataTypeTok{units=}\StringTok{"secs"}\NormalTok{)}

\KeywordTok{cat}\NormalTok{(}\StringTok{'le dataframe df6 a '}\NormalTok{,}\KeywordTok{nrow}\NormalTok{(df6),}\StringTok{' observations'}\NormalTok{,}
    \StringTok{'et '}\NormalTok{,}\KeywordTok{ncol}\NormalTok{(df6),}\StringTok{"colonnes}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, }\DataTypeTok{sep =} \StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## le dataframe df6 a 951 observationset 48colonnes
\end{verbatim}

Il est possible d'accélérer significativement la vitesse de lecture d'un fichier \emph{xlsx} en utilisant la fonction \texttt{read.xlsx2}. Il faut cependant indiquer à cette dernière le type de données de chaque colonne. Dans le cas présent, les cinq premières colonnes contiennent des données au format texte (\texttt{character}), alors que les 43 autres sont des données numériques (\texttt{numeric}). Nous utilisons la fonction \texttt{rep} afin de ne pas avoir à écrire plusieurs fois \emph{character} et \emph{numeric}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(xlsx)}

\NormalTok{t1 <-}\StringTok{ }\KeywordTok{Sys.time}\NormalTok{()}
\NormalTok{df7 <-}\StringTok{ }\KeywordTok{read.xlsx2}\NormalTok{(}\DataTypeTok{file=}\StringTok{"data/priseenmain/SR_MTL_2016.xlsx"}\NormalTok{,}
                  \DataTypeTok{sheetIndex =} \DecValTok{1}\NormalTok{, }
                  \DataTypeTok{as.data.frame =} \OtherTok{TRUE}\NormalTok{,}
                  \DataTypeTok{colClasses =} \KeywordTok{c}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\StringTok{"character"}\NormalTok{,}\DecValTok{5}\NormalTok{),}\KeywordTok{rep}\NormalTok{(}\StringTok{"numeric"}\NormalTok{,}\DecValTok{43}\NormalTok{))}
\NormalTok{                  )}
\NormalTok{t2 <-}\StringTok{ }\KeywordTok{Sys.time}\NormalTok{()}
\NormalTok{d7 <-}\StringTok{ }\KeywordTok{difftime}\NormalTok{(t2,t1,}\DataTypeTok{units=}\StringTok{"secs"}\NormalTok{)}

\KeywordTok{cat}\NormalTok{(}\StringTok{'le dataframe df6 a '}\NormalTok{,}\KeywordTok{nrow}\NormalTok{(df7),}\StringTok{' observations'}\NormalTok{,}
    \StringTok{'et '}\NormalTok{,}\KeywordTok{ncol}\NormalTok{(df7),}\StringTok{"colonnes}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, }\DataTypeTok{sep =} \StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## le dataframe df6 a 951 observationset 48colonnes
\end{verbatim}

Si l'on compare les temps d'exécution (tableau \ref{tab:tableduration}), on constate que la lecture des fichiers \emph{xlsx} peut être extrêmement longue si l'on ne spécifie pas le type des colonnes. Ceci peut devenir problématique pour des fichiers volumineux. Notez également que la lecture des fichiers \emph{csv} devient de plus en plus laborieuse à mesure que la taille du fichier \emph{csv} augmente. Si vous devez un jour charger des fichiers \emph{csv} de plusieurs gigaoctets, nous vous recommandons vivement d'utiliser la fonction \texttt{fread} du \emph{package} \textbf{data.table} qui est beaucoup plus rapide.

\begin{table}

\caption{\label{tab:tableduration}Temps nécessaire pour lire les données en fonction du type de fichiers}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{ll}
\toprule
Durée (s) & fonction\\
\midrule
0.03 secs & read.csv\\
0.03 secs & read.dbf\\
0.01 secs & read.spss\\
0.01 secs & read.dta\\
0.95 secs & read.sas7bdat\\
\addlinespace
20.07 secs & read.xlsx\\
0.42 secs & read.xlsx2\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{sect0142}{%
\subsection{\texorpdfstring{Manipuler un \emph{DataFrame}}{Manipuler un DataFrame}}\label{sect0142}}

Une fois le \emph{DataFrame} chargé, voyons comment il est possible de le manipuler.

\hypertarget{sect01421}{%
\subsubsection{\texorpdfstring{Un petit mot sur le \textbf{tidyverse}}{Un petit mot sur le tidyverse}}\label{sect01421}}

\textbf{Tidyverse} est un ensemble de \emph{packages} conçus pour faciliter la structuration et la manipulation des données dans R . Avant d'aller plus loin, il est important d'aborder brièvement un débat actuel dans la Communauté R . Entre 2010 et 2020, l'utilisation du \textbf{tidyverse} s'est peu à peu répandue. Développé et maintenu par Hadley Wickham, \textbf{tidyverse} introduit une philosophie et une grammaire spécifiques qui diffèrent du langage R traditionnel. Une partie de la communauté a pour ainsi dire complètement embrassé le \textbf{tidyverse} et de nombreux \emph{packages} en dehors du \textbf{tidyverse} ont adopté sa grammaire et sa philosophie. À l'inverse, une autre partie de la communauté est contre cette évolution (\href{https://blog.ephorie.de/why-i-dont-use-the-tidyverse}{voir l'article du blogue suivant}). Les arguments pour et contre \textbf{tidyverse} sont résumés dans le tableau suivant.

\begin{table}

\caption{\label{tab:tableTidyverse}Avantages et inconvénients du tidyverse}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{7cm}>{\raggedright\arraybackslash}p{7cm}}
\toprule
Avantage du tidyverse & Problème posé par le tidyverse\\
\midrule
Simplicité d'écriture et d'apprentissage & Nouvelle syntaxe à apprendre\\
Ajout de l'opérateur \%>\% permettant d'enchaîner les traitements & Perte de lisibilité avec l'opérateur ->\\
La meilleure librairie pour réaliser des graphiques : ggplot2 & Certaines fonctions de base sont remplacées par tidyverse lors de son chargement, pouvant créer des erreurs.\\
Crée un écosystème cohérent & Ajoute une dépendance dans le code\\
Package en développement et de plus en plus utilisé & Philosophie d'évolution agressive, aucune assurance de rétro-compatibilité\\
\bottomrule
\end{tabular}
\end{table}

Le dernier point est probablement le plus problématique. Dans sa volonté d'évoluer au mieux et sans restriction, le \emph{package} \textbf{tidyverse} n'offre aucune garantie de rétro-comptatibilité. En d'autre termes, des changements importants peuvent être introduit d'une version à l'autre rendant potentiellement obsolète votre propre code. Nous n'avons pas d'opinion tranchée sur le sujet : \textbf{tidyverse} est un outil très intéressant dans de nombreux cas; nous évitons simplement de l'utiliser systématiquement et préférons charger directement des sous-packages (comme \textbf{dplyr} ou \textbf{ggplot2}) du \textbf{tidyverse}. Notez que le \emph{package} \textbf{data.table} offre une alternative au \textbf{tidyverse} dans la manipulation de données. Au prix d'une syntaxe généralement un peu plus complexe, le package \textbf{data.table} offre une vitesse de calcul bien supérieure au \textbf{tidyverse} et assure une bonne rétro-compatibilité.

\hypertarget{sect01422}{%
\subsubsection{\texorpdfstring{Gérer les colonnes d'un \emph{DataFrame}}{Gérer les colonnes d'un DataFrame}}\label{sect01422}}

Repartons du \emph{DataFrame} que nous avions chargé précédemment grâce à un fichier \emph{csv}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\DataTypeTok{file=}\StringTok{"data/priseenmain/SR_MTL_2016.csv"}\NormalTok{, }
               \DataTypeTok{header =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{sep =} \StringTok{","}\NormalTok{, }\DataTypeTok{dec =} \StringTok{"."}\NormalTok{,}
               \DataTypeTok{stringsAsFactors =} \OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{sect014221}{%
\paragraph{Sélectionner une colonne}\label{sect014221}}

Pour rappel, il est possible d'accéder aux colonnes dans ce \emph{DataFrame} en utilisant le symbole dollar \texttt{\$ma\_colonne} ou les doubles crochets \texttt{{[}{[}"ma\_colonne"{]}{]}}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Calcul de la superficie totale de l'Île de Montréal}
\KeywordTok{sum}\NormalTok{(df}\OperatorTok{$}\NormalTok{KM2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4680.543
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sum}\NormalTok{(df[[}\StringTok{"KM2"}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4680.543
\end{verbatim}

\hypertarget{sect014222}{%
\paragraph{Sélectionner plusieurs colonnes}\label{sect014222}}

Il est possible de sélectionner plusieurs colonnes d'un \emph{DataFrame} et filtrer ainsi les colonnes inutiles. Pour cela, on peut utiliser un vecteur contenant soit la position de la colonne (1 pour la première colonne, 2 pour la seconde et ainsi de suite), soit les noms des colonnes.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Conserver les 5 premières colonnes}
\NormalTok{df2 <-}\StringTok{ }\NormalTok{df[}\DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{]}

\CommentTok{# Conserver les colonnes 1,5,10 et 15}
\NormalTok{df3 <-}\StringTok{ }\NormalTok{df[}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{10}\NormalTok{,}\DecValTok{15}\NormalTok{)]}

\CommentTok{# Cela peut aussi être utilisé pour changer l'ordre des champs}
\NormalTok{df3 <-}\StringTok{ }\NormalTok{df[}\KeywordTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{15}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{5}\NormalTok{)]}

\CommentTok{# Conserver les colonnes 1 à 5, 7 à 12, 17 et 22}
\NormalTok{df4 <-}\StringTok{ }\NormalTok{df[}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{,}\DecValTok{7}\OperatorTok{:}\DecValTok{12}\NormalTok{,}\DecValTok{17}\NormalTok{,}\DecValTok{22}\NormalTok{)]}

\CommentTok{# Conserver les colonnes avec leurs noms}
\NormalTok{df5 <-}\StringTok{ }\NormalTok{df[}\KeywordTok{c}\NormalTok{(}\StringTok{"SRIDU"}\NormalTok{,}\StringTok{"KM2"}\NormalTok{,}\StringTok{"Pop2016"}\NormalTok{,}\StringTok{"MaisonIndi"}\NormalTok{,}\StringTok{"LoyerMed"}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\hypertarget{sect014223}{%
\paragraph{Supprimer des colonnes}\label{sect014223}}

Il est parfois plus intéressant et rapide de directement supprimer des colonnes plutôt que de recréer un nouveau \emph{DataFrame}. Pour ce faire, on attribue la valeur \texttt{NULL} à ces colonnes.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Supprimer le colonnes 2, 3 et 5}
\NormalTok{df3[}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{)] <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\OtherTok{NULL}\NormalTok{)}

\CommentTok{# Supprimer une colonne avec son nom}
\NormalTok{df4}\OperatorTok{$}\NormalTok{OID <-}\StringTok{ }\OtherTok{NULL}

\CommentTok{# Supprimer plusieurs colonnes par leur nom}
\NormalTok{df5[}\KeywordTok{c}\NormalTok{(}\StringTok{"SRIDU"}\NormalTok{,}\StringTok{"LoyerMed"}\NormalTok{)] <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\OtherTok{NULL}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Notez que si vous supprimez une colonne, vous ne pouvez pas revenir en arrière. Il faudra recharger votre jeu de données ou éventuellement relancer les calculs qui avaient produit cette colonne.

\hypertarget{sect014224}{%
\paragraph{Renommer des colonnes}\label{sect014224}}

Il est possible de changer le nom d'un colonne. Cette opération est importante pour faciliter la lecture du \emph{DataFrame} ou encore s'assurer que l'exportation du \emph{DataFrame} dans un format ne posera pas de problème.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Voici les noms des colonnes}
\KeywordTok{names}\NormalTok{(df5)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "KM2"        "Pop2016"    "MaisonIndi"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Renommer toutes les colonnes}
\KeywordTok{names}\NormalTok{(df5) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'superficie_km2'}\NormalTok{,}\StringTok{'population_2016'}\NormalTok{, }\StringTok{'maison_individuelle_prt'}\NormalTok{)}
\KeywordTok{names}\NormalTok{(df5)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "superficie_km2"          "population_2016"        
## [3] "maison_individuelle_prt"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Renommer avec dplyr}
\KeywordTok{library}\NormalTok{(dplyr)}
\NormalTok{df4 <-}\StringTok{ }\KeywordTok{rename}\NormalTok{(df4, }\StringTok{"population_2016"}\NormalTok{ =}\StringTok{ "Pop2016"}\NormalTok{,}
              \StringTok{"prs_moins_14ans_prt"}\NormalTok{ =}\StringTok{ "A014"}\NormalTok{,}
              \StringTok{"prs_15_64_ans_prt"}\NormalTok{ =}\StringTok{ "A1564"}\NormalTok{,}
              \StringTok{"prs_65plus_ans_prt"}\NormalTok{ =}\StringTok{ "A65plus"}
\NormalTok{              )}
\end{Highlighting}
\end{Shaded}

\hypertarget{sect01423}{%
\subsubsection{Calculer de nouvelles variables}\label{sect01423}}

Il est possible d'utiliser les colonnes de type numérique pour calculer de nouvelles colonnes en utilisant les opérateurs mathématiques vus dans la section @ref(sect01\_35). Prenons un exemple concret : calculons la densité de population par secteur de recensement dans notre \emph{DataFrame} et affichons un résumé de cette nouvelle variable.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Calcul de la densité}
\NormalTok{df}\OperatorTok{$}\NormalTok{pop_density_}\DecValTok{2016}\NormalTok{ <-}\StringTok{ }\NormalTok{df}\OperatorTok{$}\NormalTok{Pop2016 }\OperatorTok{/}\StringTok{ }\NormalTok{df}\OperatorTok{$}\NormalTok{KM2}

\CommentTok{# Statistiques descriptives}
\KeywordTok{summary}\NormalTok{(df}\OperatorTok{$}\NormalTok{pop_density_}\DecValTok{2016}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
##    17.45  1946.96  3700.50  5465.03  7918.39 48811.79
\end{verbatim}

Nous pouvons aussi calculer le ratio entre le nombre de maisons et le nombre d'appartements.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Calcul du ratio}
\NormalTok{df}\OperatorTok{$}\NormalTok{total_maison <-}\StringTok{ }\NormalTok{(df}\OperatorTok{$}\NormalTok{MaisonIndi }\OperatorTok{+}\StringTok{ }\NormalTok{df}\OperatorTok{$}\NormalTok{MaisJumule }\OperatorTok{+}\StringTok{ }\NormalTok{df}\OperatorTok{$}\NormalTok{MaisRangee }\OperatorTok{+}\StringTok{ }\NormalTok{df}\OperatorTok{$}\NormalTok{AutreMais)}
\NormalTok{df}\OperatorTok{$}\NormalTok{total_apt <-}\StringTok{ }\NormalTok{(df}\OperatorTok{$}\NormalTok{AppDuplex }\OperatorTok{+}\StringTok{ }\NormalTok{df}\OperatorTok{$}\NormalTok{App5Moins }\OperatorTok{+}\StringTok{ }\NormalTok{df}\OperatorTok{$}\NormalTok{App5Plus)}
\NormalTok{df}\OperatorTok{$}\NormalTok{ratio_maison_apt <-}\StringTok{ }\NormalTok{df}\OperatorTok{$}\NormalTok{total_maison }\OperatorTok{/}\StringTok{ }\NormalTok{df}\OperatorTok{$}\NormalTok{total_apt}
\end{Highlighting}
\end{Shaded}

Retenez ici que R va appliquer le calcul à chaque ligne de votre jeu de données et stocker le résultat dans une nouvelle colonne. Cette opération est du calcul vectoriel : toute la colonne est calculée en une seule fois. R est d'ailleurs optimisé pour le calcul vectoriel.

\hypertarget{sect01424}{%
\subsubsection{Fonctions mathématiques}\label{sect01424}}

R propose un ensemble de fonctions de base pour effectuer du calcul. Voici une liste non-exhaustive des principales fonctions :

\begin{itemize}
\tightlist
\item
  \texttt{abs} calcule les valeurs absolues des valeurs d'un vecteur
\item
  \texttt{sqrt} calcule les racines carrées des valeurs d'un vecteur
\item
  \texttt{log} calcule les logarithmes des valeurs d'un vecteur
\item
  \texttt{exp} calcule les exponentiels des valeurs d'un vecteur
\item
  \texttt{factorial} calcule la factorielle des valeurs d'un vecteur
\item
  \texttt{round} arrondit les valeurs d'un vecteur
\item
  \texttt{ceiling}, \texttt{floor} arrondit à l'unité supérieure ou inférieure les valeurs d'un vecteur
\item
  \texttt{sin},\texttt{asin},\texttt{cos},\texttt{acos},\texttt{tan},\texttt{atan} sont des fonctions de trigonométrie classiques
\item
  \texttt{cumsum} calcule la somme cumulative des valeurs d'un vecteur.
\end{itemize}

Ces fonctions sont des fonctions vectorielles puisqu'elles s'appliquent à tous les éléments d'un vecteur. Si votre vecteur en entrée comprend cinq valeurs, le vecteur en sortie comprendra aussi cinq valeurs.

À l'inverse, les fonctions suivantes s'appliquent directement à l'ensemble d'un vecteur et ne vont renvoyer qu'une seule valeur :

\begin{itemize}
\tightlist
\item
  \texttt{sum} calcule la somme des valeurs d'un vecteur
\item
  \texttt{prod} calcule le produit des valeurs d'un vecteur
\item
  \texttt{min}, \texttt{max} renvoient les valeurs maximale et minimale d'un vecteur
\item
  \texttt{mean}, \texttt{median} renvoient la moyenne et la médiane d'un vecteur
\item
  \texttt{quantile} renvoit les percentiles d'un vecteur.
\end{itemize}

\hypertarget{sect01425}{%
\subsubsection{Fonctions pour manipuler du texte}\label{sect01425}}

En plus des données numériques, vous aurez à travailler avec des données textuelles. Le \textbf{tidyverse} avec le \emph{package} \textbf{stringr} offre des fonctions très intéressantes pour manipuler ce type de données. Pour un aperçu de toutes les fonctions offertes par \textbf{stringr}, référer-vous à sa \href{https://github.com/rstudio/cheatsheets/blob/master/strings.pdf}{Cheat Sheet}. Commençons avec un \emph{DataFrame} assez simple comprenant des adresses et des noms de personnes.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(stringr)}

\NormalTok{df <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}
  \DataTypeTok{noms =} \KeywordTok{c}\NormalTok{(}\StringTok{"Jérémy Toutanplace"}\NormalTok{,}\StringTok{"constant Tinople"}\NormalTok{,}\StringTok{"dino Resto"}\NormalTok{,}\StringTok{"Luce tancil"}\NormalTok{),}
  \DataTypeTok{adresses =} \KeywordTok{c}\NormalTok{(}\StringTok{'15 rue Levy'}\NormalTok{, }\StringTok{'413 Blvd Saint-Laurent'}\NormalTok{, }\StringTok{'3606 rue Duké'}\NormalTok{, }\StringTok{'2457 route St Marys'}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{sect014251}{%
\paragraph{Majuscules et minuscules}\label{sect014251}}

Pour harmoniser ce \emph{dataframe}, nous allons dans un premier temps mettre des majuscules au premier caractère des prénoms et noms des individus avec la fonction \texttt{str\_to\_title}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df}\OperatorTok{$}\NormalTok{noms_corr <-}\StringTok{ }\KeywordTok{str_to_title}\NormalTok{(df}\OperatorTok{$}\NormalTok{noms)}
\KeywordTok{print}\NormalTok{(df}\OperatorTok{$}\NormalTok{noms_corr)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Jérémy Toutanplace" "Constant Tinople"   "Dino Resto"        
## [4] "Luce Tancil"
\end{verbatim}

On pourrait également tout mettre en minuscule ou tout en majuscule.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df}\OperatorTok{$}\NormalTok{noms_min <-}\StringTok{ }\KeywordTok{tolower}\NormalTok{(df}\OperatorTok{$}\NormalTok{noms)}
\NormalTok{df}\OperatorTok{$}\NormalTok{noms_maj <-}\StringTok{ }\KeywordTok{toupper}\NormalTok{(df}\OperatorTok{$}\NormalTok{noms)}
\KeywordTok{print}\NormalTok{(df}\OperatorTok{$}\NormalTok{noms_min)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "jérémy toutanplace" "constant tinople"   "dino resto"        
## [4] "luce tancil"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(df}\OperatorTok{$}\NormalTok{noms_maj)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "JÉRÉMY TOUTANPLACE" "CONSTANT TINOPLE"   "DINO RESTO"        
## [4] "LUCE TANCIL"
\end{verbatim}

\hypertarget{sect014252}{%
\paragraph{Remplacer du texte}\label{sect014252}}

Dans les adresses, nous avons des caractères accentués. Ce type de caractères pose régulièrement des problèmes d'encodage et nous pourrions décider de les remplacer par des caractères simples avec la fonction \texttt{str\_replace\_all}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df}\OperatorTok{$}\NormalTok{adresses_}\DecValTok{1}\NormalTok{ <-}\StringTok{ }\KeywordTok{str_replace_all}\NormalTok{(df}\OperatorTok{$}\NormalTok{adresses,}\StringTok{'é'}\NormalTok{,}\StringTok{'e'}\NormalTok{)}
\KeywordTok{print}\NormalTok{(df}\OperatorTok{$}\NormalTok{adresses_}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "15 rue Levy"            "413 Blvd Saint-Laurent" "3606 rue Duke"         
## [4] "2457 route St Marys"
\end{verbatim}

Nous pouvons utiliser la même fonction pour remplacer les \emph{St} par Saint et les \emph{Blvd} par Boulevard.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df}\OperatorTok{$}\NormalTok{adresses_}\DecValTok{2}\NormalTok{ <-}\StringTok{ }\KeywordTok{str_replace_all}\NormalTok{(df}\OperatorTok{$}\NormalTok{adresses_}\DecValTok{1}\NormalTok{,}\StringTok{' St '}\NormalTok{,}\StringTok{' Saint '}\NormalTok{)}
\NormalTok{df}\OperatorTok{$}\NormalTok{adresses_}\DecValTok{3}\NormalTok{ <-}\StringTok{ }\KeywordTok{str_replace_all}\NormalTok{(df}\OperatorTok{$}\NormalTok{adresses_}\DecValTok{2}\NormalTok{,}\StringTok{' Blvd '}\NormalTok{,}\StringTok{' Boulevard '}\NormalTok{)}
\KeywordTok{print}\NormalTok{(df}\OperatorTok{$}\NormalTok{adresses_}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "15 rue Levy"                 "413 Boulevard Saint-Laurent"
## [3] "3606 rue Duke"               "2457 route Saint Marys"
\end{verbatim}

\hypertarget{sect014253}{%
\paragraph{Découper du texte}\label{sect014253}}

Il est parfois nécessaire de découper du texte pour en extraire des éléments. On doit alors choisir un caractère de découpage. Dans notre exemple, on pourrait vouloir extraire les numéros civiques des adresses, en utilisant le premier espace comme caractère de découpage, en utilisant la fonction \texttt{str\_split\_fixed}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df}\OperatorTok{$}\NormalTok{num_civique <-}\StringTok{ }\KeywordTok{str_split_fixed}\NormalTok{(df}\OperatorTok{$}\NormalTok{adresses_}\DecValTok{3}\NormalTok{, }\StringTok{' '}\NormalTok{,}\DataTypeTok{n=}\DecValTok{2}\NormalTok{)[,}\DecValTok{1}\NormalTok{]}
\KeywordTok{print}\NormalTok{(df}\OperatorTok{$}\NormalTok{num_civique)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "15"   "413"  "3606" "2457"
\end{verbatim}

Pour être exact, sachez que pour notre exemple, la fonction \texttt{str\_split\_fixed} renvoie deux colonnes de texte : une avec le texte avant le premier espace (donc le numéro civique) et une avec le reste du texte. Le nombre de colonnes est contrôlé par l'argument \texttt{n}. Si \texttt{n\ =\ 1}, la fonction ne fait aucun découpage, avec \texttt{n\ =\ 2} la fonction va découper en deux parties le texte avec la première occurence du délimiteur, et ainsi de suite. En ajoutant \texttt{{[},1{]}} à la fin, nous indiquons que nous souhaitons seulement garder la première des deux colonnes.

\hypertarget{sect014254}{%
\paragraph{Coller du texte}\label{sect014254}}

À l'inverse du découpage, il est parfois nécessaire de concaténer des éléments de texte, ce qu'il est possible de faire avec la fonction \texttt{paste}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df}\OperatorTok{$}\NormalTok{texte_complet <-}\StringTok{ }\KeywordTok{paste}\NormalTok{(df}\OperatorTok{$}\NormalTok{noms_corr, df}\OperatorTok{$}\NormalTok{adresses_}\DecValTok{3}\NormalTok{, }\DataTypeTok{sep =} \StringTok{" : "}\NormalTok{)}
\KeywordTok{print}\NormalTok{(df}\OperatorTok{$}\NormalTok{texte_complet)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Jérémy Toutanplace : 15 rue Levy"              
## [2] "Constant Tinople : 413 Boulevard Saint-Laurent"
## [3] "Dino Resto : 3606 rue Duke"                    
## [4] "Luce Tancil : 2457 route Saint Marys"
\end{verbatim}

Le paramètre \texttt{sep} permet de choisir le ou les caractères à intercaler entre les éléments à concaténer. Notez qu'il est possible de concaténer plus que deux éléments.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df}\OperatorTok{$}\NormalTok{ville <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'Montreal'}\NormalTok{,}\StringTok{'Montreal'}\NormalTok{,}\StringTok{'Montreal'}\NormalTok{,}\StringTok{'Montreal'}\NormalTok{)}
\KeywordTok{paste}\NormalTok{(df}\OperatorTok{$}\NormalTok{noms_corr, df}\OperatorTok{$}\NormalTok{adresses_}\DecValTok{3}\NormalTok{, df}\OperatorTok{$}\NormalTok{ville, }\DataTypeTok{sep =} \StringTok{", "}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Jérémy Toutanplace, 15 rue Levy, Montreal"              
## [2] "Constant Tinople, 413 Boulevard Saint-Laurent, Montreal"
## [3] "Dino Resto, 3606 rue Duke, Montreal"                    
## [4] "Luce Tancil, 2457 route Saint Marys, Montreal"
\end{verbatim}

\hypertarget{sect01426}{%
\subsubsection{Manipuler des colonnes de type date}\label{sect01426}}

Nous avons vu que les principaux types de données dans R sont le numérique, le texte, le booléen et le facteur. Il existe d'autres types, introduits par différent \emph{packages}. Nous abordons ici les types date et temps (\emph{date} and \emph{time}). Pour les manipuler, nous privilégions l'utilisation du \emph{package} \textbf{lubridate} du \textbf{tidyverse}. Pour illuster le tout, nous l'appliquerons avec un jeu de données ouvertes de la ville de Montréal représentant les accidents de la route incluant au moins un vélo après le premier janvier 2017.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{accidents_df <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\DataTypeTok{file=}\StringTok{"data/priseenmain/accidents.csv"}\NormalTok{, }\DataTypeTok{sep =} \StringTok{","}\NormalTok{)}
\KeywordTok{names}\NormalTok{(accidents_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "HEURE_ACCDN"       "DT_ACCDN"          "NB_VICTIMES_TOTAL"
\end{verbatim}

Nous disposons de trois colonnes représentant respectivement l'heure, la date et le nombre de victimes impliquées dans l'accident.

\hypertarget{sect014261}{%
\paragraph{Du texte à la date}\label{sect014261}}

Actuellement, les colonnes \emph{HEURE\_ACCDN} et \emph{DT\_ACCDN} sont au format texte. Nous pouvons afficher quelques lignes du jeu de données avec la fonction \texttt{head} pour visualiser comment elles ont été saisies.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(accidents_df, }\DataTypeTok{n =} \DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         HEURE_ACCDN   DT_ACCDN NB_VICTIMES_TOTAL
## 1 16:00:00-16:59:00 2017/11/02                 0
## 2 06:00:00-06:59:00 2017/01/16                 1
## 3 18:00:00-18:59:00 2017/04/18                 0
## 4 11:00:00-11:59:00 2017/05/28                 1
## 5 15:00:00-15:59:00 2017/05/28                 1
\end{verbatim}

Un peu de ménage s'impose : les heures sont indiquées comme des périodes d'une heure. Nous utilisons la fonction \texttt{str\_split\_fixed} du \emph{package} \textbf{stringr} pour ne garder que la première partie de l'heure (avant le tiret). Nous allons ensuite concaténer l'heure et la date avec la fonction \texttt{paste}, puis nous convertirons ce résultat en un objet \emph{date-time}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(lubridate)}

\CommentTok{# Étape 1 : découper la colonne Heure_ACCDN}
\NormalTok{accidents_df}\OperatorTok{$}\NormalTok{heure <-}\StringTok{ }\KeywordTok{str_split_fixed}\NormalTok{(accidents_df}\OperatorTok{$}\NormalTok{HEURE_ACCDN, }\StringTok{"-"}\NormalTok{, }\DataTypeTok{n=}\DecValTok{2}\NormalTok{)[,}\DecValTok{1}\NormalTok{]}

\CommentTok{# Étape 2 : concaténer l'heure et la date}
\NormalTok{accidents_df}\OperatorTok{$}\NormalTok{date_heure <-}\StringTok{ }\KeywordTok{paste}\NormalTok{(accidents_df}\OperatorTok{$}\NormalTok{DT_ACCDN, }
\NormalTok{                                 accidents_df}\OperatorTok{$}\NormalTok{heure,}
                                 \DataTypeTok{sep =} \StringTok{' '}\NormalTok{)}

\CommentTok{# Étape 3 : convertir au format datetime}
\NormalTok{accidents_df}\OperatorTok{$}\NormalTok{datetime <-}\StringTok{ }\KeywordTok{as_datetime}\NormalTok{(accidents_df}\OperatorTok{$}\NormalTok{date_heure,}
                                     \DataTypeTok{format =} \StringTok{"%Y/%m/%d %H:%M:%S"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Pour effectuer la conversion, nous avons utilisé la fonction \texttt{as\_datetime} du package \textbf{lubridate}. Elle prend comme paramètre un vecteur de texte et une indication du format de ce vecteur de texte. Il existe de nombreuses façons de spécifier une date et une heure et l'argument \emph{format} permet de spécifier quelle nomenclature est utilisée. Dans cet exemple, la date est structurée comme suit :
\texttt{année/mois/jour\ heure:minute:seconde}, ce qui se traduit par le format \texttt{\%Y/\%m/\%d\ \%H:\%M:\%S}.

\begin{itemize}
\tightlist
\item
  \%Y signifie une année indiquée avec quatre caractères : 2017
\item
  \%m signifie un mois, indiqué avec deux caractères : 01, 02, 03, \ldots{} 12
\item
  \%d signifie un jour, indiqué avec deux caractères : 01, 02, 03, \ldots{} 31
\item
  \%H signifie une heure, au format 24 heures avec deux caractères : 00, 02, \ldots{} 23
\item
  \%M signifie des minutes indiquées avec deux caractères : 00, 02, \ldots{} 59
\item
  \%S signifie des secondes, indiquées avec deux caractères : 00, 02, \ldots{} 59
\end{itemize}

Notez que les caractères séparant les années, jours, heures, etc. sont aussi à indiquer dans le format. Dans notre exemple, nous utilisons des \texttt{/} pour séparer les éléments de la date, des \texttt{:} pour l'heure, et un espace pour séparer la date et l'heure.

Il existe d'autres nomenclatures pour spécifier un format \emph{datetime} : par exemple, des mois renseignés par leur nom, l'indication AM-PM, etc. Vous pouvez vous référez à la documentation de la fonction \texttt{strptime} (\texttt{help(strptime)}) pour explorer les différentes nomenclatures et choisir celle qui vous convient. Bien évidemment, il est \textbf{nécessaire} que toutes les dates de votre colonne soient renseignées dans le même format. Sinon, la fonction renverra des valeurs \texttt{NA} aux endroits où elle a échoué à lire le format.

Après toutes ces opérations, rejettons un oeil à notre \emph{DataFrame}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(accidents_df, }\DataTypeTok{n =} \DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         HEURE_ACCDN   DT_ACCDN NB_VICTIMES_TOTAL    heure          date_heure
## 1 16:00:00-16:59:00 2017/11/02                 0 16:00:00 2017/11/02 16:00:00
## 2 06:00:00-06:59:00 2017/01/16                 1 06:00:00 2017/01/16 06:00:00
## 3 18:00:00-18:59:00 2017/04/18                 0 18:00:00 2017/04/18 18:00:00
## 4 11:00:00-11:59:00 2017/05/28                 1 11:00:00 2017/05/28 11:00:00
## 5 15:00:00-15:59:00 2017/05/28                 1 15:00:00 2017/05/28 15:00:00
##              datetime
## 1 2017-11-02 16:00:00
## 2 2017-01-16 06:00:00
## 3 2017-04-18 18:00:00
## 4 2017-05-28 11:00:00
## 5 2017-05-28 15:00:00
\end{verbatim}

\hypertarget{sect014262}{%
\paragraph{Extraire des informations d'une date}\label{sect014262}}

À partir de la nouvelle colonne \texttt{datetime}, nous sommes en mesure d'extraire des informations intéressantes comme :

\begin{itemize}
\tightlist
\item
  le nom du jour de la semaine avec la fonction \texttt{weekdays}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{accidents_df}\OperatorTok{$}\NormalTok{jour <-}\StringTok{ }\KeywordTok{weekdays}\NormalTok{(accidents_df}\OperatorTok{$}\NormalTok{datetime)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  la période de la journée avec les fonctions \texttt{am} et \texttt{pm}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{accidents_df}\OperatorTok{$}\NormalTok{AM <-}\StringTok{ }\KeywordTok{am}\NormalTok{(accidents_df}\OperatorTok{$}\NormalTok{datetime)}
\NormalTok{accidents_df}\OperatorTok{$}\NormalTok{PM <-}\StringTok{ }\KeywordTok{pm}\NormalTok{(accidents_df}\OperatorTok{$}\NormalTok{datetime)}

\KeywordTok{head}\NormalTok{(accidents_df[}\KeywordTok{c}\NormalTok{(}\StringTok{"jour"}\NormalTok{, }\StringTok{"AM"}\NormalTok{, }\StringTok{"PM"}\NormalTok{)], }\DataTypeTok{n=}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       jour    AM    PM
## 1    jeudi FALSE  TRUE
## 2    lundi  TRUE FALSE
## 3    mardi FALSE  TRUE
## 4 dimanche  TRUE FALSE
## 5 dimanche FALSE  TRUE
\end{verbatim}

Il est aussi possible d'accéder aux sous-éléments d'un \emph{datetime} comme l'année, le mois, le jour, l'heure, la minute, la seconde avec les fonctions \texttt{year()}, \texttt{month()},\texttt{day()}, \texttt{hour()}, \texttt{minute()} et \texttt{second()}.

\hypertarget{sect014263}{%
\paragraph{\texorpdfstring{Calculer une durée entre deux \emph{datetime}}{Calculer une durée entre deux datetime}}\label{sect014263}}

Une autre utilisation intéressante du format \emph{datetime} est de calculer des différences de temps. Par exemple, nous pourrions utiliser le nombre de minutes écoulées depuis 07:00 le matin comme une variable dans une analyse visant à déterminer le moment critique des accidents durant l'heure de pointe du matin.
Pour cela, nous devons créer un \emph{datetime} de référence en concaténant la date de chaque observation, et le temps 07:00:00 qui sera notre point de départ.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{accidents_df}\OperatorTok{$}\NormalTok{date_heure_}\DecValTok{07}\NormalTok{ <-}\StringTok{ }\KeywordTok{paste}\NormalTok{(accidents_df}\OperatorTok{$}\NormalTok{DT_ACCDN, }
                                 \StringTok{'07:00:00'}\NormalTok{,}
                                 \DataTypeTok{sep =} \StringTok{' '}\NormalTok{)}
\NormalTok{accidents_df}\OperatorTok{$}\NormalTok{ref_datetime <-}\StringTok{ }\KeywordTok{as_datetime}\NormalTok{(accidents_df}\OperatorTok{$}\NormalTok{date_heure_}\DecValTok{07}\NormalTok{,}
                                     \DataTypeTok{format =} \StringTok{"%Y/%m/%d %H:%M:%S"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Il ne nous reste plus qu'à calculer la différence de temps entre la colonne \emph{datetime} et notre temps de référence \emph{ref\_datetime}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{accidents_df}\OperatorTok{$}\NormalTok{diff_time <-}\StringTok{ }\KeywordTok{difftime}\NormalTok{(accidents_df}\OperatorTok{$}\NormalTok{datetime,}
\NormalTok{                                   accidents_df}\OperatorTok{$}\NormalTok{ref_datetime,}
                                   \DataTypeTok{units =} \StringTok{'min'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Notez qu'ici la colonne \emph{diff\_time} est d'un type spécial : une différence temporelle (\emph{difftime}). Il faut encore la convertir au format numérique pour pourvoir l'utiliser avec la fonction \texttt{as.numeric}.

Par curiosité, réalisons rapidement un histogramme avec la fonction \texttt{hist} pour analyser rapidement cette variable d'écart de temps !

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{accidents_df}\OperatorTok{$}\NormalTok{diff_time_num <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(accidents_df}\OperatorTok{$}\NormalTok{diff_time)}
\KeywordTok{hist}\NormalTok{(accidents_df}\OperatorTok{$}\NormalTok{diff_time_num, }\DataTypeTok{breaks =} \DecValTok{50}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig015-1} 

}

\caption{Répartition temporelle des accidents à vélo}\label{fig:fig015}
\end{figure}

On observe clairement deux pics, un premier entre 0 et 100 (donc entre 07:00 08:30 environ) et un second plus important entre 550 et 650 (entre 16:00 et 17:30 environ), ce qui correspond sans surprise aux heures de pointe. Il est intéressant de noter que plus d'accidents se produisent à l'heure de pointe du soir qu'à celle du matin.

\hypertarget{sect01427}{%
\subsubsection{Recoder des variables}\label{sect01427}}

Recoder des variables signifie changer la valeur d'une variable selon une condition afin d'obtenir une nouvelle variable. Si nous reprenons notre exemple précédent avec les accidents à vélo, nous pourrions créer une nouvelle colonne nous indiquant si l'accident a eu lieu en heure de pointe ou hors heure de pointe. On obtiendrait ainsi une nouvelle variable avec seulement deux catégories plutôt que la variable numérique originale. Nous pourrions aussi définir trois catégories avec l'heure de pointe du matin, l'heure de pointe du soir, le reste de la journée et la nuit.

\hypertarget{sect014271}{%
\paragraph{Le cas binaire avec ifelse}\label{sect014271}}

Si l'on ne souhaite créer que deux catégories, le plus simple est d'utiliser la fonction \texttt{ifelse}. Cette fonction va évaluer une condition (section @ref(sect01\_35)) pour chaque ligne d'un \emph{DataFrame} et produire un nouveau vecteur. Créons donc une variable binaire indiquant si un accident a eu lieu durant les heures de pointe ou hors heures de pointe. Nous devons alors évaluer les conditions suivantes :

Est-ce que l'accident a eu lieu entre 07:00 (0) \textbf{ET} 09:00 (120), \textbf{OU} est ce que l'accident a eu lieu entre 16:30 (570) \textbf{ET} 18:30 (690)?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Cond1 <-}\StringTok{ }\NormalTok{accidents_df}\OperatorTok{$}\NormalTok{diff_time_num }\OperatorTok{>=}\StringTok{ }\DecValTok{0} \OperatorTok{&}\StringTok{ }\NormalTok{accidents_df}\OperatorTok{$}\NormalTok{diff_time_num }\OperatorTok{<=}\StringTok{ }\DecValTok{120}
\NormalTok{Cond2 <-}\StringTok{ }\NormalTok{accidents_df}\OperatorTok{$}\NormalTok{diff_time_num }\OperatorTok{>=}\StringTok{ }\DecValTok{570} \OperatorTok{&}\StringTok{ }\NormalTok{accidents_df}\OperatorTok{$}\NormalTok{diff_time_num }\OperatorTok{<=}\StringTok{ }\DecValTok{690}

\NormalTok{accidents_df}\OperatorTok{$}\NormalTok{moment_bin <-}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(Cond1 }\OperatorTok{|}\StringTok{ }\NormalTok{Cond2,}
                                  \StringTok{"en heures de pointe"}\NormalTok{,}
                                  \StringTok{"hors heures de pointe"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Comme vous pouvez le constater, la fonction \texttt{ifelse} nécessite trois arguments :

\begin{itemize}
\tightlist
\item
  Une condition, pouvant être \texttt{TRUE} ou \texttt{FALSE},
\item
  La valeur à renvoyer si la condition est \texttt{TRUE}
\item
  La valeur à renvoyer si la condition est \texttt{FALSE}
\end{itemize}

Avec la fonction \texttt{table}, nous pouvons rapidement compter les effectifs des deux catégories ainsi créées :

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{table}\NormalTok{(accidents_df}\OperatorTok{$}\NormalTok{moment_bin)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##   en heures de pointe hors heures de pointe 
##                   841                  1573
\end{verbatim}

Les heures de pointes représentent quatre heures de la journée, ce qui nous laisse neuf heures hors heure de pointe entre 07:00 et 20:00.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Ratio d'accidents en heures de pointe}
\NormalTok{(}\DecValTok{841} \OperatorTok{/}\StringTok{ }\DecValTok{2414}\NormalTok{) }\OperatorTok{/}\StringTok{ }\NormalTok{(}\DecValTok{4} \OperatorTok{/}\StringTok{ }\DecValTok{13}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.132249
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Ratio d'accidents hors heure de pointe}
\NormalTok{(}\DecValTok{1573} \OperatorTok{/}\StringTok{ }\DecValTok{2414}\NormalTok{) }\OperatorTok{/}\StringTok{ }\NormalTok{(}\DecValTok{9} \OperatorTok{/}\StringTok{ }\DecValTok{13}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.9412225
\end{verbatim}

En rapportant les accidents aux durées des deux périodes, on observe une nette sur-représentation des accidents impliquant un vélo pendant les heures de pointe d'environ 13\% comparativement à la période hors des heures de pointe.

\hypertarget{sect014272}{%
\paragraph{\texorpdfstring{Le cas multiple avec la fonction \emph{case\_when}}{Le cas multiple avec la fonction case\_when}}\label{sect014272}}

Lorsque l'on souhaite créer plus que deux catégories, il est possible soit d'enchaîner plusieurs fonctions \texttt{ifelse} (ce qui produit un code plus long et moins lisible), soit d'utiliser la fonction \texttt{case\_when} provenant du \emph{package} \textbf{dplyr} du \textbf{tidyverse}. Reprenons notre exemple et créons quatre catégories :

\begin{itemize}
\tightlist
\item
  En heures de pointe du matin
\item
  En heures de pointe du soir
\item
  Le reste de la journée (entre 07:00 et 20:00)
\item
  La nuit (entre 21:00 et 07:00)
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(dplyr)}

\NormalTok{accidents_df}\OperatorTok{$}\NormalTok{moment_multi <-}\StringTok{ }\KeywordTok{case_when}\NormalTok{(}
\NormalTok{  accidents_df}\OperatorTok{$}\NormalTok{diff_time_num }\OperatorTok{>=}\StringTok{ }\DecValTok{0} \OperatorTok{&}\StringTok{ }\NormalTok{accidents_df}\OperatorTok{$}\NormalTok{diff_time_num }\OperatorTok{<=}\StringTok{ }\DecValTok{120} \OperatorTok{~}\StringTok{ "pointe matin"}\NormalTok{,}
\NormalTok{  accidents_df}\OperatorTok{$}\NormalTok{diff_time_num }\OperatorTok{>=}\StringTok{ }\DecValTok{570} \OperatorTok{&}\StringTok{ }\NormalTok{accidents_df}\OperatorTok{$}\NormalTok{diff_time_num }\OperatorTok{<=}\StringTok{ }\DecValTok{690} \OperatorTok{~}\StringTok{ "pointe soir"}\NormalTok{,}
\NormalTok{  accidents_df}\OperatorTok{$}\NormalTok{diff_time_num }\OperatorTok{>}\StringTok{ }\DecValTok{690} \OperatorTok{&}\StringTok{ }\NormalTok{accidents_df}\OperatorTok{$}\NormalTok{diff_time_num }\OperatorTok{<}\StringTok{ }\DecValTok{780} \OperatorTok{~}\StringTok{ "journee"}\NormalTok{,}
\NormalTok{  accidents_df}\OperatorTok{$}\NormalTok{diff_time_num }\OperatorTok{>}\StringTok{ }\DecValTok{120} \OperatorTok{&}\StringTok{ }\NormalTok{accidents_df}\OperatorTok{$}\NormalTok{diff_time_num }\OperatorTok{<}\StringTok{ }\DecValTok{570} \OperatorTok{~}\StringTok{ "journee"}\NormalTok{,}
\NormalTok{  accidents_df}\OperatorTok{$}\NormalTok{diff_time_num }\OperatorTok{<}\StringTok{ }\DecValTok{0} \OperatorTok{|}\StringTok{ }\NormalTok{accidents_df}\OperatorTok{$}\NormalTok{diff_time_num }\OperatorTok{>=}\StringTok{ }\DecValTok{780} \OperatorTok{~}\StringTok{ "nuit"}
\NormalTok{)}

\KeywordTok{table}\NormalTok{(accidents_df}\OperatorTok{$}\NormalTok{moment_multi)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##      journee         nuit pointe matin  pointe soir 
##         1155          418          404          437
\end{verbatim}

La syntaxe de cette fonction est un peu particulière. Elle accepte un nombre illimité d'arguments. Chaque argument est composé d'une condition et d'une valeur à renvoyer si la condition est vraie; ces deux éléments étant reliés par le symbole \texttt{\textasciitilde{}}. Notez que toutes les évaluations sont effectuées dans l'ordre des arguments. En d'autres termes, la fonction va d'abord tester la première condition et assigner ces valeurs, puis recommencer pour les prochaines conditions. Ainsi, si une observation (ligne du tableau de données) obtient \texttt{TRUE} à plusieurs conditions, elle obtiendra la valeur de la dernière condition qu'elle a validée.

\hypertarget{sect01428}{%
\subsubsection{\texorpdfstring{Sous-sélection d'un \emph{DataFrame}}{Sous-sélection d'un DataFrame}}\label{sect01428}}

Dans cette section, nous verrons comment extraire des sous-parties d'un \emph{DataFrame}. Il est possible de sous-sélectionner des lignes et des colonnes en se basant sur des conditions ou leurs index. Pour cela, nous allons utiliser un jeu de données fourni avec R : le jeu de données \textbf{iris} décrivant des fleurs du même nom.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(}\StringTok{"iris"}\NormalTok{)}
\KeywordTok{dim}\NormalTok{(iris)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 150   5
\end{verbatim}

\hypertarget{sect014281}{%
\paragraph{Sous-sélection des lignes}\label{sect014281}}

Sous-sélectionner des lignes par index est relativement simple. Admettons que nous souhaitons sélectionner les lignes 1 à 5, 10 à 25, 37 et 58.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sub_iris <-}\StringTok{ }\NormalTok{iris[}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{, }\DecValTok{10}\OperatorTok{:}\DecValTok{25}\NormalTok{, }\DecValTok{37}\NormalTok{, }\DecValTok{58}\NormalTok{),]}
\KeywordTok{nrow}\NormalTok{(sub_iris)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 23
\end{verbatim}

Sous-sélectionner des lignes avec une condition peut être effectué soit avec une syntaxe similaire, soit en utilisant la fonction \texttt{subset}. Sélectionnons toutes les fleurs de l'espèce Virginica.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris_virginica1 <-}\StringTok{ }\NormalTok{iris[iris}\OperatorTok{$}\NormalTok{Species }\OperatorTok{==}\StringTok{ "virginica"}\NormalTok{,]}
\NormalTok{iris_virginica2 <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(iris, iris}\OperatorTok{$}\NormalTok{Species }\OperatorTok{==}\StringTok{ "virginica"}\NormalTok{)}

\CommentTok{# Vérifions que les deux dataframes ont le même nombre de lignes}
\KeywordTok{nrow}\NormalTok{(iris_virginica1) }\OperatorTok{==}\StringTok{ }\KeywordTok{nrow}\NormalTok{(iris_virginica2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

Vous pouvez utiliser dans les deux cas tous les opérateurs vus dans les sections @ref(sect01\_352) et @ref(sect01\_353). L'enjeu est d'arriver à un vecteur booléen final permettant d'identifier les observations à conserver.

\hypertarget{sect014282}{%
\paragraph{Sous-sélectionner des colonnes}\label{sect014282}}

Nous avons déjà vu comment sélectionner des colonnes en utilisant leur nom ou leur index dans la section @ref(sect01\_4221). Ajoutons ici un cas particulier où nous souhaiterions sélectionner des colonnes selon une condition. Par exemple, nous pourrions vouloir conserver que les colonnes comprenant le mot \emph{Length}. Pour cela, nous utiliserons la fonction \texttt{grepl}, permettant de déterminer si des caractères sont présents dans une chaîne de caractères.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nom_cols <-}\StringTok{ }\KeywordTok{names}\NormalTok{(iris)}
\KeywordTok{print}\NormalTok{(nom_cols)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Sepal.Length" "Sepal.Width"  "Petal.Length" "Petal.Width"  "Species"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test_nom <-}\StringTok{ }\KeywordTok{grepl}\NormalTok{(}\StringTok{"Length"}\NormalTok{,nom_cols, }\DataTypeTok{fixed =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{ok_nom <-}\StringTok{ }\NormalTok{nom_cols[test_nom]}

\NormalTok{iris_}\DecValTok{2}\NormalTok{ <-}\StringTok{ }\NormalTok{iris[ok_nom]}
\KeywordTok{print}\NormalTok{(}\KeywordTok{names}\NormalTok{(iris_}\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Sepal.Length" "Petal.Length"
\end{verbatim}

Il est possible d'obtenir ce résultat en une seule ligne de code, mais elle est un peu moins lisible.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris2 <-}\StringTok{ }\NormalTok{iris[}\KeywordTok{names}\NormalTok{(iris)[}\KeywordTok{grepl}\NormalTok{(}\StringTok{"Length"}\NormalTok{,}\KeywordTok{names}\NormalTok{(iris), }\DataTypeTok{fixed =} \OtherTok{TRUE}\NormalTok{)]]}
\end{Highlighting}
\end{Shaded}

\hypertarget{sect014283}{%
\paragraph{Sélectionner des colonnes et des lignes}\label{sect014283}}

Nous avons vu qu'avec les crochets, nous pouvons extraires les colonnes et les lignes d'un \emph{DataFrame}. Il est possible de combiner les deux opérations en même temps. Pour cela, il faut indiquer en premier les indices ou la condition permettant de sélectionner une ligne, puis les indices ou la condition pour sélectionner les colonnes : \texttt{{[}index\_lignes\ ,\ index\_colonnes{]}}. Sélectionnons les trois premières colonnes et les cinq premières lignes du jeu de données iris :

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris_5x3 <-}\StringTok{ }\NormalTok{iris[}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{),}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{)]}
\KeywordTok{print}\NormalTok{(iris_5x3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   Sepal.Length Sepal.Width Petal.Length
## 1          5.1         3.5          1.4
## 2          4.9         3.0          1.4
## 3          4.7         3.2          1.3
## 4          4.6         3.1          1.5
## 5          5.0         3.6          1.4
\end{verbatim}

Combinons nos deux exemples précédents pour sélectionner uniquement les lignes avec des fleurs de l'espèce virginica, et les colonnes avec le mot Length.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris_virginica3 <-}\StringTok{ }\NormalTok{iris[iris}\OperatorTok{$}\NormalTok{Species }\OperatorTok{==}\StringTok{ "virginica"}\NormalTok{,}
                       \KeywordTok{names}\NormalTok{(iris)[}\KeywordTok{grepl}\NormalTok{(}\StringTok{"Length"}\NormalTok{,}\KeywordTok{names}\NormalTok{(iris), }\DataTypeTok{fixed =} \OtherTok{TRUE}\NormalTok{)]]}
\KeywordTok{head}\NormalTok{(iris_virginica3, }\DataTypeTok{n=}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     Sepal.Length Petal.Length
## 101          6.3          6.0
## 102          5.8          5.1
## 103          7.1          5.9
## 104          6.3          5.6
## 105          6.5          5.8
\end{verbatim}

\hypertarget{sect01429}{%
\subsubsection{\texorpdfstring{Fusionner des \emph{DataFrames}}{Fusionner des DataFrames}}\label{sect01429}}

Terminons cette section avec la fusion de \emph{DataFrames} qu'il est possible de réaliser de deux façons : par ajout ou par jointure.

\hypertarget{sect014291}{%
\paragraph{\texorpdfstring{Fusionner des \emph{DataFrame} par ajout}{Fusionner des DataFrame par ajout}}\label{sect014291}}

Ajouter deux \emph{DataFrames} peut se faire en fonction de leurs colonnes, ou en fonction de leurs lignes. Dans ces deux cas, on utilisera respectivement les fonction \texttt{cbind} et \texttt{rbind}. La figure \ref{fig:fig016} résume graphiquement le fonctionnement des deux fonctions.

\begin{figure}

{\centering \includegraphics[width=0.3\linewidth]{images/introduction/rbind_cbind} 

}

\caption{Fusion de DataFrames}\label{fig:fig016}
\end{figure}

Pour que \texttt{cbind} fonctionne, il faut que les deux \emph{DataFrames} aient le même nombre de lignes. Pour \texttt{rbind}, les deux \emph{DataFrames} doivent avoir le même nombre de colonnes.

Prenons à nouveau comme exemple le jeu de données iris. Nous allons commencer par le séparer en trois sous-jeux de données comprenant chacun une espèce d'iris. Puis, nous fusionnerons deux d'entre eux avec la fonction \texttt{rbind}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris1 <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(iris, iris}\OperatorTok{$}\NormalTok{Species }\OperatorTok{==}\StringTok{ "virginica"}\NormalTok{)}
\NormalTok{iris2 <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(iris, iris}\OperatorTok{$}\NormalTok{Species }\OperatorTok{==}\StringTok{ "versicolor"}\NormalTok{)}
\NormalTok{iris3 <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(iris, iris}\OperatorTok{$}\NormalTok{Species }\OperatorTok{==}\StringTok{ "setosa"}\NormalTok{)}

\NormalTok{iris_comb <-}\StringTok{ }\KeywordTok{rbind}\NormalTok{(iris2,iris3)}
\end{Highlighting}
\end{Shaded}

Nous pourrions aussi extraire dans les deux \emph{DataFrames} les colonnes comprenant le mot \emph{Length} et le mot \emph{Width}, puis les fusionner.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris_l <-}\StringTok{ }\NormalTok{iris[}\KeywordTok{names}\NormalTok{(iris)[}\KeywordTok{grepl}\NormalTok{(}\StringTok{"Length"}\NormalTok{,}\KeywordTok{names}\NormalTok{(iris), }\DataTypeTok{fixed =} \OtherTok{TRUE}\NormalTok{)]]}
\NormalTok{iris_w <-}\StringTok{ }\NormalTok{iris[}\KeywordTok{names}\NormalTok{(iris)[}\KeywordTok{grepl}\NormalTok{(}\StringTok{"Width"}\NormalTok{,}\KeywordTok{names}\NormalTok{(iris), }\DataTypeTok{fixed =} \OtherTok{TRUE}\NormalTok{)]]}

\NormalTok{iris_comb <-}\StringTok{ }\KeywordTok{cbind}\NormalTok{(iris_l,iris_w)}
\KeywordTok{names}\NormalTok{(iris_comb)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Sepal.Length" "Petal.Length" "Sepal.Width"  "Petal.Width"
\end{verbatim}

\hypertarget{sect014292}{%
\paragraph{\texorpdfstring{Joindre des \emph{DataFrame}}{Joindre des DataFrame}}\label{sect014292}}

Une jointure est une opération un peu plus complexe qu'un simple ajout. L'idée est d'associer des informations de plusieurs \emph{DataFrames} en utilisant une colonne (appelée une clef) présente dans les deux jeux de données. On distingue plusieurs types de jointure :

\begin{itemize}
\tightlist
\item
  Les jointures internes permettant de combiner les éléments communs entre un DataFrame A et B
\item
  La jointure complète permettant de combiner les éléments présents dans A ou B
\item
  La jointure à gauche, permettant de ne conserver que les éléments présents dans A même s'ils ne trouvent pas leur correspondance dans B.
\end{itemize}

Ces trois jointures sont présentées à la figure \ref{fig:fig016}; dans ces trois cas, la colonne commune se nomme \emph{id}.

\begin{figure}

{\centering \includegraphics[width=0.3\linewidth]{images/introduction/merging} 

}

\caption{Jointure de DataFrames}\label{fig:fig017}
\end{figure}

Vous noterez que les deux dernières jointures peuvent produire des valeurs manquantes. Pour réaliser ces opérations, il est possible d'utiliser la fonction \texttt{merge}. Prenons un exemple simple à partir d'un petit jeu de données.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{auteurs <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}
    \DataTypeTok{name =} \KeywordTok{c}\NormalTok{(}\StringTok{"Tukey"}\NormalTok{, }\StringTok{"Venables"}\NormalTok{, }\StringTok{"Tierney"}\NormalTok{, }\StringTok{"Ripley"}\NormalTok{, }\StringTok{"McNeil"}\NormalTok{, }\StringTok{"Apparicio"}\NormalTok{),}
    \DataTypeTok{nationality =} \KeywordTok{c}\NormalTok{(}\StringTok{"US"}\NormalTok{, }\StringTok{"Australia"}\NormalTok{, }\StringTok{"US"}\NormalTok{, }\StringTok{"UK"}\NormalTok{, }\StringTok{"Australia"}\NormalTok{, }\StringTok{"Canada"}\NormalTok{),}
    \DataTypeTok{retired =} \KeywordTok{c}\NormalTok{(}\StringTok{"yes"}\NormalTok{, }\KeywordTok{rep}\NormalTok{(}\StringTok{"no"}\NormalTok{, }\DecValTok{5}\NormalTok{)))}
\NormalTok{livres <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}
    \DataTypeTok{aut =} \KeywordTok{c}\NormalTok{(}\StringTok{"Tukey"}\NormalTok{, }\StringTok{"Venables"}\NormalTok{, }\StringTok{"Tierney"}\NormalTok{, }\StringTok{"Ripley"}\NormalTok{, }\StringTok{"Ripley"}\NormalTok{, }\StringTok{"McNeil"}\NormalTok{,}\StringTok{"Wickham"}\NormalTok{),}
    \DataTypeTok{title =} \KeywordTok{c}\NormalTok{(}\StringTok{"Exploratory Data Analysis"}\NormalTok{,}
              \StringTok{"Modern Applied Statistics ..."}\NormalTok{,}
              \StringTok{"LISP-STAT"}\NormalTok{,}
              \StringTok{"Spatial Statistics"}\NormalTok{, }\StringTok{"Stochastic Simulation"}\NormalTok{,}
               \StringTok{"Interactive Data Analysis"}\NormalTok{, }\StringTok{"R for Data Science"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Nous avons donc deux \emph{DataFrames}, le premier décrivant des auteurs et le second des livres. Effectuons une première jointure interne afin de savoir pour chaque livre la nationnalité de son auteur et si ce dernier est à la retraite.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df1 <-}\StringTok{ }\KeywordTok{merge}\NormalTok{(livres, auteurs, }\CommentTok{#les deux DataFrames }
             \DataTypeTok{by.x =} \StringTok{"aut"}\NormalTok{, }\DataTypeTok{by.y =} \StringTok{'name'}\NormalTok{, }\CommentTok{#les noms des colonnes de jointures}
             \DataTypeTok{all.x =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{all.y =} \OtherTok{FALSE}\NormalTok{)}

\KeywordTok{print}\NormalTok{(df1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        aut                         title nationality retired
## 1   McNeil     Interactive Data Analysis   Australia      no
## 2   Ripley            Spatial Statistics          UK      no
## 3   Ripley         Stochastic Simulation          UK      no
## 4  Tierney                     LISP-STAT          US      no
## 5    Tukey     Exploratory Data Analysis          US     yes
## 6 Venables Modern Applied Statistics ...   Australia      no
\end{verbatim}

Cette jointure est interne car les deux paramètres \emph{all.x} et \emph{all.y} ont pour valeur \texttt{FALSE}. Ainsi, nous indiquons à la fonction que nous ne souhaitons ni garder tous les éléments du premier \emph{DataFrame} ni tous les éléments du second, mais uniquement les éléments présents dans les deux. Vous noterez ainsi que le livre ``R for Data Science'' n'est pas présent dans le jeu de données final car son auteur ``Wickham'' ne fait pas partie du \emph{DataFrame} auteurs. De même, l'auteur ``Apparicio'' n'apparaît pas dans la jointure, car aucun livre dans le \emph{DataFrame} books n'a été écrit par cet auteur.

Pour conserver tous les livres, nous pouvons effectuer une jointure à gauche en renseignant \texttt{all.x\ =\ TRUE}. Nous allons ainsi forcer la fonction à garder tous les livres et mettre des valeurs vides aux informations manquantes des auteurs.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2 <-}\StringTok{ }\KeywordTok{merge}\NormalTok{(livres, auteurs, }\CommentTok{#les deux DataFrames }
             \DataTypeTok{by.x =} \StringTok{"aut"}\NormalTok{, }\DataTypeTok{by.y =} \StringTok{'name'}\NormalTok{, }\CommentTok{#les noms des colonnes de jointures}
             \DataTypeTok{all.x =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{all.y =} \OtherTok{FALSE}\NormalTok{)}

\KeywordTok{print}\NormalTok{(df2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        aut                         title nationality retired
## 1   McNeil     Interactive Data Analysis   Australia      no
## 2   Ripley            Spatial Statistics          UK      no
## 3   Ripley         Stochastic Simulation          UK      no
## 4  Tierney                     LISP-STAT          US      no
## 5    Tukey     Exploratory Data Analysis          US     yes
## 6 Venables Modern Applied Statistics ...   Australia      no
## 7  Wickham            R for Data Science        <NA>    <NA>
\end{verbatim}

Et pour garder tous les livres et tous les auteurs, nous pouvons faire une jointure complète en indiquant \texttt{all.x\ =\ TRUE} et \texttt{all.y\ =\ TRUE}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df3 <-}\StringTok{ }\KeywordTok{merge}\NormalTok{(livres, auteurs, }\CommentTok{#les deux DataFrames }
             \DataTypeTok{by.x =} \StringTok{"aut"}\NormalTok{, }\DataTypeTok{by.y =} \StringTok{'name'}\NormalTok{, }\CommentTok{#les noms des colonnes de jointures}
             \DataTypeTok{all.x =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{all.y =} \OtherTok{TRUE}\NormalTok{)}

\KeywordTok{print}\NormalTok{(df3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         aut                         title nationality retired
## 1 Apparicio                          <NA>      Canada      no
## 2    McNeil     Interactive Data Analysis   Australia      no
## 3    Ripley            Spatial Statistics          UK      no
## 4    Ripley         Stochastic Simulation          UK      no
## 5   Tierney                     LISP-STAT          US      no
## 6     Tukey     Exploratory Data Analysis          US     yes
## 7  Venables Modern Applied Statistics ...   Australia      no
## 8   Wickham            R for Data Science        <NA>    <NA>
\end{verbatim}

\hypertarget{sect015}{%
\section{Conclusion et ressources pertinentes}\label{sect015}}

Voilà qui conclut ce chapitre sur les bases du langage R . Vous avez maintenant les connaissances nécessaires pour commencer à travailler. N'hésitez pas à revenir sur les différentes sous-sections au besoin ! Pour aller plus loin dans l'apprentissage du langage, vous pouvez également vous plonger dans le chapitre R AVANCÉ. Cependant, nous vous recommandons de faire vos premiers pas avec cette base avant de vous lancer dans cette partie davantage orientée programmation. Quelques ressources pertinentes qui pourraient vous être utiles sont aussi reportées au tableau ci-dessous.

\begin{table}

\caption{\label{tab:tableRessources}Ressources pertinente pour en apprendre plus sur R}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{l>{\raggedright\arraybackslash}p{6cm}>{\raggedright\arraybackslash}p{6cm}}
\toprule
Ressource & Description & Url\\
\midrule
Rbloggers & Un recueil de nombreux blogues sur R : parfait pour être tenu au courant des nouveautés et faire des découvertes & https://www.r-bloggers.com\\
CRAN packages by date & Les derniers packages publiés sur CRAN : cela permet de garder un oeil sur les nouvelles fonctionnalités de ses packages préférés & https://cran.r-project.org/web/packages\\
Introduction à R et au TidyVerse & Une excellente ressource en français pour en apprendre plus sur le tidyverse & https://juba.github.io/tidyverse\\
Numyard & Une chaîne YouTube pour revoir les bases de R en vidéo & https://www.youtube.com/user/TheLearnR\\
Cheasheets & Des feuilles de triche résumant les fonctionnalités de nombreux packages & https://rstudio.com/resources/cheatsheets\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{part-analyses-univariuxe9es}{%
\part{Analyses univariées}\label{part-analyses-univariuxe9es}}

\hypertarget{chap02}{%
\chapter{Statistiques descriptives univariées}\label{chap02}}

Dans ce chapitre, nous décrirons la notion de variable, permettant l'opérationnalisation d'un concept. Comprendre les différents types de variables est essentiel en statistiques. En effet, en fonction du type de variable à l'étude, les tests d'hypothèse et les méthodes de statistique inférentielle que l'on pourra appliquer seront différents. Nous distinguerons ainsi cinq types de variables : nominale, ordinale, discrète, continue et semi-quantitative. Ausi, nous abordons un concept central de la statistique : les distributions. Nous présenterons ensuite les différentes statistiques descriptives univariées qui peuvent s'appliquer à ces types de variables.

\begin{bloc_package}

Dans cette section, nous utiliserons principalement les packages suivants (À MODIFIER PLUS TARD) :

\begin{itemize}
\item
  Pour créer des graphiques :

  \begin{itemize}
  \tightlist
  \item
    \textbf{ggplot2}, le seul, l'unique
  \item
    \textbf{ggpubr} pour combiner des graphiques et réaliser des diagrammes
  \end{itemize}
\item
  Pour créer des distribution :

  \begin{itemize}
  \tightlist
  \item
    \textbf{fitdistrplus} pour générer différentes distributions
  \item
    \textbf{actuar} pour la fonction de densité de Pareto
  \item
    \textbf{gamlss.dist} pour des distributions de Poisson
  \end{itemize}
\item
  Pour les statistiques descriptives :
\item
  \textbf{stats} pour les statistiques descriptives
\item
  \textbf{nortest} pour le test de Kolmogorov-Smirnov
\item
  \textbf{DescTools} pour les tests de Lilliefors, Shapiro-Wilk, Anderson-Darling et Jarque-Bera
\item
  Autres \emph{packages} :
\item
  \textbf{Hmisc} et \textbf{Weighted.Desc.Stat} pour les statistiques descriptives pondérées
\item
  \textbf{foreign} pour importer des fichiers externes
\end{itemize}

\end{bloc_package}

\hypertarget{sect021}{%
\section{Notion de variable}\label{sect021}}

\hypertarget{sect0211}{%
\subsection{La variable : l'opérationnalisation d'un concept}\label{sect0211}}

Une variable permet d'opérationnaliser un concept, soit une « idée générale et abstraite que se fait l'esprit humain d'un objet de pensée concret ou abstrait, et qui lui permet de rattacher à ce même objet les diverses perceptions qu'il en a, et d'en organiser les connaissances » (\href{https://www.larousse.fr/dictionnaires/francais/concept/17875?q=concept\#17749}{Larousse}). Pour valider un modèle théorique, il convient alors d'opérationnaliser ses différentes concepts et d'établir les relations qu'ils partagent. L'opérationnalisation d'un concept nécessite soit de mesurer (dans un intervalle de valeurs, c'est-à-dire de manière quantitative), soit de qualifier (avec plusieurs catégories, c'est-à-dire de manière qualitative) un phénomène.

Selon \href{https://www.statcan.gc.ca/fra/concepts/variable}{Statistique Canada}, « une variable est une caractéristique d'une unité statistique que l'on observe et pour laquelle une valeur numérique ou une catégorie d'une classification peut être attribuée ». Il convient alors de bien saisir à quelle unité statistique (ou unité d'observation) s'applique les valeurs d'une variable : des personnes, des ménages, des municipalités, etc.

Prenons deux exemples concrets tirées du Recensement de 2016 de Statistique Canada :

\begin{itemize}
\tightlist
\item
  Le concept \textbf{famille de recensement} est défini comme étant « un couple marié et les enfants, le cas échéant, du couple et/ou de l'un ou l'autre des conjoints; un couple en union libre et les enfants, le cas échéant, du couple et/ou de l'un ou l'autre des partenaires; ou un parent seul, peu importe son état matrimonial, habitant avec au moins un enfant dans le même logement et cet ou ces enfants. Tous les membres d'une famille de recensement particulière habitent le même logement. Un couple peut être de sexe opposé ou de même sexe. Les enfants peuvent être des enfants naturels, par le mariage, par l'union libre ou par adoption, peu importe leur âge ou leur état matrimonial, du moment qu'ils habitent dans le logement sans leur propre conjoint marié, partenaire en union libre ou enfant. Les petits-enfants habitant avec leurs grands-parents, alors qu'aucun des parents n'est présent, constituent également une famille de recensement » (\href{https://www12.statcan.gc.ca/census-recensement/2016/ref/dict/fam004-fra.cfm}{Statistique Canada}). À partir de cette définition, les familles de recensement peuvent être qualifiées selon plusieurs modalités : couples mariés sans enfant, couples mariés avec enfants, couples en union libre sans enfant, couples en union libre avec enfant, famille monoparentale (avec un parent de sexe féminin), famille monoparentale (avec un parent de sexe masculin).
\item
  Le concept de \textbf{revenu d'emploi} est défini comme étant « tous les revenus reçus sous forme de traitements, salaires et commissions d'un travail rémunéré ou le revenu net d'un travail autonome dans une entreprise agricole ou non agricole non constituée en société et/ou dans l'exercice d'une profession au cours de la période de référence. Pour le Recensement de 2016, la période de référence est l'année civile 2015 pour toutes les variables de revenu » (\href{https://www12.statcan.gc.ca/census-recensement/2016/ref/dict/pop027-fra.cfm}{Statistique Canada}). Il est donc mesurée en dollars pour chaque individu de 15 ans et plus. Pour l'ensemble de la population de 15 ans et plus, il peut ensuite être classé en déciles de revenu d'emploi, soit en dix groupes (\href{https://www12.statcan.gc.ca/census-recensement/2016/ref/dict/pop204-fra.cfm\%22\%7D}{Statistique Canada}).
\end{itemize}

\begin{bloc_attention}

\textbf{Maîtriser la définition des variables que vous utilisez : un enjeu crucial ! }

Nous avons vu qu'une variable est l'opérationnalisation d'un concept. Par conséquent, ne pas maîtriser la définition d'une variable revient à ne pas bien saisir le concept sous-jacent qu'elle tente de mesurer. Si vous exploitez des données secondaires -- par exemple, issues d'un recensement de population ou d'une enquête longitudinale ou transversale --, il faut impérativement lire les définitions des variables que vous souhaiteriez utiliser. Ne pas le faire risque d'aboutir à :

\begin{itemize}
\item
  Une mauvaise opérationnalisation de votre modèle théorique, même si votre analyse est bien menée statistiquement parlant. Autrement dit, vous risquez de ne pas sélectionner les bonnes variables. Prenons un exemple concret. Vous avez construit un modèle théorique dans lequel vous souhaitez inclure un concept sur la langue des personnes. Dans le recensement canadien de 2016, plusieurs variables relatives à la langue sont disponibles : \href{https://www12.statcan.gc.ca/census-recensement/2016/ref/dict/pop055-fra.cfm}{connaissance des langues officielles},
  \href{https://www12.statcan.gc.ca/census-recensement/2016/ref/dict/pop042-fra.cfm}{langue parlée à la maison}, \href{https://www12.statcan.gc.ca/census-recensement/2016/ref/dict/pop095-fra.cfm}{langue maternelle}, \href{https://www12.statcan.gc.ca/census-recensement/2016/ref/dict/pop034-fra.cfm}{première langue officielle parlée}, \href{https://www12.statcan.gc.ca/census-recensement/2016/ref/dict/pop054-fra.cfm}{connaissance des langues non officielles} et \href{https://www12.statcan.gc.ca/census-recensement/2016/ref/dict/pop059-fra.cfm}{langue de travail} (\href{https://www12.statcan.gc.ca/census-recensement/2016/ref/guides/003/98-500-x2016003-fra.cfm}{Statistique Canada, 2019}). La sélection de l'une de ces variables doit être faite de manière rigoureuse, c'est-à-dire en lien avec votre cadre théorique et suite à une bonne compréhension des définitions des variables. Dans une étude sur le marché du travail, on sélectionnerait probablement la variable \emph{sur la connaissance des langues officielles du Canada}, afin d'évaluer son effet sur l'employabilité, toutes choses étant égales par ailleurs. Dans une autre étude portant sur la réussite ou la performance scolaire, il est probable qu'on utilise plutôt la \emph{langue maternelle}.
\item
  Une mauvaise interprétation et discussion de vos résultats en lien avec votre cadre théorique.
\item
  Une mauvaise identification des pistes de recherche.
\end{itemize}

Finalement, la définition d'une variable peut évoluer à travers plusieurs recensements de population : la société évolue, les variables aussi ! Par conséquent, si vous comptez utiliser plusieurs années de recensement dans une même étude, assurez-vous que les définitions des variables soient similaires d'un jeu de données à l'autre et qu'elles mesurent ainsi la même chose.

\textbf{Comprendre les variables utilisées dans un article scientifique : un exercice indispensable dans l'élaboration d'une revue de littérature}

Une lecture rigoureuse d'un article scientifique suppose, entre autres, de bien comprendre les concepts et variables mobilisés. Il convient alors de lire attentivement la section méthodologique (pas uniquement la section des résultats ou pire le résumé), sans quoi vous risquez d'aboutir à une revue de littérature approximative.
Ayez aussi un \textbf{regard critique} sur les variables visant à opérationnaliser les concepts clés de l'étude. Certains concepts sont très difficiles à traduire en variables; leurs opérationalisations (mesures) peuvent ainsi faire l'objet de vifs débats parmi les chercheurs. Très succinctement, c'est notamment le cas du concept de capital social. D'une part, les définitions et ancrages sont biens différents selon Bourdieu (sociologue, ancrage au niveau des individus) et Putman (politologue, ancrage au niveau des collectivités); d'autre part, aucun consensus ne semble clairement se dégager quant à la définition de variables permettant de le mesurer efficacement (de manière quantitative).

\textbf{Variable de substitution (\emph{proxy variable} en anglais)}

On fait la moins pire des recherches ! En effet, les données disponibles sont parfois imparfaites pour répondre avec précision à une question de recherche; on peut toujours les exploiter, tout en signalant honnêtemment leurs faiblesses et limites, et ce, tant pour les données que les variables utilisées.

\begin{itemize}
\item
  Des bases de données peuvent être en effet imparfaites. Par exemple, en criminologie, des chercheur.e.s exploitant des données policières signalent habituellement la limite du \textbf{chiffre noir} : les données policières comprennent uniquement les crimes et délits découverts par la police et occultent ainsi les crimes non-découverts; ils ne peuvent ainsi refléter la criminalité réelle sur un territoire donné.
\item
  Des variables peuvent aussi être imparfaites. Dans un jeu de données, il est fréquent qu'une variable opérationnalisant un concept précis ne soit pas disponible ou qu'elle n'ait tout simplement pas été mesurée. On cherchera alors une variable de substitution (\emph{proxy}) pour la remplacer. Prenons un exemple concret portant sur l'exposition des cyclistes à la pollution atmosphérique ou au bruit environnemental. L'un des principaux facteurs d'exposition à ces pollutions est le trafic routier : plus ce dernier est élevé, plus le cycliste risque de rouler dans un environnement bruyant et pollué. Toutefois, il est rare de disposer de mesures du trafic en temps réel qui nécessitent des comptages de véhicules pendant le trajet des cyclistes (par exemple, à partir de vidéos captées par une caméra fixée sur le guidon). Pour pallier à l'absence de mesures directes, plusieurs auteurs utilisent des variables de substitution de la densité du trafic, comme la typologie des types d'axes (primaire, secondaire, tertiaire, rue locale, etc.), supposant ainsi qu'un axe primaire supporte un volume de véhicules supérieur à un axe secondaire.
\end{itemize}

\end{bloc_attention}

\hypertarget{sect0212}{%
\subsection{Les types de variables}\label{sect0212}}

On distingue habituellement les variables qualitatives (nominale ou ordinale) des variables quantitatives (discrète ou continue). Tel qu'illustré à la figure \ref{fig:figunivarie1}, l'opérationnalisation du concept en variable est réalisée par différents mécanismes visant à qualifier, classer, compter ou mesurer afin de caractériser les unités statistiques (observations) d'une population ou d'un échantillon.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{images/univariee/figure1} 

}

\caption{Les types de variables}\label{fig:figunivarie1}
\end{figure}

\hypertarget{sect02121}{%
\subsubsection{Les variables qualitatives}\label{sect02121}}

\textbf{Une variable nominale} permet de \textbf{qualifier} des observations (individus) à partir de plusieurs catégories dénommées modalités. Par exemple, la variable \emph{couleur des yeux} pourrait comprendre les modalités \emph{bleu}, \emph{marron}, \emph{vert} tandis que les \emph{types de familles} compendrait les modalités \emph{couple marié}, \emph{couple en union libre} et \emph{famille monoparentale}.

\textbf{Une variable ordinale} permet de \textbf{classer} des observations à partir de plusieurs modalités hiérarchisées. L'exemple le plus connu est certainement l'échelle de Likert, très utilisée dans les sondages évaluant le degré d'accord d'une personne à une affirmation avec les modalités suivantes : \emph{tout à fait d'accord}, \emph{d'accord}, \emph{ni en désaccord ni d'accord}, \emph{pas d'accord} et \emph{pas du tout d'accord}. Une multitude de variantes sont toutefois possibles pour classer la fréquence d'un phénomène (\emph{Très souvent}, \emph{souvent}, \emph{parfois}, \emph{rarement}, \emph{jamais}), l'importance accordée à un phénomène (\emph{Pas du tout important}, \emph{peu important}, \emph{plus ou moins important}, \emph{important}, \emph{très important}) ou la proximité perçue d'un lieu (\emph{très éloigné}, \emph{loin}, \emph{plus ou moins proche}, \emph{proche}, \emph{très proche}).

En fonction du nombre de modalités qu'elle comprend, une variable qualitative (nominale ou ordinale) est soit \textbf{dichtomique (binaire)} (deux modalités), soit \textbf{polytomique} (plus de deux modalités). Par exemple, dans le recensement canadien, le \emph{sexe} est une variable binaire (avec les modalités \emph{sexe masculin}, \emph{sexe féminin}), tandis que le \emph{genre} est une variable polytomique (avec les modalités \emph{genre masculin}, \emph{genre féminin} et \emph{diverses identités de genre}).

\begin{bloc_attention}

Les variables nominales et ordinales sont habituellement encodées avec des valeurs numériques entières (par exemple, 1 pour \emph{couple marié}, 2 pour \emph{couple en union libre} et 3 pour \emph{famille monoparentale}). Toutefois, aucune opération arithmétique (moyenne ou écart-type par exemple) n'est possible sur ces valeurs. Dans R, on utilisera un facteur pour attribuer un intitulé à chacune des valeurs numériques de la variable qualitative :

\texttt{df\$Famille\ \textless{}-\ factor(df\$Famille,\ c(1,2,3),\ labels\ =\ c("couple\ marié","couple\ en\ union\ libre",\ "famille\ monoparentale"))}

On calculera toutefois les fréquences des différentes modalités pour une variable nominale ou ordinale. Il est aussi possible de calculer la médiane sur une variable ordinale.

\end{bloc_attention}

\hypertarget{sect02122}{%
\subsubsection{Les variables quantitatives}\label{sect02122}}

\textbf{Une variable discrète} permet de \textbf{compter} un phénomène dans un ensemble fini de valeurs, comme le nombre d'accidents impliquant un cycliste à une intersection sur une période de cinq ans ou encore le nombre de vélos en libre service disponibles à une station. Il existe ainsi une variable binaire sous-jacente : la présence ou non d'un accident à l'intersection ou d'un vélo ou non à la station pour laquelle on opère un comptage. Habituellement, une variable discrète ne peut prendre que des valeurs entières (sans décimales), comme le nombre de personnes fréquentant un parc.

\textbf{Une variable continue} permet de \textbf{mesurer} un phénomène avec un nombre infini de valeurs réelles (avec décimales) dans un intervalle donné. Par exemple, une variable relative à la distance de dépassement d'un cycliste par un véhicule motorisé pourrait varier de 0 à 5 mètres (\(X \in \left[0,5\right]\)); toutefois cette distance peut être de 0,759421 ou de 4,785612 mètres. Le nombre de décimales de la valeur réelle dépendra de la précision et de la fiabilité de la mesure. Pour un capteur de distance de dépassement, le nombre de décimales dépendra de la précision du lidar ou du sonar de l'appareil; aussi, l'utilisation de trois décimales -- soit une précision au millimètre -- est largement suffisant pour mesurer la distance de dépassement. Une variable continue est soit une variable d'intervalle, soit une variable de rapport. Les \textbf{variables d'intervalle} ont une échelle relative, c'est-à-dire que les intervalles entre les valeurs de la variables ne sont pas constants; elles n'ont pas de vrai zéro. Ces valeurs peuvent être manipulées uniquement par addition et soustraction et non par multiplication et division. La variable d'intervalle la plus connue est certainement celle de la température. S'il fait 10 degrés Celsius à Montréal et 30°C à Mumbai (soit 50 et 86 degrés en Fahrenheit), on peut affirmer qu'il y a 20°C ou 36°F d'écart entre les deux villes, mais on ne peut pas affirmer qu'il fait trois fois plus chaud à Mumbai. Presque toutes les mesures statistiques sur une variable d'intervalle peuvent être calculées, exceptés le coefficient de variation et la moyenne géométrique puisqu'il n'y a pas de vrai zéro et d'intervalles constants entre les valeurs. À l'inverse, les \textbf{variables de rapport} ont une échelle absolue, c'est-à-dire que les intervalles entre les valeurs sont constants et elles ont un vrai zéro. Elles peuvent ainsi être manipulées par addition, soustraction, multiplication et division. Par exemple, le prix d'un produit exprimé dans une unité monétaire ou la distance exprimée dans le système métrique sont des variables de rapport. Un vélo dont le prix affiché est de 1000\$ est bien deux fois plus cher qu'un autre à 500\$, une piste cyclable hors rue à 25 mètres du tronçon routier le plus proche est bien quatre fois plus proche qu'une autre à 100 mètres.

\textbf{Une variable semi-quantitative}, appelée aussi variable quantitative ordonnée, est une variable discrète ou continue dont les valeurs ont été regroupées en classes hiérarchisées. Par exemple, l'âge est une variable continue pouvant être transformée avec les groupes d'âge ordonnés suivants : \emph{moins 25 ans}, \emph{25 à 44 ans}, \emph{45 à 64 ans} et \emph{65 ans et plus}.

\hypertarget{sect022}{%
\section{Les types de données}\label{sect022}}

Différents types de données sont utilisés en sciences sociales. L'objectif ici n'est pas de les décrire en détail, mais plutôt de donner quelques courtes définitions. En fonction de votre question de recherche et des bases des données disponibles ou non, il s'agira de sélectionner le ou les types de données les plus appropriés à votre sujet.

\hypertarget{sect0221}{%
\subsection{\texorpdfstring{Données secondaires \emph{versus} données primaires}{Données secondaires versus données primaires}}\label{sect0221}}

Les \textbf{données secondaires} sont des données qui existent déjà au début de votre projet de recherche : pas besoin de les collecter, il suffit de les exploiter! Une multitude de données de recensements ou d'enquêtes de Statistique Canada sont disponibles et largement exploitées en sciences sociales (par exemple, l'enquête nationale auprès des ménages -- ENM, l'enquête sur la dynamique du marché du travail et du revenu -- EDTR, l'enquête longitudinale auprès des immigrants -- ELIC, etc.).

\begin{bloc_notes}

Au Canada, les chercheurs (étudiants et professeurs) ont accès aux microdonnées des enquêtes de Statistique Canada dans les Centres de données de recherche (CDR). Vous pouvez consulter le moteur de recherche du (\href{https://crdcn.org/fr/donn\%C3\%A9es}{RCCDR}) afin d'explorer les différentes enquêtes disponibles.

Au Québec, l'accès à ces enquêtes est possible dans les différentes antennes du Centre interuniversitaire québécois de statistiques sociales de Statistique Canada (\href{https://www.ciqss.org/}{CIQSS}).

\end{bloc_notes}

Par opposition, les \textbf{données primaires} n'existent pas quand vous démarrez votre projet : vous devez les collecter spécifiquement pour votre étude! Par exemple, une chercheure souhaitant analyser l'exposition des cyclistes au bruit et à la pollution dans une ville donnée devra réaliser une collecte de données avec idéalement plusieurs participants (équipés de différents capteurs), et ce, sur plusieurs jours.
Une collecte de données primaires est peut aussi être réalisée avec une enquête par sondage. Brièvement, réaliser une collecte de données primaires nécessite différentes phases complexes comme la définition de la méthode de collecte, de la population à l'étude, l'estimation de la taille de l'échantillon, la validation des outils de collecte avec une phase de test, la réalisation de la collecte, la structuration, la gestion et l'exploitation de données collectées. Finalement, dans le milieu académique, une collecte de données primaires auprès d'individus doit être approuvée par le comité d'éthique de la recherche de l'université à laquelle est affilié le responsable du projet de recherche (qu'il soit professeur, chercheur ou étudiant).

\hypertarget{sect0222}{%
\subsection{\texorpdfstring{Données transversales \emph{versus} données longitudinales}{Données transversales versus données longitudinales}}\label{sect0222}}

Les \textbf{données transversales} sont des mesures pour une période relativement courte. L'exemple classique est un jeu de données constitué des variables extraites d'un recensement de population pour une année donnée (comme celui 2016 de Statistique Canada).

Les \textbf{données longitudinales}, appelées aussi données par panel, sont des mesures répétées pour plusieurs observations au cours du temps (\emph{N} observations pour \emph{T} dates). Par exemple, des observations pourraient être des pays, les dates pourraient être différentes années (de 1990 à 2019) pour lesquelles différentes variables seraient disponibles (population totale, taux d'urbanisation, produit intérieur brut par habitant, émissions de gaz à effet de serre par habitant, etc).

\hypertarget{sect0223}{%
\subsection{Données spatiales versus données aspatiales}\label{sect0223}}

Les observations des \textbf{données spatiales} sont des unités spatiales géoréférencées (points, lignes, polygones ou encore pixels d'une image). Elles peuvent être par exemple :

\begin{itemize}
\tightlist
\item
  des points \emph{(x,y)} ou \emph{(lat-long)} représentant des entreprises avec plusieurs variables (adresse, date de création, nombre d'employés, secteurs d'activité, etc.);
\item
  les lignes représentant des tronçons de rues pour lesquels plusieurs variables sont disponibles (types d'axe, longueur en mètres, nombre de voies, débit journalier moyen annuel, etc.);
\item
  des polygones délimitant des régions ou des arrondissements pour lesquels une multitude de variables sociodémographiques et socioéconomiques sont disponibles.
\end{itemize}

À l'inverse, aucune information spatiale n'est disponible pour des \textbf{données aspatiales}.

\hypertarget{sect0224}{%
\subsection{\texorpdfstring{Données individuelles \emph{versus} données agrégées}{Données individuelles versus données agrégées}}\label{sect0224}}

Comme son nom l'indique, pour des \textbf{données individuelles}, chaque observation correspond à un individu. Les microdonnées de recensement ou d'enquêtes, par exemple, sont des données individuelles pour lesquelles toute une série de variables est disponible. Une étude analysant les caractéristiques de chaque arbre d'un quartier nécessite aussi des données individuelles : l'information doit être disponible pour chaque arbre. Pour les microdonnées des recensements canadiens, « chaque enregistrement au niveau de la personne comprend des identifiants (comme les identifiants du ménage et de la famille), des variables géographiques et des variables directes et dérivées tirées du questionnaire » (\href{https://www150.statcan.gc.ca/n1/pub/12-002-x/2012001/article/11642-fra.htm}{Statistique Canada}). Comme signalé plus haut, ces microdonnées de recensement ou d'enquêtes sont uniquement accessibles dans les Centres de données de recherche (CDR).

Les données individuelles peuvent être \textbf{agrégées} à un niveau supérieur. Prenons le cas de microdonnées d'un recensement. Les informations disponibles pour chaque individu sont agrégées par territoire géographique (province, région économique, division de recensement, subdivision de recensement, région et agglomération de recensement, secteurs de recensement, aires de diffusion, etc.) en fonction du lieu d'habitation des individus. Des sommaires statistiques -- basés sur la moyenne, la médiane, la somme ou la proportion de chacune des variables mesurées au niveau individuel (âge, sexe, situation familiale, revenu, etc.) -- sont alors construits pour ces différents découpages géographiques (\href{https://www.statcan.gc.ca/fra/idd/trousse/section5\#a4}{Statistique Canada}).

L'agrégation n'est pas nécessairement géographique. En éducation, il est fréquent de travailler avec des données concernant les élèves, mais agrégées au niveau des écoles. La figure \ref{fig:figunivarie1b} donne un exemple simple d'agrégation de données individuelles.

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{images/univariee/aggregation} 

}

\caption{Exemple d'agrégation de données individuelles}\label{fig:figunivarie1b}
\end{figure}

Pour le cas de l'agrégation géographique, il convient alors de bien comprendre la hiérarchie des régions géographiques délimitées par l'organisme ou l'agence ayant la responsabilité de produire, gérer et diffuser les données des recensements et des enquêtes, puis de sélectionner le découpage géographique qui répond le mieux à votre question de recherche.

\begin{bloc_astuce}

Pour le recensement de 2016 de Statistique Canada vous pourrez consulter :

\begin{itemize}
\item
  la \href{https://www12.statcan.gc.ca/census-recensement/2016/ref/dict/figures/f1_1-fra.cfm}{hiérarchie des régions géographiques normalisées pour la diffusion}
\item
  le \href{https://www150.statcan.gc.ca/n1/pub/92-195-x/92-195-x2016001-fra.htm}{glossaire illustré} des régions géographiques
\item
  les différents \href{https://www12.statcan.gc.ca/census-recensement/2016/dp-pd/prof/details/download-telecharger/comp/page_dl-tc.cfm?Lang=F}{profils du recensement de 2016} à télécharger pour les différentes régions géographiques.
\end{itemize}

\end{bloc_astuce}

\begin{bloc_notes}

Bien entendu, les différents types de données abordés ci-dessus ne sont pas exclusifs. Par exemple, des données pour des régions administratives extraites de plusieurs recensements sont en fait des données secondaires, spatiales, agrégées et longitudinales.

Une collecte de données sur la pollution atmosphérique et sonore réalisée à vélo (avec différents capteurs et un GPS) sont des données spatiales primaires.

\end{bloc_notes}

\hypertarget{sect023}{%
\section{Statistique descriptive et statistique inférentielle}\label{sect023}}

\hypertarget{sect0231}{%
\subsection{Population, échantillon et inférence}\label{sect0231}}

Les notions de \textbf{population} et d'\textbf{échantillon} sont essentielles en statistique puisqu'elles sont le socle de l'inférence statistique.
Un échantillon est un \textbf{sous-ensemble représentatif} d'une population donnée. Prenons un exemple concret. Une chercheure veut comprendre la mobilité des étudiants d'une université. Bien entendu, elle ne pourra interroger l'ensemble des étudiants de son université. Elle devra alors s'assurer d'obtenir un échantillon de taille suffisante et représentatif de la population étudiante. Une fois les données collectées (avec un sondage par exemple), elle pourra utiliser des techniques inférentielles pour analyser la mobilité des étudiants interrogés. Si son échantillon est représentatif, les résultats obtenus pourront être inférés -- c'est-à-dire généralisés, extrapolés -- à l'ensemble de la population.

\begin{bloc_aller_loin}

\textbf{Les méthodes d'échantillonnage}

Nous n'abordons pas ici les méthodes d'échantillonnage. Sachez toutefois qu'il existe plusieurs méthodes probabilistes pour constituer un échantillon, notamment de manière aléatoire, systématique, stratifiée, par grappes (\href{https://www150.statcan.gc.ca/n1/edu/power-pouvoir/ch13/prob/5214899-fra.htm}{voir par exemple cette publique de Statistique Canada}).

\end{bloc_aller_loin}

Autre exemple, une autre chercheure souhaite comprendre les facteurs influençant le sentiment de sécurité des cyclistes dans un quartier. De nouveau, elle ne pourra pas enquêter tous les cyclistes du quartier et devra constituer un échantillon représentatif. Par la suite, la mise en œuvre de techniques inférentielles lui permettra d'identifier les caractéristiques individuelles (âge, sexe, habiletés à vélo, etc.) et de l'environnement urbain (types de voies empruntés, niveaux de trafic, de pollution, de bruit, etc.) ayant des effets significatifs sur le sentiment de sécurité. Si l'échantillon est représentatif, les résultats pourront être généralisés à l'ensemble des cyclistes du quartier.

\hypertarget{sect0232}{%
\subsection{Deux grandes familles de méthodes statistiques}\label{sect0232}}

On distingue deux grandes familles de méthodes statistiques :

\begin{itemize}
\tightlist
\item
  « \textbf{La statistique descriptive et exploratoire} : elle permet, par des résumés et des graphiques plus ou moins élaborés, de décrire des ensembles de données statistiques, d'établir des relations entre les variables sans faire jouer de rôle privilégié à une variable particulière. Les conclusions ne portent dans cette phase de travail que sur les données étudiées, sans être inférées à une population plus large. L'analyse exploratoire s'appuie essentiellement sur des notions élémentaires telles que des indicateurs de moyenne et de dispersion, sur des représentations graphiques. {[}\ldots{]}
\item
  \textbf{La statistique inférentielle et confirmatoire} : elle permet de valider ou d'infirmer, à partir de tests statistiques ou de modèles probabilistes, des hypothèses formulées a priori (ou après une phase exploratoire), et d'extrapoler, c'est-à-dire d'étendre certaines propriétés d'un échantillon à une population plus large. Les conclusions obtenues à partir des données vont au-delà de ces données. La statistique confirmatoire fait surtout appel aux méthodes dites explicatives et prévisionnelles, destinées comme leurs noms l'indiquent, à expliquer puis à prévoir, suivant des règles de décision, une variable privilégiée à l'aide d'une ou plusieurs variables explicatives (régressions multiples et logistiques, analyse de variance, analyse discriminante, segmentation, etc.) » \citep[p.~209]{lebart1995statistique}.
\end{itemize}

\hypertarget{sect024}{%
\section{La notion de distribution}\label{sect024}}

\begin{bloc_objectif}

Dans cette section, nous abordons un concept central de la statistique : les distributions. Prenez le temps de lire cette section à tête reposée et assurez-vous de bien comprendre chaque idée avant de passer à la suivante. N'hésitez pas à y revenir plusieurs fois si nécessaire, car la compréhension de ces concepts est essentielle pour utiliser adéquatement les méthodes que nous abordons dans ce livre.

\end{bloc_objectif}

\hypertarget{duxe9finitions-guxe9nuxe9rales}{%
\subsection{Définitions générales}\label{duxe9finitions-guxe9nuxe9rales}}

En statistique, on s'intéresse aux résultats d'expériences. Lancer un dé, mesurer la pollution atmosphérique, compter le nombre de collisions à une intersection, demander à une personne d'évaluer son sentiment de sécurité sur une échelle de 1 à 10 sont autant d'expériences pouvant produire des résultats.

\textbf{Une distribution est une fonction permettant d'associer pour chaque résultat possible d'une expérience la probabilité d'obtenir ce résultat}. En d'autres termes, il s'agit d'une fonction indiquant par exemple que pour l'expérience : « mesurer la concentration d'ozone à Montréal à 13h en été », la probabilité de mesurer une valeur inférieure à 15 μg/m3 est de seulement 2\%.

Les distributions sont toujours définies dans un intervalle en dehors duquel elles sont indéfinies; les valeurs dans cet intervalle sont appelées \textbf{l'espace d'échantillonnage}. Il s'agit donc des valeurs possibles que peut produire l'expérience. La somme des probabilités de l'ensemble des valeurs de l'espace d'échantillonnage est 1 (100\%). Intuitivement, cela signifie que si l'on réalise l'expérience, on est obligé d'obtenir un résultat, et que cette probabilité totale est répartie entre tous les résultats possibles de l'expérience. En langage mathématique, on dit que l'intégrale des fonctions de distribution est 1 dans leur intervalle de définition.

Prenons un exemple concret avec l'expérience suivante : tirer à pile ou face avec une pièce de monnaie non truquée. Si l'on souhaite décrire la probabilité d'obtenir pile ou face, on peut utiliser une distribution qui aura comme espace d'échantillonnage {[}pile ; face{]} et ces deux valeurs auront chacune comme probabilité 0,5. Il est facile d'étendre cet exemple au cas d'un dé à six faces. La distribution de probabilité décrivant l'expérience « lancer le dé » a pour espace d'échantillonnage {[}1,2,3,4,5,6{]}, chacune de ces valeurs étant associée à la probabilité 1/6.

Les deux distributions précédentes appartiennent à la famille des distributions \textbf{discrètes}. Elles servent à décrire des expériences dont le nombre de valeurs possibles est fini. Par opposition, la seconde famille de distributions regroupe les distributions \textbf{continues}, décrivant des expériences dont le nombre de résultats possibles est infini. Par exemple, mesurer la taille d'une personne adulte sélectionnée au hasard peut produire un nombre infini de valeurs comprises entre 50 cm et 280 cm. Les distributions sont utiles pour décrire les résultats attendus d'une expérience. Reprenons notre exemple du dé. Nous savons que chaque face a une chance sur six d'être tirée au hasard. Nous pouvons représenter cette distribution avec un graphique (figure \ref{fig:fig251}).

\begin{figure}

{\centering \includegraphics[width=0.5\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig251-1} 

}

\caption{Distribution théorique d'un lancé de dé}\label{fig:fig251}
\end{figure}

Nous avons donc sous les yeux un modèle statistique décrivant le comportement attendu d'un dé, nous l'appelons la distribution \textbf{théorique}. Cependant, si nous effectuons l'expérience 10 fois (nous collectons donc un échantillon), nous obtiendrons une distribution différente de cette distribution théorique (figure \ref{fig:fig252}).

\begin{figure}

{\centering \includegraphics[width=0.5\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig252-1} 

}

\caption{Distribution empirique d'un lancé de dé (n=10)}\label{fig:fig252}
\end{figure}

Nous appelons cette distribution la distribution \textbf{empirique}. Chaque échantillon aura sa propre distribution empirique. Cependant, comme le prédit la loi des grands nombres (ou théorème de Bernoulli) : si une expérience est répétée un grand nombre de fois, la probabilité empirique d'un résultat se rapproche de la probabilité théorique à mesure que le nombre de répétitions augmente. Pour nous en convaincre, collectons trois échantillons de lancer de dé de respectivement 30, 100 et 1000 observations (figure \ref{fig:fig253}).

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig253-1} 

}

\caption{Distribution empirique d'un lancé de dé (n=10)}\label{fig:fig253}
\end{figure}

On constate bien qu'au fur et à mesure que la taille de l'échantillon augmente, on tend vers la distribution théorique. Ces dernières sont donc utilisées pour modéliser des phénomènes réels et sont à la base de presque tous les tests statistiques d'inférence fréquentiste ou bayésienne.

En pratique, la question que l'on se pose le plus souvent est : quelle distribution théorique peut le mieux décrire le phénomène empirique à l'étude ? Pour répondre à cette question, deux approches sont possibles :

\begin{itemize}
\tightlist
\item
  Considérant la littérature existante sur le sujet, les connaissances accumulées et la nature de la variable étudiée, il est possible de sélectionner des distributions théoriques pouvant vraisemblablement correspondre à la variable.
\item
  Comparer visuellement ou à l'aide de tests statistiques la distribution empirique de la variable et diverses distributions théoriques pour trouver la plus adaptée.
\end{itemize}

Idéalement, le choix d'une distribution théorique devrait reposer sur ces deux méthodes combinées.

\hypertarget{anatomie-dune-distribution}{%
\subsection{Anatomie d'une distribution}\label{anatomie-dune-distribution}}

Puisqu'une distribution est une fonction, il est possible de la représenter à l'aide d'une formule mathématique (appelée \textbf{fonction de masse} pour les distributions discrètes et \textbf{fonction de densité} pour les distributions continues). Prenons un premier exemple concret avec la distribution théorique associée au lancer de pièce de monnaie : la distribution de \textbf{Bernoulli}. Sa formule est la suivante :

\begin{equation}f(x ; p)=\left\{\begin{array}{ll}
q=1-p & \text { si } x=0 \\
p & \text { si } x=1
\end{array}\right.
\label{eq:Bernoulli}
\end{equation}

avec \emph{p} la probabilité d'obtenir \(x = 1\) (pile), et \(1 – p\) la probabilité d'avoir \(x = 0\) (face). La distribution de Bernoulli ne dépend que d'un paramètre : \emph{p}. Avec différentes valeurs de \emph{p}, on peut obtenir différentes formes pour la distribution de Bernoulli. Si \emph{p} = 1/2, la distribution de Bernoulli décrit parfaitement l'expérience : obtenir pile à un lancer de pièce de monnaie. Si \emph{p} = 1/6, elle décrit alors l'expérience : obtenir 4 (tout comme n'importe quelle valeur de 1 à 6) à un lancer de dé. Pour un exemple plus appliqué, la distribution de Bernoulli est utilisée en analyse spatiale pour étudier la concentration d'accidents de la route ou de crimes en milieu urbain. En chaque endroit du territoire, il est possible de calculer la probabilité qu'un tel évènement ait lieu ou non en se basant sur les données observées et cette distribution.
La distribution continue la plus simple à décrire est certainement la distribution \textbf{uniforme}. Il s'agit d'une distribution un peu spéciale puisqu'elle attribue la même probabilité à toutes ses valeurs dans son espace d'échantillonnage. Elle est définie sur l'intervalle {[}-Inf ; +Inf{]} et a la fonction de densité suivante :

\begin{equation}f(x ; \mathrm{a} ; \mathrm{b})=\left\{\begin{array}{cc}
\frac{1}{a-b} & \text { si } a \geq x \geq b \\
0 & \text { sinon }
\end{array}\right.
\label{eq:Uniforme}
\end{equation}

La fonction uniforme a donc deux paramètres, \emph{a} et \emph{b}, représentant respectivement les valeurs maximale et minimale au-delà desquelles les valeurs ont une probabilité 0 d'être obtenues. Pour avoir une meilleure intuition de ce que décrit une fonction de densité, il est intéressant de la représenter avec un graphique (figure \ref{fig:fig254}). Notez que sur ce graphique, l'axe des ordonnées n'indique pas précisément la probabilité associée à chaque valeur car celle-ci serait infinidécimale. Il sert uniquement à représenter la densité de la fonction de distribution.

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig254-1} 

}

\caption{Distributions uniformes continues}\label{fig:fig254}
\end{figure}

On observe clairement que toutes les valeurs de \emph{x} entre \emph{a} et \emph{b} ont la même probabilité pour chacune de trois distributions uniformes présentées dans le graphique. Plus l'étendue est grande (\(a-b\)), plus l'espace d'échantillonnage est grand et plus la probabilité totale est répartie dans cet espace. Cette distribution serait donc idéale pour décrire un phénomène pour lequel chaque valeur a autant de chance de se produire qu'une autre. Prenons pour exemple un cas fictif avec un jeu de hasard qui vous proposerait la situation suivante : en tirant sur la manette d'une machine à sous, un nombre est tiré aléatoirement entre -60 et +50. Si le nombre est négatif, vous perdez de l'argent et inversement si le nombre est positif. Nous pouvons représenter cette situation avec une distribution uniforme continue et l'utiliser pour calculer quelques informations essentielles :

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Selon cette distribution, quelle est la probabilité de gagner de l'argent lors d'un tirage (x \textgreater{} 0)?
\item
  Quelle est la probabilité de perdre de l'argent ? (x \textless{} 0)?
\item
  Si je perds moins de 30\$ au premier tirage, quelle est la probabilité que ai-je d'au moins récupérer ma mise au second tirage (x \textgreater{} 30)?
\end{enumerate}

Il est assez facile de calculer ces probabilités en utilisant la fonction \texttt{punif} dans R. Concrètement, cela permet de calculer l'intégrale de la fonction de masse sur un intervalle donné.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Probabilité d'obtenir une valeur supérieure ou égale à 0}
\KeywordTok{punif}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DataTypeTok{min =} \DecValTok{-60}\NormalTok{, }\DataTypeTok{max =} \DecValTok{50}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.5454545
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Probabilité d'obtenir une valeur inférieure à 0}
\KeywordTok{punif}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DataTypeTok{min =} \DecValTok{-60}\NormalTok{, }\DataTypeTok{max =} \DecValTok{50}\NormalTok{, }\DataTypeTok{lower.tail =}\NormalTok{ F)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.4545455
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Probabilité d'obtenir une valeur supérieure à 30}
\KeywordTok{punif}\NormalTok{(}\DecValTok{30}\NormalTok{, }\DataTypeTok{min =} \DecValTok{-60}\NormalTok{, }\DataTypeTok{max =} \DecValTok{50}\NormalTok{,}\DataTypeTok{lower.tail =}\NormalTok{ F)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1818182
\end{verbatim}

Les paramètres permettent donc d'ajuster la fonction de masse ou de densité d'une distribution afin de lui permettre de prendre des formes différentes. Certains paramètres vont changer la localisation de la distribution (la déplacer vers la droite ou la gauche de l'axe des X), d'autres son degré de dispersion (distribution pointue ou aplatie) ou encore sa forme (symétrie). Les différents paramètres d'une distribution correspondent donc à sa carte d'identité et donnent une idée précise sur sa nature.

\hypertarget{principales-distributions}{%
\subsection{Principales distributions}\label{principales-distributions}}

Il existe un très grand nombre de distributions théoriques et parmi elles, de nombreuses sont en fait des cas spéciaux d'autres distributions. Pour un petit aperçu du bestiaire, vous pouvez faire un saut à la page \href{http://www.math.wm.edu/~leemis/chart/UDR/UDR.html}{Univariate Distribution Relationships}, qui liste près de 80 distributions.

Nous nous concentrons ici sur une sélection de 18 distributions très répandues en sciences sociales. La figure \ref{fig:fig255} présente graphiquement leurs fonctions de masse et de densité présentées dans cette section. Notez que ces graphiques correspondent tous à une forme possible de chaque distribution. En modifiant leurs paramètres, il serait possible de produire une figure très différente. Les distributions discrètes sont représentées avec des graphiques en barres, et les distributions continues avec des graphiques de densité.



\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{images/distributions/all_distributions} 

}

\caption{18 distributions essentielles, design inspiré de \citet{SeanOwendist}}\label{fig:figdistribs}
\end{figure}

\hypertarget{la-distribution-uniforme-discruxe8te}{%
\subsubsection{La distribution uniforme discrète}\label{la-distribution-uniforme-discruxe8te}}

Nous avons déjà abordé cette distribution dans les exemples précédents. Elle permet de décrire un phénomène dont tous les résultats possibles ont exactement la même probabilité de se produire. L'exemple classique est bien sûr un lancer de dé.

\hypertarget{la-distribution-de-bernoulli}{%
\subsubsection{La distribution de Bernoulli}\label{la-distribution-de-bernoulli}}

La distribution de Bernoulli permet de décrire une expérience pour laquelle deux résultats sont possibles. Son espace d'échantillonnage est donc \([0 ; 1]\). Sa fonction de masse est la suivante :

\begin{equation}f(x ; p)=\left\{\begin{array}{ll}
q=1-p & \text { si } x=0 \\
p & \text { si } x=1
\end{array}\right.
\label{eq:BernoulliB}
\end{equation}

avec \emph{p}, la probabilité d'obtenir \(x = 1\) (réussite) et donc \(1 – p\), la probabilité d'avoir \(x = 0\) (échec). La distribution de Bernoulli ne dépend que d'un paramètre : \emph{p} contrôlant la probabilité de réussite de l'expérience. Notez que si \(p = 1/2\), alors la distribution de Bernoulli est également une distribution uniforme. Un exemple d'application de la distribution de Bernoulli en études urbaines serait la modélisation de la survie d'un cycliste (1 pour survie, 0 pour décès) lors d'une collision avec une voiture selon une vitesse donnée.

\hypertarget{la-distribution-binomiale}{%
\subsubsection{La distribution binomiale}\label{la-distribution-binomiale}}

La distribution binomiale est utilisée pour caractériser une somme de distributions de Bernoulli. Un exemple simple serait l'accumulation des lancers d'une pièce de monnaie. Si l'on compte le nombre de fois où l'on fait pile, cette expérience est décrite par une distribution binomiale. Son espace d'échantillonnage est donc \([0 ; +\infty[\) (limité aux nombres entiers). Sa fonction de masse est la suivante :

\begin{equation}
    f(x ; n )=\binom{n}{x}p^x(1-p)^{n-x}
\label{eq:Binomial}
\end{equation}

avec \emph{x} le nombre de tirages réussis sur \emph{n} essais avec une probabilité \emph{p} de réussite à chaque tirage. Pour reprendre l'exemple précédent concernant les accidents de la route, une distribution binomiale permettrait de représenter la distribution du nombre de cyclistes survivants sur dix accidents impliquant une voiture à une intersection.

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig256-1} 

}

\caption{La distribution binomiale}\label{fig:fig256}
\end{figure}

\hypertarget{la-distribution-guxe9omuxe9trique}{%
\subsubsection{La distribution géométrique}\label{la-distribution-guxe9omuxe9trique}}

La distribution géométrique permet de représenter le nombre de tirages nécessaires avec une distribution de Bernoulli avant d'obtenir une réussite. Par exemple, avec un lancer de dé, l'idée serait de compter le nombre de lancers nécessaires avant de tomber sur un 6. Son espace d'échantillonnage est donc \([1 ; +\infty[\) (limité aux nombres entiers). Sa distribution de masse est la suivante :

\begin{equation}f(x ; p)= (1-p)^xp
\label{eq:geometrique}
\end{equation}

avec \emph{x} le nombre de tentatives avant d'obtenir une réussite, \(f(x)\) la probabilité que le premier succès n'arrive qu'après \emph{x} tentatives et \emph{p} la probabilité de réussite à chaque tentative. Cette distribution est notamment utilisée en marketing pour modéliser le nombre d'appels nécessaires avant de réussir une vente.

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig257-1} 

}

\caption{La distribution géométrique}\label{fig:fig257}
\end{figure}

\hypertarget{la-distribution-binomiale-nuxe9gative}{%
\subsubsection{La distribution binomiale négative}\label{la-distribution-binomiale-nuxe9gative}}

La distribution binomiale négative est proche de la distribution géométrique. Elle permet de représenter le nombre de tentatives nécessaires afin d'obtenir un nombre \emph{n} de réussites \([1 ; +\infty[\) (limité aux nombres entiers positifs). Sa formule est la suivante :

\begin{equation}f(x ; n ; p)=\left(\begin{array}{c}
x+n-1 \\
n
\end{array}\right) p^{n}(1-p)^{x}
\label{eq:binomialnegative}
\end{equation}

avec \emph{x} le nombre de tentatives avant d'obtenir \emph{n} réussites et \emph{p} la probabilité d'obtenir une réussite à chaque tentative. Cette distribution pourrait être utilisée pour modéliser le nombre de questionnaires \emph{x} à envoyer pour une enquête si l'on espère au moins \emph{n} réponses, sachant que la probabilité d'une réponse est \emph{p}.

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig258-1} 

}

\caption{La distribution binomiale négative}\label{fig:fig258}
\end{figure}

\hypertarget{la-distribution-de-poisson}{%
\subsubsection{La distribution de poisson}\label{la-distribution-de-poisson}}

La distribution de poisson est utilisée pour modéliser des comptages. Son espace d'échantillonnage est donc \([0 ; +\infty[\) (limité aux nombres entiers positifs). Par exemple, il est possible de compter à une intersection le nombre de collisions entre des automobilistes et des cyclistes sur une période donnée. Cet exemple devrait vous faire penser à la distribution binomiale vue plus haut. En effet, il serait possible de noter chaque rencontre entre une voiture et un cycliste et de considérer que leur collision est une « réussite » (0 : pas d'accidents, 1 : accident). Cependant, ce type de données serait fastidieux à collecter comparativement au simple comptage des accidents. La distribution de poisson à une fonction de densité avec un seul paramètre \(\lambda\) (lambda) et est décrite par la formule suivante :

\begin{equation}f(x ; \lambda)=\frac{\lambda^{x}}{x !} e^{-\lambda}
\label{eq:poisson}
\end{equation}

avec \emph{x} le nombre de cas, \emph{f(x)} la probabilité d'obtenir \emph{x} sachant \(\lambda\). \(\lambda\) peut être vue comme le taux moyen d'occurrences (nombre d'évènements divisé par la durée totale de l'expérience). Il permet à la fois de caractériser le centre et la dispersion de la distribution. Notez également que plus le paramètre \lambda augmente, plus la distribution de poisson tend vers une distribution normale.

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig259-1} 

}

\caption{La distribution de poisson}\label{fig:fig259}
\end{figure}

\hypertarget{la-distribution-de-poisson-avec-excuxe8s-de-zuxe9ros}{%
\subsubsection{La distribution de poisson avec excès de zéros}\label{la-distribution-de-poisson-avec-excuxe8s-de-zuxe9ros}}

Il arrive régulièrement qu'une variable de comptage mesurée produise un très grand nombre de zéros. Prenons pour exemple le nombre de seringues de drogue injectable par tronçon de rue ramassées sur une période d'un mois. À l'échelle de toute une ville, un très grand nombre de tronçons n'auront tout simplement aucune seringue et dans ce contexte, la distribution classique de poisson n'est pas adaptée. On lui préfère alors sa version avec une inflation de zéros qui inclut un paramètre contrôlant la forte présence de zéros. Sa fonction de densité est la suivante :

\begin{equation}f(x ; \lambda; p)=(1-p)\frac{\lambda^{x}}{x !} e^{-\lambda}
\label{eq:poissonzi}
\end{equation}

Plus exactement, la distribution de poisson avec excès de zéro (zero-inflated en anglais) est une combinaison de deux processus générant des zéros. En effet, un zéro peut être produit par la distribution de poisson originale (aussi appelé vrai zéro) ou alors par le processus menant à la surreprésentation des 0 dans le jeu de données, capturée par la probabilité \emph{p} (faux zéro). \emph{p} est donc le paramètre contrôlant la probabilité d'obtenir un zéro, indépendamment du phénomène étudié.

\begin{verbatim}
## Loading required package: stats4
\end{verbatim}

\begin{verbatim}
## Loading required package: splines
\end{verbatim}

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig259b-1} 

}

\caption{La distribution de poisson avec excès de zéros}\label{fig:fig259b}
\end{figure}

\hypertarget{la-distribution-gaussienne}{%
\subsubsection{La distribution gaussienne}\label{la-distribution-gaussienne}}

Plus communément appelée la distribution normale, la distribution gaussienne est utilisée pour représenter des variables continues centrées sur leur moyenne. Son espace d'échantillonnage est {]}-\(\infty\) ; +\(\infty\){[}. Cette distribution joue un rôle central en statistique. Le théorème central limite stipule que la somme d'un grand nombre de distributions tend généralement vers une distribution normale. Autrement dit, lorsque nous répétons une même expérience et que nous conservons les résultats de ces expériences, la distribution du résultat de ces expériences tend vers la normalité. Ceci s'explique par le fait qu'en moyenne, chaque répétition de l'expérience produit le même résultat, mais qu'un ensemble de petits facteurs aléatoires viennent rajouter de la variabilité dans les données collectées. Prenons un exemple concret, si l'on plante une centaine d'arbres simultanément dans un parc avec un degré d'ensoleillement identique et qu'on leur apporte les mêmes soins pendant dix ans, la distribution de leurs tailles suivra une distribution normale. Un ensemble de facteurs aléatoires (composition du sol, exposition au vent, aléas génétiques, passage de nuages, etc.) auront affecté différemment chaque arbre, ajoutant ainsi un peu de hasard dans leurs tailles finales. Ces dernières seront cependant davantage affectées par des paramètres centraux (espèces, ensoleillement, arrosage, etc.), et seront donc centrées autour d'une moyenne.
La fonction de densité de la distribution normale est la suivante :

\begin{equation}f(x ; \mu ; \sigma)=\frac{1}{\sigma \sqrt{2 \pi}} e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^{2}}
\label{eq:gaussien}
\end{equation}

avec \emph{x} une valeur dont on souhaite connaître la probabilité, \emph{f(x)} sa probabilité, \(\mu\) (mu) la moyenne de la distribution normale (paramètre de localisation) et \(\sigma\) (sigma) son écart-type (paramètre de dispersion). La courbe normale suit une forme de cloche. Notez que :

\begin{itemize}
\tightlist
\item
  68,2\% de la masse de la distribution normale est comprise dans l'intervalle \([\mu- \sigma≤x≤ \mu+ \sigma]\)
\item
  95,4\% dans l'intervalle \([\mu- 2\sigma≤x≤ \mu+ 2\sigma]\)
\item
  99,7\% dans l'intervalle \([\mu- 3\sigma≤x≤ \mu+ 3\sigma]\)
\end{itemize}

Autrement dit, dans le cas d'une distribution normale, il est très invraisemblable d'observer des données situées à plus de trois écarts types de la moyenne.
Notez ici que lorsque \(\mu = 0\) et \(\sigma = 0\), on obtient la loi normale générale (ou centrée-réduite) (section \ref{sect02552}).

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig260-1} 

}

\caption{La distribution Gaussienne}\label{fig:fig260}
\end{figure}

\hypertarget{la-distribution-gaussienne-asymuxe9trique}{%
\subsubsection{La distribution gaussienne asymétrique}\label{la-distribution-gaussienne-asymuxe9trique}}

La distribution normale asymétrique (skew-normal) est une extension de la distribution gaussienne permettant de modifier la forme de la distribution normale pour qu'elle ne soit plus symétrique. Son espace d'échantillonnage est donc {]}-\(\infty\) ; +\(\infty\){[}. Sa fonction de densité est la suivante :

\begin{equation}f(x;\xi;\omega;\alpha) = \frac{2}{\omega \sqrt{2 \pi}} e^{-\frac{(x-\xi)^{2}}{2 \omega^{2}}} \int_{-\infty}^{\alpha\left(\frac{x-\xi}{\omega}\right)} \frac{1}{\sqrt{2 \pi}} e^{-\frac{t^{2}}{2}} d t
\label{eq:skewgaussien}
\end{equation}

avec \(\xi\) (xi) le paramètre de localisation, \(\omega\) (omega) le paramètre de dispersion (ou d'échelle) et \(\alpha\) (alpha) le paramètre de forme (contrôlant le degré de symétrie). Si \(\alpha = 0\), alors la distribution skew-normal est une simple distribution normale. Ce type de distribution est très utile lorsque que l'on souhaite modéliser une variable pour laquelle on sait que des valeurs plus extrêmes s'observeront d'un côté ou de l'autre de la distribution. Les revenus totaux annuels des personnes ou des ménages sont de très bons exemples puisqu'ils sont distribués généralement avec une asymétrie positive : bien qu'une moyenne existe, il y a généralement plus de personnes ou de ménages avec des revenus très faibles, que de personnes ou de ménages avec des revenus très élevés.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig261-1} 

}

\caption{La distribution skew-Gaussienne}\label{fig:fig261}
\end{figure}

\hypertarget{la-distribution-log-normale}{%
\subsubsection{La distribution log-normale}\label{la-distribution-log-normale}}

Au même titre que la distribution skew-normal, la distribution log-normal est une version asymétrique de la distribution normale. Son espace d'échantillonnage est {]}0 ; +\(\infty\){[}. Cela signifie que cette distribution ne peut décrire que des données continues et positives. Sa fonction de densité est la suivante :
\begin{equation}f(x ; \mu ; \sigma)=\frac{1}{x \sigma \sqrt{2 \pi}} e^{-\left(\frac{(\ln x-\mu)^{2}}{2 \sigma^{2}}\right)}
\label{eq:loggaussien}
\end{equation}

À la différence la distribution skew-normal, la distribution log-normal ne peut avoir qu'une asymétrie positive (étirée vers la droite). Elle est cependant intéressante puisqu'elle ne compte que deux paramètres (\(\mu\) et \(\sigma\)) ce qui la rend plus facile à ajuster. À nouveau, une distribution log-normal pourrait être utilisée pour décrire les revenus totaux annuels des individus ou des ménages ou les revenus d'emploi. Elle est aussi utilisée en économie sur les marchés financiers pour représenter les cours des actions et des biens (ces derniers ne pouvant pas être inférieurs à 0).

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig262-1} 

}

\caption{La distribution log-gaussienne}\label{fig:fig262}
\end{figure}

\hypertarget{la-distribution-de-student}{%
\subsubsection{La distribution de Student}\label{la-distribution-de-student}}

La distribution de Student joue un rôle important en statistique, elle est par exemple utilisée lors du test \emph{t} pour calculer le degré de significativité du test. Comme la distribution gaussienne, la distribution de Student a une forme de cloche, est centrée sur sa moyenne et définie sur {]}-\(\infty\) ; +\(\infty\){[}. Elle a cependant des « queues plus lourdes » (\emph{heavy tails} en anglais). Entendez par-là que les valeurs extrêmes ont une plus grande probabilité d'occurrence dans une distribution de Student que dans une distribution gaussienne. Sa fonction de densité est la suivante :

\begin{equation}p(x ; \nu ; \hat{\mu} ; \hat{\sigma})=\frac{\Gamma\left(\frac{\nu+1}{2}\right)}{\Gamma\left(\frac{\nu}{2}\right) \sqrt{\pi \nu} \hat{\sigma}}\left(1+\frac{1}{\nu}\left(\frac{x-\hat{\mu}}{\hat{\sigma}}\right)^{2}\right)^{-\frac{\nu+1}{2}}
\label{eq:student}
\end{equation}

avec \(\mu\) le paramètre de localisation, \(\sigma\) le paramètre de dispersion (qui n'est cependant pas un écart-type comme pour la distribution normale) et \(\nu\) le nombre de degré de liberté. Plus \(\nu\) est grand, plus la distribution de Student tend vers une distribution normale. \(\Gamma\) représente la fonction mathématique gamma (à ne pas confondre avec la distribution de Gamma). Un exemple d'application en études urbaines serait l'exposition au bruit environnemental de cyclistes. Cette distribution s'approcherait certainement d'une distribution normale, mais les cyclistes croisent régulièrement des secteurs peu bruyants (parcs, rues résidentielles, etc.) et des secteurs très bruyants (artères majeures, zones industrielles, etc.), ce qui conduit vers une distribution de Student.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig263-1} 

}

\caption{La distribution de Student}\label{fig:fig263}
\end{figure}

\hypertarget{la-distribution-de-cauchy}{%
\subsubsection{La distribution de Cauchy}\label{la-distribution-de-cauchy}}

La distribution de Cauchy est également une distribution symétrique définie sur l'intervalle {]}-\(\infty\) ; +\(\infty\){[}. Elle a comme particularité d'avoir des queues potentiellement plus lourdes que la distribution de Student. Elle est notamment utilisée pour modéliser des phénomènes extrêmes comme les précipitations maximales annuelles, les niveaux d'inondations maximaux annuels ou les \emph{values at risk} pour les portefeuilles financiers. Il est également intéressant de noter que le quotient de deux variables indépendantes normalement distribuées suit une distribution de Cauchy. Sa fonction de densité est la suivante :

\begin{equation}\frac{1}{\pi \gamma}\left[\frac{\gamma^{2}}{\left(x-x_{0}\right)^{2}+\gamma^{2}}\right]
\label{eq:cauchy}
\end{equation}

Elle dépend donc de deux paramètres : \(x_0\), le paramètre de localisation indiquant le pic de la distribution et \(\gamma\), un paramètre de dispersion.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig264-1} 

}

\caption{La distribution de Cauchy}\label{fig:fig264}
\end{figure}

\hypertarget{la-distribution-du-chi-carruxe9}{%
\subsubsection{La distribution du Chi-carré}\label{la-distribution-du-chi-carruxe9}}

La distribution du Chi2 est utilisée dans de nombreux tests statistiques. Spécifiquement, le test du Chi2 de Pearson est utilisé pour comparer les écarts au carré entre des fréquences attendues et observées de deux variables qualitatives. La distribution du Chi2 décrit donc les sommes des carrés d'un nombre \emph{k} de variables indépendantes normalement distribuées. Il est assez rare de modéliser un phénomène à l'aide d'une distribution du Chi2, mais son omniprésence dans les tests statistiques justifie qu'elle soit mentionnée ici. Cette distribution est définie sur l'intervalle {[}0 ; +\(\infty\){[} et a pour fonction de densité :

\begin{equation}f(x;k) = \frac{1}{2^{k / 2} \Gamma(k / 2)} x^{k / 2-1} e^{-x / 2}
\label{eq:chi2}
\end{equation}

Cette fonction n'a qu'un paramètre \emph{k}, représentant donc le nombre de variables au carré sommées pour obtenir la distribution du Chi2

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig265-1} 

}

\caption{La distribution du Chi<sup>2</sup>}\label{fig:fig265}
\end{figure}

\hypertarget{la-distribution-exponentielle}{%
\subsubsection{La distribution exponentielle}\label{la-distribution-exponentielle}}

La distribution exponentielle est une version continue de la distribution géométrique. Pour cette dernière, on s'intéresserait au nombre de tentatives nécessaires pour obtenir un résultat positif, soit une dimension discrète. Pour la distribution exponentielle, cette dimension discrète est remplacée par une dimension continue. L'exemple le plus intuitif est sûrement le cas du temps. Dans ce cas, la distribution exponentielle servirait à décrire le temps d'attente nécessaire pour qu'un évènement se produise. Il pourrait aussi s'agir d'une force que l'on applique jusqu'à ce qu'un matériau cède. Cette distribution est donc définie sur l'intervalle {[}0 ; +\(\infty\){[} et a pour fonction de densité :

\begin{equation}f(x;\lambda) = \lambda e^{-\lambda x}
\label{eq:exponentiel}
\end{equation}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig266-1} 

}

\caption{La distribution exponentielle}\label{fig:fig266}
\end{figure}

\hypertarget{la-distribution-de-gamma}{%
\subsubsection{La distribution de Gamma}\label{la-distribution-de-gamma}}

La distribution de Gamma est une généralisation d'un grand nombre de distributions. Elle regroupe ainsi la distribution exponentielle et du Chi2. En d'autres termes, les distributions du chi2 et exponentielles sont des cas particuliers de la distribution de Gamma. Cette distribution est définie sur l'intervalle {]}0 ; +\(\infty\){[} (notez que le 0 est exclu) et sa fonction de densité est la suivante :

\begin{equation}f(x ; \alpha; \beta)=\frac{\beta^{\alpha} x^{\alpha-1} e^{-\beta x}}{\Gamma(\alpha)}
\label{eq:gamma}
\end{equation}

Elle comprend donc deux paramètres : \(\alpha\) et \(\beta\). Le premier est le paramètre de forme et le second un paramètre d'échelle (à l'inverse d'un paramètre de dispersion, plus sa valeur est petite, plus la distribution sera dispersée). Notez que cette distribution ne dispose pas d'un paramètre de localisation. Du fait de sa flexibilité, cette distribution est largement utilisée, que ce soit dans la modélisation des temps d'attente avant un évènement, la taille des réclamations d'assurance, les quantités de précipitations, etc.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig267-1} 

}

\caption{La distribution de Gamma}\label{fig:fig267}
\end{figure}

\hypertarget{la-distribution-de-beta}{%
\subsubsection{La distribution de Beta}\label{la-distribution-de-beta}}

La distribution de Beta est définie sur l'intervalle {[}0 ; 1{]}, elle est donc énormément utilisée pour représenter des variables étant des proportions ou des probabilités. Elle a aussi une utilité pratique en statistique, car en combinaison avec d'autres distributions, elle permet de modéliser leurs paramètres de probabilité (distribution beta-binomial, beta-negative-binomial, etc.). Un autre usage plus rare, mais intéressant est la modélisation de la fraction du temps représentée par une tâche dans le temps nécessaire à la réalisation de deux tâches de façon séquentielle. Ceci est dû au fait que la distribution d'une distribution gamma \emph{g1} divisée par la somme de \emph{g1} et d'une autre distribution gamma \emph{g2}, suit une distribution beta. Un exemple concret serait par exemple la fraction du temps effectué à pied dans un déplacement multimodal. La distribution de beta a la fonction de densité suivante :

\begin{equation}f(x;\alpha;\beta) = \frac{1}{\mathrm{B}(\alpha, \beta)} x^{\alpha-1}(1-x)^{\beta-1}
\label{eq:beta}
\end{equation}

Elle a donc deux paramètres \(\alpha\) et \(\beta\) contrôlant tous les deux la forme de la distribution. Cette caractéristique lui permet d'avoir une très grande flexibilité et même d'adopter des formes bimodales. \(B\) correspondant à la fonction mathématique Beta, à ne pas confondre avec la distribution de Beta et le paramètre Beta (\(\beta\)) de cette même distribution.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig268-1} 

}

\caption{La distribution de Beta}\label{fig:fig268}
\end{figure}

\hypertarget{la-distribution-de-weibull}{%
\subsubsection{La distribution de Weibull}\label{la-distribution-de-weibull}}

La distribution de Weibull est directement liée à la distribution exponentielle, cette dernière étant en fait un cas particulier de distribution de Weibull. Elle sert donc à représenter une quantité \emph{x} (souvent le temps) à accumuler pour qu'un évènement se produise. La distribution de Weibull est définie sur l'intervalle {[}0 ; +\(\infty\){[} et a la fonction de densité suivante :

\begin{equation}f(x;\lambda) = \frac{k}{\lambda} (\frac{x}{\lambda})^{k-1} e^{-(\frac{x}{\lambda})^k}
\label{eq:weibull}
\end{equation}

\(\lambda\) est le paramètre de dispersion (analogue a celui d'une distribution exponentielle classique) et \emph{k} le paramètre de forme. Pour bien comprendre le rôle de \emph{k}, prenons un exemple : la propagation d'un champignon d'un arbre à son voisin. Si \(k<1\), cela signifie que la probabilité que l'évènement modélisé se produise diminue avec le temps. En d'autres termes, dans de nombreux cas la contamination se fait rapidement. Si \(k=1\), alors la probabilité que l'évènement se produise reste stable dans le temps. Si \(k > 1\), alors la probabilité que l'évènement se produisent augmente avec le temps, ce qui signifie une augmentation des risques de contamination à mesure que les deux arbres restent à proximité. La distribution de Weibull est très utilisée en analyse de survie, en météorologie, en ingénierie des matériaux et dans la théorie des valeurs extrêmes.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig269-1} 

}

\caption{La distribution de Weibull}\label{fig:fig269}
\end{figure}

\hypertarget{la-distribution-de-pareto}{%
\subsubsection{La distribution de Pareto}\label{la-distribution-de-pareto}}

La distribution de Pareto est à la distribution exponentielle ce que la distribution log-normal est à la distribution gaussienne : la distribution de l'exponentiel (e) de cette distribution originale. Elle est définie sur l'intervalle \([x_m ; +\infty[\) avec la fonction de densité suivante :

\begin{equation}f(x;x_m;k) = (\frac{x_m}{x})^k
\label{eq:pareto}
\end{equation}

Elle comprend donc deux paramètres, \(x_m\) étant un paramètre de localisation (décalant la distribution vers la droite ou vers la gauche) et \(k\) un paramètre de forme. Plus \(k\) augmente, plus la probabilité prédite par la distribution décroît rapidement.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig270-1} 

}

\caption{La distribution de Pareto}\label{fig:fig270}
\end{figure}

Originalement, le mathématicien Pareto a utilisé cette fonction pour décrire la répartition du capital parmi la population puisqu'une large partie du capital est détenue par une petite fraction de la population. Elle peut également être utilisée pour décrire la répartition de la taille des villes \citep{William_pareto_ville}, \href{https://medium.com/@worstonlinedater/tinder-experiments-ii-guys-unless-you-are-really-hot-you-are-probably-better-off-not-wasting-your-2ddf370a6e9a}{la popularité des hommes sur tinder} ou la taille des fichiers échangés sur internet \citep{William_pareto}. Pour ces trois exemples, nous avons une situation avec : de nombreuses petites villes, profils peu attractifs, petits fichiers échangés et à l'inverse très peu de grandes villes, profils très attractifs, gros fichiers échangés.

\hypertarget{cas-particuliers}{%
\subsubsection{Cas particuliers}\label{cas-particuliers}}

Sachez également qu'il existe des formes « plus exotiques » de distributions que nous n'abordons pas ici, mais auxquelles vous pourriez être confrontés un jour :

\begin{itemize}
\tightlist
\item
  Les distributions sphériques, servant à décrire des données dont le 0 est équivalent à la valeur maximale. Par exemple, des angles puisque 0 et 360 degrés sont identiques.
\item
  Les mixtures de distributions, décrivant des combinaisons de distributions. Par exemple, la distribution de la taille de tous les humains est en réalité un mixte entre deux distributions gaussiennes, une pour chaque sexe, puisque ces deux sous-distributions n'ont pas la même moyenne ni le même écart-type.
\item
  Les distributions multivariées, permettant de décrire des phénomènes multidimensionnels. Par exemple, la réussite des élèves en français et en mathématique pourrait être modélisée comme une distribution gaussienne bivariée plutôt que deux distributions distinctes.
\item
  Les distributions censurées décrivant des variables pour lesquels des valeurs sont possibles au-delà d'une certaine limite mais que l'on est incapable de mesurer. Un bon exemple serait la mesure de la pollution sonore avec un capteur incapable de détecter des niveaux sonores en dessous de 55 décibels. Il arrive parfois en ville que les niveaux sonores soient si faibles, mais les données collectées ne le montrent pas. Dans ce contexte, il est important d'utiliser des versions censurées des distributions présentées précédemment. Les observations au-delà de la limite sont conservées dans l'analyse, mais nous ne disposons que d'une information partielle à leur égard.
\item
  Les distributions tronquées, souvent confondues avec les distributions censurées, décrivent des situations ou des données qui au-delà d'une certaine limite sont retirées simplement de l'analyse.
\end{itemize}

\hypertarget{conclusion-sur-les-distributions}{%
\subsection{Conclusion sur les distributions}\label{conclusion-sur-les-distributions}}

Voilà qui conclut cette exploration des principales distributions à connaître. L'idée n'est bien sûr pas de toutes les retenir par cœur (et encore moins les formules mathématiques), mais plutôt de se rappeler dans quels contextes elles peuvent être utiles; et de revenir au besoin sur ce chapitre. Vous aurez certainement besoin de le relire avant d'aborder le chapitre portant sur les modèles linéaires généralisés (GLM).
Wikipédia dispose d'informations très détaillées sur chaque distribution si vous avez besoin d'informations complémentaires. Pour un tour d'horizon plus exhaustif des distributions, vous pouvez aussi faire un tour sur les projets \href{https://sites.google.com/site/probonto/screenshots}{probonto} et \href{https://blog.wolfram.com/2013/02/01/the-ultimate-univariate-probability-distribution-explorer/}{the ultimate probability distribution explorer}.

\hypertarget{sect025}{%
\section{Statistiques descriptives sur des variables quantitatives}\label{sect025}}

\hypertarget{sect0251}{%
\subsection{Les paramètres de tendance centrale}\label{sect0251}}

Trois mesures de tendance centrale permettent de résumer rapidement une variable quantitative :

\begin{itemize}
\tightlist
\item
  la \textbf{moyenne arithmétique} est simplement la somme des données d'une variable divisée par le nombre d'observations (\(n\)), soit \(\frac{\sum_{i=1}^n x_i}{n}\) notée \(\mu\) (prononcez \emph{mu}) pour des données pour une population et \(\bar{x}\) (prononcez \emph{x barre}) pour un échantillon.
\item
  la \textbf{médiane} est la valeur qui coupe la distribution d'une variable d'une population ou d'un échantillon en deux parties égales. Autrement dit, 50\% des valeurs des observations lui sont supérieures et 50\% lui sont inférieures.
\item
  le \textbf{mode} est la valeur la plus fréquente parmi un ensemble d'observations pour une variable. Il s'applique ainsi à des variables discrètes (avec un nombre fini de valeurs discrètes dans un intervalle donné) et non à des variables continues (avec un nombre infini de valeurs réelles dans un intervalle donné). Prenons deux variables, l'une discrète relative au nombre d'accidents par intersection (avec \(X \in \left[0,20\right]\)) et l'autre continue relative à la distance de dépassement (en mètres) d'un cycliste par un véhicule motorisé (avec \(X \in \left[0,5\right]\)). Pour la première, le mode -- la valeur la plus fréquente -- est certainement 0. Pour la seconde, identifier le mode n'est pas pertinent puisqu'il peut y avoir un nombre infini de valeurs entre 0 et 5 mètres.
\end{itemize}

Il convient de ne pas confondre moyenne et médiane ! Dans le tableau \ref{tab:tableRevMoyMed}, nous avons reporté les valeurs moyennes et médianes des revenus des ménages pour les municipalités de l'île de Montréal en 2015. Par exemple, les 8685 ménages résidant à Wesmount disposaient en moyenne d'un revenu de 295099\$; la moitié de ces 8685 ménages avaient un revenu inférieur à 100153\$ et l'autre moitié un revenu supérieur à cette valeur (médiane). Cela démontre clairement que la moyenne peut être grandement affectée par des valeurs extrêmes (faibles ou fortes); autrement dit, plus l'écart entre les valeurs de la moyenne et la médiane est importante, plus les données de la variable sont inégalement réparties. À Westmount, soit la municipalité la plus nantie de l'île de Montréal, les valeurs extrêmes sont des ménages avec des revenus très élevés tirant fortement la moyenne vers le haut. À l'inverse, le faible écart entre les valeurs moyenne et médiane dans la municipalité de Montréal-Est (58594\$ versus 50318\$) soulignent que les revenus des ménages sont plus également répartis. Cela explique que pour comparer les revenus totaux ou d'emploi entre différents groupes (selon le sexe, le groupe d'âge, le niveau d'éducation, la municipalité ou région métropolitaine, etc.), on prévilégie habituellement l'utilisation des revenus médians.

\begin{table}

\caption{\label{tab:tableRevMoyMed}Revenus moyens et médians des ménages en dollars, municipalités de l'île de Montréal, 2015}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{lrrr}
\toprule
Municipalité & Nombre de ménages & Revenu moyen & Revenu médian\\
\midrule
Baie-D'Urfé & 1 330 & 171 390 & 118 784\\
Beaconsfield & 6 660 & 187 173 & 123 392\\
Côte-Saint-Luc & 13 490 & 94 570 & 58 935\\
Dollard-Des Ormeaux & 17 210 & 102 104 & 78 981\\
Dorval & 8 390 & 89 952 & 64 689\\
\addlinespace
Hampstead & 2 470 & 250 497 & 122 496\\
Kirkland & 6 685 & 144 676 & 115 381\\
Montréal & 779 805 & 69 047 & 50 227\\
Montréal-Est & 1 730 & 58 594 & 50 318\\
Montréal-Ouest & 1 850 & 159 374 & 115 029\\
\addlinespace
Mont-Royal & 7 370 & 205 309 & 109 540\\
Pointe-Claire & 12 380 & 100 294 & 80 242\\
Sainte-Anne-de-Bellevue & 1 960 & 102 969 & 67 200\\
Senneville & 345 & 203 790 & 116 224\\
Westmount & 8 685 & 295 099 & 100 153\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{sect0252}{%
\subsection{Les paramètres de position}\label{sect0252}}

Les paramètres de position permettent de diviser une distribution en \emph{n} parties égales.

\begin{itemize}
\tightlist
\item
  Les \textbf{quartiles} qui divisent une distribution en quatre parties (25\%) :

  \begin{itemize}
  \tightlist
  \item
    Q1 (25\%), soit le quartile inférieur ou premier quartile;
  \item
    Q2 (50\%), soit la médiane;
  \item
    Q3 (75\%), soit le quartile supérieur ou troisième quartile.
  \end{itemize}
\item
  Les \textbf{quintiles} qui divisent une distribution en cinq parties égales (20\%).
\item
  Les \textbf{déciles} (de D1 à D9) qui divisent une distribution en dix parties égales (10\%).
\item
  Les \textbf{centiles} (de C1 à C99) qui divisent une distribution en cent parties égales (1\%).
\end{itemize}

En cartographie, les quartiles et les quintiles sont souvent utilisés pour discrétiser une variable quantitative (continue ou discrète) en quatre ou cinq classes et plus rarement, en huit ou dix classes. Avec les quartiles, les bornes des classes qui comprendront chacune 25\% des unités spatiales seront ainsi définies comme suit : {[}Min à Q1{]}, {[}Q1 à Q2{]}, {[}Q2 à Q3{]} et {[}Q3 à Max{]}. La méthode de discrétisation selon les quartiles ou quintiles permet alors de repérer, en un coup d'œil, à quelle tranche de 25\% ou 20\% des données appartient chacune des unités spatiales. Cette méthode de discrétisation est aussi utile pour comparer plusieurs cartes et vérifier si deux phénomènes sont ou non colocalisés \citep{pumain1994}. En guise d'exemple, les pourcentages de personnes à faible revenu et de locataires par secteur de recensement ont clairement des distributions spatiales très semblables dans la région métropolitaine de Montréal en 2016 (figure \ref{fig:figunivarie2}).

\begin{figure}

{\centering \includegraphics[width=0.85\linewidth]{images/univariee/figure2} 

}

\caption{Exemples de cartographie avec une discrétisation selon les quantiles}\label{fig:figunivarie2}
\end{figure}

Une lecture attentive des valeurs des centiles permet de repérer la présence de valeurs extrêmes voire aberrantes dans un jeu de données. Il n'est donc pas rare de les voir reportées dans un tableau de statistiques descriptives d'un article scientifique, et ce, afin de décrire succinctement les variables à l'étude. Par exemple, dans une étude récente comparant les niveaux d'exposition au bruit des cyclistes dans trois villes \citep{2020_1}, les auteurs reportent à la fois les valeurs moyennes et celles de plusieurs centiles. Globalement, la lecture des valeurs moyennes permet de constater que, sur la base des données collectées, les cyclistes sont plus exposés au bruit à Paris qu'à Montréal et Copenhague (73,4 dB(A) contre 70,7 et 68,4, tableau \ref{tab:tableCentiles}). Compte tenu de l'échelle logarithmique du bruit, la différence de 5 dB(A) entre les valeurs moyennes du bruit de Copenhague et de Paris peut être considérée comme une multiplication de l'énergie sonore par plus de 3. Pour Paris, l'analyse des quartiles montre que durant 25\% du temps des trajets à vélo (plus de 63 heures de collecte), les participants ont été exposés à des niveaux de bruit soit inférieurs à 69,1 dB(A) (premier quartile), soit supérieurs à 74 dB(A). Quant à l'analyse des centiles, elle permet de constater que durant 5\% et 10\% du temps, les participants étaient exposés à des niveaux de bruit très élevés, dépassant 77 dB(A) (C90=76 et C90=77,2).

\begin{table}

\caption{\label{tab:tableCentiles}Stastistiques descriptives de l'exposition au bruit des cyclistes par minute dans trois villes (dB(A), Laeq 1min)}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{lrrr}
\toprule
Statistiques & Copenhague & Montréal & Paris\\
\midrule
N & 6 212,0 & 4 723,0 & 3 793,0\\
Moyenne de bruit & 68,4 & 70,7 & 73,4\\
Centiles &  &  & \\
1 & 57,5 & 59,2 & 62,3\\
5 & 59,1 & 61,1 & 65,0\\
\addlinespace
10 & 60,3 & 62,3 & 66,5\\
25 (premier quartile) & 62,7 & 64,5 & 69,1\\
50 (médiane) & 66,0 & 67,7 & 71,6\\
75 (troisième quartile) & 69,2 & 71,0 & 74,0\\
90 & 71,9 & 73,7 & 76,0\\
\addlinespace
95 & 73,3 & 75,2 & 77,2\\
99 & 76,5 & 78,9 & 81,0\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{sect0253}{%
\subsection{Les paramètres de dispersion}\label{sect0253}}

Cinq principales mesures de dispersion permettent d'évaluer la variabilité des valeurs d'une variable quantitative : l'étendue, l'écart interquartile, la variance, l'écart-type et le coefficient de variation. Notez d'emblée que cette dernière mesure ne s'applique pas à des variables d'intervalle (section \ref{sect02122}).

\begin{itemize}
\item
  \textbf{L'étendue} est la différence entre les valeurs minimale et maximale d'une variable, soit l'intervalle des valeurs dans lequel elle a été mesurée. Il convient d'analyser avec prudence cette mesure puisqu'elle inclut dans son calcul des valeurs potentiellement extrêmes voire aberrantes (faibles ou fortes).
\item
  \textbf{L'intervalle ou écart interquartile} est la différence entre les troisième et premier quartiles (\(Q3 − Q1\)). Il représente ainsi une mesure de la dispersion des valeurs de 50\% des observations centrales de la distribution. Plus la valeur de l'écart interquartile est élevée, plus la dispersion des 50\% des observations centrales est forte. Contrairement à l'étendue, cette mesure élimine l'influence des valeurs extrêmes puisqu'elle ne tient pas compte des 25\% des observations les plus faibles {[}Min à Q1{]} et des 25\% des observations les plus fortes {[}Q3 à Max{]}. Graphiquement, l'intervalle interquartile est représenté à l'aide d'une boîte à moustaches (\emph{boxplot} en anglais) : plus l'intervalle interquartile sera grand, plus la boîte sera allongée (figure \ref{fig:figunivarie3})
\end{itemize}

\begin{figure}

{\centering \includegraphics[width=0.3\linewidth]{images/univariee/figure3} 

}

\caption{Graphique en violon, boîte à moustaches et intervalle interquartile}\label{fig:figunivarie3}
\end{figure}

\begin{itemize}
\tightlist
\item
  \textbf{La variance} est la somme des déviations à la moyenne au carré (numérateur) divisée par le nombre d'observations pour une population (\(\sigma^2\)) ou divisée par le nombre d'observations moins une (\(s^2\)) pour un échantillon (eq. \eqref{eq:variance}). Puisque les déviations à la moyenne sont mises au carré, la valeur de la variance (tout comme celle de l'écart-type) sera toujours positive. Plus sa valeur est élevée, plus les observations sont dispersées autour de la moyenne. La variance représente ainsi l'écart au carré moyen des observations à la moyenne.
\end{itemize}

\begin{equation} 
\sigma^2=\frac{\sum_{i=1}^n (x_{i}-\mu)^2}{n} \text{ ou } s^2=\frac{\sum_{i=1}^n (x_{i}-\bar{x})^2}{n-1}
\label{eq:variance}
\end{equation}

\begin{itemize}
\tightlist
\item
  \textbf{L'écart-type} est la racine carrée de la variance (eq. \eqref{eq:ecartype}). Rappelez-vous que la variance est calculée à partir des déviations à la moyenne mises au carré. Étant donné que l'écart-type est la racine carrée de la variance, il est donc évalué dans les mêmes unités que la variable, contrairement à la variance. Bien entendu, comme pour la variance, plus la valeur de l'écart-type est élevée, plus la distribution des observations autour de la moyenne est dispersée.
\end{itemize}

\begin{equation} 
\sigma=\sqrt{\sigma^2}=\sqrt{\frac{\sum_{i=1}^n (x_{i}-\mu)^2}{n}} \text{ ou } s=\sqrt{s^2}=\sqrt{\frac{\sum_{i=1}^n (x_{i}-\bar{x})^2}{n-1}}
\label{eq:ecartype}
\end{equation}

\begin{bloc_notes}

Les formules des variances et des écart-types pour une population et un échantillon sont très similaires : seul le dénominateur change avec \(n\) \emph{versus} \(n-1\) observations. Par conséquent, plus le nombre d'observations de votre jeu de données sera important, plus l'écart entre ces deux mesures de dispersion pour une population et un échantillon sera minime.

Comme dans la plupart des logiciels de statistique, les fonctions de base \texttt{var} et \texttt{sd} de R calculent la variance et l'écart-type pour un échantillon (\(n-1\) au dénominateur). Si vous souhaitez les calculer pour une population, adaptez la syntaxe ci-dessous dans laquelle \texttt{df\$var1} représente la variable intitulée \texttt{var1} présente dans un \emph{dataframe} nommé \texttt{df}.

\texttt{var.p\ \textless{}-\ mean((df\$var1\ -\ mean(df\$var1))\^{}2)}

\texttt{sd.p\ \textless{}-\ sqrt(mean((df\$var1\ -\ mean(df\$var1))\^{}2))}

\end{bloc_notes}

\begin{itemize}
\tightlist
\item
  \textbf{Le coefficient de variation (CV)} est le rapport entre l'écart-type et la moyenne, représentant ainsi une standardisation de l'écart-type ou, en d'autres termes, une mesure de dispersion relative (eq. \eqref{eq:cv}). L'écart-type étant exprimé dans l'unité de mesure de la variable, il ne peut pas être utilisé pour comparer les dispersions de variables exprimées des unités de mesure différentes (par exemple, en pourcentage, en kilomètres, en dollars, etc.). Pour y remédier, on utilisera le coefficient de variation : une variable est plus dispersée qu'une autre si la valeur de son CV est plus élevée. Certains préfèreront multiplier la valeur du CV par 100 : l'écart-type est alors exprimé en pourcentage de la moyenne.
\end{itemize}

\begin{equation} 
CV=\frac{\sigma}{\mu} \text{ ou } CV=\frac{s^2}{\bar{x}}
\label{eq:cv}
\end{equation}

Illustrons comment calculer les cinq mesures de dispersion précédemment décrites à partir de valeurs fictives pour huit observations (colonne intitulée \(x_i\) au tableau \ref{tab:datavar}). Les différentes statistiques reportées dans ce tableau sont calculées comme suit :

\begin{itemize}
\item
  La \textbf{moyenne} est la somme divisée par le nombre d'observations, soit \(248/8=31\).
\item
  L'\textbf{étendue} est la différence entre les valeurs maximale et minimale, soit \(40-22=30\).
\item
  Les quartiles coupent la distribution en quatre parties égales. Avec huit observations triées par ordre croissant, \textbf{le premier quartile} est égale à la valeur de la 2\textsuperscript{e} observation (soit 25), la \textbf{médiane} à celle de la 4\textsuperscript{e} (30), le \textbf{troisième quartile} à celle de la 6\textsuperscript{e} (35).
\item
  \textbf{L'écart interquartile} est la différence entre Q3 et Q1, soit \(35-25=10\).
\item
  La seconde colonne du tableau est l'écart à la moyenne (\(x_i-\bar{x}\)), soit \(22 - 31 = -9\) pour l'observation \emph{1}; la somme de ces écarts est toujours égale à 0. La troisième colonne est cette déviation mise au carré (\((x_i-\bar{x})^2\)), soit \(-9^2 = 81\), toujours pour l'observation \emph{1}. La somme de ces déviations à la moyenne au carré (\(268\)) représente le numérateur de la variance (eq. \eqref{eq:variance}). En divisant cette somme par le nombre d'observations, on obtient la \textbf{variance pour une population} (\(268/8=33,5\)) tandis que la \textbf{variance d'un échantillon} est égale à \(268/(8-1)=38,29\).
\item
  L'écart-type est la racine carrée de la variance (eq. \eqref{eq:ecartype}), soit \(\sigma=\sqrt{33,5}=5,79\) et \(s=\sqrt{38,29}=6,19\).
\item
  Finalement, les valeurs des coefficients de variation (eq. \eqref{eq:cv}) sont de \(5,79/31=0,19\) pour une population et \(6,19/31=0,20\) pour un échantillon.
\end{itemize}

\begin{table}

\caption{\label{tab:datavar}Calcul des mesures de dispersion sur des données fictives}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{lrrr}
\toprule
Observation & $x_i$ & $x_i-\bar{x}$ & $(x_i-\bar{x})^2$\\
\midrule
1 & 22,00 & -9 & 81,0\\
2 & 25,00 & -6 & 36,0\\
3 & 27,00 & -4 & 16,0\\
4 & 30,00 & -1 & 1,0\\
5 & 32,00 & 1 & 1,0\\
\addlinespace
6 & 35,00 & 4 & 16,0\\
7 & 37,00 & 6 & 36,0\\
8 & 40,00 & 9 & 81,0\\
\textbf{Statistique} & \textbf{} & \textbf{} & \textbf{}\\
N & 8,00 &  & \\
\addlinespace
Somme & 248,00 & 0 & 268,0\\
Moyenne ($\bar{x}$ ou $\mu$) & 31,00 & 0 & 33,5\\
Étendue & 18,00 &  & \\
Premier quartile & 25,00 &  & \\
Troisième quartile & 35,00 &  & \\
\addlinespace
Intervalle interquartile & 10,00 &  & \\
Variance (population, $\sigma^2$) & 33,50 &  & \\
Écart-type (population, $\sigma$) & 5,79 &  & \\
Variance (échantillon, $s^2$) & 38,29 &  & \\
Écart-type (échantillon, $s$) & 6,19 &  & \\
\addlinespace
Coefficient de variation ($\sigma / \mu$) & 0,19 &  & \\
Coefficient de variation ($s / \bar{x}$) & 0,20 &  & \\
\bottomrule
\end{tabular}
\end{table}

Le tableau \ref{tab:datavar2} vise à démontrer à partir de trois variables comment certaines mesures de dispersion sont sensibles à l'unité de mesure et/ou aux valeurs extrêmes.

Concernant \textbf{l'unité de mesure}, nous avons créé deux variables \emph{A} et \emph{B}, avec \emph{B} étant simplement \emph{A} multiplié par 10. Pour \emph{A}, les valeurs de la moyenne, l'étendue et l'intervalle interquartile sont respectivement de 31, 18 et 10. Sans surprise, celles de B sont multipliées par 10 (310, 180, 100). La variance étant la moyenne des déviations à la moyenne au carré, elle est égale à 33,50 pour \emph{A} et donc à \(33,50\times10^2=3350\) pour \emph{B}; l'écart-type de \emph{B} est égal à celui de \emph{A} multiplié par 10. Cela démontre que l'étendue, l'intervalle interquartile, la variance et l'écart-type sont des mesures de dispersion dépendantes de l'unité de mesure. Par contre, le coefficient de variation (CV) étant le rapport de l'écart-type avec la moyenne, il a la même valeur pour \emph{A} et \emph{B}, ce qui démontre que CV est bien une mesure de dispersion relative permettant de comparer des variables exprimées dans des unités de mesure différentes.

Concernant \textbf{la sensibilité aux valeurs extrêmes}, nous avons créé la variable \emph{C} pour laquelle seule la huitième observation a une valeur différente (40 pour \emph{A} et \emph{105} pour B). Cette valeur de 105 pourrait être soit une valeur extrême positive mesurée, soit une valeur aberrante (par exemple, si l'unité de mesure était un pourcentage variant de 0 à 100\%). Cette valeur a un impact important sur la moyenne (31 contre 39,12) et l'étendue (18 contre 83) et corollairement sur la variance (33,50 contre 641,86), l'écart-type (5,79 contre 25,33) et le coefficient de variation (0,19 contre 0,65). Par contre, l'intervalle interquartile étant calculé sur 50\% des observations centrales (\(Q3-Q1\)), il n'est pas affecté par cette valeur extrême.

\begin{table}

\caption{\label{tab:datavar2}Illustration de la sensibilité des mesures de dispersion à l'unité de mesure et aux valeurs extrêmes}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{lrrr}
\toprule
Observation & A & B & C\\
\midrule
1 & 22,00 & 220,00 & 22,00\\
2 & 25,00 & 250,00 & 25,00\\
3 & 27,00 & 270,00 & 27,00\\
4 & 30,00 & 300,00 & 30,00\\
5 & 32,00 & 320,00 & 32,00\\
\addlinespace
6 & 35,00 & 350,00 & 35,00\\
7 & 37,00 & 370,00 & 37,00\\
8 & 40,00 & 400,00 & 105,00\\
\textbf{Statistique} & \textbf{} & \textbf{} & \textbf{}\\
Moyenne (\$\textbackslash{}mu\$) & 31,00 & 310,00 & 39,12\\
\addlinespace
Étendue & 18,00 & 180,00 & 83,00\\
Intervalle interquartile & 10,00 & 100,00 & 10,00\\
Variance (population, \$\textbackslash{}sigma\textasciicircum{}2\$) & 33,50 & 3 350,00 & 641,86\\
Écart-type (population, \$\textbackslash{}sigma\$) & 5,79 & 57,88 & 25,33\\
Coefficient de variation (\$\textbackslash{}sigma / \textbackslash{}mu\$) & 0,19 & 0,19 & 0,65\\
\bottomrule
\end{tabular}
\end{table}

\begin{table}

\caption{\label{tab:resume}Résumé de la sensibilité de la moyenne et des mesures de dispersion}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{lll}
\toprule
Statistique & Unité de mesure & Valeurs extrêmes\\
\midrule
Moyenne & X & X\\
Étendue & X & X\\
Intervalle interquartile & X & \\
Variance & X & X\\
Écart-type & X & X\\
\addlinespace
Coefficient de variation &  & X\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{sect0254}{%
\subsection{Les paramètres de forme}\label{sect0254}}

\hypertarget{vuxe9rifier-la-normalituxe9-dune-variable-quantitative}{%
\subsubsection{Vérifier la normalité d'une variable quantitative}\label{vuxe9rifier-la-normalituxe9-dune-variable-quantitative}}

\begin{bloc_objectif}

De nombreuses méthodes statistiques qui seront abordées dans les chapitres suivants -- entre autres, la corrélation de Pearson, les test \emph{t} et l'analyse de variance, les régressions simple et multiple -- requièrent que la variable quantitative suive une \textbf{distribution normale} (nommée aussi \textbf{distribution gaussienne}).

Dans cette sous-section, nous décrirons trois démarches pour vérifier si la distribution d'une variable est normale : les coefficients d'asymétrie et d'applatissement (\emph{skewness} et \emph{kurtosis} en anglais), les graphiques (histogramme avec courbe normale, diagramme quantile-quantile), les tests de normalité (tests de Shapiro-Wilk, Kolmogorov-Smirnov, Lilliefors, Anderson-Darling et Jarque-Bera).

\textbf{Il est vivement recommandé de réaliser les trois démarches !}

\end{bloc_objectif}

Une distribution est normale quand elle est symétrique et mésokurtique (figure \ref{fig:figFormeDistr}).

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{images/univariee/FormeDistribution} 

}

\caption{Formes d'une distribution et les coefficients d'asymétrie et d'aplatissement}\label{fig:figFormeDistr}
\end{figure}

\hypertarget{vuxe9rifier-la-normalituxe9-avec-les-coefficients-dasymuxe9trie-et-dapplatissement}{%
\paragraph{Vérifier la normalité avec les coefficients d'asymétrie et d'applatissement}\label{vuxe9rifier-la-normalituxe9-avec-les-coefficients-dasymuxe9trie-et-dapplatissement}}

\textbf{Une distribution est dite symétrique} quand la moyenne arithmétique est au centre de la distribution, c'est-à-dire que les observations sont bien réparties de part et d'autre de la moyenne qui sera alors égale à la médiane et au mode (on utilisera uniquement le mode pour une variable discrète et non pour une variable continue). Pour évaluer l'asymétrie, on utilise habituellement le coefficient d'asymétrie (\emph{skewness} en anglais).

Sachez toutefois qu'il existe trois façons (formules) pour le calculer \citep{joanes1998comparing} : \(g_1\) est la formule classique (eq. \eqref{eq:SkewType1}, disponible dans R avec la fonction \texttt{skewness} du \emph{package} \textbf{moments}), \(G_1\) est une version ajustée (eq. \eqref{eq:SkewType2}, utilisée dans les logiciels SAS et SPSS notamment) et \(b_1\) est une autre version ajustée (eq. \eqref{eq:SkewType3}, utilisée par les logiciels MINITAB et BMDP). Nous verrons qu'avec les \emph{packages} \textbf{DescTools} ou \textbf{e1071}, il possible de calculer ces trois méthodes. Aussi, pour des grands échantillons (\(n>100\)), il y a très peu de différences entre les résultats produits par ces trois formules \citep{joanes1998comparing}. Quelle que soit la formule utilisée, le coefficient d'assymétrie s'interprète comme suit (figure \ref{fig:asymetrie}) :

\begin{itemize}
\tightlist
\item
  quand la valeur du \emph{skewness} est négative, la \textbf{distribution est asymétrique négative}. La distribution est alors tirée à gauche par des valeurs extrêmes faibles, mais peu nombreuses. On emploie souvent l'expression \emph{la queue de distribution} est étirée vers la gauche. La moyenne est alors inférieure à la médiane.
\item
  quand la valeur du \emph{skewness} est égale à 0, \textbf{la distribution est symétrique} (la médiane sera égale à la moyenne). Pour une variable discrète, les valeurs du mode, de la moyenne et de la médiane seront égales.
\item
  quand la valeur du \emph{skewness} est positive, la \textbf{distribution est symétrique positive}. La distribution est alors tirée à droite par des valeurs extrêmes fortes, mais peu nombreuses. La queue de distribution est alors étirée vers la droite. La moyenne est alors supérieure à la médiane. En sciences sociales, les variables de revenu (totaux ou d'emploi, des individus ou des ménages) ont souvent des distributions asymétriques positives : la moyenne est affectée par quelques observations avec des valeurs de revenu très élevées et est ainsi supérieure à la médiane. En études urbaines, la densité de population pour des unités géographiques d'une métropole donnée (secteur de recensement par exemple) a aussi souvent une distribution asymétrique positive : quelques secteurs de recensement au centre de la métropole sont caractérisés par des valeurs de densité très élevées qui tirent la distribution vers la droite.
\end{itemize}

\begin{equation} 
g_1=\frac{ \frac{1}{n} \sum_{i=1}^n(x_i-\bar{x})^3} { \left[\frac{1}{n}\sum_{i=1}^n(x_i-\bar{x})^2\right] ^\frac{3}{2}}
\label{eq:SkewType1}
\end{equation}

\begin{equation} 
G_1= \frac{\sqrt{n(n-1)}}{n-2} g_1
\label{eq:SkewType2}
\end{equation}

\begin{equation} 
b_1= \left( \frac{n-1}{n} \right) ^\frac{3}{2} g_1
\label{eq:SkewType3}
\end{equation}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/asymetrie-1} 

}

\caption{Asymétrie d'une distribution}\label{fig:asymetrie}
\end{figure}

\textbf{Pour évaluer l'applatissement d'une distribution}, on utilisera le coefficient d'aplatissement (\emph{kurtosis} en anglais). Là encore, il existe trois formules pour le calculer (eq. \eqref{eq:KurtType1}, \eqref{eq:KurtType2}, \eqref{eq:KurtType3}) qui renverront des valeurs très sembables pour de grands échantillons \citep{joanes1998comparing}. Cette mesure s'interprète comme suit (figure \ref{fig:asymetrie}) :

\begin{itemize}
\tightlist
\item
  quand la valeur du \emph{kurtosis} est négative, la \textbf{distribution est platikurtique}. La distribution est dite plate, c'est-à-dire que la valeur de l'écart-type est importante (comparativement à une distribution normale), signalant une grande dispersion des valeurs de part et d'autre la moyenne.
\item
  quand la valeur du \emph{kurtosis} est égale à 0, \textbf{la distribution est mésokurtique}, ce qui est typique d'une distribution normale.
\item
  quand la valeur du \emph{kurtosis} est positive, la \textbf{distribution est leptokurtique}, signalant que l'écart-type (la dispersion des valeurs) est plutôt faible. Autrement dit, la dispersion des valeurs autour de la moyenne est faible.
\end{itemize}

\begin{equation} 
g_2=\frac{\frac{1}{n}\sum_{i=1}^n(x_i-\bar{x})^4} {\left( \frac{1}{n}\sum_{i=1}^n(x_i-\bar{x})^2\right)^2}-3
\label{eq:KurtType1}
\end{equation}

\begin{equation} 
G_2 = \frac{n-1}{(n-2)(n-3)} \{(n+1) g_2 + 6\}
\label{eq:KurtType2}
\end{equation}

\begin{equation} 
b_2 = (g_2 + 3) (1 - 1/n)^2 - 3
\label{eq:KurtType3}
\end{equation}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/kurtosis-1} 

}

\caption{Applatissement d'une distribution}\label{fig:kurtosis}
\end{figure}

\begin{bloc_attention}

Regardez attentivement les équations \eqref{eq:KurtType1}, \eqref{eq:KurtType2}, \eqref{eq:KurtType3}; vous remarquez que pour \(g_2\) et \(b_2\), il y a une soustraction de \(-3\) et une addition \(+6\) pour \(G_2\). On parle alors de \emph{kurtosis} normalisé (\emph{excess kurtosis} en anglais). Pour une distribution normale, il prendra la valeur de 0, comparativement à la valeur de 3 pour un \emph{kurtosis} non normalisé. Par conséquent, avant de calculer du \emph{kurtosis}, il convient de s'assurer que la fonction que vous utilisez implémente une méthode de calcul normalisée (donnant une valeur de 0 pour une distribution normale). Par exemple, la fonction \texttt{Kurt} du \emph{package} \textbf{DescTools} calcule les trois formules normalisées tandis que la fonction \texttt{kurtosis} du \emph{package} \textbf{moments} renvoie un \emph{kurtosis} non normalisé.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(DescTools)}
\KeywordTok{library}\NormalTok{(moments)}
\CommentTok{#Générer une variable normalement distribuée avec 1000 observations}
\NormalTok{Normale <-}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{1500}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{)}
\KeywordTok{round}\NormalTok{(DescTools}\OperatorTok{::}\KeywordTok{Kurt}\NormalTok{(Normale),}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -0.122
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{round}\NormalTok{(moments}\OperatorTok{::}\KeywordTok{kurtosis}\NormalTok{(Normale),}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.882
\end{verbatim}

\end{bloc_attention}

\hypertarget{vuxe9rifier-la-normalituxe9-avec-des-graphiques}{%
\paragraph{Vérifier la normalité avec des graphiques}\label{vuxe9rifier-la-normalituxe9-avec-des-graphiques}}

Les graphiques sont un excellent moyen de vérifier visuellement si une distribution est normale ou pas. Bien entendu, les histogrammes, que nous avons déjà largement utilisés, sont un incontournable; à titre de rappel, ils permettent de représenter la forme de la distribution des données (figure \ref{fig:CourbeNormale}). Un autre type de graphique intéressant est le \textbf{diagramme quantile-quantile} (\emph{Q-Q plot} en anglais) qui permet de comparer la distribution d'une variable avec une distribution gaussienne (normale). Trois éléments composent ce graphique tel qu'illustré à la figure \ref{fig:qqplot} :

\begin{itemize}
\tightlist
\item
  les points, représentant les observations de la variable
\item
  la distribution gaussienne (normale), représentée par une ligne
\item
  l'intervalle de confiance à 5\% de la distribution normale (en orange sur la figure).
\end{itemize}

Quand la variable est normale distribuée, les points seront situés le long de la ligne. Plus les points localisés en dehors de l'intervalle de confiance (bande orange) seront nombreux, plus la variable sera alors anormalement distribuée.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/CourbeNormale-1} 

}

\caption{Distributions et courbe normale}\label{fig:CourbeNormale}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/qqplot-1} 

}

\caption{Diagrammes quantile-quantile}\label{fig:qqplot}
\end{figure}

\hypertarget{sect025413}{%
\paragraph{Vérifier la normalité avec des tests de normalité}\label{sect025413}}

Cinq principaux tests d'hypothèse permettent de vérifier la normalité d'une variable : les tests de \textbf{Kolmogorov-Smirnov} (KS), \textbf{Lilliefors} (LF), \textbf{Shapiro-Wilk} (SW), \textbf{Anderson-Darling}, et de \textbf{Jarque-Bera} (JB); sachez toutefois qu'il y en a d'autres non discutés ici (tests de D'Agostino--Pearson, Cramer--von Mises, de Ryan-Joiner, Shapiro--Francia, etc.). Pour les formules et une description détaillée de ces tests, vous pouvez consulter Razali et al.~\citeyearpar{razali2011power} ou Yap et Sim \citeyearpar{yap2011comparisons}. \textbf{Quel test choisir ?} Plusieurs auteurs ont comparé ces différents tests à partir de plusieurs échantillons, et ce, en faisant varier la forme de la distribution et le nombre d'observations \citep{razali2011power, yap2011comparisons}. Selon Razali et al.~\citeyearpar{razali2011power}, le meilleur test semble être celui de Shapiro-Wilk, puis ceux de Anderson-Darling, Lilliefors et Kolmogorov-Smirnov. Yap et Sim \citeyearpar{yap2011comparisons} concluent aussi que le Shapiro-Wilk semble être le plus performant.

Quoi qu'il en soit, ces cinq tests postulent que la variable suit une distribution gaussienne (hypothèse nulle, h0). Cela signifie que si la valeur de P associée à la valeur de chacun des tests est supérieure au seuil alpha choisi (habituellement \(\alpha=0,05\)), la distribution est normale. À l'inverse, si \(P<0,05\), on choisit l'hypothèse alternative (h1), c'est-à-dire que la distribution est anormale.

\begin{table}

\caption{\label{tab:testnormalites}Les différents tests d'hypothèse pour la normalité}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{l>{\raggedright\arraybackslash}p{6cm}>{\raggedright\arraybackslash}p{6cm}}
\toprule
Test & Propriétés et interprétation & Fonction R\\
\midrule
Kolmogorov-Smirnov & Plus sa valeur est proche de zéro, plus la distribution est normale.  L'avantage de ce test est qu'il peut être utilisé pour vérifier si une variable suit la distribution de n'importe quelle loi (autre que la loi normale). & `ks.test` du *package* **stats**\\
Lilliefors & Ce test est une adaptation du test de Kolmogorov-Smirnov. Plus sa valeur est proche de zéro, plus la distribution est normale. & `lillie.test` du *package* **nortest**\\
Shapiro-Wilk & Si la valeur de la statistique de Shapiro-Wilk est proche de 1, alors la distribution est normale; et anormale quand elle est inférieure à 1. & `shapiro.test` du *package* **stats**\\
Anderson-Darling & Ce test est une modification du test de Cramer-von Mises (CVM). Il peut être aussi utilisé pour tester d'autres distributions (uniforme, log-normale, exponentielle, Weibull, distribution de pareto généralisée, logistique, etc.). & `ad.test` du *package* **stats**\\
Jarque-Bera & Basé sur un test du type multiplicateur de Lagrange, il utilise dans son calcul les valeurs du *Skewness* et du *Kurtosis*. Plus sa valeur s'approche de 0, plus la distribution est normale. Ce test est surtout utilisé pour vérifier si les résidus d'un modèle de régression linéaire sont normalement distribués, nous y reviendrons dans le chapitre sur la régression multiple. Il s'écrit \$JB=\textbackslash{}frac\{1\}\{6\} \textbackslash{}left(\{g\_1\}\textasciicircum{}2+\textbackslash{}frac\{\{g\_1\}\textasciicircum{}2\}\{4\} \textbackslash{}right)\$ avec \$g\_1\$ et \$g\_2\$ qui sont respectivement les valeurs du *skewness* et du *kurtosis* de la variable (voir plus haut les équations \textbackslash{}@ref(eq:SkewType1) et \textbackslash{}@ref(eq:KurtType1). & `JarqueBeraTest` du *package* **DescTools**\\
\bottomrule
\end{tabular}
\end{table}

Dans le tableau ci-dessous sont reportées les valeurs des différents tests pour les cinq types de distribution générées à la figure \ref{fig:CourbeNormale}. Sans surprise, pour l'ensemble des tests, la valeur de \emph{P} est inférieur à 0,05 pour la distribution normale.

\begin{table}

\caption{\label{tab:calcultestnormalites}Calculs des tests de normalité pour différentes distributions}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{lrrrrr}
\toprule
  & Normale & Asymétrie négative & Asymétrie positive & Leptokurtique & Platikurtique\\
\midrule
Skewness & 0,113 & 1,148 & -1,427 & -0,529 & 0,032\\
Kurtosis & -0,015 & 1,159 & 3,414 & 8,784 & -1,008\\
Kolmogorov-Smirnov (KS) & 0,032 & 0,103 & 0,093 & 0,109 & 0,061\\
Lilliefors (LF) & 0,032 & 0,103 & 0,093 & 0,109 & 0,061\\
Shapiro-Wilk (SW) & 0,998 & 0,911 & 0,902 & 0,897 & 0,971\\
\addlinespace
Anderson-Darling (AD) & 0,221 & 11,856 & 9,317 & 11,721 & 2,928\\
Jarque-Bera (JB) & 1,108 & 186,519 & 479,923 & 3 987,901 & 16,089\\
KS (valeur p) & 0,690 & 0,000 & 0,000 & 0,000 & 0,048\\
LF (valeur p) & 0,250 & 0,000 & 0,000 & 0,000 & 0,000\\
SW (valeur p) & 0,714 & 0,000 & 0,000 & 0,000 & 0,000\\
\addlinespace
AD (valeur p) & 0,831 & 0,000 & 0,000 & 0,000 & 0,000\\
JB (valeur p) & 0,575 & 0,000 & 0,000 & 0,000 & 0,000\\
\bottomrule
\end{tabular}
\end{table}

\begin{bloc_attention}

\textbf{Attention} ! La plupart des auteurs s'entendent sur le fait que ces tests sont très restrictifs : plus la taille de votre échantillon (\(n\)) est importante, plus les tests risquent de vous signaler que vos distributions sont anormales (à la lecture des valeurs de P).

Certains conseillent même de ne pas les utiliser quand \(n>200\) et de vous fier uniquement aux graphiques (histogramme et diagramme Q-Q) !

\end{bloc_attention}

\begin{bloc_astuce}

Bref, vérifier la normalité d'une variable n'est pas une tâche si simple. De nouveau, nous vous conseillons vivement de :

\begin{itemize}
\tightlist
\item
  construire les graphiques pour analyser visuellement la forme de la distribution (histogramme avec courbe normale et diagramme Q-Q)
\item
  calculer le \emph{skewness} et le \emph{kurtosis},
\item
  calculer plusieurs tests (minimalement Shapiro-Wilk et Kolmogorov-Smirnov)
\item
  accorder une importance particulière aux graphiques lorsque vous traitez des grands échantillons (\(n>200\)).
\end{itemize}

\end{bloc_astuce}

\hypertarget{vuxe9rifier-dautres-formes-de-distributions}{%
\subsubsection{Vérifier d'autres formes de distributions}\label{vuxe9rifier-dautres-formes-de-distributions}}

Comme nous l'avons vu, la distribution normale n'est que l'une des multiples distributions existantes. Dans de nombreuses situations, elle ne sera pas adaptée pour décrire vos variables. La démarche à adopter pour trouver une distribution adaptée est la suivante :

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Définissez la nature de votre variable, identifier si elle est discrète ou continue et l'intervalle dans lequel elle est définie. Une variable dont les valeurs sont positives ou négatives ne pourra pas être décrite avec une distribution Gamma par exemple (à moins de la décaler).
\item
  Explorez votre variable, affichez son histogramme et son graphique de densité pour avoir une vue générale de sa morphologie.
\item
  Présélectionnez un ensemble de distributions candidates compte tenu des observations précédentes. Vous pouvez également vous reporter à la littérature existante sur votre sujet d'étude pour inclure d'autres distributions. Soyez flexible ! Une variable strictement positive pourrait tout de même avoir une forme normale. De même, une variable décrivant des comptages suffisamment grands pourrait être mieux décrite par une distribution normale qu'une distribution de poisson.
\item
  Tentez d'ajuster chacune des distributions retenues à vos données et comparez les qualités d'ajustements pour retenir la plus adaptée.
\end{enumerate}

Pour ajuster une distribution à un jeu de données, il faut trouver les valeurs des paramètres de cette distribution qui lui permettront d'adopter une forme la plus proche possible des données. On appelle cette opération \textbf{ajuster un modèle}, puisque la distribution théorique est utilisée pour modéliser les données. L'ajustement des paramètres est un problème d'optimisation que plusieurs algorithmes sont capables de résoudre (\emph{gradient descent}, \emph{Newton-Raphson method}, \emph{Fisher scoring}, etc.). Dans R, le \emph{package} \textbf{fitdistrplus} permet d'ajuster pratiquement n'importe quelle distribution à des données en offrant plusieurs stratégies d'optimisation grâce à la fonction \texttt{fitdist}. Il suffit de disposer d'une fonction représentant la distribution de densité ou de masse de la distribution en question, généralement noté \texttt{dnomdeladistribution} (\texttt{dnorm}, \texttt{dgamma}, \texttt{dpoisson}, etc.) dans R. Notez que certains \emph{packages} comme \textbf{VGAM} ou \textbf{gamlss.dist} ajoutent un grand nombre de fonctions de densité et de masse à celles déjà disponibles de base dans R.

Pour comparer l'ajustement de plusieurs distributions théoriques à des données, trois approches doivent être combinées :

\begin{itemize}
\tightlist
\item
  Observer graphiquement l'ajustement de la courbe théorique à l'histogramme des données. Cela permet d'éliminer au premier coup d'œil les distributions qui ne correspondent pas.
\item
  Comparer les \emph{loglikelihood}. Le \emph{loglikelihood} est un score d'ajustement des distributions aux données. Pour faire simple, plus le \emph{loglikelihood} est grand, plus la distribution théorique est proche des données. Référez-vous à l'encadré suivant pour une description plus en profondeur du \emph{loglikelihood}.
\item
  Utiliser le test de Kolmogorov-Smirnov pour déterminer si une distribution particulière est mieux ajustée pour les données.
\end{itemize}

\begin{bloc_aller_loin}

\textbf{Qu'est-ce-que le loglikelihood} ?

Le \emph{loglikelihood} est une mesure de l'ajustement d'un modèle à des données. Il est utilisé à peu près partout en statistique. Comprendre sa signification est donc un exercice important pour développer une meilleure intuition du fonctionnement général de nombreuses méthodes. Si les concepts de fonction de densité et de fonction de masse vous semblent encore flous, reportez-vous à la section \ref{sect024} sur les distributions dans un premier temps.

Admettons que nous disposons d'une variable continue \emph{v} que nous avons tenté de modéliser avec une distribution \emph{d} (il peut s'agir de n'importe quelle distribution). \emph{d} a une fonction de densité avec laquelle il est possible de calculer pour chacune des valeurs de \emph{v} sa probabilité d'être observée selon le modèle \emph{d}.

Prenons un exemple concret dans R. Admettons que nous avons une variable comprenant 10 valeurs (oui, c'est un petit échantillon, mais c'est pour faire un exemple simple).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{v <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{,}\DecValTok{8}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{8}\NormalTok{,}\DecValTok{10}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{9}\NormalTok{,}\DecValTok{7}\NormalTok{)}
\NormalTok{moyenne <-}\StringTok{ }\KeywordTok{mean}\NormalTok{(v)}
\NormalTok{ecart_type <-}\StringTok{ }\KeywordTok{sd}\NormalTok{(v)}
\end{Highlighting}
\end{Shaded}

En calculant sa moyenne et son écart type, nous obtenons les paramètres d'une distribution normale que nous pouvons utiliser pour représenter les données observées. En utilisant la fonction \texttt{dnorm} (la fonction de densité de la distribution normale), nous pouvons calculer la probabilité d'observer chacune des valeurs de \emph{v} selon cette distribution normale.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{probas <-}\StringTok{ }\KeywordTok{dnorm}\NormalTok{(v, moyenne, ecart_type)}
\NormalTok{df <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{valeur =}\NormalTok{ v,}
                 \DataTypeTok{proba =}\NormalTok{ probas)}
\KeywordTok{print}\NormalTok{(df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    valeur      proba
## 1       5 0.11203710
## 2       8 0.19624888
## 3       7 0.22228296
## 4       8 0.19624888
## 5      10 0.06009897
## 6       4 0.04985613
## 7       7 0.22228296
## 8       6 0.18439864
## 9       9 0.12689976
## 10      7 0.22228296
\end{verbatim}

On observe ainsi que les valeurs 7 et 8 sont très probables selon le modèle alors que la valeur 10 est très improbable.

Le \emph{likelihood} est simplement le produit de toutes ces probabilités. Il s'agit donc de \textbf{la probabilité conjointe} d'avoir observé toutes les valeurs de \emph{v} \textbf{sous l'hypothèse} que \emph{d} est la distribution produisant ces valeurs. Si \emph{d} décrit efficacement \emph{v}, alors le \emph{likelihood} est plus grand que si \emph{d} ne décrit pas efficacement \emph{v}. Il s'agit d'une forme de raisonnement par l'absurde : après avoir observé \emph{v}, on calcule la probabilité d'avoir observé \emph{v} (\emph{likelihood}) si notre modèle \emph{d} était vrai. Si cette probabilité est très basse, alors c'est que notre modèle est mauvais puisqu'on a bien observé \emph{v}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{likelihood_norm <-}\StringTok{ }\KeywordTok{prod}\NormalTok{(probas)}
\KeywordTok{print}\NormalTok{(likelihood_norm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.322759e-09
\end{verbatim}

Cependant, multiplier un grand nombre de valeurs inférieures à zéro tend à produire des chiffres infiniment petits et donc à complexifier grandement le calcul. On préfère donc utiliser le \emph{loglikelihood}. L'idée étant transformer les probabilités obtenues avec la fonction \emph{log} puis d'additionner leurs résultats, puisque \(log(xy) = log(x)+log(y)\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{loglikelihood_norm <-}\StringTok{ }\KeywordTok{sum}\NormalTok{(}\KeywordTok{log}\NormalTok{(probas))}
\KeywordTok{print}\NormalTok{(loglikelihood_norm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -19.52247
\end{verbatim}

Comparons ce \emph{loglikelihood} a celui d'un second modèle dans lequel nous utilisons toujours la distribution normale, mais avec une moyenne différente (faussée en rajoutant +3) :

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{probas2 <-}\StringTok{ }\KeywordTok{dnorm}\NormalTok{(v, moyenne}\OperatorTok{+}\DecValTok{3}\NormalTok{, ecart_type)}
\NormalTok{loglikelihood_norm2 <-}\StringTok{ }\KeywordTok{sum}\NormalTok{(}\KeywordTok{log}\NormalTok{(probas2))}
\KeywordTok{print}\NormalTok{(loglikelihood_norm2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -33.53631
\end{verbatim}

Ce second \emph{loglikehood} est plus faible, indiquant clairement que le premier modèle est plus adapté aux données.

\end{bloc_aller_loin}

Passons à la pratique avec deux exemples.

\hypertarget{temps-de-retard-des-bus-de-la-ville-de-toronto}{%
\paragraph{Temps de retard des bus de la ville de Toronto}\label{temps-de-retard-des-bus-de-la-ville-de-toronto}}

Analysons les temps de retard pris par les bus de la ville de Toronto lorsqu'un évènement perturbe la circulation. Ce jeu de données est disponible sur le site de l'\href{https://open.toronto.ca/catalogue/?search=bus\%20delay\&sort=score\%20desc}{Open Data} de la ville de Toronto. Compte tenu de la grande quantité d'observations, nous avons fait le choix de nous concentrer sur les évènements ayant eu lieu durant le mois de janvier 2019. Puisque la variable étudiée est une durée exprimée en minutes, elle est strictement positive (supérieure à 0), car un bus avec zéro minute de retard est à l'heure. Nous considérons également qu'un bus ayant plus de 150 minutes de retard (2h30) n'est tout simplement pas passé (personne ne risque d'attendre 2h30 pour prendre son bus). Commençons par charger les données et observer leur distribution empirique.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ggplot2)}
\CommentTok{# charger le jeu de données}
\NormalTok{data_trt_bus <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{'data/univariee/bus-delay-2019_janv.csv'}\NormalTok{, }\DataTypeTok{sep =}\StringTok{';'}\NormalTok{)}
\CommentTok{# retirer les observations aberrantes}
\NormalTok{data_trt_bus <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(data_trt_bus, data_trt_bus}\OperatorTok{$}\NormalTok{Min.Delay }\OperatorTok{>}\StringTok{ }\DecValTok{0} \OperatorTok{&}
\StringTok{                         }\NormalTok{data_trt_bus}\OperatorTok{$}\NormalTok{Min.Delay }\OperatorTok{<}\StringTok{ }\DecValTok{150}\NormalTok{)}
\CommentTok{# représenter la distribution empirique du jeu de données}
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ data_trt_bus) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{Min.Delay, }\DataTypeTok{y =}\NormalTok{ ..density..), }\DataTypeTok{bins =} \DecValTok{40}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_density}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{Min.Delay), }\DataTypeTok{color =} \StringTok{'blue'}\NormalTok{, }\DataTypeTok{bw =} \DecValTok{2}\NormalTok{, }\DataTypeTok{size =} \FloatTok{0.8}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{'temps de retard (min)'}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{''}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/figbustrt-1} 

}

\caption{Distribution empirique des temps de retard des bus à Toronto en janvier 2019}\label{fig:figbustrt}
\end{figure}

Compte tenu de la forme de la distribution empirique et de sa nature, quatre distributions sont envisageables :

\begin{itemize}
\tightlist
\item
  La distribution Gamma, strictement positive et asymétrique, elle est aussi une généralisation de la distribution exponentielle utilisée pour modéliser des temps d'attente. Pour des raisons similaires, on peut aussi retenir la distribution de Weibull et la distribution log-normale. Nous écartons ici la distribution skew-normale puisque le jeu de données n'a clairement pas une forme normale au départ.
\item
  La distribution de Pareto, strictement positive et permettant de représenter ici le fait que la plupart des retards durent moins de 10 minutes, mais que quelques retards sont également beaucoup plus longs.
\end{itemize}

Commençons par ajuster les quatre distributions avec la fonction \texttt{fitdist} du \emph{package} \textbf{fitdistrplus} et représentons-les graphiquements pour éliminer les moins bons candidats. Nous utilisons également le \emph{package} \textbf{actuar} pour la fonction de densité de Pareto (\texttt{dpareto}).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(fitdistrplus)}
\KeywordTok{library}\NormalTok{(actuar)}
\KeywordTok{library}\NormalTok{(ggpubr)}
\CommentTok{# ajustement des modèles}
\NormalTok{model_gamma <-}\StringTok{ }\KeywordTok{fitdist}\NormalTok{(data_trt_bus}\OperatorTok{$}\NormalTok{Min.Delay, }\DataTypeTok{distr =} \StringTok{"gamma"}\NormalTok{)}
\NormalTok{model_weibull <-}\StringTok{ }\KeywordTok{fitdist}\NormalTok{(data_trt_bus}\OperatorTok{$}\NormalTok{Min.Delay, }\DataTypeTok{distr =} \StringTok{"weibull"}\NormalTok{)}
\NormalTok{model_lognorm <-}\StringTok{ }\KeywordTok{fitdist}\NormalTok{(data_trt_bus}\OperatorTok{$}\NormalTok{Min.Delay, }\DataTypeTok{distr =} \StringTok{"lnorm"}\NormalTok{)}
\NormalTok{model_pareto <-}\StringTok{ }\KeywordTok{fitdist}\NormalTok{(data_trt_bus}\OperatorTok{$}\NormalTok{Min.Delay, }\DataTypeTok{distr =} \StringTok{"pareto"}\NormalTok{, }
                        \DataTypeTok{start =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{shape =} \DecValTok{1}\NormalTok{, }\DataTypeTok{scale =} \DecValTok{1}\NormalTok{),}
                        \DataTypeTok{method =} \StringTok{"mse"}\NormalTok{) }\CommentTok{# différentes méthodes d'optimisations}
\CommentTok{# réalisation des graphiques}
\NormalTok{plot1 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ data_trt_bus) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{Min.Delay, }\DataTypeTok{y =}\NormalTok{ ..density..), }\DataTypeTok{bins =} \DecValTok{40}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{stat_function}\NormalTok{(}\DataTypeTok{fun =}\NormalTok{ dgamma, }\DataTypeTok{color =} \StringTok{'red'}\NormalTok{, }\DataTypeTok{size =} \FloatTok{0.8}\NormalTok{, }
                \DataTypeTok{args =} \KeywordTok{as.list}\NormalTok{(model_gamma}\OperatorTok{$}\NormalTok{estimate))}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{'temps de retard (min)'}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{''}\NormalTok{,}
       \DataTypeTok{subtitle =} \StringTok{"modèle Gamma"}\NormalTok{)}
\NormalTok{plot2 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ data_trt_bus) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{Min.Delay, }\DataTypeTok{y =}\NormalTok{ ..density..), }\DataTypeTok{bins =} \DecValTok{40}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{stat_function}\NormalTok{(}\DataTypeTok{fun =}\NormalTok{ dweibull, }\DataTypeTok{color =} \StringTok{'red'}\NormalTok{, }\DataTypeTok{size =} \FloatTok{0.8}\NormalTok{, }
                \DataTypeTok{args =} \KeywordTok{as.list}\NormalTok{(model_weibull}\OperatorTok{$}\NormalTok{estimate))}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{'temps de retard (min)'}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{''}\NormalTok{,}
       \DataTypeTok{subtitle =} \StringTok{"modèle Weibull"}\NormalTok{)}
\NormalTok{plot3 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ data_trt_bus) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{Min.Delay, }\DataTypeTok{y =}\NormalTok{ ..density..), }\DataTypeTok{bins =} \DecValTok{40}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{stat_function}\NormalTok{(}\DataTypeTok{fun =}\NormalTok{ dlnorm, }\DataTypeTok{color =} \StringTok{'red'}\NormalTok{, }\DataTypeTok{size =} \FloatTok{0.8}\NormalTok{, }
                \DataTypeTok{args =} \KeywordTok{as.list}\NormalTok{(model_lognorm}\OperatorTok{$}\NormalTok{estimate))}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{'temps de retard (min)'}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{''}\NormalTok{,}
       \DataTypeTok{subtitle =} \StringTok{"modèle log-normal"}\NormalTok{)}
\NormalTok{plot4 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ data_trt_bus) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{Min.Delay, }\DataTypeTok{y =}\NormalTok{ ..density..), }\DataTypeTok{bins =} \DecValTok{40}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{stat_function}\NormalTok{(}\DataTypeTok{fun =}\NormalTok{ dpareto, }\DataTypeTok{color =} \StringTok{'red'}\NormalTok{, }\DataTypeTok{size =} \FloatTok{0.8}\NormalTok{, }
                \DataTypeTok{args =} \KeywordTok{as.list}\NormalTok{(model_pareto}\OperatorTok{$}\NormalTok{estimate))}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{'temps de retard (min)'}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{''}\NormalTok{,}
       \DataTypeTok{subtitle =} \StringTok{"Modèle Pareto"}\NormalTok{)}
\KeywordTok{ggarrange}\NormalTok{(}\DataTypeTok{plotlist =} \KeywordTok{list}\NormalTok{(plot1, plot2, plot3, plot4),}
          \DataTypeTok{ncol =} \DecValTok{2}\NormalTok{, }\DataTypeTok{nrow =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/figbustrt2-1} 

}

\caption{Comparaison des distributions ajustées aux données de retard des bus}\label{fig:figbustrt2}
\end{figure}

Visuellement, on constate que la distribution de Pareto est un mauvais choix. Pour les trois autres distributions, la comparaison des \emph{loglikelihood} s'impose.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{model =} \KeywordTok{c}\NormalTok{(}\StringTok{"Gamma"}\NormalTok{,}\StringTok{"Weibull"}\NormalTok{,}
                           \StringTok{"log-normal"}\NormalTok{), }
                 \DataTypeTok{loglikelihood =} \KeywordTok{c}\NormalTok{(model_gamma}\OperatorTok{$}\NormalTok{loglik, }
\NormalTok{                 model_weibull}\OperatorTok{$}\NormalTok{loglik,}
\NormalTok{                 model_lognorm}\OperatorTok{$}\NormalTok{loglik))}
\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
\NormalTok{  df, }\DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
  \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{"Distributon"}\NormalTok{,}\StringTok{"LogLikelihood"}\NormalTok{),}
  \DataTypeTok{caption =} \StringTok{'Comparaison des LogLikekelihood des trois distributions'}\NormalTok{,}
  \DataTypeTok{escape =} \OtherTok{FALSE}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{kableExtra}\OperatorTok{::}\KeywordTok{kable_styling}\NormalTok{(}\DataTypeTok{font_size =} \DecValTok{8}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:tabledistribs}Comparaison des LogLikekelihood des trois distributions}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{lr}
\toprule
Distributon & LogLikelihood\\
\midrule
Gamma & -23062.56\\
Weibull & -23195.54\\
log-normal & -23375.74\\
\bottomrule
\end{tabular}
\end{table}

Le plus grand \emph{logLikelihood} est obtenu par la distribution de Gamma qui s'ajuste donc le mieux à nos données. Pour finir, nous pouvons tester formellement avec le test de Kolmogorov-Smirnov si nos données proviennent bien de cette distribution de Gamma.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{params <-}\StringTok{ }\KeywordTok{as.list}\NormalTok{(model_gamma}\OperatorTok{$}\NormalTok{estimate)}
\KeywordTok{ks.test}\NormalTok{(data_trt_bus}\OperatorTok{$}\NormalTok{Min.Delay,}
        \DataTypeTok{y =}\NormalTok{ pgamma, }\DataTypeTok{shape =}\NormalTok{ params}\OperatorTok{$}\NormalTok{shape, }\DataTypeTok{rate =}\NormalTok{ params}\OperatorTok{$}\NormalTok{rate)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 	One-sample Kolmogorov-Smirnov test
## 
## data:  data_trt_bus$Min.Delay
## D = 0.099912, p-value < 2.2e-16
## alternative hypothesis: two-sided
\end{verbatim}

La valeur de \emph{p} est inférieure à 0,05, on ne peut donc pas accepter l'hypothèse que notre jeu de données suit effectivement un loi de Gamma. Considérant le nombre d'observations et le fait que de nombreux temps d'attente sont identiques (ce à quoi le test est très sensible), ce résultat n'est pas surprenant. La distribution de Gamma reste cependant la distribution qui représente le mieux nos données. Nous pouvons estimer grâce à cette distribution la probabilité qu'un bus ait un retard de plus de 10 minutes de la façon suivante :

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pgamma}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DataTypeTok{shape =}\NormalTok{ params}\OperatorTok{$}\NormalTok{shape, }\DataTypeTok{rate =}\NormalTok{ params}\OperatorTok{$}\NormalTok{rate, }\DataTypeTok{lower.tail =}\NormalTok{ F)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.5409424
\end{verbatim}

ce qui correspond à 54\% de chance.

Pour moins de 10 minutes :

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pgamma}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DataTypeTok{shape =}\NormalTok{ params}\OperatorTok{$}\NormalTok{shape, }\DataTypeTok{rate =}\NormalTok{ params}\OperatorTok{$}\NormalTok{rate, }\DataTypeTok{lower.tail =}\NormalTok{ T)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.4590576
\end{verbatim}

soit 46\%.

Uun dernier exemple avec la probabilité qu'un retard dépasse 45 minutes :

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pgamma}\NormalTok{(}\DecValTok{45}\NormalTok{, }\DataTypeTok{shape =}\NormalTok{ params}\OperatorTok{$}\NormalTok{shape, }\DataTypeTok{rate =}\NormalTok{ params}\OperatorTok{$}\NormalTok{rate, }\DataTypeTok{lower.tail =}\NormalTok{ F)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.01348194
\end{verbatim}

Soit seulement 1,3\%.

Par conséquent, si un matin à Toronto votre bus a plus de 45 minutes de retard, bravo vous êtes tombé sur une des très rares occasions où un tel retard se produit

\hypertarget{les-accidents-de-vuxe9lo-uxe0-montruxe9al}{%
\paragraph{Les accidents de vélo à Montréal}\label{les-accidents-de-vuxe9lo-uxe0-montruxe9al}}

Le second jeu de données représente le nombre d'accidents de la route impliquant un vélo sur les intersections dans les quartiers centraux de Montréal. Le jeu de données complet est disponible sur le site des \href{http://donnees.ville.montreal.qc.ca/dataset/collisions-routieres}{données ouvertes} de la ville de Montréal. Puisque ces données correspondent à des comptages, la première distribution à envisager est la distribution de poisson. Cependant, puisque nous aurons également un grand nombre d'intersections sans accident, il serait judicieux de tester la distribution de poisson avec excès de zéro.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ggplot2)}
\CommentTok{# charger le jeu de données}
\NormalTok{data_accidents <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{'data/univariee/accidents_mtl.csv'}\NormalTok{, }\DataTypeTok{sep =}\StringTok{','}\NormalTok{)}
\NormalTok{counts <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\KeywordTok{table}\NormalTok{(data_accidents}\OperatorTok{$}\NormalTok{nb_accident))}
\KeywordTok{names}\NormalTok{(counts) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"nb_accident"}\NormalTok{,}\StringTok{'frequence'}\NormalTok{)}
\NormalTok{counts}\OperatorTok{$}\NormalTok{nb_accident <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(}\KeywordTok{as.character}\NormalTok{(counts}\OperatorTok{$}\NormalTok{nb_accident))}
\NormalTok{counts}\OperatorTok{$}\NormalTok{prop <-}\StringTok{ }\NormalTok{counts}\OperatorTok{$}\NormalTok{frequence }\OperatorTok{/}\StringTok{ }\KeywordTok{sum}\NormalTok{(counts}\OperatorTok{$}\NormalTok{frequence)}
\CommentTok{# représenter la distribution empirique du jeu de donnée}
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ counts) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{nb_accident, }\DataTypeTok{weight =}\NormalTok{ frequence), }\DataTypeTok{width =} \FloatTok{0.5}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"nombre d'accidents"}\NormalTok{,}
      \DataTypeTok{y =} \StringTok{'fréquence'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/figaccmtl-1} 

}

\caption{Distribution empirique du nombre d'accidents par intersection impliquant un cycliste à Montréal en 2017 dans les quartiers centraux}\label{fig:figaccmtl}
\end{figure}

Nous avons effectivement de nombreux zéros ici, essayons d'ajuster nos deux distributions à ce jeu de données. Dans le graphique suivant, les barres grises représentent la distribution empirique du jeu de données et les barres rouges les distributions théoriques ajustées. Nous utilisons ici le \emph{package} \textbf{gamlss.dist} pour avoir la fonction de masse d'une distribution de poisson avec excès de zéros.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(gamlss.dist)}
\CommentTok{#ajuster le modèle de poisson}
\NormalTok{model_poisson <-}\StringTok{ }\KeywordTok{fitdist}\NormalTok{(data_accidents}\OperatorTok{$}\NormalTok{nb_accident, }\DataTypeTok{distr =} \StringTok{"pois"}\NormalTok{)}
\CommentTok{#ajuster le modèle de poisson avec excès de zéros}
\NormalTok{model_poissonzi <-}\StringTok{ }\KeywordTok{fitdist}\NormalTok{(data_accidents}\OperatorTok{$}\NormalTok{nb_accident, }\StringTok{"ZIP"}\NormalTok{,}
    \DataTypeTok{start =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{mu =} \DecValTok{4}\NormalTok{, }\DataTypeTok{sigma =} \FloatTok{0.15}\NormalTok{), }\CommentTok{# valeurs pour faciliter la convergence}
    \DataTypeTok{optim.method =} \StringTok{"L-BFGS-B"}\NormalTok{, }\CommentTok{# méthode d'optimisation recommandée dans la doc}
    \DataTypeTok{lower =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.00001}\NormalTok{, }\FloatTok{0.00001}\NormalTok{),}\CommentTok{# valeurs minimales des deux paramètres}
    \DataTypeTok{upper =} \KeywordTok{c}\NormalTok{(}\OtherTok{Inf}\NormalTok{, }\DecValTok{1}\NormalTok{)}\CommentTok{# valeurs maximales des deux paramètres}
\NormalTok{    )}
\NormalTok{dfpoisson <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{x=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\OperatorTok{:}\DecValTok{10}\NormalTok{),}
                        \DataTypeTok{y=}\KeywordTok{dpois}\NormalTok{(}\DecValTok{0}\OperatorTok{:}\DecValTok{10}\NormalTok{, model_poisson}\OperatorTok{$}\NormalTok{estimate)}
\NormalTok{                        )}
\NormalTok{plot1 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{nb_accident, }\DataTypeTok{weight =}\NormalTok{ prop), }\DataTypeTok{width =} \FloatTok{0.6}\NormalTok{, }\DataTypeTok{data =}\NormalTok{ counts)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{x, }\DataTypeTok{weight =}\NormalTok{ y), }\DataTypeTok{width =} \FloatTok{0.15}\NormalTok{, }\DataTypeTok{data =}\NormalTok{ dfpoisson, }\DataTypeTok{fill =} \StringTok{"red"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_x_continuous}\NormalTok{(}\DataTypeTok{limits =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\FloatTok{0.5}\NormalTok{,}\DecValTok{7}\NormalTok{), }\DataTypeTok{breaks =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\OperatorTok{:}\DecValTok{7}\NormalTok{))}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{subtitle =} \StringTok{"modèle poisson"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"nombre d'accidents"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{""}\NormalTok{)}
\NormalTok{dfpoissonzi <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{x=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\OperatorTok{:}\DecValTok{10}\NormalTok{),}
                        \DataTypeTok{y=}\KeywordTok{dZIP}\NormalTok{(}\DecValTok{0}\OperatorTok{:}\DecValTok{10}\NormalTok{, model_poissonzi}\OperatorTok{$}\NormalTok{estimate[[}\DecValTok{1}\NormalTok{]],}
\NormalTok{                               model_poissonzi}\OperatorTok{$}\NormalTok{estimate[[}\DecValTok{2}\NormalTok{]])}
\NormalTok{                        )}
\NormalTok{plot2 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{nb_accident, }\DataTypeTok{weight =}\NormalTok{ prop), }\DataTypeTok{width =} \FloatTok{0.6}\NormalTok{, }\DataTypeTok{data =}\NormalTok{ counts)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{x, }\DataTypeTok{weight =}\NormalTok{ y), }\DataTypeTok{width =} \FloatTok{0.15}\NormalTok{, }\DataTypeTok{data =}\NormalTok{ dfpoissonzi, }\DataTypeTok{fill =} \StringTok{"red"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_x_continuous}\NormalTok{(}\DataTypeTok{limits =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\FloatTok{0.5}\NormalTok{,}\DecValTok{7}\NormalTok{), }\DataTypeTok{breaks =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\OperatorTok{:}\DecValTok{7}\NormalTok{))}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{subtitle =} \StringTok{"modèle poisson avec excès de zéro"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"nombre d'accident"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{""}\NormalTok{)}
\KeywordTok{ggarrange}\NormalTok{(}\DataTypeTok{plotlist =} \KeywordTok{list}\NormalTok{(plot1,plot2), }\DataTypeTok{ncol =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/figaccmtldist-1} 

}

\caption{Ajustement des distributions de poisson et poisson avec excès de zéros}\label{fig:figaccmtldist}
\end{figure}

Visuellement, le modèle avec excès de zéro semble s'imposer. Nous pouvons vérifier cette impression avec la comparaison des \emph{loglikelihood}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(model_poisson}\OperatorTok{$}\NormalTok{loglik)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -989.83
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(model_poissonzi}\OperatorTok{$}\NormalTok{loglik)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -931.8778
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#afficher les paramètres ajustés}
\NormalTok{model_poissonzi}\OperatorTok{$}\NormalTok{estimate}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        mu     sigma 
## 0.6690301 0.7022605
\end{verbatim}

Nous avons donc la confirmation que le modèle de poisson avec excès de zéros est mieux ajusté. Nous apprenons donc que 70\% (sigma = 0,70) des intersections sont en fait exclues du phénomène étudié (probablement parce que très peu de cyclistes les utilisent ou parce qu'elles sont très peu accidentogènes) et que pour les autres, le taux d'accidents par année en 2017 était de 0,67 (mu = 0,669, mu signifiant \(\lambda\) pour le \emph{package} \textbf{gamlss}). À nouveau, nous pouvons effectuer un test formel avec le fonction \texttt{ks.test}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{params <-}\StringTok{ }\KeywordTok{as.list}\NormalTok{(model_poissonzi}\OperatorTok{$}\NormalTok{estimate)}
\KeywordTok{ks.test}\NormalTok{(data_accidents}\OperatorTok{$}\NormalTok{nb_accident,}
        \DataTypeTok{y =}\NormalTok{ pZIP, }\DataTypeTok{mu =}\NormalTok{ params}\OperatorTok{$}\NormalTok{mu, }\DataTypeTok{sigma =}\NormalTok{ params}\OperatorTok{$}\NormalTok{sigma)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 	One-sample Kolmogorov-Smirnov test
## 
## data:  data_accidents$nb_accident
## D = 0.85476, p-value < 2.2e-16
## alternative hypothesis: two-sided
\end{verbatim}

Encore une fois, on doit rejeter l'hypothèse selon laquelle le test suit une distribution de poisson avec excès de zéros. Ces deux exemples montrent à quel point ce test est restrictif.

\hypertarget{sect0255}{%
\subsection{La transformation des variables}\label{sect0255}}

\hypertarget{sect02551}{%
\subsubsection{Les transformations visant à atteindre la normalité}\label{sect02551}}

Comme énoncé au début de cette section, plusieurs méthodes statistiques nécessitent que la variable quantitative soit normalement distribuée. C'est notamment le cas de l'analyse de variance et des tests \emph{t} (abordés dans les chapitres suivants) qui fourniront des résultats plus robustes lorsque la variable est normalement distribuée. Plusieurs transformations sont possibles, les plus courantes étant la racine carrée, le logarithme et l'inverse de la variable. Selon plusieurs auteurs (notamment, Tabacknick et \emph{et al.} \citeyearpar[p.~89]{tabachnick2007}), en fonction du type (positive ou négative) et du degré d'asymétrie, les transformations suivantes sont possibles afin d'améliorer la normalité de la variable :

\begin{itemize}
\tightlist
\item
  Asymétrie positive modérée : la racine carrée de la variable \emph{X} avec la fonction \texttt{sqrt(df\$x)}.
\item
  Asymétrie positive importante : le logarithme de la variable avec \texttt{log10(df\$x)}
\item
  Asymétrie positive sévère : l'inverse de la variable avec \texttt{1/(df\$x)}
\end{itemize}

\begin{bloc_astuce}

Attention, pour une valeur égale ou inférieure à 0, on ne peut pas calculer une racine carrée ou un logarithme. Par conséquent, il convient de décaler simplement la distribution vers la droite afin de s'assurer qu'il n'y ait plus de valeurs négative ou égale à 0 :

\begin{itemize}
\tightlist
\item
  \texttt{sqrt(df\$x\ -\ min(df\$x+1))}avec pour une asymétrie positive avec des valeurs négatives ou égales à 0
\item
  \texttt{log(df\$x\ -\ min(df\$x+1))}pour une asymétrie positive avec des valeurs négatives ou égales à 0
\end{itemize}

Par exemple, si la valeur minimale de la variable est égale à -10, la valeur minimale de variable décalée sera ainsi de 11.

\begin{itemize}
\tightlist
\item
  Asymétrie négative modérée : \texttt{sqrt(max(df\$x+1)\ -\ df\$x)}.
\item
  Asymétrie négative importante :\texttt{log(max(df\$x+1)\ -\ df\$x)}
\item
  Asymétrie négative sévère : \texttt{1/(max(df\$x+1)\ -\ df\$x)}
\end{itemize}

\end{bloc_astuce}

\begin{bloc_attention}

\textbf{Transformation des variables pour atteindre la normalité : ce n'est pas toujours la panacée !}

La transformation des données fait et fera encore longtemps débat à la fois parmi les statisticiens, les débutants et utilisateurs avancés des méthodes quantitatives. Field et al.~\citeyearpar[pp.~193]{field2012discovering} résument le tout avec humour : « To transform or not transform, that is the question ».

\textbf{Avantages de la transformation}

\begin{itemize}
\tightlist
\item
  L'obtention de \emph{résultats plus robustes}.
\item
  Dans une régression linéaire multiple, la transformation de la variable dépendante peut \emph{remédier au non-respect des hypothèses de base liées à la régression} (linéarité et homoscédasticité des erreurs, absence des valeurs aberrantes, etc.).
\end{itemize}

\textbf{Inconvénients de la transformation}

\begin{itemize}
\item
  \emph{Une variable transformée est plus difficile à interpréter} puisque cela change l'unité de mesure de la variable. Prenons un exemple concret : vous souhaitez comparer les moyennes de revenu de deux groupes \emph{A} et \emph{B}. Vous obtenez une différence de 15000\$, soit une valeur facile à interpréter. Par contre, si la variable a été préalablement transformée en logarithme, il est possible que vous obteniez une différence de 9, ce qui est beaucoup moins parlant. Aussi, en transformant la variable en \emph{log}, vous ne comparez plus les moyennes arithmétiques des deux groupes, mais plutôt leurs moyennes géométriques \citep[pp.~193]{field2012discovering}.
\item
  \emph{Pourquoi perdre la forme initiale de la distribution du phénomène à expliquer ?} Il est possible pour de nombreuses méthodes de choisir la distribution que l'on souhaite utiliser, il n'est donc pas nécessaire de toujours se limiter à la distribution normale. Par exemple, dans les modèles de régression généralisés (GLM), on pourrait indiquer que notre variable indépendante suit une distribution de \emph{Student} plutôt que de vouloir à tout prix la rendre normale. De même, certains tests non-paramétriques permettent d'analyser des variables ne suivant pas une distribution normale.
\end{itemize}

\textbf{Démarche à suivre avant et après la transformation}

\begin{itemize}
\item
  \emph{La transformation est-elle nécessaire ?} Ne transformez jamais une variable sans avoir analyser rigoureusement sa forme (histogramme avec courbe normale, \emph{skewness} et \emph{kurtosis}, tests de normalité).
\item
  \emph{D'autres options à la transformation d'une variable dépendante (VD) sont-elles envisageables ?} Identifiez la forme de la distribution de la VD et utilisez au besoin un modèle GLM adapté à cette distribution. Autrement dit, ne transformez pas automatiquement votre VD pour simplement pouvoir l'introduire dans une régression linéaire multiple.
\item
  \emph{La transformation a-t-elle un apport significatif ?} Premièrement, vérifiez si la transformation utilisée (logarithme, racine carrée, inverse, etc.) améliore la normalité de la variable. Ce n'est toujours le cas, pourquoi c'est pire ! Prenez soin de comparer les histogrammes, les valeurs de \emph{skewness}, \emph{kurtosis} et des différents tests de normalité avant et après la transformation. Deuxièmement, comparez les résultats de vos analyses statistiques sans et avec transformation, et ce, dans une démarche coût-avantage. Vos résultats sont-ils bien plus robustes? Par exemple, un R\textsuperscript{2} qui passe de 0,597 à 0,602 avant et après la transformation des variables avec des associations significatives similaires, mais plus difficiles à interpréter (du fait des transformations), n'est pas forcément un gain significatif. La modélisation en sciences sociales ne vise pas à prédire la trajectoire d'un satellite ou l'atterrissage d'un engin sur Mars ! La précision à la quatrième décimale n'est pas une condition ! Par conséquent, un modèle un peu moins robuste, mais plus facile à interpréter est parfois préférable.
\end{itemize}

\end{bloc_attention}

\hypertarget{sect02552}{%
\subsubsection{Autres types de transformations}\label{sect02552}}

Les trois transformations les plus couramment utilisées sont :

\begin{itemize}
\tightlist
\item
  \textbf{La côte \(z\)} (\emph{z score} en anglais) qui consiste à soustraire à chaque valeur sa moyenne (soit un centrage), puis à la diviser par son écart-type (soit une réduction) (eq. \eqref{eq:scorez}). Par conséquent, on parle aussi de variable centrée-réduite qui a comme propriétés intéressantes une moyenne égale à 0 et un écart-type égale à 1 (la variance est aussi égale à 1 puisque \(1^2=1\)). Nous verrons que cette transformation est largement utilisée dans les méthodes de classification (chapitre \ref{chap09}) et les méthodes factorielles (chapitre \ref{chap10}).
\end{itemize}

\begin{equation} 
z= \frac{x_i-\mu}{\sigma}
\label{eq:scorez}
\end{equation}

\begin{itemize}
\item
  \textbf{La transformation en rangs} qui consiste simplement à trier une variable en ordre croissant, puis à affecter le rang de chaque observation de 1 à \(n\). Cette transformation est très utilisée quand la variable est très anormalement distribuée, notamment pour calculer le coefficient de corrélation de Spearman (section \ref{sect04133}) et certains tests non-paramétriques (sections \ref{sect0432} et \ref{sect0442}).
\item
  \textbf{La transformation sur une échelle de 0 à 1} (ou de 0 à 100) qui consiste à soustraite à chaque observation la valeur minimale et à diviser le tout par l'étendue (eq. \eqref{eq:t01}).
\end{itemize}

\begin{equation} 
X_{\in\lbrack0-1\rbrack}= \frac{x_i-max}{max-min} \text{ ou } X_{\in\lbrack0-100\rbrack}= \frac{x_i-min}{max-min}\times100
\label{eq:t01}
\end{equation}

\begin{table}

\caption{\label{tab:AutresTransformation}Illustration des trois tranformations}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{lrrrr}
\toprule
Observation & \$x\_i\$ & Côte \$z\$ & Rang & 0 à 1\\
\midrule
1 & 22,00 & -1,45 & 1 & 0,00\\
2 & 27,00 & -0,65 & 3 & 0,28\\
3 & 25,00 & -0,97 & 2 & 0,17\\
4 & 30,00 & -0,16 & 4 & 0,44\\
5 & 37,00 & 0,97 & 7 & 0,83\\
\addlinespace
6 & 32,00 & 0,16 & 5 & 0,56\\
7 & 35,00 & 0,65 & 6 & 0,72\\
8 & 40,00 & 1,45 & 8 & 1,00\\
Moyenne & 31,00 & 0,00 &  & \\
Écart-type & 6,19 & 1,00 &  & \\
\bottomrule
\end{tabular}
\end{table}

Pour un \emph{dataframe} nommé \emph{df} comprenant une variable \emph{x}, la syntaxe ci-dessous illustre comment obtenir quatre transformations (côte \(z\), rangs, 0 à 1 et 0 à 100).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2 <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{x =} \KeywordTok{c}\NormalTok{(}\DecValTok{22}\NormalTok{,}\DecValTok{27}\NormalTok{,}\DecValTok{25}\NormalTok{,}\DecValTok{30}\NormalTok{,}\DecValTok{37}\NormalTok{,}\DecValTok{32}\NormalTok{,}\DecValTok{35}\NormalTok{,}\DecValTok{40}\NormalTok{))}

\CommentTok{# Transformation centrée-réduite : côte Z}
\NormalTok{df2}\OperatorTok{$}\NormalTok{zx <-}\StringTok{ }\NormalTok{(df2}\OperatorTok{$}\NormalTok{x}\OperatorTok{-}\KeywordTok{mean}\NormalTok{(df2}\OperatorTok{$}\NormalTok{x))}\OperatorTok{/}\KeywordTok{sd}\NormalTok{(df2}\OperatorTok{$}\NormalTok{x)}

\CommentTok{# Transformation en rangs avec la fonction rank}
\NormalTok{df2}\OperatorTok{$}\NormalTok{rz <-}\StringTok{ }\KeywordTok{rank}\NormalTok{(df2}\OperatorTok{$}\NormalTok{x)}

\CommentTok{# Transformation en rangs de 0 à 1}
\NormalTok{df2}\OperatorTok{$}\NormalTok{x01 <-}\StringTok{ }\NormalTok{(df2}\OperatorTok{$}\NormalTok{x}\OperatorTok{-}\KeywordTok{min}\NormalTok{(df2}\OperatorTok{$}\NormalTok{x))}\OperatorTok{/}\NormalTok{(}\KeywordTok{max}\NormalTok{(df2}\OperatorTok{$}\NormalTok{x)}\OperatorTok{-}\KeywordTok{min}\NormalTok{(df2}\OperatorTok{$}\NormalTok{x))}

\CommentTok{# Transformation en rangs de 0 à 100}
\NormalTok{df2}\OperatorTok{$}\NormalTok{x0100 <-}\StringTok{ }\NormalTok{(df2}\OperatorTok{$}\NormalTok{x}\OperatorTok{-}\KeywordTok{min}\NormalTok{(df2}\OperatorTok{$}\NormalTok{x))}\OperatorTok{/}\NormalTok{(}\KeywordTok{max}\NormalTok{(df2}\OperatorTok{$}\NormalTok{x)}\OperatorTok{-}\KeywordTok{min}\NormalTok{(df2}\OperatorTok{$}\NormalTok{x))}\OperatorTok{*}\DecValTok{100}
\end{Highlighting}
\end{Shaded}

\begin{bloc_aller_loin}

Ces trois transformations sont parfois utilisées pour générer un indice composite à partir de plusieurs variables ou encore dans une analyse de sensibilité avec les indices de Sobol \citeyearpar{Sobol1993}.

\end{bloc_aller_loin}

\hypertarget{sect0256}{%
\subsection{Mise en œuvre dans R}\label{sect0256}}

Il existe une multitude de \emph{packages} dédiés au calcul des statistiques descriptives univariées. Par parcimonie, nous en utiliserons uniquement trois : \texttt{DescTools}, \texttt{nortest} et \texttt{stats}. Libre à vous de faire vos recherches sur Internet pour utiliser d'autres \emph{packages} au besoin. Les principales fonctions que nous utilisons ici sont :

\begin{itemize}
\tightlist
\item
  \texttt{summary} : pour obtenir un résumé sommaire des statistiques descriptives (minimum, Q1, Q2 Q3, Maximum)
\item
  \texttt{mean} : moyenne
\item
  \texttt{min} : minimum
\item
  \texttt{max} : maximum
\item
  \texttt{range} : minimum et maximum
\item
  \texttt{quantile} : quartiles
\item
  \texttt{quantile((x,\ probs\ =\ seq(.0,\ 1,\ by\ =\ .2))} : quintiles
\item
  \texttt{quantile((x,\ probs\ =\ seq(.0,\ 1,\ by\ =\ .1))} : déciles
\item
  \texttt{var} : variance
\item
  \texttt{sd} : écart-type
\item
  \texttt{Skew} du \emph{package} \texttt{DescTools} : coefficient d'asymétrie
\item
  \texttt{Kurt} du \emph{package} \texttt{DescTools} : coefficient d'applatissement
\item
  \texttt{ks.test(x,\ "pnorm",\ mean=mean(x),\ sd=sd(x))} du \emph{package} \texttt{nortest} : test de Kolmogorov-Smirnov
\item
  \texttt{shapiro.test} du \emph{package} \texttt{DescTools} : test de Shapiro-Wilk
\item
  \texttt{lillie.test} du \emph{package} \texttt{DescTools} : du package \textbf{nortest} : test de Lilliefors
\item
  \texttt{ad.test} du \emph{package} \texttt{DescTools} : test d'Anderson-Darling
\item
  \texttt{JarqueBeraTest} du \emph{package} \texttt{DescTools} : test de Jarque-Bera
\end{itemize}

\hypertarget{sect02561}{%
\subsubsection{Application à une seule variable}\label{sect02561}}

Admettons que vous voulez obtenir des statistiques pour une seule variable présente dans un \emph{dataframe} (\texttt{dataMTL\$PctFRev}) :

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(DescTools)}
\KeywordTok{library}\NormalTok{(stats)}
\KeywordTok{library}\NormalTok{(nortest)}

\CommentTok{# Importation du fichier csv dans un dataframe}
\NormalTok{dataMTL <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/univariee/DataSR2016.csv"}\NormalTok{)}
\CommentTok{# Tableau sommaire pour la variable PctFRev}
\KeywordTok{summary}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{PctFRev)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   1.846  11.242  15.471  16.822  20.229  68.927
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# PARAMÈTRES DE TENDANCE CENTRALE}
\KeywordTok{mean}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{PctFRev)   }\CommentTok{# Moyenne}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 16.82247
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{median}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{PctFRev)   }\CommentTok{# Médiane}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 15.471
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# PARAMÈTRES DE POSITION}
\CommentTok{# Quartiles}
\KeywordTok{quantile}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{PctFRev)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      0%     25%     50%     75%    100% 
##  1.8460 11.2420 15.4710 20.2285 68.9270
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Quintiles}
\KeywordTok{quantile}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{PctFRev, }\DataTypeTok{probs =} \KeywordTok{seq}\NormalTok{(.}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DataTypeTok{by =} \FloatTok{.2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     0%    20%    40%    60%    80%   100% 
##  1.846 10.294 13.626 16.918 21.756 68.927
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Déciles}
\KeywordTok{quantile}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{PctFRev, }\DataTypeTok{probs =} \KeywordTok{seq}\NormalTok{(.}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DataTypeTok{by =} \FloatTok{.1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     0%    10%    20%    30%    40%    50%    60%    70%    80%    90%   100% 
##  1.846  8.402 10.294 12.172 13.626 15.471 16.918 18.868 21.756 26.854 68.927
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Percentiles personnalisés avec apply}
\KeywordTok{quantile}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{PctFRev, }\DataTypeTok{probs =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.01}\NormalTok{,.}\DecValTok{05}\NormalTok{,}\FloatTok{0.10}\NormalTok{,.}\DecValTok{25}\NormalTok{,.}\DecValTok{50}\NormalTok{,.}\DecValTok{75}\NormalTok{,.}\DecValTok{90}\NormalTok{,.}\DecValTok{95}\NormalTok{,.}\DecValTok{99}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      1%      5%     10%     25%     50%     75%     90%     95%     99% 
##  5.2290  7.1470  8.4020 11.2420 15.4710 20.2285 26.8540 31.7530 45.6010
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# PARAMÈTRES DE DISPERSION}
\KeywordTok{range}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{PctFRev)  }\CommentTok{# Min et Max}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  1.846 68.927
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Étendue}
\KeywordTok{max}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{PctFRev)}\OperatorTok{-}\KeywordTok{min}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{PctFRev)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 67.081
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Écart interquartile}
\KeywordTok{quantile}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{PctFRev)[}\DecValTok{4}\NormalTok{]}\OperatorTok{-}\KeywordTok{quantile}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{PctFRev)[}\DecValTok{2}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    75% 
## 8.9865
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{PctFRev) }\CommentTok{# Variance}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 66.62482
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sd}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{PctFRev)  }\CommentTok{# Écart-type}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 8.162403
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sd}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{PctFRev) }\OperatorTok{/}\StringTok{ }\KeywordTok{mean}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{PctFRev) }\CommentTok{# CV}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.4852083
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# PARAMÈTRES DE FORME}
\KeywordTok{Skew}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{PctFRev)    }\CommentTok{# Skewness}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.67367
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{Kurt}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{PctFRev)    }\CommentTok{# Kurtosis}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4.858815
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# TESTS D'HYPOTHÈSE SUR LA NORMALITÉ}
\CommentTok{# K-Smirnov}
\KeywordTok{ks.test}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{PctFRev, }\StringTok{"pnorm"}\NormalTok{, }\DataTypeTok{mean=}\KeywordTok{mean}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{PctFRev), }\DataTypeTok{sd=}\KeywordTok{sd}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{PctFRev))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 	One-sample Kolmogorov-Smirnov test
## 
## data:  dataMTL$PctFRev
## D = 0.10487, p-value = 1.646e-09
## alternative hypothesis: two-sided
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{shapiro.test}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{PctFRev) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 	Shapiro-Wilk normality test
## 
## data:  dataMTL$PctFRev
## W = 0.88748, p-value < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{lillie.test}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{PctFRev) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 	Lilliefors (Kolmogorov-Smirnov) normality test
## 
## data:  dataMTL$PctFRev
## D = 0.10487, p-value < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ad.test}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{PctFRev) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 	Anderson-Darling normality test
## 
## data:  dataMTL$PctFRev
## A = 21.072, p-value < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{JarqueBeraTest}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{PctFRev) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 	Robust Jarque Bera Test
## 
## data:  dataMTL$PctFRev
## X-squared = 2173.1, df = 2, p-value < 2.2e-16
\end{verbatim}

Pour construire un histogramme avec la courbe normale, vous pourez consulter la section \ref{sect03213} ou la syntaxe ci-dessous.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{moyenne <-}\StringTok{ }\KeywordTok{mean}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{PctFRev)}
\NormalTok{ecart_type <-}\StringTok{ }\KeywordTok{sd}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{PctFRev)}

\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ dataMTL) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ PctFRev, }\DataTypeTok{y =}\NormalTok{ ..density..),}
                 \DataTypeTok{bins =} \DecValTok{30}\NormalTok{, }\DataTypeTok{color =} \StringTok{"#343a40"}\NormalTok{, }\DataTypeTok{fill =} \StringTok{"#a8dadc"}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{y =} \StringTok{"densité"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{stat_function}\NormalTok{(}\DataTypeTok{fun =}\NormalTok{ dnorm, }\DataTypeTok{args =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{mean =}\NormalTok{ moyenne, }\DataTypeTok{sd =}\NormalTok{ ecart_type), }
                \DataTypeTok{color =} \StringTok{"#e63946"}\NormalTok{, }\DataTypeTok{size =} \FloatTok{1.2}\NormalTok{, }\DataTypeTok{linetype =} \StringTok{"dashed"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/GcourbeNormale-1} 

}

\caption{Histogramme avec courbe normale}\label{fig:GcourbeNormale}
\end{figure}

\hypertarget{sect02562}{%
\subsubsection{Application à plusieurs variables}\label{sect02562}}

Pour obtenir des sorties de statistiques descriptives pour plusieurs variables, nous vous conseillons :

\begin{itemize}
\tightlist
\item
  de créer un vecteur avec les noms de variables (\emph{VarsSelect} dans la syntaxe ci-dessous)
\item
  d'utiliser ensuite les fonctions \texttt{sapply} et \texttt{apply.}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Noms des variables du dataframe}
\KeywordTok{names}\NormalTok{(dataMTL)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "CTNAME"                "PopTotal"              "HabKm2"               
##  [4] "PctFRev"               "TxChomage"             "PctImmigrant"         
##  [7] "PctImgRecent"          "PctMenage1pers"        "PctFamilleMono"       
## [10] "PctLangueMaternelleFR" "PctLangueMaternelleAN" "PctLangueMaternelleAU"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Vecteur pour trois variables}
\NormalTok{VarsSelect <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"HabKm2"}\NormalTok{, }\StringTok{"TxChomage"}\NormalTok{, }\StringTok{"PctFRev"}\NormalTok{ )}

\CommentTok{# Tableau sommaire pour les 3 variables}
\KeywordTok{summary}\NormalTok{(dataMTL[VarsSelect])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      HabKm2        TxChomage         PctFRev      
##  Min.   :   18   Min.   : 1.942   Min.   : 1.846  
##  1st Qu.: 1980   1st Qu.: 5.482   1st Qu.:11.242  
##  Median : 3773   Median : 7.130   Median :15.471  
##  Mean   : 5513   Mean   : 7.743   Mean   :16.822  
##  3rd Qu.: 7916   3rd Qu.: 9.391   3rd Qu.:20.229  
##  Max.   :50282   Max.   :26.882   Max.   :68.927
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# PARAMÈTRES DE TENDANCE CENTRALE}
\KeywordTok{sapply}\NormalTok{(dataMTL[VarsSelect], mean)   }\CommentTok{# Moyenne}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      HabKm2   TxChomage     PctFRev 
## 5512.830705    7.743329   16.822470
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sapply}\NormalTok{(dataMTL[VarsSelect], median) }\CommentTok{# Médiane}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    HabKm2 TxChomage   PctFRev 
##  3773.000     7.130    15.471
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# PARAMÈTRES DE POSITION}
\CommentTok{# Quartiles}
\KeywordTok{sapply}\NormalTok{(dataMTL[VarsSelect], quantile)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       HabKm2 TxChomage PctFRev
## 0%      18.0    1.9420  1.8460
## 25%   1980.5    5.4825 11.2420
## 50%   3773.0    7.1300 15.4710
## 75%   7915.5    9.3910 20.2285
## 100% 50282.0   26.8820 68.9270
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Quintiles}
\KeywordTok{apply}\NormalTok{(dataMTL[VarsSelect], }\DecValTok{2}\NormalTok{, }\ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{quantile}\NormalTok{(x, }\DataTypeTok{probs =} \KeywordTok{seq}\NormalTok{(.}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DataTypeTok{by =} \FloatTok{.2}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      HabKm2 TxChomage PctFRev
## 0%       18     1.942   1.846
## 20%    1525     5.116  10.294
## 40%    2953     6.422  13.626
## 60%    4971     7.973  16.918
## 80%    9509    10.000  21.756
## 100%  50282    26.882  68.927
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Déciles}
\KeywordTok{apply}\NormalTok{(dataMTL[VarsSelect], }\DecValTok{2}\NormalTok{, }\ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{quantile}\NormalTok{(x, }\DataTypeTok{probs =} \KeywordTok{seq}\NormalTok{(.}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DataTypeTok{by =} \FloatTok{.1}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      HabKm2 TxChomage PctFRev
## 0%       18     1.942   1.846
## 10%     455     4.369   8.402
## 20%    1525     5.116  10.294
## 30%    2298     5.780  12.172
## 40%    2953     6.422  13.626
## 50%    3773     7.130  15.471
## 60%    4971     7.973  16.918
## 70%    6918     8.909  18.868
## 80%    9509    10.000  21.756
## 90%   13055    11.749  26.854
## 100%  50282    26.882  68.927
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Percentiles personnalisés avec apply}
\KeywordTok{apply}\NormalTok{(dataMTL[VarsSelect], }\DecValTok{2}\NormalTok{, }
      \ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{quantile}\NormalTok{(x, }\DataTypeTok{probs =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.01}\NormalTok{,.}\DecValTok{05}\NormalTok{,}\FloatTok{0.10}\NormalTok{,.}\DecValTok{25}\NormalTok{,.}\DecValTok{50}\NormalTok{,.}\DecValTok{75}\NormalTok{,.}\DecValTok{90}\NormalTok{,.}\DecValTok{95}\NormalTok{,.}\DecValTok{99}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      HabKm2 TxChomage PctFRev
## 1%     58.5    2.9665  5.2290
## 5%    178.0    3.8980  7.1470
## 10%   455.0    4.3690  8.4020
## 25%  1980.5    5.4825 11.2420
## 50%  3773.0    7.1300 15.4710
## 75%  7915.5    9.3910 20.2285
## 90% 13055.0   11.7490 26.8540
## 95% 15355.0   13.8400 31.7530
## 99% 18578.5   17.1920 45.6010
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# PARAMÈTRES DE DISPERSION}
\KeywordTok{sapply}\NormalTok{(dataMTL[VarsSelect], range)  }\CommentTok{# Min et Max}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      HabKm2 TxChomage PctFRev
## [1,]     18     1.942   1.846
## [2,]  50282    26.882  68.927
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Étendue}
\KeywordTok{sapply}\NormalTok{(dataMTL[VarsSelect], max) }\OperatorTok{-}\StringTok{ }\KeywordTok{sapply}\NormalTok{(dataMTL[VarsSelect], min)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    HabKm2 TxChomage   PctFRev 
## 50264.000    24.940    67.081
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Écart interquartile}
\KeywordTok{sapply}\NormalTok{(dataMTL[VarsSelect], quantile)[}\DecValTok{4}\NormalTok{,] }\OperatorTok{-}\StringTok{ }\KeywordTok{sapply}\NormalTok{(dataMTL[VarsSelect], quantile)[}\DecValTok{2}\NormalTok{,]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    HabKm2 TxChomage   PctFRev 
## 5935.0000    3.9085    8.9865
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sapply}\NormalTok{(dataMTL[VarsSelect], var)    }\CommentTok{# Variance}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       HabKm2    TxChomage      PctFRev 
## 2.633462e+07 9.880932e+00 6.662482e+01
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sapply}\NormalTok{(dataMTL[VarsSelect], sd)     }\CommentTok{# Écart-type}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      HabKm2   TxChomage     PctFRev 
## 5131.726785    3.143395    8.162403
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Coefficient de variation}
\KeywordTok{sapply}\NormalTok{(dataMTL[VarsSelect], sd) }\OperatorTok{/}\StringTok{ }\KeywordTok{sapply}\NormalTok{(dataMTL[VarsSelect], mean)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    HabKm2 TxChomage   PctFRev 
## 0.9308696 0.4059488 0.4852083
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# PARAMÈTRES DE FORME}
\KeywordTok{sapply}\NormalTok{(dataMTL[VarsSelect], Skew)    }\CommentTok{# Skewness}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    HabKm2 TxChomage   PctFRev 
##  1.967468  1.280216  1.673670
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sapply}\NormalTok{(dataMTL[VarsSelect], Kurt)    }\CommentTok{# Kurtosis}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    HabKm2 TxChomage   PctFRev 
##  8.546403  2.892443  4.858815
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# TESTS D'HYPOTHÈSE POUR LA NORMALITÉ}
\CommentTok{# K-Smirnov}
\KeywordTok{apply}\NormalTok{(dataMTL[VarsSelect], }\DecValTok{2}\NormalTok{, }\ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{ks.test}\NormalTok{(x, }\StringTok{"pnorm"}\NormalTok{, }\DataTypeTok{mean=}\KeywordTok{mean}\NormalTok{(x), }\DataTypeTok{sd=}\KeywordTok{sd}\NormalTok{(x)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $HabKm2
## 
## 	One-sample Kolmogorov-Smirnov test
## 
## data:  x
## D = 0.14899, p-value < 2.2e-16
## alternative hypothesis: two-sided
## 
## 
## $TxChomage
## 
## 	One-sample Kolmogorov-Smirnov test
## 
## data:  x
## D = 0.080183, p-value = 9.778e-06
## alternative hypothesis: two-sided
## 
## 
## $PctFRev
## 
## 	One-sample Kolmogorov-Smirnov test
## 
## data:  x
## D = 0.10487, p-value = 1.646e-09
## alternative hypothesis: two-sided
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sapply}\NormalTok{(dataMTL[VarsSelect], shapiro.test)       }\CommentTok{# Shapiro-Wilk}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           HabKm2                        TxChomage                    
## statistic 0.8385086                     0.9235146                    
## p.value   5.648795e-30                  1.451222e-21                 
## method    "Shapiro-Wilk normality test" "Shapiro-Wilk normality test"
## data.name "X[[i]]"                      "X[[i]]"                     
##           PctFRev                      
## statistic 0.8874803                    
## p.value   1.00278e-25                  
## method    "Shapiro-Wilk normality test"
## data.name "X[[i]]"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sapply}\NormalTok{(dataMTL[VarsSelect], lillie.test)       }\CommentTok{# Lilliefors}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           HabKm2                                          
## statistic 0.148988                                        
## p.value   5.689619e-58                                    
## method    "Lilliefors (Kolmogorov-Smirnov) normality test"
## data.name "X[[i]]"                                        
##           TxChomage                                       
## statistic 0.0801829                                       
## p.value   7.758887e-16                                    
## method    "Lilliefors (Kolmogorov-Smirnov) normality test"
## data.name "X[[i]]"                                        
##           PctFRev                                         
## statistic 0.1048704                                       
## p.value   7.43257e-28                                     
## method    "Lilliefors (Kolmogorov-Smirnov) normality test"
## data.name "X[[i]]"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sapply}\NormalTok{(dataMTL[VarsSelect], ad.test)           }\CommentTok{# Anderson-Darling}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           HabKm2                            TxChomage                        
## statistic 36.40276                          14.9237                          
## p.value   3.7e-24                           3.7e-24                          
## method    "Anderson-Darling normality test" "Anderson-Darling normality test"
## data.name "X[[i]]"                          "X[[i]]"                         
##           PctFRev                          
## statistic 21.07194                         
## p.value   3.7e-24                          
## method    "Anderson-Darling normality test"
## data.name "X[[i]]"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sapply}\NormalTok{(dataMTL[VarsSelect], JarqueBeraTest)    }\CommentTok{# Jarque-Bera}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           HabKm2                    TxChomage                
## statistic 4270.113                  639.2741                 
## parameter 2                         2                        
## p.value   0                         0                        
## method    "Robust Jarque Bera Test" "Robust Jarque Bera Test"
## data.name "X[[i]]"                  "X[[i]]"                 
##           PctFRev                  
## statistic 2173.082                 
## parameter 2                        
## p.value   0                        
## method    "Robust Jarque Bera Test"
## data.name "X[[i]]"
\end{verbatim}

\hypertarget{sect02563}{%
\subsubsection{Transformer une variable dans R}\label{sect02563}}

La syntaxe ci-dessous illustre trois exemples de transformation (logarithme, racine carrée et inverse de la variable). Rappelez-vous qu'il faut compare les valeurs de forme (\emph{skewness} et \emph{kurtosis}) et de forme (tests de Shapiro-Wilk) avant et après les transformations pour identifier celle qui est la plus efficace.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ggpubr)}

\CommentTok{# Importation du fichier csv dans un dataframe}
\NormalTok{dataMTL <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/univariee/DataSR2016.csv"}\NormalTok{)}

\CommentTok{# Noms des variables du dataframe}
\KeywordTok{names}\NormalTok{(dataMTL)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "CTNAME"                "PopTotal"              "HabKm2"               
##  [4] "PctFRev"               "TxChomage"             "PctImmigrant"         
##  [7] "PctImgRecent"          "PctMenage1pers"        "PctFamilleMono"       
## [10] "PctLangueMaternelleFR" "PctLangueMaternelleAN" "PctLangueMaternelleAU"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Transformations}
\NormalTok{dataMTL}\OperatorTok{$}\NormalTok{HabKm2_log <-}\StringTok{  }\KeywordTok{log10}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{HabKm2)}
\NormalTok{dataMTL}\OperatorTok{$}\NormalTok{HabKm2_sqrt <-}\StringTok{  }\KeywordTok{sqrt}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{HabKm2)}
\NormalTok{dataMTL}\OperatorTok{$}\NormalTok{HabKm2_inv <-}\StringTok{  }\DecValTok{1}\OperatorTok{/}\NormalTok{dataMTL}\OperatorTok{$}\NormalTok{HabKm2}

\CommentTok{# Vecteur pour la variable et les trois transformations}
\NormalTok{VarsSelect <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"HabKm2"}\NormalTok{, }\StringTok{"HabKm2_log"}\NormalTok{, }\StringTok{"HabKm2_sqrt"}\NormalTok{, }\StringTok{"HabKm2_inv"}\NormalTok{)}

\CommentTok{# paramètres de forme}
\KeywordTok{sapply}\NormalTok{(dataMTL[VarsSelect], Skew)    }\CommentTok{# Skewness}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      HabKm2  HabKm2_log HabKm2_sqrt  HabKm2_inv 
##   1.9674683  -1.2071326   0.4179037   8.2536901
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sapply}\NormalTok{(dataMTL[VarsSelect], Kurt)    }\CommentTok{# Kurtosis}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      HabKm2  HabKm2_log HabKm2_sqrt  HabKm2_inv 
##  8.54640302  1.55670769  0.04563433 82.85604898
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# TESTS D'HYPOTHÈSE SUR LA NORMALITÉ}
\KeywordTok{sapply}\NormalTok{(dataMTL[VarsSelect], shapiro.test) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           HabKm2                        HabKm2_log                   
## statistic 0.8385086                     0.9113234                    
## p.value   5.648795e-30                  4.11156e-23                  
## method    "Shapiro-Wilk normality test" "Shapiro-Wilk normality test"
## data.name "X[[i]]"                      "X[[i]]"                     
##           HabKm2_sqrt                   HabKm2_inv                   
## statistic 0.9771699                     0.2530266                    
## p.value   4.638049e-11                  8.324983e-52                 
## method    "Shapiro-Wilk normality test" "Shapiro-Wilk normality test"
## data.name "X[[i]]"                      "X[[i]]"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Histogrammes avec courbe normale}
\NormalTok{Graph1 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ dataMTL) }\OperatorTok{+}
\StringTok{          }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ HabKm2, }\DataTypeTok{y =}\NormalTok{ ..density..),}
                 \DataTypeTok{bins =} \DecValTok{30}\NormalTok{, }\DataTypeTok{color =} \StringTok{"#343a40"}\NormalTok{, }\DataTypeTok{fill =} \StringTok{"#a8dadc"}\NormalTok{) }\OperatorTok{+}
\StringTok{          }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x=}\StringTok{"Habitants au km2"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"densité"}\NormalTok{)}\OperatorTok{+}
\StringTok{          }\KeywordTok{stat_function}\NormalTok{(}\DataTypeTok{fun =}\NormalTok{ dnorm, }
                        \DataTypeTok{args =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{mean =} \KeywordTok{mean}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{HabKm2), }
                                    \DataTypeTok{sd =} \KeywordTok{sd}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{HabKm2)), }
                        \DataTypeTok{color =} \StringTok{"#e63946"}\NormalTok{, }\DataTypeTok{size =} \FloatTok{1.2}\NormalTok{)}

\NormalTok{Graph2 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ dataMTL) }\OperatorTok{+}
\StringTok{          }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ HabKm2_log, }\DataTypeTok{y =}\NormalTok{ ..density..),}
                         \DataTypeTok{bins =} \DecValTok{30}\NormalTok{, }\DataTypeTok{color =} \StringTok{"#343a40"}\NormalTok{, }\DataTypeTok{fill =} \StringTok{"#a8dadc"}\NormalTok{) }\OperatorTok{+}
\StringTok{          }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x=}\StringTok{"habitants au km2 (logarithme)"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"densité"}\NormalTok{)}\OperatorTok{+}
\StringTok{          }\KeywordTok{stat_function}\NormalTok{(}\DataTypeTok{fun =}\NormalTok{ dnorm, }
                        \DataTypeTok{args =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{mean =} \KeywordTok{mean}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{HabKm2_log), }
                                    \DataTypeTok{sd =} \KeywordTok{sd}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{HabKm2_log)), }
                        \DataTypeTok{color =} \StringTok{"#e63946"}\NormalTok{, }\DataTypeTok{size =} \FloatTok{1.2}\NormalTok{)}

\NormalTok{Graph3 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ dataMTL) }\OperatorTok{+}
\StringTok{          }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ HabKm2_sqrt, }\DataTypeTok{y =}\NormalTok{ ..density..),}
                         \DataTypeTok{bins =} \DecValTok{30}\NormalTok{, }\DataTypeTok{color =} \StringTok{"#343a40"}\NormalTok{, }\DataTypeTok{fill =} \StringTok{"#a8dadc"}\NormalTok{) }\OperatorTok{+}
\StringTok{          }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x=}\StringTok{"habitants au km2 (racine carrée)"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"densité"}\NormalTok{)}\OperatorTok{+}
\StringTok{          }\KeywordTok{stat_function}\NormalTok{(}\DataTypeTok{fun =}\NormalTok{ dnorm, }
                        \DataTypeTok{args =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{mean =} \KeywordTok{mean}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{HabKm2_sqrt), }
                                    \DataTypeTok{sd =} \KeywordTok{sd}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{HabKm2_sqrt)), }
                        \DataTypeTok{color =} \StringTok{"#e63946"}\NormalTok{, }\DataTypeTok{size =} \FloatTok{1.2}\NormalTok{)}

\NormalTok{Graph4 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ dataMTL) }\OperatorTok{+}
\StringTok{          }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ HabKm2_inv, }\DataTypeTok{y =}\NormalTok{ ..density..),}
                         \DataTypeTok{bins =} \DecValTok{30}\NormalTok{, }\DataTypeTok{color =} \StringTok{"#343a40"}\NormalTok{, }\DataTypeTok{fill =} \StringTok{"#a8dadc"}\NormalTok{) }\OperatorTok{+}
\StringTok{          }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x=}\StringTok{"habitants au km2 (inverse)"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"densité"}\NormalTok{)}\OperatorTok{+}
\StringTok{          }\KeywordTok{stat_function}\NormalTok{(}\DataTypeTok{fun =}\NormalTok{ dnorm, }
                        \DataTypeTok{args =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{mean =} \KeywordTok{mean}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{HabKm2_inv), }\DataTypeTok{sd =} \KeywordTok{sd}\NormalTok{(dataMTL}\OperatorTok{$}\NormalTok{HabKm2_inv)), }
                        \DataTypeTok{color =} \StringTok{"#e63946"}\NormalTok{, }\DataTypeTok{size =} \FloatTok{1.2}\NormalTok{)}

\KeywordTok{ggarrange}\NormalTok{(}\DataTypeTok{plotlist =} \KeywordTok{list}\NormalTok{(Graph1, Graph2, Graph3, Graph4), }\DataTypeTok{ncol =} \DecValTok{2}\NormalTok{, }\DataTypeTok{nrow=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/GTranf-1} 

}

\caption{Histogramme des transformations}\label{fig:GTranf}
\end{figure}

La variable \emph{HabKm2} est asymétrique positive et leptokurtique. Tant les valeurs des statistiques de forme, du test de Shapiro-Wilk que les histogrammes semblent démontrer que la transformation la plus efficace est la racine carrée. Si la variable originale est asymétrique positive, sa transformation logarithme est par contre asymétrique négative. Cela démontre que la transformation logarithmique n'est pas toujours la panacée.

\hypertarget{sect026}{%
\section{Statistiques descriptives sur des variables qualitatives et semi-qualitatives}\label{sect026}}

\hypertarget{sect0261}{%
\subsection{Les fréquences}\label{sect0261}}

En guise de rappel, les variables nominales, ordinales et semi-quantitatives comprennent plusieurs modalités pour lesquelles plusieurs types de fréquences sont généralement calculées. Pour illustrer le tout, nous avons extrait du recensement de 2016 de Statistique Canada les effectifs des modalités de la variable sur le principal mode de transport utilisé pour les déplacements domicile-travail, et ce, pour la subdivision de recensement (MRC) de l'île de Montréal (tableau \ref{tab:Frequences}). Les différents types de fréquences sont les suivantes :

\begin{itemize}
\item
  les fréquences absolues simples (\textbf{FAS}) ou fréquences observées représentent le nombre d'observations pour chacune des modalités. Par exemple, sur 857 540 navetteurs domicile-travail (ligne totale), seulement 30 645 optent pour le vélo, alors que 427 530 conduisent un véhicule motorisé (automobile, camion ou fourgonnette) comme principal mode de transport.
\item
  les fréquences relatives simples (\textbf{FRS}) sont les proportions de chaque modalité sur le total (\(30645/857540=0,036\)); leur somme est égale à 1. Elles peuvent bien entendu être exprimées en pourcentage (\(30645/857540 \times 100=3,57\)); leur somme est alors égale à 100\%. Par exemple, 3,7\% des navetteurs utilisent le vélo comme mode de transport principal.
\item
  les fréquences absolues cumulées (\textbf{FAC}) représentent la fréquence observée (FAS) de la modalité auxquelles sont additionnées celles qui la précèdent. La valeur de la FAC pour la dernière est donc égale au total.
\item
  À partir des fréquences absolues cumulées (FAC), il est alors possible de calculer les fréquences relatives cumulées (\textbf{FRC}) en proportion (\(453930 / 857540 = 0,529\)) et en pourcentage (\(453930 / 857540 \times 100= 52,93\)). Par exemple, plus de la moitié des navetteurs utilisent l'automobile comme mode de transport principal (passager ou conducteur).
\end{itemize}

\begin{table}

\caption{\label{tab:Frequences}Les différents types de fréquences sur une variable qualitative ou semi-qualitative}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{lrrrrrr}
\toprule
Mode de transport & FAS & FRS & FRS (\%) & FAC & FRC & FRC (\%)\\
\midrule
Véhicule motorisé (conducteur) & 427 530 & 0,499 & 49,86 & 427 530 & 0,499 & 49,86\\
Véhicule motorisé (passager) & 26 400 & 0,031 & 3,08 & 453 930 & 0,529 & 52,93\\
Transport en commun & 295 860 & 0,345 & 34,50 & 749 790 & 0,874 & 87,43\\
À pied & 69 410 & 0,081 & 8,09 & 819 200 & 0,955 & 95,53\\
Bicyclette & 30 645 & 0,036 & 3,57 & 849 845 & 0,991 & 99,10\\
\addlinespace
Autre moyen & 7 695 & 0,009 & 0,90 & 857 540 & 1,000 & 100,00\\
Total & 857 540 & 1,000 & 100,00 &  &  & \\
\bottomrule
\end{tabular}
\end{table}

\begin{bloc_attention}

\textbf{Les fréquences cumulées : peu pertinentes pour les variables nomimales}

Le calcul et l'analyse des fréquences cumulées (absolues et relatives) sont très souvent inutiles pour les variables nominales.

Par exemple, au tableau \ref{tab:Frequences}, la fréquence cumulée relative (en \%) est de 87,43\% pour la troisième ligne. Cela signifie que 87,43\% des navetteurs se déplacent en véhicule motorisé (conducteur ou passager) ou en transport en commun. Par contre, si la troisième modalité avait été \emph{à pied}, le pourcentage aurait été de 61,02 (\(52,93+8,09\)). Si vous souhaitez calculer les fréquences cumulées sur une variable nominale, assurez-vous que l'ordre des modalités vous convient et de le modifier au besoin. Sinon, abstenez-vous de les calculer!

\textbf{Les fréquences cumulées : très utiles pour l'analyse pour des variables ordinales ou semi-quantitatives}

Pour des modalités hiérarchisées (variable ordinale ou semi-quantitative), l'analyse des fréquences cumulées (absolues et relatives) est par contre très intéressante. Par exemple, au tableau \ref{tab:Frequences2}, elle permet de constater rapidement que sur l'île de Montréal, un peu moins du très de la population à moins de 25 ans (35,95\%) et 83,33\% moins de 65 ans.

\end{bloc_attention}

\begin{table}

\caption{\label{tab:Frequences2}Les différents types de fréquences sur une variable semi-qualitative}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{lrrrrrr}
\toprule
Groupes d'âge & FAS & FRS & FRS (\%) & FAC & FRC & FRC (\%)\\
\midrule
0 à 14 ans & 304 470 & 0,157 & 15,68 & 304 470 & 0,157 & 15,68\\
15 à 24 ans & 237 555 & 0,122 & 12,23 & 542 025 & 0,279 & 27,91\\
25 à 44 ans & 582 150 & 0,300 & 29,98 & 1 124 175 & 0,579 & 57,89\\
45 à 64 ans & 494 205 & 0,254 & 25,45 & 1 618 380 & 0,833 & 83,33\\
65 à 84 ans & 271 560 & 0,140 & 13,98 & 1 889 940 & 0,973 & 97,32\\
\addlinespace
85 ans et plus & 52 100 & 0,027 & 2,68 & 1 942 040 & 1,000 & 100,00\\
Total & 1 942 040 & 1,000 & 100,00 &  &  & \\
\bottomrule
\end{tabular}
\end{table}

Différents graphiques peuvent être construits pour illustrer la répartition des observations : les graphiques en barres (verticales et horizontales) avec les fréquences absolues, les diagrammes circulaires ou en anneau pour les fréquences relatives (figure \ref{fig:GraphiquesFreq1}). Ces graphiques seront présentés plus en détails dans le chapitre suivant.

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/GraphiquesFreq1-1} 

}

\caption{Différents graphiques pour représenter les fréquences absolues et relatives}\label{fig:GraphiquesFreq1}
\end{figure}

\hypertarget{sect0262}{%
\subsection{Mise en œuvre dans R}\label{sect0262}}

La syntaxe ci-dessous permet de calculer les différentes fréquences présentées au tableau \ref{tab:Frequences2}. Notez que pour les fréquences cumulées, nous utilisons la fonction \texttt{cumsum}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Vecteur pour les noms des modalités}
\NormalTok{Modalite <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"0 à 14 ans"}\NormalTok{,}
             \StringTok{"15 à 24 ans"}\NormalTok{,}
             \StringTok{"25 à 44 ans"}\NormalTok{,}
             \StringTok{"45 à 64 ans"}\NormalTok{,}
             \StringTok{"65 à 84 ans"}\NormalTok{,}
             \StringTok{"85 ans et plus"}\NormalTok{)}
\CommentTok{# Vecteur pour les fréquences absolues simples (FAS)}
\NormalTok{Navetteurs <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{304470}\NormalTok{,}\DecValTok{237555}\NormalTok{,}\DecValTok{582150}\NormalTok{,}\DecValTok{494205}\NormalTok{,}\DecValTok{271560}\NormalTok{,}\DecValTok{52100}\NormalTok{)}
\CommentTok{# Somme des FAS}
\NormalTok{sumFAS <-}\StringTok{  }\KeywordTok{sum}\NormalTok{(Navetteurs)}
\CommentTok{# Construction du dataframe avec les deux vecteurs}
\NormalTok{df <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}
  \DataTypeTok{GroupeAge =}\NormalTok{ Modalite, }
  \DataTypeTok{FAS =}\NormalTok{ Navetteurs,}
  \DataTypeTok{FRS =}\NormalTok{ Navetteurs }\OperatorTok{/}\StringTok{ }\NormalTok{sumFAS, }
  \DataTypeTok{FRSpct =}\NormalTok{ Navetteurs }\OperatorTok{/}\StringTok{ }\NormalTok{sumFAS }\OperatorTok{*}\StringTok{ }\DecValTok{100}\NormalTok{,}
  \DataTypeTok{FAC =} \KeywordTok{cumsum}\NormalTok{(Navetteurs),}
  \DataTypeTok{FRC =} \KeywordTok{cumsum}\NormalTok{(Navetteurs) }\OperatorTok{/}\StringTok{ }\NormalTok{sumFAS,}
  \DataTypeTok{FRCpct =} \KeywordTok{cumsum}\NormalTok{(Navetteurs) }\OperatorTok{/}\StringTok{ }\NormalTok{sumFAS }\OperatorTok{*}\StringTok{ }\DecValTok{100}
\NormalTok{  )}
\NormalTok{df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        GroupeAge    FAS        FRS    FRSpct     FAC       FRC    FRCpct
## 1     0 à 14 ans 304470 0.15677844 15.677844  304470 0.1567784  15.67784
## 2    15 à 24 ans 237555 0.12232240 12.232240  542025 0.2791008  27.91008
## 3    25 à 44 ans 582150 0.29976211 29.976211 1124175 0.5788629  57.88629
## 4    45 à 64 ans 494205 0.25447725 25.447725 1618380 0.8333402  83.33402
## 5    65 à 84 ans 271560 0.13983234 13.983234 1889940 0.9731725  97.31725
## 6 85 ans et plus  52100 0.02682746  2.682746 1942040 1.0000000 100.00000
\end{verbatim}

\hypertarget{sect027}{%
\section{Pour aller un peu plus loin : les statistiques descriptives pondérées}\label{sect027}}

Dans la section \ref{sect025}, les différentes statistiques descriptives sur des variables quantitatives -- paramètres de tendance centrale, de position, de dispersion et de forme -- ont été largement abordées. Il est possible de calculer ces différentes statistiques en tenant compte d'une pondération. La statistique descriptive pondérée la plus connue est certainement la moyenne arithmétique pondérée. Son calcul est très simple; pour chaque observation, deux valeurs sont disponibles :

\begin{itemize}
\tightlist
\item
  \(x_i\), soit la valeur de la variable \(X\) pour l'observation \(i\)
\item
  \(w_i\), soit la valeur de la pondération pour \(i\).
\end{itemize}

Prenez soin de comparer les deux équations ci-dessous (à gauche, la moyenne arithmétique; à droite, la moyenne arithmétique pondérée). Vous constaterez rapidement qu'il suffit simplement de multiplier chaque observation par sa pondération (numérateur) et de diviser ce produit par la somme des pondérations (dénominateur; et non par \(n\), soit le nombre d'observations comme pour la moyenne arithmétique non pondérée).

\begin{equation} 
\bar{x}=\frac{\sum_{i=1}^n x_i}{n} \text { versus } \bar{m}=\frac{\sum_{i=1}^n  w_ix_i}{\sum_{i=1}^nw_i}
\label{eq:moypond}
\end{equation}

\begin{table}

\caption{\label{tab:MoyPondCalcul}Calcul de la moyenne pondérée}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{lrrr}
\toprule
Observation & \$x\_i\$ & \$w\_i\$ & \$x\_i \textbackslash{}times w\_i\$\\
\midrule
1 & 200 & 20 & 4 000\\
2 & 225 & 80 & 18 000\\
3 & 275 & 50 & 13 750\\
4 & 300 & 200 & 60 000\\
Somme & 1 000 & 350 & 95 750\\
\addlinespace
Moyenne & 250 &  & \\
Moyenne pondérée &  &  & 274\\
\bottomrule
\end{tabular}
\end{table}

\begin{bloc_notes}

\textbf{Calcul d'autres statistiques descriptives pondérées}

Nous n'allons pas reporter ici les formules des versions pondérées de toutes les statistiques descriptives. Retenez toutefois le principe suivant permettant de les calculer à partir de l'exemple du tableau \ref{tab:MoyPondCalcul}. Pour la variable \emph{X}, dupliquons respectivement 20, 80, 50, 200 fois les observations 1 à 4. Si nous calculons la moyenne arithmétique sur ces valeurs dupliquées, alors cette valeur sera identique à la celle de la moyenne arithmétique pondérée. Le même principe reposant sur la duplication des valeurs s'applique à l'ensemble des statistiques descriptives.

\end{bloc_notes}

Dans un article récent, Alvarenga et al.~\citeyearpar{de2018accessibilite} évaluent l'accessibilité aux aires de jeux dans les parcs de la Communauté métropolitaine de Montréal (CMM). Pour les 881 secteurs de recensement de la CMM, ils ont calculé la distance à l'aire de jeux la plus proche à travers le réseau de rues. Ce résultat, cartographié à la figure \ref{fig:FigParcCMM}, permet d'avancer le constat suivant : « la quasi-totalité des secteurs de recensement de l'agglomération de Montréal présente des distances de l'aire de jeux la plus proche inférieures à 500 m, alors que les secteurs situés à plus d'un kilomètre d'une aire de jeux sont très majoritairement localisés dans les couronnes
nord et sud de la CMM » \citep[p.~238]{de2018accessibilite}.

Pour chaque secteur de recensement, Alvarenga et al.~\citeyearpar{de2018accessibilite} disposent des données suivantes :

\begin{itemize}
\tightlist
\item
  \(x_i\), soit la distance à l'aire de jeux la plus proche pour le secteur de recensement \emph{i} et
\item
  \(w_i\), la pondération, soit le nombre d'enfants de moins de dix ans.
\end{itemize}

Il est alors possible de calculer les statistiques descriptives de la proximité à l'aire de jeux la plus proche en tenant compte du nombre d'enfants résidant dans chaque secteur de recensement (tableau \ref{tab:MoyPondParc}). Cet exercice permet de conclure que : « {[}\ldots{]} globalement, les enfants ont une bonne accessibilité aux aires de jeux sur le territoire de la CMM. {[}\ldots{]} Les enfants sont en moyenne à un peu plus de 500 m de l'aire de jeux la plus proche (moyenne = 559 ; médiane = 512). Toutefois, les valeurs percentiles extrêmes signalent que respectivement 10\% et 5\% des enfants résident à près de 800 m et à plus de 1000 m de l'aire de jeux la plus proche » \citeyearpar[p.~236]{de2018accessibilite}.

\begin{figure}

{\centering \includegraphics[width=0.85\linewidth]{images/bivariee/BivarieeFigureParc} 

}

\caption{Accessibilité aux aires de jeux par secteur de recensement, Communauté métropolitaine de Montréal, 2016}\label{fig:FigParcCMM}
\end{figure}

\begin{table}

\caption{\label{tab:MoyPondParc}Statistiques de l'aire de jeux la plus proche par secteur de recensement pondérées par la population de moins de 10 ans}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{rrrrrrrrr}
\toprule
N & Moyenne & P5 & P10 & Q1 & Médiane & Q3 & P90 & P95\\
\midrule
881 & 559 & 282 & 327 & 408 & 512 & 640 & 799 & 1 006\\
\bottomrule
\end{tabular}
\end{table}

De nombreux \emph{packages} sont disponibles pour calculer des statistiques pondérées, dont notamment \texttt{Weighted.Desc.Stat} et \texttt{Hmisc} utilisés dans la syntaxe ci-dessous.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(foreign)}
\KeywordTok{library}\NormalTok{(Hmisc)}
\KeywordTok{library}\NormalTok{(Weighted.Desc.Stat)}

\NormalTok{df <-}\StringTok{ }\KeywordTok{read.dbf}\NormalTok{(}\StringTok{"data/bivariee/SR_AireJeux_PopMoins10.dbf"}\NormalTok{)}

\KeywordTok{head}\NormalTok{(df, }\DataTypeTok{n =} \DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     SRNOM PopMoins10 AireJeux
## 1 0659.06        380 600.1921
## 2 0410.02        390 324.4396
## 3 0863.01        325 524.3323
## 4 0734.05        875 574.6682
## 5 0073.00        100 352.9505
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# xi (variable) et wi (pondération)}
\NormalTok{x <-}\StringTok{ }\NormalTok{df}\OperatorTok{$}\NormalTok{AireJeux}
\NormalTok{w <-}\StringTok{ }\NormalTok{df}\OperatorTok{$}\NormalTok{PopMoins10}

\CommentTok{# Calcul des paramètres de position}
\CommentTok{# Moyenne}
\NormalTok{Hmisc}\OperatorTok{::}\KeywordTok{wtd.mean}\NormalTok{(x, w)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 559.8026
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Weighted.Desc.Stat}\OperatorTok{::}\KeywordTok{w.mean}\NormalTok{(x, w)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 559.8026
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Quartiles et percentile}
\NormalTok{Hmisc}\OperatorTok{::}\KeywordTok{wtd.quantile}\NormalTok{(x, }\DataTypeTok{weights=}\NormalTok{w, }\DataTypeTok{probs=}\KeywordTok{c}\NormalTok{(.}\DecValTok{05}\NormalTok{, }\FloatTok{.10}\NormalTok{, }\FloatTok{.25}\NormalTok{, }\FloatTok{.50}\NormalTok{, }\FloatTok{.75}\NormalTok{, }\FloatTok{.90}\NormalTok{, }\FloatTok{.95}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        5%       10%       25%       50%       75%       90%       95% 
##  281.3623  327.3056  406.0759  511.5880  639.4813  798.6559 1011.5493
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Paramètres de dispersion avec le package Weighted.Desc.Stat}
\CommentTok{# Variance, écart-type et coefficient de variation}
\KeywordTok{w.var}\NormalTok{(x,w)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 82818.18
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{w.sd}\NormalTok{(x,w)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 287.7815
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{w.cv}\NormalTok{(x,w)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.5140767
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Paramètres de forme avec le package Weighted.Desc.Stat}
\CommentTok{# Skewness et kurtosis }
\KeywordTok{w.skewness}\NormalTok{(x, w)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4.735351
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{w.kurtosis}\NormalTok{(x, w)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 41.17146
\end{verbatim}

\hypertarget{chap03}{%
\chapter{La magie des graphiques}\label{chap03}}

Dans ce chapitre, nous découvrirons les incroyables capacités graphiques de R. Pour ce faire, nous couvrirons en profondeur les capacités du \emph{package} \textbf{ggplot2} du \textbf{tidyverse}. Il s'agit de loin du meilleur \emph{package} pour réaliser des graphiques selon nous.

\begin{bloc_package}

Dans cette section, nous utiliserons principalement les packages suivants :

\begin{itemize}
\tightlist
\item
  Pour créer des graphiques :

  \begin{itemize}
  \tightlist
  \item
    \textbf{ggplot2}, le seul, l'unique
  \item
    \textbf{ggpubr} pour combiner des graphiques
  \item
    \textbf{ggthemes} thèmes complémentaires pour les graphiques
  \end{itemize}
\item
  Pour les couleurs :

  \begin{itemize}
  \tightlist
  \item
    \textbf{rcolorbrewer} pour avoir accès des palettes de couleurs
  \end{itemize}
\item
  Pour les graphiques spéciaux :

  \begin{itemize}
  \tightlist
  \item
    \textbf{chorddiag} pour construire des graphiques d'accord
  \item
    \textbf{fmsb} pour construire des graphiques ren radar
  \item
    \textbf{treemap} pour construire un graphique \emph{treemap}
  \item
    \textbf{wordcloud2} pour construire un nuage de mots
    fmsb
  \end{itemize}
\item
  Pour les cartes :

  \begin{itemize}
  \tightlist
  \item
    \textbf{classInt} pour calculer les intervalles des classes
  \item
    \textbf{ggsn} pour afficher une échelle
  \item
    \textbf{tmap} pour la cartographie
  \end{itemize}
\item
  Autres \emph{packages} :

  \begin{itemize}
  \tightlist
  \item
    \textbf{dplyr} et \textbf{reshape2} pour manipuler des données
  \item
    \textbf{pdftools} pour extraire les textes des fichiers pdf
  \item
    \textbf{udpipe} pour obtenir des dictionnaires linguistiques
  \item
    \textbf{sf} pour manipuler des \emph{simple feature collection}
  \end{itemize}
\end{itemize}

\end{bloc_package}

\begin{bloc_notes}

\textbf{Qu'est-ce que la visualisation de données ?}

La représentation visuelle de données consiste à transposer des informations en une représentation graphique facilitant la lecture de ces dernières. Il s'agit autant d'un ensemble de méthodes, d'un art que d'un moyen de communication. Voici deux exemples marquants avant de détailler ce propos.

Cette première illustration permet de visualiser le volume de plastique que représente la consommation d'eau en bouteille : 480 milliards de bouteilles vendues en 10 ans ! Ce chiffre astronomique est inimaginable. En revanche, une \href{https://graphics.reuters.com/ENVIRONMENT-PLASTIC/0100B275155/index.html}{montagne de plastique} de 2400 mètres surplombant Manhattan marque davantage les esprits.

\begin{figure}[H]

{\centering \includegraphics[width=0.9\linewidth]{images/magie_graphiques/Drowning-in-Plastic} 

}

\caption{Noyer dans le plastique selon Reuters Graphics}\label{fig:fig3A}
\end{figure}

Ce \href{https://www.maplecroft.com/insights/analysis/84-of-worlds-fastest-growing-cities-face-extreme-climate-change-risks/}{second graphique} représente quatre informations pour 234 villes à travers le monde :

\begin{itemize}
\tightlist
\item
  la croissance démographique (axe des abcisses)
\item
  la vulnérabilité au changement climatique (axes de ordonnées)
\item
  la taille des villes (taille des cercles)
\item
  le continent sur lequel est localisé chaque ville (couleur des cercles).
\end{itemize}

\begin{figure}[H]

{\centering \includegraphics[width=0.7\linewidth]{images/magie_graphiques/climate_change_exposure} 

}

\caption{Changement climatique et vulnérabilité par Verisk Maplecroft}\label{fig:fig3B}
\end{figure}

Le graphique est à la fois très accrocheur et esthétique. En un coup d'œil, on constate que les villes avec une forte croissance démographique sont aussi les plus vénérables (lecture des deux axes) et qu'elles sont surtout localisées en Afrique et secondairement en Asie (en rouge et orange), quelle que soit leur taille (taille du cercle). À l'inverse, les villes européennes et américaines (en bleu) sont beaucoup moins vulnérables aux changements climatiques et avec une croissance démographique plus faible, qu'elles soient des petites, moyennes ou grandes villes.

Souvent négligée, la visualisation de données est perçue comme un tâche triviale : il s'agit simplement de représenter une donnée sous forme d'un graphique car c'est l'option la plus pratique ou prenant le moins de place. Pourtant, les avantages de la visualisation des données sont limites. Par exemple, la visualisation de données intègre aujourd'hui des supports dynamiques comme des animations, des figures interactives ou des applications webs. R offre d'ailleurs des possibilités très intéressantes en la matière avec des \emph{packages} comme \textbf{shiny}, \textbf{plotly}, ou \textbf{leaflet}. Toutefois, nous ne couvrirons pas ici ces méthodes plus récentes en visualisation des données qui devraient faire l'objet d'un autre livre en tant quel tel.

\textbf{Les principaux avantages de la visualisation des données} :

\begin{itemize}
\tightlist
\item
  \textbf{Analyse exploratoire des données} (\emph{exploratory data analysis - EDA} en anglais). Visualiser des données est crucial pour détecter des problèmes en tout genre (données manquantes, valeurs extrêmes ou aberrantes, non respect de conditions d'application de tests statistiques, etc.), mais aussi pour repérer de nouvelles associations entre les variables.
\item
  \textbf{Communication de vos résultats}. La raison d'être d'un graphique est de délivrer un message clair relatif à un résultat obtenu suite à une analyse rigoureuse de vos données. Si votre graphique n'apporte aucune information claire, il vaut mieux ne pas le présenter, le diffuser. Les représentations ne sont pas neutres. Les couleurs et les formes ont des significations particulières en fonction de la culture et du contexte. Posez-vous donc toujours la question : à quel public est destiné le message ? Évitez de surcharger vos visualisation de données, sinon l'essence du message sera perdu.
\item
  \textbf{Aide à la décision}. Une illustration (graphique ou carte) peut être un outil facilitant la prise de décisions.
\end{itemize}

\end{bloc_notes}

\hypertarget{sect031}{%
\section{Philosophie du ggplot2}\label{sect031}}

\textbf{ggplot2} fait partie du \textbf{tidyverse} et dispose donc d'une logique de fonctionnement particulière. Cette dernière se nomme \emph{The Grammar of Graphics} (les deux G sont d'ailleurs à l'origine du nom \textbf{ggplot2}) et a été proposée par Hadley Wickham (le créateur du \textbf{tidyverse} !) dans un article intitulé \emph{A layered grammar of graphics} \citep{wickham2010layered}. Nous proposons de synthétiser ici les concepts et principes centraux qui sous-tendent la production de graphiques avec \textbf{ggplot2}.

\hypertarget{sect0311}{%
\subsection{Une grammaire}\label{sect0311}}

Hadley Wickham propose une grammaire pour unifier la création de graphiques. L'idée est donc de dépasser les simples dénominations comme un nuage de points, un diagramme en boite, un graphique en ligne, etc, pour comprendre ce qui relie tous ces graphiques. Ces éléments communs et centraux sont les géométries, les échelles et systèmes de coordonnées, et les annotations (figure \ref{fig:fig30}) :

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{images/magie_graphiques/composantes} 

}

\caption{Trois composantes d'un graphique, adapté de @wickham2010layered}\label{fig:fig30}
\end{figure}

\begin{itemize}
\tightlist
\item
  Les \textbf{géométries} sont les formes utilisées pour représenter les données. Il peut s'agire de points, lignes, cercles, rectangles, arcs de cercles, etc.
\item
  Les \textbf{échelles et systèmes de coordonnées} permettent de contrôler la localisation des éléments dans un graphique en convertissant les données depuis leur échelle originale (dollars, kilomètres, pourcentages, etc.) vers l'échelle du graphique (pixels).
\item
  Les \textbf{annotations} recoupent l'ensemble des informations complémentaires ajoutées au graphique comme son titre et sous-titre, la source des données, la mention sur les droits d'auteurs, etc.
\end{itemize}

En plus de ces trois éléments, il est bien sûr nécessaire de disposer de \textbf{données}. Ces dernières sont assignées à des dimensions du graphique pour être représentées (notamment les axes \emph{X} et \emph{Y} et la couleur). Cette étape est appelée \textbf{aesthetics mapping} dans \textbf{ggplot2}.

Lorsque l'on combine des données, leur assignation a des dimensions, un type de géométries, des échelles et un système de coordonnées, on obtient un \textbf{calque} (ou \emph{layer}). Un graphique peut comprendre plusieurs calques comme nous le verrons dans les prochaines sections.

Prenons un premier exemple très simple et construisons un nuage de points à partir du jeu de données \emph{iris} fourni de base dans R. Nous allons représenter la relation qui existe entre la longueur et la largeur des sépals de ces fleurs. Pour commencer, nous devons charger le package \textbf{ggplot2} et instancier un graphique avec la fonction \texttt{ggplot}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ggplot2)}
\KeywordTok{data}\NormalTok{(iris)}
\KeywordTok{names}\NormalTok{(iris)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Sepal.Length" "Sepal.Width"  "Petal.Length" "Petal.Width"  "Species"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig31-1} 

}

\caption{Base d'un graphique}\label{fig:fig31}
\end{figure}

Pour le moment, le graphique est vide. La seconde étape consiste à lui ajouter des données (au travers du paramètre \texttt{data}) et à définir les dimensions à associer aux données (avec le paramètre \texttt{mapping} et la fonction \texttt{aes()}). Dans notre cas, nous voulons utiliser les coodonnées \emph{X} pour représenter la largeur des sépals, et les coordonnées \emph{Y} pour représenter la longueur des sépals. Enfin, nous souhaitons représenter les observations par des points, nous utiliserons donc la géométrie \texttt{geom\_point}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width), }\DataTypeTok{data =}\NormalTok{ iris) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig32-1} 

}

\caption{Ajout des dimensions au graphique}\label{fig:fig32}
\end{figure}

Ce graphique ne comprend qu'un seul calque avec une géométrie de type point. Chaque calque est ajouté avec l'opérateur \texttt{+} qui permet de superposer des calques, le dernier apparaissant au dessus des autres. Les arguments \texttt{mapping} et \texttt{data} sont définis ici dans la fonction \texttt{ggplot} et sont donc appliqués à tous les calques qui composeraient le graphique. Il est aussi possible de définir \texttt{mapping} et \texttt{data} au sein des fonctions des géométries :

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width), }\DataTypeTok{data =}\NormalTok{ iris)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig33-1} 

}

\caption{Autre spécification des arguments mapping et data}\label{fig:fig33}
\end{figure}

La troisième étape consiste à ajouter au graphique ses annotations. Pour notre cas, il faudrait ajouter un titre, un sous-titre, et des intitulés plus clairs pour les axes \emph{X} et \emph{Y}, ce qu'il est possible de faire avec la fonction \texttt{labs}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width), }\DataTypeTok{data =}\NormalTok{ iris) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Morphologie des sépals des iris"}\NormalTok{, }\DataTypeTok{subtitle =} \StringTok{"n = 150"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"Longueur des sépals"}\NormalTok{, }
       \DataTypeTok{y =} \StringTok{"Largeur des sépals"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig34-1} 

}

\caption{Ajouter les annotations}\label{fig:fig34}
\end{figure}

\hypertarget{sect0312}{%
\subsection{Les types de géométries}\label{sect0312}}

\textbf{ggplot2} permet d'utiliser un très grand nombre de géométries différentes. Dans le tableau \ref{tab:tablegeometries}, nous avons reporté les principales géométries disponibles afin que vous puissiez vous faire une idée du bestiaire existant. Il ne s'agit que d'un extrait des principales fonctions. Sachez qu'il existe aussi des \emph{packages} proposant des géométries supplémentaires pour compléter \textbf{ggplot2}.

\begin{table}

\caption{\label{tab:tablegeometries}Principales géométries proposée par **ggplot2**}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{ll}
\toprule
Géométrie & Fonction\\
\midrule
point & geom\_point\\
ligne & geom\_line\\
chemin & geom\_path\\
boite à moustache & geom\_boxplot\\
diagramme violon & geom\_violin\\
\addlinespace
histogramme & geom\_histogram\\
barre & geom\_bar\\
densité & geom\_density\\
texte & geom\_label\\
barre d'erreur & geom\_errorbar\\
\addlinespace
surface & geom\_ribbon\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{sect0313}{%
\subsection{L'habillage}\label{sect0313}}

Nous avons montré dans le premier exemple comment rajouter le titre, le sous-titre et le nom des axes sur un graphique. Il est également possible de rajouter un texte sous le graphique (généralement la source des données avec l'argument \texttt{caption}) et des annotations textuelles (\texttt{annotate}). Pour ces dernières, il convient de spécifier leur localisation (cordonnées \texttt{x} et \texttt{y}) et le texte à intégrer (\texttt{label}); elles sont ensuite ajoutées au graphique avec l'opérateur \texttt{+}. Ajoutons deux annotations pour identifier deux fleurs spécifiques.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width), }\DataTypeTok{data =}\NormalTok{ iris) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Morphologie des sépals des iris"}\NormalTok{, }\DataTypeTok{subtitle =} \StringTok{"n = 150"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"Longueur des sépals"}\NormalTok{, }
       \DataTypeTok{y =} \StringTok{"Largeur des sépals"}\NormalTok{,}
       \DataTypeTok{caption =} \StringTok{"source : iris dataset"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{annotate}\NormalTok{(}\StringTok{"text"}\NormalTok{, }\DataTypeTok{x =} \FloatTok{6.7}\NormalTok{, }\DataTypeTok{y =} \FloatTok{2.5}\NormalTok{, }\CommentTok{# position de la note}
           \DataTypeTok{label =} \StringTok{"une virginica"}\NormalTok{,  }\CommentTok{# texte de la note}
           \DataTypeTok{hjust =} \StringTok{"left"}\NormalTok{, }\DataTypeTok{vjust =} \StringTok{"top"}\NormalTok{, }\CommentTok{# ajustement}
           \DataTypeTok{size =} \DecValTok{3}\NormalTok{, }\DataTypeTok{fontface =} \StringTok{"italic"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{annotate}\NormalTok{(}\StringTok{"text"}\NormalTok{, }\DataTypeTok{x =} \FloatTok{5.7}\NormalTok{, }\DataTypeTok{y =} \FloatTok{4.4}\NormalTok{, }\CommentTok{# position de la note}
           \DataTypeTok{label =} \StringTok{"une setosa"}\NormalTok{,  }\CommentTok{# texte de la note}
           \DataTypeTok{hjust =} \StringTok{"left"}\NormalTok{, }\DataTypeTok{vjust =} \StringTok{"top"}\NormalTok{, }\CommentTok{# ajustement}
           \DataTypeTok{size =} \DecValTok{3}\NormalTok{, }\DataTypeTok{fontface =} \StringTok{"italic"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig35-1} 

}

\caption{Ajouter des annotations textuelles}\label{fig:fig35}
\end{figure}

Comme vous pouvez le constater, de nombreux paramètres permettent de contrôler le style des annotations. Pour avoir la liste des arguments disponibles, n'hésitez pas à afficher l'aide de la fonction : \texttt{help(annotate)}.

En plus des annotations de type texte, il est possible d'ajouter des annotations de type géométrique. Nous pourrions ainsi délimiter une boite encadrant les fleurs de l'espère setosa.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{setosas <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(iris, iris}\OperatorTok{$}\NormalTok{Species }\OperatorTok{==}\StringTok{ "setosa"}\NormalTok{)}
\NormalTok{sepal.length_extent <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\KeywordTok{min}\NormalTok{(setosas}\OperatorTok{$}\NormalTok{Sepal.Length),}\KeywordTok{max}\NormalTok{(setosas}\OperatorTok{$}\NormalTok{Sepal.Length))}
\NormalTok{sepal.width_extent <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\KeywordTok{min}\NormalTok{(setosas}\OperatorTok{$}\NormalTok{Sepal.Width),}\KeywordTok{max}\NormalTok{(setosas}\OperatorTok{$}\NormalTok{Sepal.Width))}

\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width), }\DataTypeTok{data =}\NormalTok{ iris) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Morphologie des sépals des iris"}\NormalTok{, }\DataTypeTok{subtitle =} \StringTok{"n = 150"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"Longueur des sépals"}\NormalTok{, }
       \DataTypeTok{y =} \StringTok{"Largeur des sépals"}\NormalTok{,}
       \DataTypeTok{caption =} \StringTok{"source : iris dataset"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{annotate}\NormalTok{(}\StringTok{"text"}\NormalTok{, }\DataTypeTok{x =} \FloatTok{6.7}\NormalTok{, }\DataTypeTok{y =} \FloatTok{2.5}\NormalTok{, }\CommentTok{# position de la note}
           \DataTypeTok{label =} \StringTok{"une virginica"}\NormalTok{,  }\CommentTok{# texte de la note}
           \DataTypeTok{hjust =} \StringTok{"left"}\NormalTok{, }\DataTypeTok{vjust =} \StringTok{"top"}\NormalTok{, }\CommentTok{# ajustement}
           \DataTypeTok{size =} \DecValTok{3}\NormalTok{, }\DataTypeTok{fontface =} \StringTok{"italic"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{annotate}\NormalTok{(}\StringTok{"text"}\NormalTok{, }\DataTypeTok{x =} \FloatTok{5.7}\NormalTok{, }\DataTypeTok{y =} \FloatTok{4.4}\NormalTok{, }\CommentTok{# position de la note}
           \DataTypeTok{label =} \StringTok{"une setosa"}\NormalTok{,  }\CommentTok{# texte de la note}
           \DataTypeTok{hjust =} \StringTok{"left"}\NormalTok{, }\DataTypeTok{vjust =} \StringTok{"top"}\NormalTok{, }\CommentTok{# ajustement}
           \DataTypeTok{size =} \DecValTok{3}\NormalTok{, }\DataTypeTok{fontface =} \StringTok{"italic"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{annotate}\NormalTok{(}\StringTok{"rect"}\NormalTok{, }
           \DataTypeTok{ymin =}\NormalTok{ sepal.width_extent[[}\DecValTok{1}\NormalTok{]],}
           \DataTypeTok{ymax =}\NormalTok{ sepal.width_extent[[}\DecValTok{2}\NormalTok{]],}
           \DataTypeTok{xmin =}\NormalTok{ sepal.length_extent[[}\DecValTok{1}\NormalTok{]],}
           \DataTypeTok{xmax =}\NormalTok{ sepal.length_extent[[}\DecValTok{2}\NormalTok{]],}
           \DataTypeTok{fill =} \KeywordTok{rgb}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{), }\CommentTok{# remplissage transparent}
           \DataTypeTok{color =} \StringTok{"green"}\NormalTok{) }\CommentTok{# contour de couleur verte}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig36-1} 

}

\caption{Ajouter des annotations géométriques}\label{fig:fig36}
\end{figure}

Vous noterez que comme le dernier calque ajouté au graphique est le rectangle, il recouvre tous les calques existant, y compris les précédentes annotations. Pour corriger cela, il suffit de changer l'ordre des calques.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width), }\DataTypeTok{data =}\NormalTok{ iris) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Morphologie des sépals des iris"}\NormalTok{, }\DataTypeTok{subtitle =} \StringTok{"n = 150"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"Longueur des sépals"}\NormalTok{, }
       \DataTypeTok{y =} \StringTok{"Largeur des sépals"}\NormalTok{,}
       \DataTypeTok{caption =} \StringTok{"source : iris dataset"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{annotate}\NormalTok{(}\StringTok{"rect"}\NormalTok{, }
           \DataTypeTok{ymin =}\NormalTok{ sepal.width_extent[[}\DecValTok{1}\NormalTok{]],}
           \DataTypeTok{ymax =}\NormalTok{ sepal.width_extent[[}\DecValTok{2}\NormalTok{]],}
           \DataTypeTok{xmin =}\NormalTok{ sepal.length_extent[[}\DecValTok{1}\NormalTok{]],}
           \DataTypeTok{xmax =}\NormalTok{ sepal.length_extent[[}\DecValTok{2}\NormalTok{]],}
           \DataTypeTok{fill =} \KeywordTok{rgb}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{),  }\CommentTok{# remplissage transparent}
           \DataTypeTok{color =} \StringTok{"green"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\CommentTok{# contour de couleur verte}
\StringTok{  }\KeywordTok{annotate}\NormalTok{(}\StringTok{"text"}\NormalTok{, }\DataTypeTok{x =} \FloatTok{6.7}\NormalTok{, }\DataTypeTok{y =} \FloatTok{2.5}\NormalTok{, }\CommentTok{# position de la note}
           \DataTypeTok{label =} \StringTok{"une virginica"}\NormalTok{,  }\CommentTok{# texte de la note}
           \DataTypeTok{hjust =} \StringTok{"left"}\NormalTok{, }\DataTypeTok{vjust =} \StringTok{"top"}\NormalTok{, }\CommentTok{# ajustement}
           \DataTypeTok{size =} \DecValTok{3}\NormalTok{, }\DataTypeTok{fontface =} \StringTok{"italic"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{annotate}\NormalTok{(}\StringTok{"text"}\NormalTok{, }\DataTypeTok{x =} \FloatTok{5.7}\NormalTok{, }\DataTypeTok{y =} \FloatTok{4.4}\NormalTok{, }\CommentTok{# position de la note}
           \DataTypeTok{label =} \StringTok{"une setosa"}\NormalTok{,  }\CommentTok{# texte de la note}
           \DataTypeTok{hjust =} \StringTok{"left"}\NormalTok{, }\DataTypeTok{vjust =} \StringTok{"top"}\NormalTok{, }\CommentTok{# ajustement}
           \DataTypeTok{size =} \DecValTok{3}\NormalTok{, }\DataTypeTok{fontface =} \StringTok{"italic"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig37-1} 

}

\caption{Gérer l'ordre des annotations}\label{fig:fig37}
\end{figure}

\hypertarget{utiliser-des-thuxe8mes}{%
\subsection{Utiliser des thèmes}\label{utiliser-des-thuxe8mes}}

De nombreux autres éléments peuvent être modifiés dans un graphique comme les paramètres des polices, l'arrière-plan, la grille de repères, etc. Il peut être fastidieux de paramétrer tous ces éléments. Une alternative intéressante est d'utiliser des thèmes déjà préconstruits. \textbf{ggplot2} propose une dizaine de thèmes, constatons leur impact sur le graphique précédent.

\begin{itemize}
\tightlist
\item
  Le thème classique
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width), }\DataTypeTok{data =}\NormalTok{ iris) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Morphologie des sépals des iris"}\NormalTok{, }\DataTypeTok{subtitle =} \StringTok{"n = 150"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"Longueur des sépals"}\NormalTok{, }
       \DataTypeTok{y =} \StringTok{"Largeur des sépals"}\NormalTok{,}
       \DataTypeTok{caption =} \StringTok{"source : iris dataset"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{theme_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig38-1} 

}

\caption{Thème classique}\label{fig:fig38}
\end{figure}

\begin{itemize}
\tightlist
\item
  Le thème gris
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width), }\DataTypeTok{data =}\NormalTok{ iris) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Morphologie des sépals des iris"}\NormalTok{, }\DataTypeTok{subtitle =} \StringTok{"n = 150"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"Longueur des sépals"}\NormalTok{, }
       \DataTypeTok{y =} \StringTok{"Largeur des sépals"}\NormalTok{,}
       \DataTypeTok{caption =} \StringTok{"source : iris dataset"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{theme_gray}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig39-1} 

}

\caption{Thème gris}\label{fig:fig39}
\end{figure}

\begin{itemize}
\tightlist
\item
  Le thème noir et blanc
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width), }\DataTypeTok{data =}\NormalTok{ iris) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Morphologie des sépals des iris"}\NormalTok{, }\DataTypeTok{subtitle =} \StringTok{"n = 150"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"Longueur des sépals"}\NormalTok{, }
       \DataTypeTok{y =} \StringTok{"Largeur des sépals"}\NormalTok{,}
       \DataTypeTok{caption =} \StringTok{"source : iris dataset"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{theme_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig310-1} 

}

\caption{Thème noir et blanc}\label{fig:fig310}
\end{figure}

\begin{itemize}
\tightlist
\item
  Le thème minimal
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width), }\DataTypeTok{data =}\NormalTok{ iris) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Morphologie des sépals des iris"}\NormalTok{, }\DataTypeTok{subtitle =} \StringTok{"n = 150"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"Longueur des sépals"}\NormalTok{, }
       \DataTypeTok{y =} \StringTok{"Largeur des sépals"}\NormalTok{,}
       \DataTypeTok{caption =} \StringTok{"source : iris dataset"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{theme_minimal}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig311-1} 

}

\caption{Thème minimal}\label{fig:fig311}
\end{figure}

Il est aussi possible d'utiliser le \emph{package} \textbf{ggthemes} qui apporte des thèmes complémentaires intéressants dont :

\begin{itemize}
\tightlist
\item
  Le thème tufte (à l'ancienne\ldots)
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ggthemes)}

\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width), }\DataTypeTok{data =}\NormalTok{ iris) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Morphologie des sépals des iris"}\NormalTok{, }\DataTypeTok{subtitle =} \StringTok{"n = 150"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"Longueur des sépals"}\NormalTok{, }
       \DataTypeTok{y =} \StringTok{"Largeur des sépals"}\NormalTok{,}
       \DataTypeTok{caption =} \StringTok{"source : iris dataset"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{theme_tufte}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig312-1} 

}

\caption{Thème tufte}\label{fig:fig312}
\end{figure}

\begin{itemize}
\tightlist
\item
  Le thème economist (inspiré de la revue du même nom)
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width), }\DataTypeTok{data =}\NormalTok{ iris) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Morphologie des sépals des iris"}\NormalTok{, }\DataTypeTok{subtitle =} \StringTok{"n = 150"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"Longueur des sépals"}\NormalTok{, }
       \DataTypeTok{y =} \StringTok{"Largeur des sépals"}\NormalTok{,}
       \DataTypeTok{caption =} \StringTok{"source : iris dataset"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{theme_economist}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig313-1} 

}

\caption{Thème economist}\label{fig:fig313}
\end{figure}

\begin{itemize}
\tightlist
\item
  Le thème solarized (plus original)
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width), }\DataTypeTok{data =}\NormalTok{ iris) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Morphologie des sépals des iris"}\NormalTok{, }\DataTypeTok{subtitle =} \StringTok{"n = 150"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"Longueur des sépals"}\NormalTok{, }
       \DataTypeTok{y =} \StringTok{"Largeur des sépals"}\NormalTok{,}
       \DataTypeTok{caption =} \StringTok{"source : iris dataset"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{theme_solarized}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig314-1} 

}

\caption{Thème solarized}\label{fig:fig314}
\end{figure}

Il en existe bien d'autres et vous pouvez composer vos propres thèmes. N'hésitez pas à explorer la documentation de \textbf{ggplot2} et \textbf{ggthemes} pour en apprendre plus !

\hypertarget{sect0314}{%
\subsection{Composer une figure avec plusieurs graphiques}\label{sect0314}}

Il est très fréquent de vouloir combiner plusieurs graphiques dans une même figure. Deux cas se distinguent :

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Les données pour les différents graphiques proviennent du même \emph{DataFrame} et peuvent être distinguées selon une variables catégorielle. L'objectif est alors de dupliquer le même graphique, mais pour des sous-groupes de données. Dans ce cas, nous recommandons d'utiliser la fonction \texttt{facet\_wrap} de \textbf{ggplot2}.
\item
  Les graphiques sont complètement indépendants. Dans ce cas, nous recommandons d'utiliser la fonction \texttt{ggarrange} du package \textbf{ggpubr}.
\end{enumerate}

\hypertarget{sect03141}{%
\subsubsection{\texorpdfstring{\textbf{ggplot2} et ses facettes}{ggplot2 et ses facettes}}\label{sect03141}}

Nous pourrions souhaiter réaliser une figure composite avec le jeu de données iris et séparer notre nuage de points en trois graphiques distincts selon les espèces des iris. Pour cela, il faut au préalable convertir la variable espèce en facteur.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris}\OperatorTok{$}\NormalTok{Species_fac <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(iris}\OperatorTok{$}\NormalTok{Species)}

\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width), }\DataTypeTok{data =}\NormalTok{ iris) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Morphologie des sépals des iris"}\NormalTok{, }\DataTypeTok{subtitle =} \StringTok{"n = 150"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"Longueur des sépals"}\NormalTok{, }
       \DataTypeTok{y =} \StringTok{"Largeur des sépals"}\NormalTok{,}
       \DataTypeTok{caption =} \StringTok{"source : iris dataset"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\KeywordTok{vars}\NormalTok{(Species_fac), }\DataTypeTok{ncol=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig315-1} 

}

\caption{Graphique à facettes}\label{fig:fig315}
\end{figure}

Notez que le nom de la variable (ici \texttt{Species\_fac}) doit être spécifié au sein d'une sous-fonction \texttt{vars} : \texttt{vars(Species\_fac)}. Nous aurions aussi pu réaliser le graphique sur une seule ligne en spécifiant \texttt{ncol\ =\ 3}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width), }\DataTypeTok{data =}\NormalTok{ iris) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Morphologie des sépals des iris"}\NormalTok{, }\DataTypeTok{subtitle =} \StringTok{"n = 150"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"Longueur des sépals"}\NormalTok{, }
       \DataTypeTok{y =} \StringTok{"Largeur des sépals"}\NormalTok{,}
       \DataTypeTok{caption =} \StringTok{"source : iris dataset"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\KeywordTok{vars}\NormalTok{(Species_fac), }\DataTypeTok{ncol=}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig316-1} 

}

\caption{Graphique à facette en une ligne}\label{fig:fig316}
\end{figure}

\hypertarget{sect03142}{%
\subsubsection{Arranger des graphiques}\label{sect03142}}

La solution avec les facettes est très pratique, mais également très limitée puisqu'elle ne permet pas de créer une figure avec des graphiques combinant plusieurs types de géométries. \texttt{ggarrange} du \emph{package} \textbf{ggpubr} permet tout simplement de combiner des graphiques déjà existant. Créons trois nuages de points comparant plusieurs variables en fonction de l'espèce des iris, puis combinons les. Nous allons également attribuer aux points une couleur en fonction de l'espèce des fleurs afin de mieux les distinguer en associant la variable \texttt{Species} au paramètre \texttt{color}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ggpubr)}

\NormalTok{plot1 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ iris) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width, }\DataTypeTok{color =}\NormalTok{ Species)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{subtitle =} \StringTok{"Caractéristiques des sépals"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"Longueur"}\NormalTok{, }
       \DataTypeTok{y =} \StringTok{"Largeur"}\NormalTok{)}

\NormalTok{plot2 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ iris) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Petal.Length, }\DataTypeTok{y =}\NormalTok{ Petal.Width, }\DataTypeTok{color =}\NormalTok{ Species)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{subtitle =} \StringTok{"Caractéristiques des pétals"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"Longueur"}\NormalTok{, }
       \DataTypeTok{y =} \StringTok{"Largeur"}\NormalTok{)}

\NormalTok{liste_plots <-}\StringTok{ }\KeywordTok{list}\NormalTok{(plot1, plot2)}
\NormalTok{comp_plot <-}\StringTok{ }\KeywordTok{ggarrange}\NormalTok{(}\DataTypeTok{plotlist =}\NormalTok{ liste_plots, }\DataTypeTok{ncol =} \DecValTok{2}\NormalTok{, }\DataTypeTok{nrow =} \DecValTok{1}\NormalTok{,}
          \DataTypeTok{common.legend =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{legend =} \StringTok{"bottom"}\NormalTok{) }\CommentTok{#gérer la légende}

\KeywordTok{annotate_figure}\NormalTok{(comp_plot,}
                \DataTypeTok{top =} \KeywordTok{text_grob}\NormalTok{(}\StringTok{"Morphologie des sépals et pétals chez des iris"}\NormalTok{,}
                                \DataTypeTok{face =} \StringTok{"bold"}\NormalTok{, }\DataTypeTok{size =} \DecValTok{12}\NormalTok{, }\DataTypeTok{just =} \StringTok{"center"}\NormalTok{),}
                \DataTypeTok{bottom =} \KeywordTok{text_grob}\NormalTok{(}\StringTok{"source : iris dataset"}\NormalTok{,}
                                \DataTypeTok{face =} \StringTok{"italic"}\NormalTok{, }\DataTypeTok{size =} \DecValTok{8}\NormalTok{, }\DataTypeTok{just =} \StringTok{"left"}\NormalTok{)}
                
\NormalTok{                )}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig317-1} 

}

\caption{Figure avec plusieurs graphiques avec ggarrange}\label{fig:fig317}
\end{figure}

Vous constaterez que quatre étapes sont nécessaires :

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Créer les graphiques et les enregistrer dans des objets (ici \emph{plot1} et \emph{plot2}).
\item
  Encapsuler ces objets dans une liste (ici \emph{liste\_plots}).
\item
  Composer la figure finale avec la fonction \texttt{ggarrange}.
\item
  Ajouter les annotations à la figure composite.
\end{enumerate}

L'argument \texttt{common.legend} permet d'indiquer à la fonction \texttt{ggarrange} de regrouper les légendes des deux graphiques. Dans notre cas, les deux graphiques ont les mêmes légendes, il est donc judicieux de les regrouper. L'argument \texttt{legend} contrôle la position de la légende, et peut prendre les valeurs : \emph{top}, \emph{bottom}, \emph{left}, \emph{right} ou \emph{none} (absence de légende). La fonction \texttt{annotate\_figure} permet d'ajouter des éléments de texte au-dessus, au-dessous et sur les cotés de la figure composite.

\hypertarget{sect0315}{%
\subsection{La couleur}\label{sect0315}}

Dans un graphique, la couleur peut être utilisée à la fois pour représenter une variable quantitative (dégradé de couleur ou discrétisation), ou une variable qualitative (couleur par catégorie). Dans \textbf{ggplot2}, il est possible d'attribuer une couleur au contour des géométries avec l'argument \texttt{color} et au remplissage avec l'argument \texttt{fill}. Il est possible de spécifier une couleur de trois façons dans R :

\begin{itemize}
\tightlist
\item
  En utilisant le nom de la couleur dans une chaîne de caractère : \texttt{"chartreuse4"}. R dispose 657 noms de couleurs prédéfinis. Pour tous les afficher, utilisez la fonction \texttt{colors()} qui permet de les visualiser (figure \ref{fig:figcolors}) .
\end{itemize}

\begin{figure}

{\centering \includegraphics[width=0.85\linewidth]{images/magie_graphiques/all_colors} 

}

\caption{Couleurs de base}\label{fig:figcolors}
\end{figure}

\begin{itemize}
\item
  En indiquant le code hexadécimal de la couleur. Il s'agit d'une suite de six lettres et de chiffres précédée par un dièse : \texttt{"\#99ff33"}
\item
  En utilisant une notation RGB (rouge, vert, bleu). Cette notation doit contenir quatre nombres entre 0 et 1 (0\% et 100\%), le premier indiquant la quantité de rouge, le second de vert, le troisième de bleu, et le quatrième la transparence. Ces quatres nombres sont donnés comme argument à la fonction \texttt{rgb} : \texttt{rgb(0.6,\ 1,\ 0.2,\ 0)}.
\end{itemize}

Le choix des couleurs est un problème plus complexe que la manière de les spécifier. Il existe d'ailleurs tout un pan de la sémiologie graphique dédié à la question du choix et de l'association des couleurs. Une première ressource intéressante est \href{https://colorbrewer2.org/\#type=sequential\&scheme=BuGn\&n=3}{ColorBrewer}. Il s'agit d'une sélection de palettes de couleurs particulièrements efficaces et dont certaines sont mêmes adaptées pour les personnes daltoniennes. Il est possible d'accéder directement aux palettes dans R grâce au package \textbf{RColorBrewer} et la fonction \texttt{brewer.pal} :

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(RColorBrewer)}

\KeywordTok{display.brewer.all}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.85\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/figcolorBrewer-1} 

}

\caption{palette de couleurs de ColorBrewer}\label{fig:figcolorBrewer}
\end{figure}

Une autre ressource pertinente est le site web \href{https://coolors.co/palettes/trending}{coolors.co} qui propose de nombreuses palettes à portée de clic.

\hypertarget{sect032}{%
\section{Principaux graphiques}\label{sect032}}

\begin{bloc_objectif}

Puisque vous êtes désormais initié aux bases de la grammaire des graphiques implémentées par \textbf{ggplot2}, vous apprendrez dans les sous-sections suivantes à construire les principaux graphiques que vous utiliserez régulièrement et/ou que vous retrouverez présenter dans un article scientifique.

\end{bloc_objectif}

\hypertarget{sect0321}{%
\subsection{Histogramme}\label{sect0321}}

L'histogramme permet de décrire graphiquement la forme de la distribution d'une variable. Pour le réaliser, on utilise la fonction \texttt{geom\_histogram}. Le paramètre le plus important est le nombre de barres (\texttt{bins}) qui composent l'histogramme. Plus ce nombre est grand, plus l'histogramme est précis et à l'inverse, plus il est petit, plus l'histogramme est simplifié. En revanche, il faut éviter d'utiliser un nombre de barres trop élevé comparativement au nombre d'observations disponibles dans le jeu de données, sinon votre histogramme sera plein de trous.

\hypertarget{sect03211}{%
\subsubsection{histogrammes simples}\label{sect03211}}

Générons quatre variables ayant respectivement une distribution Gaussienne, Student, Gamma et Beta, puis réalisons un histogramme pour chacune de ces variables et combinons les avec la fonction \texttt{ggarrange}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{distribs <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}
  \DataTypeTok{gaussien =} \KeywordTok{rnorm}\NormalTok{(}\DecValTok{1000}\NormalTok{, }\DataTypeTok{mean =} \DecValTok{5}\NormalTok{, }\DataTypeTok{sd =} \FloatTok{1.5}\NormalTok{),}
  \DataTypeTok{gamma =} \KeywordTok{rgamma}\NormalTok{(}\DecValTok{1000}\NormalTok{, }\DataTypeTok{shape =} \DecValTok{2}\NormalTok{, }\DataTypeTok{rate =} \DecValTok{12}\NormalTok{),}
  \DataTypeTok{beta =} \KeywordTok{rbeta}\NormalTok{(}\DecValTok{1000}\NormalTok{,}\DataTypeTok{shape1 =} \DecValTok{5}\NormalTok{, }\DataTypeTok{shape2 =} \DecValTok{1}\NormalTok{, }\DataTypeTok{ncp =} \DecValTok{2}\NormalTok{),}
  \DataTypeTok{student =} \KeywordTok{rt}\NormalTok{(}\DecValTok{1000}\NormalTok{,}\DataTypeTok{ncp =} \DecValTok{20}\NormalTok{, }\DataTypeTok{df =} \DecValTok{5}\NormalTok{)}
\NormalTok{)}

\NormalTok{plot1 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ distribs) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ gaussien), }\DataTypeTok{bins =} \DecValTok{50}\NormalTok{, }\DataTypeTok{color =} \StringTok{"#343a40"}\NormalTok{, }\DataTypeTok{fill =} \StringTok{"#e63946"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{ylim}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{130}\NormalTok{))}

\NormalTok{plot2 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ distribs) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ gamma), }\DataTypeTok{bins =} \DecValTok{50}\NormalTok{, }\DataTypeTok{color =} \StringTok{"#343a40"}\NormalTok{, }\DataTypeTok{fill =} \StringTok{"#f1faee"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{ylim}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{130}\NormalTok{))}

\NormalTok{plot3 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ distribs) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ beta), }\DataTypeTok{bins =} \DecValTok{50}\NormalTok{, }\DataTypeTok{color =} \StringTok{"#343a40"}\NormalTok{, }\DataTypeTok{fill =} \StringTok{"#a8dadc"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{ylim}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{130}\NormalTok{))}

\NormalTok{plot4 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ distribs) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ student), }\DataTypeTok{bins =} \DecValTok{50}\NormalTok{, }\DataTypeTok{color =} \StringTok{"#343a40"}\NormalTok{, }\DataTypeTok{fill =} \StringTok{"#1d3557"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{ylim}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{130}\NormalTok{))}

\NormalTok{histogrammes <-}\StringTok{ }\KeywordTok{list}\NormalTok{(plot1, plot2, plot3, plot4)}

\KeywordTok{ggarrange}\NormalTok{(}\DataTypeTok{plotlist =}\NormalTok{ histogrammes, }\DataTypeTok{ncol =} \DecValTok{2}\NormalTok{, }\DataTypeTok{nrow =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig318-1} 

}

\caption{Histogrammes}\label{fig:fig318}
\end{figure}

Notez que cette syntaxe est très lourde. Dans le cas présent, il serait plus judicieux d'utiliser la fonction \texttt{facet\_wrap}. Pour cela, nous devons au préalable empiler nos données, ce qui signifie changer la forme du \emph{dataframe} actuel qui comprend quatre colonnes (gaussien, gamma, beta et student) et 1000 observations, pour qu'il n'ait plus que deux colonnes (la valeur originale et le nom de l'ancienne colonne) et 4000 observations. La figure \ref{fig:fig319} décrit graphiquement ce processus qui peut être effectué avec la fonction \texttt{melt} du \emph{package} \textbf{reshape2}.

\begin{figure}

{\centering \includegraphics[width=0.3\linewidth]{images/magie_graphiques/melting} 

}

\caption{Empiler les données d'un dataframe}\label{fig:fig319}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(reshape2)}

\CommentTok{#faire fondre le jeu de données}
\NormalTok{melted_distribs <-}\StringTok{ }\KeywordTok{melt}\NormalTok{(distribs, }\DataTypeTok{measure.vars =} \KeywordTok{c}\NormalTok{(}\StringTok{"gaussien"}\NormalTok{, }\StringTok{"gamma"}\NormalTok{,}
                                                   \StringTok{"beta"}\NormalTok{,}\StringTok{"student"}\NormalTok{))}
\CommentTok{#renommer les colonnes du nouveau dataframe}
\KeywordTok{names}\NormalTok{(melted_distribs) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"distribution"}\NormalTok{, }\StringTok{"valeur"}\NormalTok{)}
\CommentTok{#convertir la variable catégorielle en facteur}
\NormalTok{melted_distribs}\OperatorTok{$}\NormalTok{distribution <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(melted_distribs}\OperatorTok{$}\NormalTok{distribution)}

\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ melted_distribs)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ valeur, }\DataTypeTok{fill =}\NormalTok{ distribution), }\DataTypeTok{bins =} \DecValTok{50}\NormalTok{, }\DataTypeTok{color =} \StringTok{"#343a40"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{ylim}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{130}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"valeur"}\NormalTok{, }
       \DataTypeTok{y =} \StringTok{"fréquence"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_fill_manual}\NormalTok{(}\DataTypeTok{values =} \KeywordTok{c}\NormalTok{(}\StringTok{"#e63946"}\NormalTok{,}\StringTok{"#f1faee"}\NormalTok{,}\StringTok{"#a8dadc"}\NormalTok{,}\StringTok{"#1d3557"}\NormalTok{))}\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\KeywordTok{vars}\NormalTok{(distribution), }\DataTypeTok{ncol=}\DecValTok{2}\NormalTok{, }\DataTypeTok{scales =} \StringTok{"free"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig320-1} 

}

\caption{Histogrammes en facettes}\label{fig:fig320}
\end{figure}

\hypertarget{sect03212}{%
\subsubsection{histogrammes de densité}\label{sect03212}}

Les histogrammes que nous venons de construire utilisent les fréquences des observations pour délimiter la hauteur des barres. Il est possible de changer ce comportement pour plutôt utiliser la densité. L'intérêt est notamment de se rapprocher encore de la définition d'une distribution puisqu'avec cette configuration la somme totale de la surface de l'histogramme est égale à 1. La hauteur de chaque barre représente alors la probabilité d'obtenir l'étendue de valeurs représentées par cette barre. Prenons pour exemple la variable avec la distribution normale que nous venons de voir.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plot1 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ distribs) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ gaussien, }\DataTypeTok{y =}\NormalTok{ ..density..),}
                 \DataTypeTok{bins =} \DecValTok{30}\NormalTok{, }\DataTypeTok{color =} \StringTok{"#343a40"}\NormalTok{, }\DataTypeTok{fill =} \StringTok{"#1d3557"}\NormalTok{)}

\NormalTok{plot2 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ distribs) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ gaussien, }\DataTypeTok{y =}\NormalTok{ ..count..),}
                 \DataTypeTok{bins =} \DecValTok{30}\NormalTok{, }\DataTypeTok{color =} \StringTok{"#343a40"}\NormalTok{, }\DataTypeTok{fill =} \StringTok{"#a8dadc"}\NormalTok{)}

\KeywordTok{ggarrange}\NormalTok{(}\DataTypeTok{plotlist =} \KeywordTok{list}\NormalTok{(plot1, plot2), }\DataTypeTok{ncol =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig321-1} 

}

\caption{Histogrammes de densité}\label{fig:fig321}
\end{figure}

Le graphique de droite (fréquence) nous indique donc que plus de 100 observations ont une valeur d'environ 5 (entre 4,76 et 5,34, compte tenu de la largeur de la barre), ce qui se traduit par une probabilité de presque 30\% d'obtenir cette valeur en tirant une observation au hasard dans le jeu de données.

\hypertarget{sect03213}{%
\subsubsection{Histogramme avec courbe de distribution}\label{sect03213}}

Les histogrammes sont souvent utilisés pour vérifier graphiquement si une distribution empirique s'approche d'une courbe normale. Pour cela, on rajoute sur l'histogramme de la variable empirique la forme qu'aurait une distribution normale parfaite en utilisant la moyenne et l'écart type de la distribution empirique. Pour créer cette figure dans \textbf{ggplot2}, il suffit d'utiliser la fonction \texttt{stat\_function} pour créer un nouveau calque. Pour faire bonne mesure, il est aussi possible d'ajouter une ligne verticale (\texttt{geom\_vline}) pour indiquer la moyenne de la distribution.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{moyenne <-}\StringTok{ }\KeywordTok{mean}\NormalTok{(distribs}\OperatorTok{$}\NormalTok{gaussien)}
\NormalTok{ecart_type <-}\StringTok{ }\KeywordTok{sd}\NormalTok{(distribs}\OperatorTok{$}\NormalTok{gaussien)}

\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ distribs) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ gaussien, }\DataTypeTok{y =}\NormalTok{ ..density..),}
                 \DataTypeTok{bins =} \DecValTok{30}\NormalTok{, }\DataTypeTok{color =} \StringTok{"#343a40"}\NormalTok{, }\DataTypeTok{fill =} \StringTok{"#a8dadc"}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"gaussien"}\NormalTok{, }
       \DataTypeTok{y =} \StringTok{"densité"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{stat_function}\NormalTok{(}\DataTypeTok{fun =}\NormalTok{ dnorm, }\DataTypeTok{args =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{mean =}\NormalTok{ moyenne, }\DataTypeTok{sd =}\NormalTok{ ecart_type), }
                \DataTypeTok{color =} \StringTok{"#e63946"}\NormalTok{, }\DataTypeTok{size =} \FloatTok{1.2}\NormalTok{, }\DataTypeTok{linetype =} \StringTok{"dashed"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_vline}\NormalTok{(}\DataTypeTok{xintercept =}\NormalTok{ moyenne, }\DataTypeTok{color =} \StringTok{'red'}\NormalTok{, }\DataTypeTok{size =} \DecValTok{1}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{annotate}\NormalTok{(}\StringTok{"text"}\NormalTok{, }\DataTypeTok{x =} \KeywordTok{round}\NormalTok{(moyenne,}\DecValTok{2}\NormalTok{)}\OperatorTok{+}\FloatTok{0.5}\NormalTok{, }\DataTypeTok{y =} \FloatTok{0.31}\NormalTok{, }\DataTypeTok{hjust =} \StringTok{'left'}\NormalTok{,}
           \DataTypeTok{label =} \KeywordTok{paste}\NormalTok{(}\StringTok{'moyenne : '}\NormalTok{,}\KeywordTok{round}\NormalTok{(moyenne,}\DecValTok{2}\NormalTok{),}\DataTypeTok{sep=}\StringTok{''}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig322-1} 

}

\caption{Histogrammes et courbe normale}\label{fig:fig322}
\end{figure}

Dans notre cas, nous savons que notre variable est normalement distribuée (car produite avec la fonction \texttt{rnorm}), et l'on peut constater la grande proximité entre l'histogramme et la courbe normale.

\hypertarget{sect03214}{%
\subsubsection{Histogramme avec coloration des valeurs extrêmes}\label{sect03214}}

Il peut être nécessaire d'attirer le regard sur certaines parties de l'histogramme, comme par exemple des valeurs extrêmes. Si nous reprenons notre distribution de Student, nous pouvons clairement distinguer un ensemble de valeurs fortes à droite de la distribution. On pourrait dans notre cas considérer que des valeurs au delà de 50 constituent des cas extrêmes que nous souhaitons représenter dans une autre couleur. Pour cela, nous devons créer une variable catégorielle nous permettant de distinguer ces cas particuliers.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{distribs}\OperatorTok{$}\NormalTok{cas_extreme <-}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(distribs}\OperatorTok{$}\NormalTok{student }\OperatorTok{>=}\DecValTok{50}\NormalTok{, }\StringTok{"extrême", "}\NormalTok{normal}\StringTok{")}

\StringTok{ggplot(data = distribs) +}
\StringTok{  geom_histogram(aes(x = student, y = ..count.., fill = cas_extreme),}
\StringTok{                 bins = 30, color = "}\CommentTok{#343a40")+}
  \KeywordTok{scale_fill_manual}\NormalTok{(}\StringTok{'cas extrême', values = c("#a8dadc","#e63946"))+}
\StringTok{  labs(title = '}\NormalTok{Distribution de Student}\StringTok{',x = "", y = "fréquence")}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig323-1} 

}

\caption{Histogramme coloré}\label{fig:fig323}
\end{figure}

\hypertarget{sect0322}{%
\subsection{Graphique de densité}\label{sect0322}}

L'histogramme est utilisé pour approximer graphiquement la distribution d'une variable. Sa principale limite est de représenter la variable de façon discontinue. Une alternative intéressante est d'utiliser à la place de l'histogramme une version lissée de celui-ci : le graphique de densité. Cette opération de lissage est réalisée le plus souvent à partir de fonctions \emph{kernel}. Reconstruisons notre figure avec les quatres distributions, mais en utilisant cette fois-ci des graphiques de densité.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ melted_distribs)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_density}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ valeur, }\DataTypeTok{fill =}\NormalTok{ distribution), }\DataTypeTok{color =} \StringTok{"#343a40"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_fill_manual}\NormalTok{(}\DataTypeTok{values =} \KeywordTok{c}\NormalTok{(}\StringTok{"#e63946"}\NormalTok{,}\StringTok{"#f1faee"}\NormalTok{,}\StringTok{"#a8dadc"}\NormalTok{,}\StringTok{"#1d3557"}\NormalTok{))}\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\KeywordTok{vars}\NormalTok{(distribution), }\DataTypeTok{ncol=}\DecValTok{2}\NormalTok{, }\DataTypeTok{scales =} \StringTok{"free"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig324-1} 

}

\caption{Graphiques de densité en facette}\label{fig:fig324}
\end{figure}

Les graphiques de densité sont souvent utilisés pour comparer la distribution d'une variable pour plusieurs sous groupe d'une population. Si nous reprenons le jeu de données iris, nous pouvons comparer les longueurs de sépals en fonction des espèces. On constate ainsi que les setosa ont une nette tendance à avoir des sépals plus courts et qu'à l'inverse, les virginca ont les sépals généralement les plus longs.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ iris)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_density}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{fill =}\NormalTok{ Species), }
               \DataTypeTok{color =} \StringTok{"#343a40"}\NormalTok{, }\DataTypeTok{alpha =} \FloatTok{0.4}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{'Longueur de sépals'}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{''}\NormalTok{,}
       \DataTypeTok{fill =} \StringTok{'Espèce'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig325-1} 

}

\caption{Graphiques de densité}\label{fig:fig325}
\end{figure}

\hypertarget{sect0323}{%
\subsection{Nuage de points}\label{sect0323}}

Un nuage de points est un outil très intéressant pour visualiser la relation existante entre deux variables. Prenons un exemple concret et analysons le volume de CO2 produit annuellement par habitant dans l'ensemble des pays à travers le monde en comparaison avec le niveau d'urbanisation de ces pays. Nous avons extrait ces données sur le site web de la \href{https://donnees.banquemondiale.org/indicateur}{Banque Mondiale}, puis nous les avons structuré dans un fichier \emph{csv}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data_co2 <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/graphique/world_urb_co2.csv"}\NormalTok{)}
\KeywordTok{names}\NormalTok{(data_co2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "country_code" "year"         "Population"   "Urbanisation" "CO2_kt"      
## [6] "Country.Name" "CO2t_hab"     "region7"      "region23"
\end{verbatim}

\hypertarget{sect03231}{%
\subsubsection{Nuage de points simple}\label{sect03231}}

Commençons par un nuage de points simple avec l'ensemble des données.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ data_co2)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Urbanisation, }\DataTypeTok{y =}\NormalTok{ CO2t_hab))}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Niveau d'urbanisation (%)"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{'tonnes de CO2 annuelle / habitant'}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{'Relation entre urbanisation et production de CO2 par habitant'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig326-1} 

}

\caption{Nuage de points simple}\label{fig:fig326}
\end{figure}

À la première lecture de ce graphique, on observe immédiatement un ensemble de points étranges dont le volume de CO2 par habitant annuel est compris entre 150 et plus de 350 tonnes et dont le niveau d'urbanisation est proche de 50\%. Isolons ces données pour observer de quoi il s'agit.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cas_etrange <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(data_co2, data_co2}\OperatorTok{$}\NormalTok{CO2t_hab }\OperatorTok{>=}\StringTok{ }\DecValTok{150}\NormalTok{)}
\KeywordTok{print}\NormalTok{(cas_etrange}\OperatorTok{$}\NormalTok{Country.Name)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "Aruba" "Aruba" "Aruba" "Aruba" "Aruba" "Aruba" "Aruba" "Aruba" "Aruba"
## [10] "Aruba" "Aruba" "Aruba" "Aruba" "Aruba" "Aruba" "Aruba" "Aruba" "Aruba"
## [19] "Aruba" "Aruba" "Aruba" "Aruba" "Aruba" "Aruba" "Aruba"
\end{verbatim}

Il s'agit d'une petite île néerlandaise des Caraïbes nommée Aruba disposant d'une faible population mais avec des activités très polluantes (raffinerie et extraction d'or). Nous faisons ici le choix de retirer ces observations puisqu'elles sont assez peu représentatives de la tendance mondiale. {Cette démarche si simple relève ainsi de l'analyse exploratoire des données ! Sans ce graphique, nous n'aurions probablement jamais identifié ces cas problématiques.}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data_co2 <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(data_co2, data_co2}\OperatorTok{$}\NormalTok{CO2t_hab }\OperatorTok{<=}\StringTok{ }\DecValTok{150}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Reconstruisons le nuage de points maintenant que ces données aberrantes ont été retirées.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ data_co2)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Urbanisation, }\DataTypeTok{y =}\NormalTok{ CO2t_hab))}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Niveau d'urbanisation (%)"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{'tonnes de CO2 annuelle / habitant'}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{'Relation entre urbanisation et production de CO2 par habitant'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig327-1} 

}

\caption{Nuage de points simple sans données aberrantes}\label{fig:fig327}
\end{figure}

Voilà qui est mieux ! Cependant, le grand nombre de points restant rend la lecture du graphique assez difficile puisqu'ils se superposent. Une première option à envisager dans ce cas est à la fois d'ajouter de la transparence aux points et de réduire leur taille :

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ data_co2)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Urbanisation, }\DataTypeTok{y =}\NormalTok{ CO2t_hab), }\DataTypeTok{alpha =} \FloatTok{0.2}\NormalTok{, }\DataTypeTok{size =} \FloatTok{0.5}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Niveau d'urbanisation (%)"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{'tonnes de CO2 annuelle / habitant'}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{'Relation entre urbanisation et production de CO2 par habitant'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig328-1} 

}

\caption{Nuage de points simple avec transparence}\label{fig:fig328}
\end{figure}

\hypertarget{sect03232}{%
\subsubsection{Nuage de points avec densité}\label{sect03232}}

Bien que la transparence nous aide un peu à distinguer les secteurs du graphique avec le plus de points, il serait plus efficace d'abandonner la géométrie des points pour la remplacer par une géométrie de densité en deux dimensions. Une première approche consiste à diviser l'espace du graphique en petits carrés et à compter le nombre de points tombant dans chaque carré (en somme, un histogramme en deux dimensions).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ data_co2)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_bin2d}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Urbanisation, }\DataTypeTok{y =}\NormalTok{ CO2t_hab), }\DataTypeTok{bins =} \DecValTok{50}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_fill_continuous}\NormalTok{(}\DataTypeTok{type =} \StringTok{"viridis"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Niveau d'urbanisation (%)"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{'tonnes de CO2 annuelle / habitant'}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{'Relation entre urbanisation et production de CO2 par habitant'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig329-1} 

}

\caption{Densité en deux dimensions par carrés}\label{fig:fig329}
\end{figure}

On observe ainsi une forte concentration dans le bas du graphique, les pays avec des rejets annuels de CO2 supérieurs à 15 tonnes par habitant sont relativement rares. Pour les personnes préférant les représentations plus élaborées, il est aussi possible de diviser l'espace du graphique avec des hexagones en utilisant le package \textbf{hexbin}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ data_co2)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_hex}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Urbanisation, }\DataTypeTok{y =}\NormalTok{ CO2t_hab), }\DataTypeTok{bins =} \DecValTok{50}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_fill_continuous}\NormalTok{(}\DataTypeTok{type =} \StringTok{"viridis"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Niveau d'urbanisation (%)"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{'tonnes de CO2 annuelle / habitant'}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{'Relation entre urbanisation et production de CO2 par habitant'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig330-1} 

}

\caption{Densité en deux dimensions par hexagones}\label{fig:fig330}
\end{figure}

Enfin, il est aussi possible de réaliser une version lissée de ces graphiques avec une fonction \emph{kernel} en deux dimensions (\texttt{stat\_density\_2d}) :

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ data_co2)}\OperatorTok{+}
\StringTok{  }\KeywordTok{stat_density_2d}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Urbanisation, }\DataTypeTok{y =}\NormalTok{ CO2t_hab, }\DataTypeTok{fill =}\NormalTok{ ..density..), }
                  \DataTypeTok{geom =} \StringTok{"raster"}\NormalTok{, }\DataTypeTok{n =} \DecValTok{50}\NormalTok{, }\DataTypeTok{contour =} \OtherTok{FALSE}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_fill_continuous}\NormalTok{(}\DataTypeTok{type =} \StringTok{"viridis"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Niveau d'urbanisation (%)"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{'tonnes de CO2 annuelle / habitant'}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{'Relation entre urbanisation et production de CO2 par habitant'}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{ylim}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig331-1} 

}

\caption{Densité en deux dimensions lissée}\label{fig:fig331}
\end{figure}

\hypertarget{sect03233}{%
\subsubsection{Nuage de points et droite de régression}\label{sect03233}}

Afin de faire ressortir une éventuelle relation entre les variables représentées sur les deux axes, il est possible d'afficher la droite de régression sur le graphique entre X et Y. Cette opération s'effectue avec la fonction \texttt{geom\_smooth}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ data_co2)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Urbanisation, }\DataTypeTok{y =}\NormalTok{ CO2t_hab), }\DataTypeTok{alpha =} \FloatTok{0.2}\NormalTok{, }\DataTypeTok{size =} \FloatTok{0.5}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Urbanisation, }\DataTypeTok{y =}\NormalTok{ CO2t_hab), }\DataTypeTok{method =}\NormalTok{ lm, }\DataTypeTok{color =} \StringTok{"red"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Niveau d'urbanisation (%)"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{'tonnes de CO2 annuelle / habitant'}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{'Relation entre urbanisation et production de CO2 par habitant'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig332-1} 

}

\caption{Nuage de points avec droite de régression}\label{fig:fig332}
\end{figure}

Notez que l'argument \texttt{method\ =\ lm} permet d'indiquer que nous souhaitons utiliser une régression linéaire (\emph{linear model}) pour tracer la géométrie (une droite de régression). La droite semble bien indiquer une relation positive entre les deux variables : une augmentation de l'urbanisation serait associée avec une augmentation de la production annuelle de CO2 par habitant. On pourrait également vérifier si une relation non linéaire serait plus adaptée au jeu de données. Dans notre cas, une relation quadratique pourrait produire un meilleur ajustement.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ data_co2)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Urbanisation, }\DataTypeTok{y =}\NormalTok{ CO2t_hab), }\DataTypeTok{alpha =} \FloatTok{0.2}\NormalTok{, }\DataTypeTok{size =} \FloatTok{0.7}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Urbanisation, }\DataTypeTok{y =}\NormalTok{ CO2t_hab), }\DataTypeTok{method =}\NormalTok{ lm, }
              \DataTypeTok{color =} \StringTok{"red"}\NormalTok{, }\DataTypeTok{formula =}\NormalTok{ y }\OperatorTok{~}\StringTok{ }\KeywordTok{I}\NormalTok{(x}\OperatorTok{**}\DecValTok{2}\NormalTok{))}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Niveau d'urbanisation (%)"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{'tonnes de CO2 annuelle / habitant'}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{'Relation entre urbanisation et production de CO2 par habitant'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig333-1} 

}

\caption{Nuage de points avec droite de régression exponentielle}\label{fig:fig333}
\end{figure}

La régression quadratique (avec \emph{x} au carré) nous indique ainsi que l'impact du niveau d'urbanisation est plus important à mesure que le niveau d'urbanisation augmente. Vous pouvez également constater que la courbe ne prédit pas de valeurs négatives comparativement à la droite précédente. Il est égalemment possible d'ajuster une courbe sans choisir au préalable sa forme (dans le cas précédent \(x^2\)) en utilisant une méthode d'ajustement local appelée \emph{loess}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ data_co2)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Urbanisation, }\DataTypeTok{y =}\NormalTok{ CO2t_hab), }\DataTypeTok{alpha =} \FloatTok{0.2}\NormalTok{, }\DataTypeTok{size =} \FloatTok{0.5}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Urbanisation, }\DataTypeTok{y =}\NormalTok{ CO2t_hab), }\DataTypeTok{method =}\NormalTok{ loess, }
              \DataTypeTok{color =} \StringTok{"red"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Niveau d'urbanisation (%)"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{'tonnes de CO2 annuelle / habitant'}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{'Relation entre urbanisation et production de CO2 par habitant'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig334-1} 

}

\caption{Nuage de points avec droite de régression non linéaire}\label{fig:fig334}
\end{figure}

La relation non linéaire révèle davantage d'informations : l'augmentation de l'urbanisation est associée à une augmentation de l'émission de CO2 par habitant uniquement jusqu'à 75\% d'urbanisation; au-delà de ce seuil, la relation ne tient plus. Ces résultats semblent cohérents avec l'évolution classique de l'économie d'un pays passant progressivement d'une économie agricole, à une économie industrialisée et finalement une économie de services.

\hypertarget{sect0324}{%
\subsection{Graphique en lignes}\label{sect0324}}

Un graphique en ligne permet de représenter l'évolution d'une variable, généralement dans le temps. Dans le jeu de données précédent, nous disposons des émissions de CO2 par habitant de nombreux pays sur plusieurs années. Nous pouvons ainsi représenter l'évolution des émissions pour chaque pays avec un graphique en ligne. Pour éviter de le surcharger, cet exercice est réalisé uniquement sur les pays de l'Europe de l'Ouest.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# conversion de la variable year textuelle en variable numérique}
\NormalTok{data_co2}\OperatorTok{$}\NormalTok{an <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(data_co2}\OperatorTok{$}\NormalTok{year)}
\CommentTok{# extraction des données d'Europe de l'Ouest}
\NormalTok{data_europe <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(data_co2, data_co2}\OperatorTok{$}\NormalTok{region23 }\OperatorTok{==}\StringTok{ "Western Europe"}\NormalTok{)}
\CommentTok{# choix des valeurs pour l'axe des x}
\NormalTok{x_ticks <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DecValTok{1960}\NormalTok{,}\DecValTok{2020}\NormalTok{,}\DecValTok{10}\NormalTok{)}

\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ data_europe)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_path}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ an, }\DataTypeTok{y =}\NormalTok{ CO2t_hab, }\DataTypeTok{color =}\NormalTok{ Country.Name))}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Années"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{'Tonnes de CO2 annuelle / habitant'}\NormalTok{,}
       \DataTypeTok{color =} \StringTok{"Pays"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{'Évolution de la production de CO2 par habitant'}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_x_continuous}\NormalTok{(}\DataTypeTok{breaks =}\NormalTok{ x_ticks, }\DataTypeTok{labels =}\NormalTok{ x_ticks)}\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_tufte}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig335-1} 

}

\caption{Graphique en ligne}\label{fig:fig335}
\end{figure}

On remarque notamment qu'aucune donnée avant 2005 n'est disponible pour le Liechtenstein.

\hypertarget{sect03241}{%
\subsubsection{Barre d'erreur et en bande}\label{sect03241}}

Sur un graphique, il est souvent pertinent de représenter l'incertitude que nous avons sur nos données. Cela peut être fait à l'aide de barres d'erreurs ou à l'aide de polygones délimitant les marges d'incertitude. En guise d'exemple, admettons que les données précédentes sont fiables à plus ou moins 10\%. En d'autres termes, la valeur d'émission de CO2 annuelle serait relativement incertaine et pourrait se situer dans un intervalle de 10\% autour de la valeur fourni par la Banque Mondiale. Nous obtenons ainsi une borne inférieure (valeur donnée - 10\%) et une borne supérieure (valeur donnée + 10\%). Nous pouvons facilement calculer ces bornes et les faire apparaître dans notre graphique précédent.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data_europe}\OperatorTok{$}\NormalTok{borne_basse <-}\StringTok{ }\NormalTok{data_europe}\OperatorTok{$}\NormalTok{CO2t_hab }\OperatorTok{-}\StringTok{ }\FloatTok{0.1} \OperatorTok{*}\StringTok{ }\NormalTok{data_europe}\OperatorTok{$}\NormalTok{CO2t_hab}
\NormalTok{data_europe}\OperatorTok{$}\NormalTok{borne_haute <-}\StringTok{ }\NormalTok{data_europe}\OperatorTok{$}\NormalTok{CO2t_hab }\OperatorTok{+}\StringTok{ }\FloatTok{0.1} \OperatorTok{*}\StringTok{ }\NormalTok{data_europe}\OperatorTok{$}\NormalTok{CO2t_hab}

\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ data_europe)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ an, }\DataTypeTok{y =}\NormalTok{ CO2t_hab, }\DataTypeTok{color =}\NormalTok{ Country.Name), }\DataTypeTok{size =} \FloatTok{0.7}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_errorbar}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ an, }\DataTypeTok{ymin =}\NormalTok{ borne_basse, }\DataTypeTok{ymax =}\NormalTok{ borne_haute, }\DataTypeTok{color =}\NormalTok{ Country.Name))}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Années"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{'Tonnes de CO2 annuelle / habitant'}\NormalTok{,}
       \DataTypeTok{color =} \StringTok{"Pays"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{'Évolution de la production de CO2 par habitant'}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_x_continuous}\NormalTok{(}\DataTypeTok{breaks =}\NormalTok{ x_ticks, }\DataTypeTok{labels =}\NormalTok{ x_ticks)}\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_tufte}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig336-1} 

}

\caption{Graphique en ligne avec barres d'erreur}\label{fig:fig336}
\end{figure}

Ces barres d'erreurs indiquent notamment qu'il n'y a finalement aucun écart significatif entre la Belgique, les Pays-Bas et l'Allemagne à partir des années 1990. Une autre option de représentation est d'utiliser des polygones avec la fonction \texttt{geom\_ribbon}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ data_europe)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_path}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ an, }\DataTypeTok{y =}\NormalTok{ CO2t_hab, }\DataTypeTok{color =}\NormalTok{ Country.Name), }\DataTypeTok{size =} \FloatTok{0.7}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_ribbon}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ an, }\DataTypeTok{ymin =}\NormalTok{ borne_basse, }\DataTypeTok{ymax =}\NormalTok{ borne_haute, }\DataTypeTok{fill =}\NormalTok{ Country.Name), }\DataTypeTok{alpha =} \FloatTok{0.4}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Années"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{'Tonnes de CO2 annuelle / habitant'}\NormalTok{,}
       \DataTypeTok{color =} \StringTok{"Pays"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{'Évolution de la production de CO2 par habitant'}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_x_continuous}\NormalTok{(}\DataTypeTok{breaks =}\NormalTok{ x_ticks, }\DataTypeTok{labels =}\NormalTok{ x_ticks)}\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_tufte}\NormalTok{()}\OperatorTok{+}
\StringTok{  }\KeywordTok{guides}\NormalTok{( }\DataTypeTok{fill =} \OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig337-1} 

}

\caption{Graphique en ligne avec marge d'erreur}\label{fig:fig337}
\end{figure}

Le message du graphique est le même. Notez que nous avons utilisé ici la fonction \texttt{guides} pour retirer de la légende les couleurs associées au remplissage des marges d'erreurs. Ces couleurs sont les mêmes que celles des lignes et il n'est pas utile de dédoubler la légende. De nombreuses méthodes statistiques produisent des résultats accompagnés d'une mesure de l'incertitude associée à ces résultats. Représenter cette incertitude est crucial pour que le lecteur puisse délimiter la portée des conclusions de vos analyses.

\hypertarget{sect0325}{%
\subsection{Boites à moustache}\label{sect0325}}

Les boites à moustache (\emph{box plot} en anglais) sont des graphiques permettant de comparer les moyennes et les intervalles interquartiles d'une variable continue selon plusieurs groupes d'une population. Si l'on reprend notre exemple précédent, nous pourrions comparer en fonction de la région du monde la moyenne de production annuelle de CO2 par habitant. Pour cela, il suffit d'utiliser la fonction \texttt{geom\_boxplot}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#retirer les observations n'étant pas associées à une région}
\NormalTok{data_co2_comp <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(data_co2, }\KeywordTok{is.na}\NormalTok{(data_co2}\OperatorTok{$}\NormalTok{region7) }\OperatorTok{==}\StringTok{ }\NormalTok{F)}

\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ data_co2_comp)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_boxplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ region7, }\DataTypeTok{x =}\NormalTok{ CO2t_hab))}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x=}\StringTok{"Tonnes de CO2 par an et habitant"}\NormalTok{, }\DataTypeTok{y=}\StringTok{"Région"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig338-1} 

}

\caption{Boite à moustache}\label{fig:fig338}
\end{figure}

La barre centrale d'une boite représente la moyenne. Les extrêmités de la boite représentent le premier et le troisième quartile. Plus une boite est allongée, plus les situations sont diversifiées pour les observations appartenant au groupe représenté par la boite. Au contraire, une boite étroite indique un groupe homogène. Notez qu'en inversant les variables dans les axes \emph{X} et \emph{Y}, on obtiendrait des boites à moustache verticales. Cependant, les noms des régions étant assez longs, cela nécessiterait d'avoir un graphique très large. Améliorons quelque peu le rendu de ce graphique en ajoutant des titres.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ data_co2_comp)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_boxplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ region7, }\DataTypeTok{x =}\NormalTok{ CO2t_hab))}\OperatorTok{+}
\StringTok{  }\KeywordTok{xlim}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{50}\NormalTok{))}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Niveaux d'émission de CO2 par habitant par région géographique"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"Tonnes de CO2 par an et habitant"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{'Région'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig339-1} 

}

\caption{Boite à moustache améliorée}\label{fig:fig339}
\end{figure}

Les points noirs sur le graphique représentent des valeurs extrêmes, soit des observations situées à plus de 1,5 intervalle interquatile d'une extrêmité de la boite. Pour mieux rendre compte de la densité d'observations le long de chaque boite à moustache, il est possible de les représenter directement avec la fonction \texttt{geom\_jitter}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ data_co2_comp)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_boxplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ region7, }\DataTypeTok{x =}\NormalTok{ CO2t_hab), }\DataTypeTok{outlier.shape =} \OtherTok{NA}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_jitter}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ region7, }\DataTypeTok{x =}\NormalTok{ CO2t_hab), }\DataTypeTok{size =} \FloatTok{0.2}\NormalTok{, }\DataTypeTok{alpha =} \FloatTok{0.2}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{xlim}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{50}\NormalTok{))}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Niveaux d'émission de CO2 par habitant par région géographique"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"Tonnes de CO2 annuelle par habitant"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{'Région'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig340-1} 

}

\caption{Boite à moustache avec observations}\label{fig:fig340}
\end{figure}

Notez que pour éviter que les valeurs extrêmes identifiées par la fonction \texttt{geom\_boxplot} se superposent avec les points représentant les observations, nous les avons supprimées avec l'argument \texttt{outlier.shape\ =\ NA}.

\hypertarget{sect0326}{%
\subsection{Graphique en violons}\label{sect0326}}

Les boites à moustaches donnent des informations pertinentes sur le centre et la dispersion d'une variable en fonction de sous groupes de la population. Cependant, une grande partie de l'information reste masquée par la représentation sous forme de boite. Une alternative est de remplacer la simple boite par la distribution de la variable étudiée. On obtient ainsi des graphiques en violon (\texttt{geom\_violin}). Considérant les très grands écarts entre les régions que nous avons observés avec les boites à moustache, il est préférable de tracer les graphiques en violon en excluant les régions Afrique Sub-Saharienne et Asie du Sud.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# retirons les observations de régions que nous ne souhaitons par garder}
\NormalTok{data_co2_comp <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(data_co2, (}\OperatorTok{!}\StringTok{ }\NormalTok{data_co2}\OperatorTok{$}\NormalTok{region7 }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Sub-Saharan Africa"}\NormalTok{, }\StringTok{"South Asia"}\NormalTok{)) }
                        \OperatorTok{&}\StringTok{ }\KeywordTok{is.na}\NormalTok{(data_co2}\OperatorTok{$}\NormalTok{region7)}\OperatorTok{==}\OtherTok{FALSE}\NormalTok{)}

\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ data_co2_comp)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_violin}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ region7,}\DataTypeTok{x =}\NormalTok{ CO2t_hab))}\OperatorTok{+}
\StringTok{  }\KeywordTok{xlim}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{50}\NormalTok{))}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Comparaison des niveaux d'émission de CO2 par habitant par région géographique"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"Tonnes de CO2 annuelle / habitant"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{''}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_vline}\NormalTok{(}\DataTypeTok{xintercept =} \DecValTok{12}\NormalTok{, }\DataTypeTok{linetype =} \StringTok{'dashed'}\NormalTok{, }\DataTypeTok{color =} \StringTok{'blue'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig341-1} 

}

\caption{Graphique en violon}\label{fig:fig341}
\end{figure}

Ces distributions permettent notamment de souligner que deux groupes distincts se retrouvent en Amérique du Nord. L'un dont les émissions annuelles de CO2 par habitant sont inférieure à 12 tonnes (ligne bleue) et un autre groupe pour lequel elles sont supérieures. En explorant les données, on constate que les Bermudes sont inclus dans le groupe Amérique du Nord, mais ont des niveaux d'émission inférieurs à ceux du Canada et des États Unis, ce qui explique cette distribution bimodale. Cette information était masquée avec les boites à moustaches. Finalement, il est aussi possible de superposer graphique en violon et boite à moustaches pour bénéficier des avantages des deux.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ data_co2_comp)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_violin}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ region7,}\DataTypeTok{x =}\NormalTok{ CO2t_hab))}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_boxplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ region7,}\DataTypeTok{x =}\NormalTok{ CO2t_hab), }\DataTypeTok{width =} \FloatTok{0.15}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{xlim}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{50}\NormalTok{))}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Comparaison des niveaux d'émission de CO2 par habitant par région géographique"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"Tonnes de CO2 annuelle / habitant"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{''}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig342-1} 

}

\caption{Graphique en violon et boite à moustaches}\label{fig:fig342}
\end{figure}

\hypertarget{sect0327}{%
\subsection{Graphique en barres}\label{sect0327}}

Les graphiques en barres permettent de représenter des quantités (hauteur des barres) réparties dans des catégories (une barre par catégorie). Nous proposons ici un exemple avec des données de déplacements issues de l'\emph{enquête origine destination de Québec de 2017} au niveau des grands secteurs (figure \ref{fig:fig342}).

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{images/magie_graphiques/carte_secteurs} 

}

\caption{Grands secteurs de Québec}\label{fig:fig343}
\end{figure}

Nous représentons pour chaque secteur le nombre déplacements moyen entrant et sortant un jour de semaine en heures de pointe. Les données sont présentées sous forme d'une matrice carrée (avec autant de lignes que de colonnes). L'intersection de la ligne A et de la colonne C indique le nombre de personnes partant du secteur A pour se rendre dans le secteur C. À l'inverse, l'intersection de la ligne C et de la colonne A indique le nombre de personnes partant du secteur C pour se rendre dans le secteur A. En sommant les valeurs de chaque ligne, on obtient le nombre total de départs par secteur tandis que le nombre d'arrivées est la somme de chaque colonne. Ces opérations peuvent simplement être effectuées avec les fonctions \texttt{rowSums} et \texttt{colSums}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# chargement des donneées}
\NormalTok{matriceOD <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{'data/graphique/Quebec_2017_OD_MJ.csv'}\NormalTok{,}
                 \DataTypeTok{header =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{sep =} \StringTok{';'}\NormalTok{) }\CommentTok{# fichier csv sans entête}

\CommentTok{# calcul des sommes en lignes et en colonnes}
\NormalTok{tot_depart <-}\StringTok{ }\KeywordTok{rowSums}\NormalTok{(matriceOD)}
\NormalTok{tot_arrivee <-}\StringTok{ }\KeywordTok{colSums}\NormalTok{(matriceOD)}

\CommentTok{# création d'un DataFrame avec les valeurs et les noms des secteurs}
\NormalTok{df <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{depart =}\NormalTok{ tot_depart,}
                 \DataTypeTok{arrivee =}\NormalTok{ tot_arrivee, }
                 \DataTypeTok{secteur =} \KeywordTok{c}\NormalTok{(}\StringTok{'Arr. de Beauport (Québec)'}\NormalTok{,}
                            \StringTok{'Arr. de Charlesbourg (Québec)'}\NormalTok{,}
                            \StringTok{'Arr. des Rivières (Québec)'}\NormalTok{,}
                            \StringTok{'Arr. de la Cité-Limoilou (Québec)'}\NormalTok{,}
                            \StringTok{'Arr. de la Haute-St-Charles (Québec)'}\NormalTok{,}
                            \StringTok{'Arr. de Sainte-Foy-Sillery- Cap-Rouge (Québec)'}\NormalTok{,}
                            \StringTok{'Arr.de Desjardins (Lévis)'}\NormalTok{,}
                            \StringTok{'Arr. des Chutes–de-la-Chaudière-Est (Lévis)'}\NormalTok{,}
                            \StringTok{'Arr. Les Chutes de la Chaudière-Ouest (Lévis)'}\NormalTok{,}
                            \StringTok{'Ceinture Nord'}\NormalTok{,}
                            \StringTok{'Ceinture Sud'}\NormalTok{,}
                            \StringTok{'Hors Territoire'}\NormalTok{),}
                 \DataTypeTok{code =} \KeywordTok{c}\NormalTok{(}\StringTok{'A'}\NormalTok{,}\StringTok{'B'}\NormalTok{,}\StringTok{'C'}\NormalTok{,}\StringTok{'D'}\NormalTok{,}\StringTok{'E'}\NormalTok{,}\StringTok{'F'}\NormalTok{,}\StringTok{'G'}\NormalTok{,}\StringTok{'H'}\NormalTok{,}\StringTok{'I'}\NormalTok{,}\StringTok{'J'}\NormalTok{,}\StringTok{'K'}\NormalTok{,}\StringTok{'X'}\NormalTok{))}

\CommentTok{# création des deux graphiques en barres}
\NormalTok{plot1 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ df)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ code, }\DataTypeTok{weight =}\NormalTok{ depart))}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{subtitle =} \StringTok{'Départs'}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{'total'}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{''}\NormalTok{)}

\NormalTok{plot2 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ df)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ code, }\DataTypeTok{weight =}\NormalTok{ arrivee))}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{subtitle =} \StringTok{'Arrivées'}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{'total'}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{''}\NormalTok{)}

\CommentTok{# stocker les graphiques dans une liste et composer une figure}
\NormalTok{list_plot <-}\StringTok{ }\KeywordTok{list}\NormalTok{(plot1, plot2)}
\NormalTok{tot_plot <-}\StringTok{ }\KeywordTok{ggarrange}\NormalTok{(}\DataTypeTok{plotlist =}\NormalTok{ list_plot, }\DataTypeTok{ncol =} \DecValTok{1}\NormalTok{)}

\CommentTok{# création d'une légende pour associer le code de chaque secteur }
\CommentTok{# à son nom. Pour cela on concatène en premier les lettres et les noms, }
\CommentTok{# on fusionne ensuite le tout en les séparant par le symbole \textbackslash{}n représentant }
\CommentTok{# un saut de ligne.}
\NormalTok{nom_secteurs <-}\StringTok{ }\KeywordTok{paste}\NormalTok{(df}\OperatorTok{$}\NormalTok{code, df}\OperatorTok{$}\NormalTok{secteur, }\DataTypeTok{sep=} \StringTok{' : '}\NormalTok{)}
\NormalTok{string_names <-}\StringTok{ }\KeywordTok{paste}\NormalTok{(nom_secteurs, }\DataTypeTok{collapse =} \StringTok{'}\CharTok{\textbackslash{}n}\StringTok{'}\NormalTok{)}

\NormalTok{titre <-}\StringTok{ "Déplacements journaliers moyens en heures de pointe de la région de Québec"}
\CommentTok{# production finale de la figure}
\KeywordTok{annotate_figure}\NormalTok{(tot_plot,}
                \DataTypeTok{top =} \KeywordTok{text_grob}\NormalTok{(titre, }\DataTypeTok{face =} \StringTok{"bold"}\NormalTok{, }\DataTypeTok{size =} \DecValTok{11}\NormalTok{, }\DataTypeTok{just =} \StringTok{"left"}\NormalTok{),}
                \DataTypeTok{right =} \KeywordTok{text_grob}\NormalTok{(string_names, }\DataTypeTok{face =} \StringTok{"italic"}\NormalTok{, }\DataTypeTok{size =} \DecValTok{8}\NormalTok{,}
                                  \DataTypeTok{just =} \StringTok{"left"}\NormalTok{, }\DataTypeTok{x =} \FloatTok{0.05}\NormalTok{) }\CommentTok{# position du texte}
\NormalTok{                )}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig344-1} 

}

\caption{Graphiques en barres simples}\label{fig:fig344}
\end{figure}

Plutôt que de représenter les arrivées et les départs dans deux graphiques séparés, il est possible de les empiler dans un même graphique en barres. Nous devons au préalable « faire fondre nos données » avec la fonction \texttt{melt}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# faire fondre le jeu de données (empiler les colonnes depart et arrivee)}
\NormalTok{melted_df <-}\StringTok{ }\KeywordTok{melt}\NormalTok{(df, }\DataTypeTok{id.vars =} \KeywordTok{c}\NormalTok{(}\StringTok{'code'}\NormalTok{), }\DataTypeTok{measure.vars =} \KeywordTok{c}\NormalTok{(}\StringTok{'depart'}\NormalTok{,}\StringTok{'arrivee'}\NormalTok{))}
\KeywordTok{names}\NormalTok{(melted_df) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'code'}\NormalTok{,}\StringTok{'deplacement'}\NormalTok{,}\StringTok{'effectif'}\NormalTok{)}
\CommentTok{# ajouter les accents dans la colonne déplacement}
\NormalTok{melted_df}\OperatorTok{$}\NormalTok{deplacement <-}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(melted_df}\OperatorTok{$}\NormalTok{deplacement }\OperatorTok{==}\StringTok{ 'depart'}\NormalTok{, }\StringTok{'départ'}\NormalTok{, }\StringTok{'arrivée'}\NormalTok{)}

\CommentTok{# comparaison du format original et du format "fondu"}
\KeywordTok{head}\NormalTok{(df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    depart arrivee                                        secteur code
## V1  49241   34777                      Arr. de Beauport (Québec)    A
## V2  48909   36344                  Arr. de Charlesbourg (Québec)    B
## V3  48044   67198                     Arr. des Rivières (Québec)    C
## V4  63132  108138              Arr. de la Cité-Limoilou (Québec)    D
## V5  57367   30859           Arr. de la Haute-St-Charles (Québec)    E
## V6  86504  112379 Arr. de Sainte-Foy-Sillery- Cap-Rouge (Québec)    F
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(melted_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   code deplacement effectif
## 1    A      départ    49241
## 2    B      départ    48909
## 3    C      départ    48044
## 4    D      départ    63132
## 5    E      départ    57367
## 6    F      départ    86504
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# réalisation du graphique}
\NormalTok{plot1 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ melted_df)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ code,}\DataTypeTok{weight =}\NormalTok{ effectif, }\DataTypeTok{fill =}\NormalTok{ deplacement),}\DataTypeTok{color =} \StringTok{'#e3e3e3'}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_fill_manual}\NormalTok{(}\DataTypeTok{values =} \KeywordTok{c}\NormalTok{(}\StringTok{"#e63946"}\NormalTok{,}\StringTok{"#1d3557"}\NormalTok{))}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =}\NormalTok{ titre,}
       \DataTypeTok{y =} \StringTok{'Effectifs'}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{''}\NormalTok{,}
       \DataTypeTok{fill =} \StringTok{'Déplacements'}\NormalTok{)}

\KeywordTok{annotate_figure}\NormalTok{(plot1,}\DataTypeTok{right =} \KeywordTok{text_grob}\NormalTok{(string_names, }\DataTypeTok{face =} \StringTok{"italic"}\NormalTok{, }\DataTypeTok{size =} \DecValTok{7}\NormalTok{,}
                                  \DataTypeTok{just =} \StringTok{"left"}\NormalTok{, }\DataTypeTok{x =} \FloatTok{0.05}\NormalTok{)) }\CommentTok{# position du texte)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig345-1} 

}

\caption{Graphique en barres empilées}\label{fig:fig345}
\end{figure}

\hypertarget{sect0328}{%
\subsection{Graphique circulaire}\label{sect0328}}

Une alternative directe au graphique en barre est le graphique ou diagramme circulaire, appelé aussi graphique en pointes de tarte (pour ceux à la dent sucrée) ou en camembert (pour les amateurs de fromage). Il est suffissamment connu et utilisé pour qu'aucune présentation ne s'impose. Pour être exact, un graphique en pointes de tarte n'est rien d'autre qu'un graphique en barres dont le système de coordonnées a été modifié. Cela impose cependant de calculer à l'avance la position des étiquettes que l'on souhaite ajouter sur le graphique. Reprenons les données de production mondiale de CO2 et calculons les productions totales par région géographique en 2015.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(dplyr)}

\CommentTok{# extraire les données de 2018 pour lesquelles on connait la région}
\NormalTok{data_co2_}\DecValTok{2015}\NormalTok{ <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(data_co2,data_co2}\OperatorTok{$}\NormalTok{year }\OperatorTok{==}\StringTok{ "2015"} \OperatorTok{&}\StringTok{ }\OperatorTok{!}\StringTok{ }\KeywordTok{is.na}\NormalTok{(data_co2}\OperatorTok{$}\NormalTok{region7))}

\CommentTok{# effectuer la somme du CO2 par région}
\NormalTok{co2_}\DecValTok{2015}\NormalTok{ <-}\StringTok{ }\NormalTok{data_co2_}\DecValTok{2015} \OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(region7) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{total_co2 =} \KeywordTok{sum}\NormalTok{(CO2_kt,}\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{))}

\CommentTok{# attribuer un code à chaque région pour faciliter la lecture}
\NormalTok{co2_}\DecValTok{2015}\OperatorTok{$}\NormalTok{code <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"A"}\NormalTok{,}\StringTok{"B"}\NormalTok{,}\StringTok{"C"}\NormalTok{,}\StringTok{"D"}\NormalTok{,}\StringTok{"E"}\NormalTok{,}\StringTok{"F"}\NormalTok{,}\StringTok{"G"}\NormalTok{)}

\CommentTok{# modifier l'ordre des données, calculer les proportions et la position des labels}
\NormalTok{df <-}\StringTok{ }\NormalTok{co2_}\DecValTok{2015} \OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(code)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{prop =}\NormalTok{ total_co2 }\OperatorTok{/}\StringTok{ }\KeywordTok{sum}\NormalTok{(co2_}\DecValTok{2015}\OperatorTok{$}\NormalTok{total_co2) }\OperatorTok{*}\DecValTok{100}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{ypos =} \KeywordTok{cumsum}\NormalTok{(prop)}\OperatorTok{-}\StringTok{ }\FloatTok{0.5}\OperatorTok{*}\NormalTok{prop )}

\CommentTok{# préparer la légende (pourcentages et vrais noms)}
\NormalTok{nom_region <-}\StringTok{ }\KeywordTok{rev}\NormalTok{(}\KeywordTok{paste}\NormalTok{(df}\OperatorTok{$}\NormalTok{code, }\StringTok{" : "}\NormalTok{, df}\OperatorTok{$}\NormalTok{region7, }\StringTok{"("}\NormalTok{, }\KeywordTok{round}\NormalTok{(df}\OperatorTok{$}\NormalTok{prop,}\DecValTok{1}\NormalTok{),}\StringTok{"%)"}\NormalTok{))}
\NormalTok{string_region <-}\StringTok{ }\KeywordTok{paste}\NormalTok{(nom_region, }\DataTypeTok{collapse =} \StringTok{'}\CharTok{\textbackslash{}n}\StringTok{'}\NormalTok{)}

\CommentTok{# construire le graphique}
\NormalTok{plot1 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(df, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\StringTok{""}\NormalTok{, }\DataTypeTok{y=}\NormalTok{prop, }\DataTypeTok{fill=}\NormalTok{code)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\DataTypeTok{stat=}\StringTok{"identity"}\NormalTok{, }\DataTypeTok{width=}\DecValTok{1}\NormalTok{, }\DataTypeTok{color=}\StringTok{"white"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{coord_polar}\NormalTok{(}\StringTok{"y"}\NormalTok{, }\DataTypeTok{start=}\DecValTok{0}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_void}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position=}\StringTok{"none"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_text}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ ypos, }\DataTypeTok{label =}\NormalTok{ code), }\DataTypeTok{color =} \StringTok{"white"}\NormalTok{, }\DataTypeTok{size=}\DecValTok{3}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_fill_grey}\NormalTok{()}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Proportion du CO2 émis en 2015"}\NormalTok{)}

\CommentTok{# ajouter la légende}
\KeywordTok{annotate_figure}\NormalTok{(plot1,}\DataTypeTok{right =} \KeywordTok{text_grob}\NormalTok{(string_region, }\DataTypeTok{face =} \StringTok{"italic"}\NormalTok{, }\DataTypeTok{size =} \DecValTok{9}\NormalTok{,}
                                  \DataTypeTok{just =} \StringTok{"left"}\NormalTok{, }\DataTypeTok{x =} \FloatTok{0.05}\NormalTok{)) }\CommentTok{# position du texte)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig346-1} 

}

\caption{Graphique en pointes de tarte}\label{fig:fig346}
\end{figure}

Si à la place de la géométrie \texttt{geom\_bar}, vous utilisez \texttt{geom\_rect}, vous pouvez convertir votre graphique en pointes de tarte en graphique en anneau (ou en beigne, pour ceux à la dent sucrée) :

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# calculer la limite inférieure et supérieure du beigne}
\NormalTok{df}\OperatorTok{$}\NormalTok{ymax <-}\StringTok{ }\KeywordTok{cumsum}\NormalTok{(df}\OperatorTok{$}\NormalTok{prop)}
\NormalTok{df}\OperatorTok{$}\NormalTok{ymin <-}\StringTok{  }\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\KeywordTok{head}\NormalTok{(df}\OperatorTok{$}\NormalTok{ymax, }\DataTypeTok{n=}\OperatorTok{-}\DecValTok{1}\NormalTok{))}

\CommentTok{# construire le graphique}
\NormalTok{plot1 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(df, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{ymax=}\NormalTok{ymax, }\DataTypeTok{ymin=}\NormalTok{ymin, }
                        \DataTypeTok{xmax=}\DecValTok{4}\NormalTok{, }\DataTypeTok{xmin=}\DecValTok{3}\NormalTok{,}
                        \DataTypeTok{y=}\NormalTok{prop, }\DataTypeTok{fill=}\NormalTok{code)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_rect}\NormalTok{(}\DataTypeTok{stat=}\StringTok{"identity"}\NormalTok{, }\DataTypeTok{color=}\StringTok{"white"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{coord_polar}\NormalTok{(}\StringTok{"y"}\NormalTok{, }\DataTypeTok{start=}\DecValTok{0}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_void}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position=}\StringTok{"none"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_text}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =} \FloatTok{3.5}\NormalTok{,}\DataTypeTok{y =}\NormalTok{ ypos, }\DataTypeTok{label =}\NormalTok{ code), }\DataTypeTok{color =} \StringTok{"white"}\NormalTok{, }\DataTypeTok{size=}\DecValTok{3}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_fill_grey}\NormalTok{()}\OperatorTok{+}
\StringTok{  }\KeywordTok{xlim}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{4}\NormalTok{))}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Proportion du CO2 émis en 2015"}\NormalTok{)}

\CommentTok{# ajouter la légende}
\KeywordTok{annotate_figure}\NormalTok{(plot1,}\DataTypeTok{right =} \KeywordTok{text_grob}\NormalTok{(string_region, }\DataTypeTok{face =} \StringTok{"italic"}\NormalTok{, }\DataTypeTok{size =} \DecValTok{8}\NormalTok{,}
                                  \DataTypeTok{just =} \StringTok{"left"}\NormalTok{, }\DataTypeTok{x =} \FloatTok{0.05}\NormalTok{)) }\CommentTok{# position du texte)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig347-1} 

}

\caption{Graphique en anneau}\label{fig:fig347}
\end{figure}

\hypertarget{sect033}{%
\section{Graphiques spéciaux}\label{sect033}}

Dans cette dernière section, nous allons aborder des graphiques plus rarement utilisés. Ils sont toutefois très utiles dans certains contextes du fait de leur capacité à synthétiser des informations complexes.

\hypertarget{sect0331}{%
\subsection{Graphique en radar}\label{sect0331}}

Les graphiques en radar (ou en toile d'araignée) sont utilisés pour comparer une série de variables continues pour plusieurs observations ou groupe d'observations. Chaque variable est associée à un axe et chaque observation est représentée avec un polygone. Prenons comme exemple les données de logement par secteur de recensement dans la région métropolitaine de Montréal en 2016. On pourrait souhaiter comparer la moyenne des pourcentages des différents types de logements pour les régions des Laurentides, de la Montérégie, de Laval, de Longueuil et de Montréal. Malheureusement, \textbf{ggplot2} ne permet pas de dessiner des graphiques en radar satisfaisants, nous devrons donc utiliser le \emph{package} \textbf{fmsb}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(fmsb)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Attaching package: 'fmsb'
\end{verbatim}

\begin{verbatim}
## The following objects are masked from 'package:DescTools':
## 
##     CronbachAlpha, VIF
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{'data/bivariee/sr_rmr_mtl_2016.csv'}\NormalTok{, }\DataTypeTok{header =}\NormalTok{ T, }\DataTypeTok{encoding =} \StringTok{'UTF-8'}\NormalTok{)}

\CommentTok{# aggrégeons les données au niveau des régions en calculant la moyenne des pourcentages}
\NormalTok{variables <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"MaisonIndi"}\NormalTok{,}\StringTok{"App5Plus"}\NormalTok{,}\StringTok{"MaisRangee"}\NormalTok{,}\StringTok{"AppDuplex"}\NormalTok{,}\StringTok{"Proprio"}\NormalTok{,}\StringTok{"Locataire"}\NormalTok{)}

\NormalTok{data_region <-}\StringTok{ }\NormalTok{data[}\KeywordTok{c}\NormalTok{(}\StringTok{"Region"}\NormalTok{,variables)] }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(Region) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise_all}\NormalTok{(}\DataTypeTok{.funs =} \KeywordTok{list}\NormalTok{(mean))}

\CommentTok{# gérer le nom des colonnes pour ajuster les données aux besoins de }
\CommentTok{# la fonction radachart}
\NormalTok{new_names <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Region"}\NormalTok{,}\KeywordTok{paste}\NormalTok{(variables,}\StringTok{"_mean"}\NormalTok{,}\DataTypeTok{sep=}\StringTok{""}\NormalTok{))}
\KeywordTok{names}\NormalTok{(data_region) <-}\StringTok{ }\NormalTok{new_names}
\NormalTok{data_region <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(data_region)}
\KeywordTok{rownames}\NormalTok{(data_region) <-}\StringTok{ }\NormalTok{data_region}\OperatorTok{$}\NormalTok{Region}
\NormalTok{data_region}\OperatorTok{$}\NormalTok{Region <-}\StringTok{ }\OtherTok{NULL}

\CommentTok{# ajouter deux lignes aux données avec les valeurs maximales et minimales }
\CommentTok{# de chaque colonne. Ces informations aideront la fonction radachart à}
\CommentTok{# dessiner chacun des axes du radar}
\NormalTok{data_chart <-}\StringTok{ }\KeywordTok{rbind}\NormalTok{(}\KeywordTok{apply}\NormalTok{(data_region,}\DataTypeTok{MARGIN =} \DecValTok{2}\NormalTok{, }\DataTypeTok{FUN =}\NormalTok{ max),}
                    \KeywordTok{apply}\NormalTok{(data_region,}\DataTypeTok{MARGIN =} \DecValTok{2}\NormalTok{, }\DataTypeTok{FUN =}\NormalTok{ min),}
\NormalTok{                    data_region}
\NormalTok{                    )}

\CommentTok{# choix des couleurs pour l'intérieur des polygones (avec transparence)}
\NormalTok{couleurs <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}
  \KeywordTok{rgb}\NormalTok{(}\FloatTok{0.94}\NormalTok{, }\FloatTok{0.28}\NormalTok{, }\FloatTok{0.44}\NormalTok{, }\FloatTok{0.25}\NormalTok{),}
  \KeywordTok{rgb}\NormalTok{(}\FloatTok{1.00}\NormalTok{, }\FloatTok{0.82}\NormalTok{, }\FloatTok{0.40}\NormalTok{, }\FloatTok{0.25}\NormalTok{),}
  \KeywordTok{rgb}\NormalTok{(}\FloatTok{0.02}\NormalTok{, }\FloatTok{0.84}\NormalTok{, }\FloatTok{0.63}\NormalTok{, }\FloatTok{0.25}\NormalTok{),}
  \KeywordTok{rgb}\NormalTok{(}\FloatTok{0.07}\NormalTok{, }\FloatTok{0.54}\NormalTok{, }\FloatTok{0.70}\NormalTok{, }\FloatTok{0.25}\NormalTok{),}
  \KeywordTok{rgb}\NormalTok{(}\FloatTok{0.03}\NormalTok{, }\FloatTok{0.23}\NormalTok{, }\FloatTok{0.30}\NormalTok{, }\FloatTok{0.25}\NormalTok{)}
\NormalTok{)}

\CommentTok{# choix des couleurs pour l'intérieur des polygones (sans transparence)}
\NormalTok{couleurs_contour <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}
  \KeywordTok{rgb}\NormalTok{(}\FloatTok{0.94}\NormalTok{, }\FloatTok{0.28}\NormalTok{, }\FloatTok{0.44}\NormalTok{),}
  \KeywordTok{rgb}\NormalTok{(}\FloatTok{1.00}\NormalTok{, }\FloatTok{0.82}\NormalTok{, }\FloatTok{0.40}\NormalTok{),}
  \KeywordTok{rgb}\NormalTok{(}\FloatTok{0.02}\NormalTok{, }\FloatTok{0.84}\NormalTok{, }\FloatTok{0.63}\NormalTok{),}
  \KeywordTok{rgb}\NormalTok{(}\FloatTok{0.07}\NormalTok{, }\FloatTok{0.54}\NormalTok{, }\FloatTok{0.70}\NormalTok{),}
  \KeywordTok{rgb}\NormalTok{(}\FloatTok{0.03}\NormalTok{, }\FloatTok{0.23}\NormalTok{, }\FloatTok{0.30}\NormalTok{)}
\NormalTok{)}

\CommentTok{# dessin du graphique}
\KeywordTok{radarchart}\NormalTok{(data_chart,}
           \DataTypeTok{title =} \StringTok{"Comparaison des types de logements dans la RMR"}\NormalTok{,}
           \DataTypeTok{pcol =}\NormalTok{ couleurs_contour, }\DataTypeTok{pfcol =}\NormalTok{ couleurs,}
           \DataTypeTok{plwd =} \DecValTok{2}\NormalTok{, }\DataTypeTok{plty=}\DecValTok{1}\NormalTok{,}
           \DataTypeTok{cglcol=}\StringTok{"grey"}\NormalTok{, }\DataTypeTok{cglty=}\DecValTok{1}\NormalTok{, }\DataTypeTok{axislabcol=}\StringTok{"grey"}\NormalTok{, }\DataTypeTok{cglwd=}\FloatTok{0.8}\NormalTok{,}
           \DataTypeTok{vlcex=}\FloatTok{0.8}\NormalTok{,}
           \DataTypeTok{vlabels =} \KeywordTok{c}\NormalTok{(}\StringTok{"maison individuelle"}\NormalTok{, }\StringTok{"immeuble d'appartements"}\NormalTok{,}
                       \StringTok{"maison }\CharTok{\textbackslash{}n}\StringTok{en rangée"}\NormalTok{, }\StringTok{"duplex"}\NormalTok{,}
                       \StringTok{"propriétaire"}\NormalTok{, }\StringTok{"locataire"}\NormalTok{)}
\NormalTok{           )}

\CommentTok{# ajout d'une légende}
\KeywordTok{legend}\NormalTok{(}\DataTypeTok{x=}\FloatTok{1.3}\NormalTok{, }\DataTypeTok{y=}\DecValTok{1}\NormalTok{, }\DataTypeTok{legend =} \KeywordTok{rownames}\NormalTok{(data_chart[}\OperatorTok{-}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{),]), }\DataTypeTok{bty =} \StringTok{"n"}\NormalTok{, }
       \DataTypeTok{pch=}\DecValTok{20}\NormalTok{ , }\DataTypeTok{col=}\NormalTok{couleurs , }\DataTypeTok{text.col =} \StringTok{"black"}\NormalTok{, }\DataTypeTok{cex=}\FloatTok{0.9}\NormalTok{, }\DataTypeTok{pt.cex=}\FloatTok{1.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig348-1} 

}

\caption{Graphique en anneau}\label{fig:fig348}
\end{figure}

À la lecture du graphique, on constate rapidement que l'île de Montréal a une situation très différentes des trois autres régions. Laval se ditingue également avec une part importante de logements dans des immeubles d'appartements. Ce type de graphique a pour objectif d'orienter le regard sur de potentielles différences dans un contexte multidimensionnelle, mais il comporte quelques inconvénients :

\begin{itemize}
\tightlist
\item
  Les échelles de chaque axe sont différentes. Il est donc essentiel de se rapporter aux valeurs exactes pour estimer si les écarts sont importants en termes absolus.
\item
  La superposition de plusieurs polygones peut rendre la lecture difficile. Une alternative envisageable est de réaliser un graphique par polygone, mais cela prend beaucoup de place dans un document.
\item
  L'utilisation de polygones donne parfois de fausses impressions d'écarts. Dans le précédent graphique, l'œil est attiré en bas à gauche par le polygone de Montréal très différent des autres. Cependant, les écarts sur l'axe \emph{maison en rangée} sont relativement petit comparativement à l'axe \emph{locataire} situé à l'opposé.
\end{itemize}

\hypertarget{sect0332}{%
\subsection{Diagramme d'accord}\label{sect0332}}

Les diagrammes d'accord (\emph{chord diagram} en anglais) sont utilisés pour représenter des échanges ou des connexions entre des entités. Il peut s'agir par exemple de marchandises importées / exportées entre pays, des messages envoyés entre utilisateurs de réseaux sociaux, de flux de population, etc. Reprenons nos données de l'\emph{enquête origine destination de la région de Québec en 2017} pour illustrer le tout. Nous utiliserons le \emph{package} \textbf{chorddiag}, très facile d'utilisation et produisant des graphiques interactifs, facilitant grandement la lecture de ce type de graphique. Cependant ce \emph{package} ne fait pas partie du répertoire \emph{CRAN}, nous devrons l'installer directement depuis \emph{github} avec la fonction \texttt{devtools::install\_github}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{devtools}\OperatorTok{::}\KeywordTok{install_github}\NormalTok{(}\StringTok{'mattflor/chorddiag'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(chorddiag)}

\CommentTok{# chargement des données}
\NormalTok{matriceOD <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{'data/graphique/Quebec_2017_OD_MJ.csv'}\NormalTok{,}
                 \DataTypeTok{header =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{sep =} \StringTok{';'}\NormalTok{) }\CommentTok{# fichier csv sans entête}

\CommentTok{# transformation du dataframe en matrice}
\NormalTok{matriceOD <-}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{(matriceOD)}
\NormalTok{codes <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'A'}\NormalTok{,}\StringTok{'B'}\NormalTok{,}\StringTok{'C'}\NormalTok{,}\StringTok{'D'}\NormalTok{,}\StringTok{'E'}\NormalTok{,}\StringTok{'F'}\NormalTok{,}\StringTok{'G'}\NormalTok{,}\StringTok{'H'}\NormalTok{,}\StringTok{'I'}\NormalTok{,}\StringTok{'J'}\NormalTok{,}\StringTok{'K'}\NormalTok{,}\StringTok{'X'}\NormalTok{)}
\NormalTok{secteurs <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'Arr. de Beauport'}\NormalTok{,}
            \StringTok{'Arr. de Charlesbourg'}\NormalTok{,}
            \StringTok{'Arr. des Rivières'}\NormalTok{,}
            \StringTok{'Arr. de la Cité-Limoilou'}\NormalTok{,}
            \StringTok{'Arr. de la Haute-St-Charles'}\NormalTok{,}
            \StringTok{'Arr. de Sainte-Foy-Sillery-Cap-Rouge'}\NormalTok{,}
            \StringTok{'Arr.de Desjardins'}\NormalTok{,}
            \StringTok{'Arr. des Chutes–de-la-Chaudière-Est'}\NormalTok{,}
            \StringTok{'Arr. Les Chutes de la-Chaudière-Ouest'}\NormalTok{,}
            \StringTok{'Ceinture Nord'}\NormalTok{,}
            \StringTok{'Ceinture Sud'}\NormalTok{,}
            \StringTok{'Hors Territoire'}\NormalTok{)}

\CommentTok{# ajout de noms aux colonnes et aux lignes de la matrice}
\KeywordTok{rownames}\NormalTok{(matriceOD) <-}\StringTok{ }\NormalTok{secteurs}
\KeywordTok{colnames}\NormalTok{(matriceOD) <-}\StringTok{ }\NormalTok{secteurs}

\CommentTok{#on supprime les trois secteurs Ceinture Nord, Sud et Hors territoire }
\CommentTok{#qui comprennent de toute façon peu de déplacements}
\NormalTok{mat <-}\StringTok{ }\NormalTok{matriceOD[}\DecValTok{1}\OperatorTok{:}\DecValTok{8}\NormalTok{,}\DecValTok{1}\OperatorTok{:}\DecValTok{8}\NormalTok{]}

\CommentTok{# choix aléatoire de couleurs pour les lignes}
\CommentTok{# col <- sample(colors(),nrow(mat),replace = F)}

\CommentTok{# choix de couleurs }
\NormalTok{col <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"#a491d3"}\NormalTok{, }\StringTok{"#818aa3"}\NormalTok{, }\StringTok{"#C5DCA0"}\NormalTok{, }\StringTok{"#F5F2B8"}\NormalTok{,}
         \StringTok{"#F9DAD0"}\NormalTok{, }\StringTok{"#F45B69"}\NormalTok{, }\StringTok{"#22181C"}\NormalTok{, }\StringTok{"#5A0001"}\NormalTok{)}

\CommentTok{# réalisation du graphique : sortie html}
\ControlFlowTok{if}\NormalTok{(knitr}\OperatorTok{::}\KeywordTok{is_html_output}\NormalTok{())\{}
  \KeywordTok{chorddiag}\NormalTok{(mat, }\DataTypeTok{groupColors =}\NormalTok{ col, }\DataTypeTok{showTicks =}\NormalTok{ F,}
        \DataTypeTok{type =} \StringTok{'bipartite'}\NormalTok{, }\DataTypeTok{chordedgeColor =} \StringTok{'white'}\NormalTok{,}
        \DataTypeTok{groupnameFontsize =} \DecValTok{12}\NormalTok{, }\DataTypeTok{groupnamePadding =} \DecValTok{5}\NormalTok{)}
\NormalTok{\}}

\CommentTok{# pour la sortie pdf}
\ControlFlowTok{if}\NormalTok{(knitr}\OperatorTok{::}\KeywordTok{is_latex_output}\NormalTok{())\{}
\NormalTok{  knitr}\OperatorTok{::}\KeywordTok{include_graphics}\NormalTok{(}\StringTok{'images/magie_graphiques/chord_diagramme.png'}\NormalTok{, }\DataTypeTok{dpi =} \OtherTok{NA}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{images/magie_graphiques/chord_diagramme} 

}

\caption{Diagramme d'accord}\label{fig:fig349}
\end{figure}

Le graphique permet de remarquer que la plupart des flux s'effectuent au sein d'un même secteur. La majorité des déplacements se font au sein du secteur Sainte-Foy (segment rouge central). On peut cependant constater que les secteurs des Rivières, la cité Limoilou et Haute-Saint-Charle attirent une plus grande quantité et diversité de flux. Si vous lisez ce livre dans un navigateur web (et pas au format \emph{pdf}), le graphique est interactif ! En plaçant votre souris sur un lien, vous verrez s'afficher le nombre de déplacements qu'il représente.

\hypertarget{sect0333}{%
\subsection{Nuage de mots}\label{sect0333}}

Un nuage de mots est un graphique utilisé en analyse de texte pour représenter les mots les plus importants d'un document. Mesurer l'importance des termes dans un document est une discipline à part entière (\emph{Natural Language Processing}), nous proposons un simple exemple ici avec la méthode \emph{TextRank} (basée sur la théorie des graphs) proposée par \citet{mihalcea2004textrank} et implémentée dans le \emph{package} \textbf{textrank}. Nous aurons également besoin des \emph{packages} \textbf{udpipe} (fournissant des dictionnaires linguistiques), \textbf{RColorBrewer} (pour sélectionner une palette de couleurs) et \textbf{wordcloud2} (pour générer le graphique). En guise d'exemple, nous avons choisi d'extraire les textes de deux Schémas d'Aménagement et de Développement (SAD), ceux des agglomérations de Québec et Montréal en vigueur en 2020. Il s'agit de deux documents de planification définissant les lignes directrices de l'organisation physique du territoire des municipalités régionales de comté (MRC) ou des agglomérations. Pour ces deux documents, nous nous concentrons sur le chapitre portant sur les grandes orientations d'aménagement et de développement, soit les pages 30 à 135 pour Québec et 30 à 97 pour Montréal. Pour extraire les textes des fichiers pdf, nous utilisons le \emph{package} \textbf{pdftools}.

Nous devons donc réaliser les étapes suivantes pour produire le nuage de mots :

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Extraire les sections qui nous intéressent des fichiers \emph{pdf}
\item
  Extraire le texte de ces sections
\item
  Retirer les caractères représentant les sauts de lignes et les sauts de paragraphes (\texttt{\textbackslash{}n} et \texttt{\textbackslash{}r})
\item
  Concaténer tout le texte en une seule longue chaîne de caractère
\item
  Utiliser un dictionnaire pour déterminer la nature des mots du texte (noms, adjectifs, verbes, etc.)
\item
  Utiliser l'algorithme \emph{TextRank} pour identifier les mots clefs
\item
  Nettoyer les erreurs potentielles parmi les mots clefs
\item
  Construire le nuage de mots.
\end{enumerate}

Notez que toutes ces étapes de nettoyage ne seraient pas nécessaires si nous utilisions un simple fichier texte comme point de départ. Cependant, il est plus courant de rencontrer des fichiers \emph{pdf}, cet exercice est donc davantage révélateur de la difficulté réelle de la réalisation d'un nuage de mots.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(wordcloud2)}
\KeywordTok{library}\NormalTok{(udpipe)}
\KeywordTok{library}\NormalTok{(RColorBrewer)}
\KeywordTok{library}\NormalTok{(pdftools)}
\KeywordTok{library}\NormalTok{(textrank)}

\CommentTok{# Étape 1 : extraire les sections pertinentes des fichiers pdf}
\NormalTok{extrait_qc <-}\StringTok{ }\KeywordTok{pdf_subset}\NormalTok{(}\StringTok{"data/graphique/SAD_quebec.pdf"}\NormalTok{, }\DataTypeTok{pages =} \KeywordTok{c}\NormalTok{(}\DecValTok{30}\OperatorTok{:}\DecValTok{135}\NormalTok{),}
                         \DataTypeTok{output =} \StringTok{"data/graphique/SAD_quebec_ext.pdf"}\NormalTok{)}
\NormalTok{extrait_mtl <-}\StringTok{ }\KeywordTok{pdf_subset}\NormalTok{(}\StringTok{"data/graphique/SAD_montreal.pdf"}\NormalTok{, }\DataTypeTok{pages =} \KeywordTok{c}\NormalTok{(}\DecValTok{30}\OperatorTok{:}\DecValTok{97}\NormalTok{),}
                          \DataTypeTok{output =} \StringTok{"data/graphique/SAD_montral_ext.pdf"}\NormalTok{)}

\CommentTok{# Étape 2 : extraire le texte des fichiers pdf sous forme de vecteur de texte}
\NormalTok{file_qc <-}\StringTok{ }\KeywordTok{pdf_text}\NormalTok{(extrait_qc)}
\NormalTok{file_mtl <-}\StringTok{ }\KeywordTok{pdf_text}\NormalTok{(extrait_mtl)}

\CommentTok{# Étape 3 : retirer les saut de lignes et les paragraphes}
\NormalTok{file_qc <-}\StringTok{ }\KeywordTok{gsub}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}r}\StringTok{"}\NormalTok{,}\StringTok{""}\NormalTok{,}\DataTypeTok{x =}\NormalTok{ file_qc)}
\NormalTok{file_qc <-}\StringTok{ }\KeywordTok{gsub}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{,}\StringTok{""}\NormalTok{,}\DataTypeTok{x =}\NormalTok{ file_qc)}

\NormalTok{file_mtl <-}\StringTok{ }\KeywordTok{gsub}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}r}\StringTok{"}\NormalTok{,}\StringTok{""}\NormalTok{,}\DataTypeTok{x =}\NormalTok{ file_mtl)}
\NormalTok{file_mtl <-}\StringTok{ }\KeywordTok{gsub}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{,}\StringTok{""}\NormalTok{,}\DataTypeTok{x =}\NormalTok{ file_mtl)}

\CommentTok{# Étape 4 : créer une seule longue chaîne de caractères}
\CommentTok{# à partir des vecteurs de texte}
\NormalTok{text_qc <-}\StringTok{ }\KeywordTok{paste}\NormalTok{(file_qc, }\DataTypeTok{collapse =} \StringTok{" "}\NormalTok{)}
\NormalTok{text_mtl <-}\StringTok{ }\KeywordTok{paste}\NormalTok{(file_mtl, }\DataTypeTok{collapse =} \StringTok{" "}\NormalTok{)}

\CommentTok{# charger le modèle linguistique français}
\NormalTok{model <-}\StringTok{ }\KeywordTok{udpipe_load_model}\NormalTok{(}\StringTok{'data/graphique/french-sequoia-ud-2.4-190531.udpipe'}\NormalTok{)}

\CommentTok{# pour télécharger le modèle si ce n'est pas encore fait : }
\CommentTok{# model <- udpipe_download_model("french-sequoia")}
\CommentTok{# model <- udpipe_load_model(model)}

\CommentTok{# Etape 5 : Analyse de la nature des mots du texte avec le dictionnaire fr}
\CommentTok{# On obtient des dataframes décrivant les mots des textes}
\NormalTok{annote_qc <-}\StringTok{ }\KeywordTok{udpipe_annotate}\NormalTok{(model, text_qc)}
\NormalTok{df_qc <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(annote_qc)}

\NormalTok{annote_mtl <-}\StringTok{ }\KeywordTok{udpipe_annotate}\NormalTok{(model, text_mtl)}
\NormalTok{df_mtl <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(annote_mtl)}

\CommentTok{# Etape 6 : Utilisation de la méthode TextRank}
\NormalTok{stats_qc <-}\StringTok{ }\KeywordTok{textrank_keywords}\NormalTok{(df_qc}\OperatorTok{$}\NormalTok{lemma,}
                  \DataTypeTok{relevant =}\NormalTok{ df_qc}\OperatorTok{$}\NormalTok{upos }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"NOUN"}\NormalTok{, }\StringTok{"ADJ"}\NormalTok{), }\DataTypeTok{ngram_max=}\DecValTok{2}\NormalTok{)}

\NormalTok{stats_mtl <-}\StringTok{ }\KeywordTok{textrank_keywords}\NormalTok{(df_mtl}\OperatorTok{$}\NormalTok{lemma,}
                  \DataTypeTok{relevant =}\NormalTok{ df_mtl}\OperatorTok{$}\NormalTok{upos }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"NOUN"}\NormalTok{,}\StringTok{"ADJ"}\NormalTok{), }\DataTypeTok{ngram_max=}\DecValTok{2}\NormalTok{)}

\CommentTok{# Etape 7 : Nettoyer les coquilles dans les mots clefs }
\CommentTok{# NB : nous faisons ici le choix de garder des mots clefs uniques (ngram == 1)}
\CommentTok{# il serait aussi possible de garder des associations de plusieurs mots}
\NormalTok{dfstats_qc <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(stats_qc}\OperatorTok{$}\NormalTok{keywords, stats_qc}\OperatorTok{$}\NormalTok{keywords}\OperatorTok{$}\NormalTok{ngram }\OperatorTok{==}\StringTok{ }\DecValTok{1} \OperatorTok{&}
\StringTok{                       }\KeywordTok{nchar}\NormalTok{(stats_qc}\OperatorTok{$}\NormalTok{keywords}\OperatorTok{$}\NormalTok{keyword)}\OperatorTok{>}\DecValTok{2}\NormalTok{)}
\NormalTok{dfstats_qc}\OperatorTok{$}\NormalTok{keyword <-}\StringTok{ }\KeywordTok{gsub}\NormalTok{(}\StringTok{"d’"}\NormalTok{,}\StringTok{""}\NormalTok{,dfstats_qc}\OperatorTok{$}\NormalTok{keyword,}\DataTypeTok{fixed =}\NormalTok{ T)}
\NormalTok{dfstats_qc}\OperatorTok{$}\NormalTok{keyword <-}\StringTok{ }\KeywordTok{gsub}\NormalTok{(}\StringTok{"l’"}\NormalTok{,}\StringTok{""}\NormalTok{,dfstats_qc}\OperatorTok{$}\NormalTok{keyword,}\DataTypeTok{fixed =}\NormalTok{ T)}

\NormalTok{dfstats_mtl <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(stats_mtl}\OperatorTok{$}\NormalTok{keywords, stats_mtl}\OperatorTok{$}\NormalTok{keywords}\OperatorTok{$}\NormalTok{ngram }\OperatorTok{==}\StringTok{ }\DecValTok{1} \OperatorTok{&}
\StringTok{                        }\KeywordTok{nchar}\NormalTok{(stats_mtl}\OperatorTok{$}\NormalTok{keywords}\OperatorTok{$}\NormalTok{keyword)}\OperatorTok{>}\DecValTok{2}\NormalTok{)}
\NormalTok{dfstats_mtl}\OperatorTok{$}\NormalTok{keyword <-}\StringTok{ }\KeywordTok{gsub}\NormalTok{(}\StringTok{"d’"}\NormalTok{,}\StringTok{""}\NormalTok{,dfstats_mtl}\OperatorTok{$}\NormalTok{keyword,}\DataTypeTok{fixed =}\NormalTok{ T)}
\NormalTok{dfstats_mtl}\OperatorTok{$}\NormalTok{keyword <-}\StringTok{ }\KeywordTok{gsub}\NormalTok{(}\StringTok{"l’"}\NormalTok{,}\StringTok{""}\NormalTok{,dfstats_mtl}\OperatorTok{$}\NormalTok{keyword,}\DataTypeTok{fixed =}\NormalTok{ T)}

\CommentTok{# Etape 8 : Réaliser les nuages de mots}
\NormalTok{couleurs <-}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\KeywordTok{brewer.pal}\NormalTok{(}\DecValTok{12}\NormalTok{, }\StringTok{"Paired"}\NormalTok{)) }\CommentTok{# mise en désordre des couleurs}

\KeywordTok{wordcloud2}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ dfstats_mtl[}\KeywordTok{c}\NormalTok{(}\StringTok{"keyword"}\NormalTok{, }\StringTok{"freq"}\NormalTok{)],}
           \DataTypeTok{color =}\NormalTok{ couleurs, }\DataTypeTok{size =} \FloatTok{0.5}\NormalTok{, }\DataTypeTok{shuffle =}\NormalTok{ F)}

\KeywordTok{wordcloud2}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ dfstats_qc[}\KeywordTok{c}\NormalTok{(}\StringTok{"keyword"}\NormalTok{, }\StringTok{"freq"}\NormalTok{)],}
           \DataTypeTok{color =}\NormalTok{ couleurs, }\DataTypeTok{size =} \FloatTok{0.6}\NormalTok{, }\DataTypeTok{shuffle =}\NormalTok{ F)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.85\linewidth]{images/magie_graphiques/nuage_mtl} 

}

\caption{Nuage de mots pour le SAD de Montréal}\label{fig:fig350}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=0.85\linewidth]{images/magie_graphiques/nuage_qc} 

}

\caption{Nuage de mots pour le SAD de Québec}\label{fig:fig351}
\end{figure}

Notez qu'à chaque génération du nuage de mots, vous obteindrez une disposition différente. N'hésitez pas à en essayer plusieurs jusqu'à trouver celle qui vous semble optimale.

\hypertarget{sect0334}{%
\subsection{Treemaps}\label{sect0334}}

Un \emph{treemap} est un graphique permettant de représenter une quantité partagée entre plusieurs observations structurées dans une hiérarchie de groupe. Le jeu de données portant sur les émissions de CO2 se prête tout à fait à une représentation par \emph{treemaps}. La variable de quantité est bien sûr les émissions de CO2 par pays; ces pays sont regroupés dans un premier ensemble de régions (découpage en 23 régions), qui elles-mêmes sont regroupées dans des régions plus larges (découpage en sept régions). Pour construire un \emph{treemap}, nous allons utiliser le \emph{package} \textbf{treemap}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(treemap)}
\KeywordTok{library}\NormalTok{(RColorBrewer)}

\CommentTok{# extraire les données de CO2 en 2015}
\NormalTok{data_co2_}\DecValTok{2015}\NormalTok{ <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(data_co2,data_co2}\OperatorTok{$}\NormalTok{year }\OperatorTok{==}\StringTok{ "2015"} \OperatorTok{&}\StringTok{ }\OperatorTok{!}\StringTok{ }\KeywordTok{is.na}\NormalTok{(data_co2}\OperatorTok{$}\NormalTok{region7))}

\CommentTok{# construire le treemap}

\KeywordTok{treemap}\NormalTok{(data_co2_}\DecValTok{2015}\NormalTok{, }\DataTypeTok{index=}\KeywordTok{c}\NormalTok{(}\StringTok{"region7"}\NormalTok{,}\StringTok{"region23"}\NormalTok{),}
    \DataTypeTok{vSize=}\StringTok{"CO2_kt"}\NormalTok{, }\DataTypeTok{type=}\StringTok{"index"}\NormalTok{,}
    \DataTypeTok{title =} \StringTok{"CO2 rejetés par pays en 2015"}\NormalTok{,}
    \DataTypeTok{fontsize.labels=}\KeywordTok{c}\NormalTok{(}\DecValTok{12}\NormalTok{,}\DecValTok{8}\NormalTok{), }\CommentTok{# taille des étiquettes              }
    \DataTypeTok{fontcolor.labels=}\KeywordTok{c}\NormalTok{(}\StringTok{"white"}\NormalTok{,}\StringTok{"black"}\NormalTok{), }\CommentTok{# couleur des étiquettes}
    \DataTypeTok{fontface.labels=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{), }\CommentTok{# style des polices}
    \DataTypeTok{bg.labels=}\KeywordTok{c}\NormalTok{(}\StringTok{"transparent"}\NormalTok{), }\CommentTok{# arrière plan des étiquettes}
    \DataTypeTok{align.labels=}\KeywordTok{list}\NormalTok{(}
        \KeywordTok{c}\NormalTok{(}\StringTok{"center"}\NormalTok{, }\StringTok{"center"}\NormalTok{), }
        \KeywordTok{c}\NormalTok{(}\StringTok{"right"}\NormalTok{, }\StringTok{"bottom"}\NormalTok{)}
\NormalTok{        ),  }\CommentTok{# localisation des étiquettes dans les boites}
    \DataTypeTok{overlap.labels=}\FloatTok{0.5}\NormalTok{, }\CommentTok{# tolérance de superposition}
    \DataTypeTok{inflate.labels=}\NormalTok{F, }\CommentTok{# agrandir la taille des étiquettes ou non}
    \DataTypeTok{palette =} \KeywordTok{brewer.pal}\NormalTok{(}\DecValTok{7}\NormalTok{,}\StringTok{'Paired'}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig352-1} 

}

\caption{Treemap}\label{fig:fig352}
\end{figure}

\hypertarget{sect034}{%
\section{Les cartes}\label{sect034}}

Toute comme un graphique, un carte est aussi une illustration visuelle, avec la généralisation des données géographiques, il peut être utile de savoir représenter ce type de données. Si R n'est pas un logiciel de cartographie, il est possible de réaliser des cartes assez facilement, directement avec \textbf{ggplot2}. Nous avons cependant une préférence pour le \emph{package} \textbf{tmap} qui propose de nombreuses fonctionnalités. Pour tracer des cartes, \textbf{tmap} et \textbf{ggplot2} ont besoin d'utiliser un format de données comprenant la géométrie (polyones, lignes ou points), la localisation et le système de projection des entités spatiales étudiées. Le format de fichier le plus courant pour ce type de données est le \emph{shapefile} (\emph{.shp}), mais vous pourrez parfois croiser des fichiers \emph{geojson} (.js), ou encore \emph{geopackages} (.gpkg). Pour lire ces fichiers, il est possible d'utiliser la fonction \emph{readOGR} du \emph{package} \textbf{rgdal}, ou la fonction \emph{st\_read} du package \textbf{sf}. Notez ici que ces deux fonctions ne produisent pas des \emph{DataFrame}, mais respectivement un \emph{SpatialDataFrame} et un objet \emph{sf} (\emph{simple feature collection}). Sans rentrer dans les détails, sachez que deux \emph{packages} permettent de manipuler des objets spatiaux dans R : le traditionnel \textbf{sp} (avec les \emph{SpatialDataFrame}) et le plus récent \textbf{sf} (avec les objets du même nom). Il est assez facile de convertir un objet de \textbf{sp} vers \textbf{sf} (et inversement) et cette opération est souvent nécessaire car de nombreux \emph{packages} dédiés à l'analyse spatiale utilisent l'un ou l'autre des formats. Dans le cas de \textbf{tmap}, des objets de \textbf{sp} et de \textbf{sf} peuvent être utilisés sans distinction. En revanche, pour cartographier directement avec \textbf{ggplot2}, il est plus facile d'utiliser un objet de type \emph{sf}.

Une carte thématique permet de représenter la répartition spatiale de variables qualitatives ou quantitatives. On les distingue des cartes topographiques dont l'objectif est de représenter la localisation d'objets spécifiques (route, habitation, rivière, lac, etc.). Les premières sont relativement faciles à construire dans R car elles se limitent à quelques symboles relativement peu complexes. Pour les secondes, on préferera généralement un logiciel comme \href{https://qgis.org/en/site/}{QGis}.

Créons une carte thématique à partir des données de densité de végétation sur l'Île de Montréal avec les packages \textbf{ggplot2} puis \textbf{tmap}.

Avec \textbf{ggplot2}, nous aurons aussi besoin des \emph{packages} \textbf{classInt} pour calculer les intervalles des classes et de \textbf{ggsn} pour afficher une échelle.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(sf)}
\KeywordTok{library}\NormalTok{(classInt)}
\KeywordTok{library}\NormalTok{(ggsn)}

\CommentTok{# chargement des données}
\NormalTok{spatialdf <-}\StringTok{ }\KeywordTok{st_read}\NormalTok{(}\StringTok{"data/bivariee/IlotsVeg2006.shp"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Reading layer `IlotsVeg2006' from data source `D:\Articles et colloque\Livre en cours\AnalysesQuanti\Livre\livre_statistique_Phil_Jere\data\bivariee\IlotsVeg2006.shp' using driver `ESRI Shapefile'
## Simple feature collection with 10213 features and 12 fields
## geometry type:  MULTIPOLYGON
## dimension:      XY
## bbox:           xmin: 267518.7 ymin: 5029292 xmax: 306663.7 ymax: 5062652
## projected CRS:  NAD83 / MTM zone 8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# création d'une discrétisation en 7 classes égales}
\NormalTok{values <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\KeywordTok{max}\NormalTok{(spatialdf}\OperatorTok{$}\NormalTok{ArbPct)}\OperatorTok{+}\FloatTok{0.01}\NormalTok{,spatialdf}\OperatorTok{$}\NormalTok{ArbPct)}

\NormalTok{quant <-}\StringTok{ }\KeywordTok{classIntervals}\NormalTok{(values, }\DataTypeTok{n =} \DecValTok{7}\NormalTok{,}
                        \DataTypeTok{style =} \StringTok{"quantile"}\NormalTok{,}
                        \DataTypeTok{intervalClosure =} \StringTok{'right'}\NormalTok{)}

\NormalTok{spatialdf}\OperatorTok{$}\NormalTok{class_col <-}\StringTok{ }\KeywordTok{cut}\NormalTok{(spatialdf}\OperatorTok{$}\NormalTok{ArbPct, }\DataTypeTok{breaks =}\NormalTok{ quant}\OperatorTok{$}\NormalTok{brks, }\DataTypeTok{right =}\NormalTok{ F)}


\CommentTok{# cartographie avec ggplot2}
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ spatialdf) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_sf}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{fill =}\NormalTok{ class_col), }\DataTypeTok{color =} \KeywordTok{rgb}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{))}\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_fill_brewer}\NormalTok{(}\DataTypeTok{palette =} \StringTok{"Greens"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Végétation dans les Îlos de recensement"}\NormalTok{,}
       \StringTok{'fill'}\NormalTok{ =}\StringTok{ 'Densité de la canopée (%)'}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{axis.line=}\KeywordTok{element_blank}\NormalTok{(),}\DataTypeTok{axis.text.x=}\KeywordTok{element_blank}\NormalTok{(),}
        \DataTypeTok{axis.text.y=}\KeywordTok{element_blank}\NormalTok{(),}\DataTypeTok{axis.ticks=}\KeywordTok{element_blank}\NormalTok{(),}
        \DataTypeTok{axis.title.x=}\KeywordTok{element_blank}\NormalTok{(), }\DataTypeTok{axis.title.y=}\KeywordTok{element_blank}\NormalTok{(),}
        \DataTypeTok{panel.background=}\KeywordTok{element_blank}\NormalTok{(),}
        \DataTypeTok{panel.border=}\KeywordTok{element_blank}\NormalTok{(),}\DataTypeTok{panel.grid.major=}\KeywordTok{element_blank}\NormalTok{(),}
        \DataTypeTok{panel.grid.minor=}\KeywordTok{element_blank}\NormalTok{(),}\DataTypeTok{plot.background=}\KeywordTok{element_blank}\NormalTok{(),}
        \DataTypeTok{legend.key.size =} \KeywordTok{unit}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\StringTok{"cm"}\NormalTok{))}\OperatorTok{+}
\StringTok{  }\KeywordTok{scalebar}\NormalTok{(spatialdf, }\DataTypeTok{dist =} \DecValTok{5}\NormalTok{, }\DataTypeTok{st.size=}\DecValTok{3}\NormalTok{, }\DataTypeTok{height=}\FloatTok{0.01}\NormalTok{, }\DataTypeTok{model =} \StringTok{'WGS84'}\NormalTok{, }
           \DataTypeTok{dist_unit =} \StringTok{"km"}\NormalTok{, }\DataTypeTok{transform =}\NormalTok{ F, }\DataTypeTok{location =} \StringTok{'bottomright'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.85\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig353-1} 

}

\caption{Carte thématique avec ggplot2}\label{fig:fig353}
\end{figure}

Il est possible d'arriver à un résultat similaire avec \textbf{tmap} avec moins de code !

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tmap)}

\NormalTok{colors <-}\StringTok{ }\KeywordTok{brewer.pal}\NormalTok{(}\DecValTok{7}\NormalTok{,}\StringTok{"Greens"}\NormalTok{)}

\KeywordTok{tm_shape}\NormalTok{(spatialdf) }\OperatorTok{+}
\StringTok{  }\KeywordTok{tm_polygons}\NormalTok{(}\StringTok{"ArbPct"}\NormalTok{, }\DataTypeTok{palette =}\NormalTok{ colors, }\DataTypeTok{border.alpha =} \DecValTok{0}\NormalTok{,}
            \DataTypeTok{n =} \DecValTok{7}\NormalTok{, }\DataTypeTok{style =} \StringTok{'quantile'}\NormalTok{,}
            \DataTypeTok{title =} \StringTok{'Densité de la canopée (%)'}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{tm_scale_bar}\NormalTok{(}\DataTypeTok{breaks =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{10}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{tm_layout}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Végétation dans les Îlos de recensement"}\NormalTok{,}
            \DataTypeTok{attr.outside =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{frame =} \OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.85\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig354-1} 

}

\caption{Carte thématique avec tmap}\label{fig:fig354}
\end{figure}

Les graphiques créés par \textbf{tmap} ne peuvent malheureusement pas être combinés avec la fonction \texttt{ggarrange}, mais \textbf{tmap} dispose de sa propre fonction \texttt{tmap\_arrange} si vous souhaitez combiner plusieurs cartes.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tmap)}

\NormalTok{colors <-}\StringTok{ }\KeywordTok{brewer.pal}\NormalTok{(}\DecValTok{7}\NormalTok{,}\StringTok{"Greens"}\NormalTok{)}

\NormalTok{colors2 <-}\StringTok{ }\KeywordTok{brewer.pal}\NormalTok{(}\DecValTok{7}\NormalTok{,}\StringTok{"Reds"}\NormalTok{)}

\NormalTok{carte1 <-}\StringTok{ }\KeywordTok{tm_shape}\NormalTok{(spatialdf) }\OperatorTok{+}
\StringTok{  }\KeywordTok{tm_polygons}\NormalTok{(}\StringTok{"ArbPct"}\NormalTok{, }\DataTypeTok{palette =}\NormalTok{ colors, }\DataTypeTok{border.alpha =} \DecValTok{0}\NormalTok{,}
            \DataTypeTok{n =} \DecValTok{7}\NormalTok{, }\DataTypeTok{style =} \StringTok{'quantile'}\NormalTok{,}
            \DataTypeTok{title =} \StringTok{'Densité de la canopée (%)'}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{tm_scale_bar}\NormalTok{(}\DataTypeTok{breaks =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{10}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{tm_layout}\NormalTok{(}\DataTypeTok{attr.outside =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{frame =} \OtherTok{FALSE}\NormalTok{)}

\NormalTok{carte2 <-}\StringTok{ }\KeywordTok{tm_shape}\NormalTok{(spatialdf) }\OperatorTok{+}
\StringTok{  }\KeywordTok{tm_polygons}\NormalTok{(}\StringTok{"LogDens"}\NormalTok{, }\DataTypeTok{palette =}\NormalTok{ colors2, }\DataTypeTok{border.alpha =} \DecValTok{0}\NormalTok{,}
            \DataTypeTok{n =} \DecValTok{7}\NormalTok{, }\DataTypeTok{style =} \StringTok{'quantile'}\NormalTok{,}
            \DataTypeTok{title =} \StringTok{'Densité de logement'}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{tm_scale_bar}\NormalTok{(}\DataTypeTok{breaks =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{10}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{tm_layout}\NormalTok{(}\DataTypeTok{attr.outside =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{frame =} \OtherTok{FALSE}\NormalTok{)}

\KeywordTok{tmap_arrange}\NormalTok{(carte1, carte2, }\DataTypeTok{ncol =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.85\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig355-1} 

}

\caption{Combiner des cartes avec tmap}\label{fig:fig355}
\end{figure}

\hypertarget{sect035}{%
\section{Exporter des graphiques}\label{sect035}}

Tous les graphiques que nous avons construits dans ce chapitre peuvent être exportés assez facilement. Dans RStudio, vous pouvez directement cliquer sur le bouton \emph{export} (figure \ref{fig:fig355})) pour enregistrer votre figure au format image (raster) ou au format PDF (vecteur). Notez qu'avec la seconde option, vous pourrez retoucher votre graphique avec un logiciel externe comme \emph{Inkscape} ou \emph{Illustrator}, ce qui est souvent nécessaire.

\begin{figure}

{\centering \includegraphics[width=0.4\linewidth]{images/magie_graphiques/export} 

}

\caption{Exporter un graphique dans RStudio}\label{fig:fig356}
\end{figure}

Lorsque vous créez un graphique avec \textbf{ggplot2}, il est aussi possible de l'exporter avec la fonction \texttt{ggsave}. Cette fonctionnalité est très pratique lorsque vous souhaitez automatiser la production de graphiques et ne pas avoir à tous les exporter à la main. Pour en apprendre plus sur l'automatisation de tâches dans R, référez vous au chapitre XXX.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(iris)}

\NormalTok{plot1 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width), }\DataTypeTok{data =}\NormalTok{ iris)}

\KeywordTok{ggsave}\NormalTok{(}\DataTypeTok{filename =} \StringTok{'graphique.pdf'}\NormalTok{,}
       \DataTypeTok{path =} \StringTok{'mon/dossier'}\NormalTok{,}
       \DataTypeTok{plot =}\NormalTok{ plot1,}
       \DataTypeTok{width =} \DecValTok{10}\NormalTok{, }\DataTypeTok{height =} \DecValTok{10}\NormalTok{, }\DataTypeTok{units =} \StringTok{"cm"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Pour les graphiques n'étant pas réalisés avec \textbf{ggplot2}, l'alternative à la fonction \texttt{ggsave} est l'ensemble de fonctions \texttt{png}, \texttt{bmp}, \texttt{jpeg}, \texttt{tiff} et \texttt{pdf}, qui permettent d'exporter n'importe quel graphique dans ces différents formats. Le processus comprend trois étapes :

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Ouvrir une connexion vers le fichier dans lequel le graphique sera exporté avec une des fonctions \texttt{png}, \texttt{bmp}, \texttt{jpeg}, \texttt{tiff} et \texttt{pdf}.
\item
  Réaliser son graphique comme si on souhaitait l'afficher dans RSudio. Il n'apparaitra cependant pas, car il sera écrit dans le fichier en question à la place.
\item
  Fermer la connexion au fichier avec la fonction \texttt{dev.off} pour définitivement enregistrer le graphique.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(iris)}

\CommentTok{# 1. Ouvrir la connexion}
\KeywordTok{png}\NormalTok{(}\DataTypeTok{filename =} \StringTok{'mon/dossier/graphique.png'}\NormalTok{)}

\CommentTok{# 2. Afficher le graphique}
\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width), }\DataTypeTok{data =}\NormalTok{ iris)}

\CommentTok{# 3. fermer la connexion}
\KeywordTok{dev.off}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\hypertarget{sect036}{%
\section{Conclusion sur les graphiques}\label{sect036}}

Vous avez pu constater que les capacités de représentation graphique de R sont vastes et pourtant nous n'avons fait qu'observer la partie émergée de l'iceberg dans ce chapitre. Il est également possible de réaliser de la visualisation en 3D dans R (\textbf{plot3D}, \textbf{rgl}), d'animer des graphiques pour en faire des \emph{GIF} ou des vidéos (\textbf{gganimate}), de rendre des graphiques interactifs, ou même de construire des plateformes de visualisation de données disponibles en ligne (\textbf{shiny}). Vous continuerez à découvrir de nouvelles formes de représentations au fur et à mesure de votre pratique, en apprenant de nouvelles méthodes nécessitant des visualisations spécifiques.

Voici également deux références trés utiles qui nous ont notamment aidé à construire ce chapitre :

\begin{itemize}
\tightlist
\item
  \href{https://www.r-graph-gallery.com/}{The R Graph Gallery}, probablement \textbf{LE} site web proposant le plus de matériel sur comment réaliser des grahiques dans R.
\item
  \href{https://www.data-to-viz.com/}{Data to viz}, si vous ne savez pas quel graphique pourrait le mieux correspondre à vos données, Data to viz est là pour vous aider. Vous y trouverez un arbre de décision pour vous indiquer quel graphique utiliser dans quelle situation, ainsi que de nombreux conseils sur la visualisation de données.
\end{itemize}

\hypertarget{part-analyse-bivariuxe9e}{%
\part{Analyse bivariée}\label{part-analyse-bivariuxe9e}}

\hypertarget{chap04}{%
\chapter{Analyses bivariées}\label{chap04}}

Dans ce chapitre, nous présentons les principales méthodes exploratoires et confirmatoires bivariées permettant d'évaluer la relation entre deux variables, et ce, en fonction de leur type : deux variables quantitatives, deux variables qualitatives ou encore une variable quantitative \emph{versus} une variable qualitative (comprenant deux modalités ou plus de deux modalités) (figure \ref{fig:fig1}).

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{images/bivariee/figure1} 

}

\caption{Les principales méthodes bivariées}\label{fig:fig1}
\end{figure}

Plus spécifiquement, nous présentrons puis mettrons en œuvre dans le logiciel les méthodes suivantes : covariance, corrélation et régression linéaire simple (entre deux variables quantitatives, section \ref{sect041}), tableau de contingence et test du khi\textsuperscript{2} (entre deux variables qualitatives, section \ref{sect042}), t de student (test \emph{t}) et test de Wilcoxon (entre une variable quantitative et une variable qualitative comprenant deux modalités, section \ref{sect043}), et analyse de variance et test de Kruskal-Wallis (entre une variable quantitative et une variable qualitative comprenant plus de deux modalités, section \ref{sect044}).

\begin{bloc_package}

Dans cette section, nous utiliserons principalement les \emph{packages} suivants :

\begin{itemize}
\tightlist
\item
  Pour créer des graphiques :

  \begin{itemize}
  \tightlist
  \item
    \textbf{ggplot2}, le seul, l'unique
  \item
    \textbf{ggpubr}, pour combiner des graphiques et réaliser des diagrammes quantiles-quantiles
  \end{itemize}
\item
  Pour manipuler des données :

  \begin{itemize}
  \tightlist
  \item
    \textbf{dplyr}, avec les fonctions \emph{group\_by}, \emph{summarize} et les pipes \emph{\%\textgreater\%}
  \end{itemize}
\item
  Pour les corrélations (section \ref{sect0411}) :

  \begin{itemize}
  \tightlist
  \item
    \textbf{correlation}, de l'ensemble de package \textbf{easy\_stats}, offrant une large gamme de méthodes de corrélations
  \item
    \textbf{boot} pour réaliser des corrélations avec \emph{bootstrap}
  \item
    \textbf{Hmisc} pour calculer des corrélations de Pearson et Spearman
  \item
    \textbf{ppcor}, notamment pour des corrélations partielles
  \item
    \textbf{psych} pour obtenir une matrice de corrélation (Pearson, Spearman et Kendall), les intervalles de confiance et les valeurs de p.
  \item
    \textbf{stargazer} pour créer des beaux tableaux d'une matrice de corrélation en Html ou en LaTeX ou en ASCII.
  \item
    \textbf{corrplot}, pour créer des graphiques de matrices de corrélation
  \end{itemize}
\item
  Pour le tableau de contignence (section \ref{sect0412}) :

  \begin{itemize}
  \tightlist
  \item
    \textbf{gmodels}, pour construire des tableaux de contingence et calculer les tests \emph{t} et ses différentes variantes (section \ref{sect0424})
  \item
    \textbf{vcd}, pour construire un graphique pour un tableau de contigence ((section \ref{sect0424}))
  \end{itemize}
\item
  Pour les test \emph{t} :

  \begin{itemize}
  \tightlist
  \item
    \textbf{sjstats} pour réaliser des test \emph{t} pondérés
  \item
    \textbf{effectsize}, pour calculer les tailles d'effet de tests de \emph{t}
  \end{itemize}
\item
  Pour la section sur les ANOVA (section \ref{sect0441}) :

  \begin{itemize}
  \tightlist
  \item
    \textbf{car}, pour les ANOVA classiques
  \item
    \emph{lmtest} pour le test de Breusch-Pagan d'homogénéité des variances
  \item
    \textbf{rstatix}, intégrant de nombreux tests classiques (comme le test de Shapiro) avec \textbf{tidyverse}
  \end{itemize}
\end{itemize}

\end{bloc_package}

\hypertarget{sect041}{%
\section{Relation linéaire entre deux variables quantitatives}\label{sect041}}

\begin{bloc_objectif}

\textbf{Deux variables continues varient-elles dans le même sens ou bien en sens contraire ?} Répondre à cette question est une démarche exploratoire classique en sciences sociales puisque les données socioéconomiques sont souvent associées linéairement. En d'autres termes, lorsque l'une des deux variables tant à augmenter, la seconde augmente également ou diminue systématiquement.

En études urbaines, on pourrait vouloir vérifier si certaines variables socioéconomiques sont associées positivement ou négativement à des variables environnementales jugées positives (comme la couverture végétale ou des mesures d'accessibilité spatiale aux parcs) ou négatives (pollutions atmosphériques et sonores).

Par exemple, au niveau des secteurs de recensement d'une ville canadienne ou américaine, on pourrait vouloir vérifier si le revenu médian des ménages ou encore le coût moyen du loyer varient dans le même sens que la couverture végétale ; ou au contraire, en sens inverse des niveaux moyens de dioxyde d'azote ou de bruit routier.

Pour évaluer la linéarité entre deux variables continues, deux statistiques descriptives sont utilisées : la \textbf{covariance}\index{covariance} (section \ref{sect0412}) et la \textbf{corrélation}\index{corrélation} (section \ref{sect0413}).

\end{bloc_objectif}

\hypertarget{sect0411}{%
\subsection{Bref retour sur le postulat de la relation linéaire}\label{sect0411}}

Vérifier le postulat de la linéarité consiste à évaluer si deux variables quantitatives varient dans le même sens ou bien en sens contraire. Toutefois, la relation entre deux variables quantitatives n'est pas forcément linéaire. En guise d'illustration, la figure \ref{fig:fig2} permet de distinguer quatre types de relations :

\begin{itemize}
\item
  le cas \textbf{a} illustre une relation linéaire positive entre les deux variables puisqu'elles vont dans le même sens. Autrement dit, quand les valeurs de \emph{X} augmentent, celles de \emph{Y} augmentent aussi. En guise d'exemple, pour les secteurs de recensement d'une métropole donnée, il est fort probable que le coût moyen du loyer soit associé positivement avec le revenu médian des ménages. Graphiquement parlant, il est clair qu'une droite dans ce nuage de points résumerait efficacement la relation entre ces deux variables.
\item
  le cas \textbf{b} illustre une relation linéaire négative entre les deux variables puisqu'elles vont en sens inverse. Autrement dit, quand les valeurs de \emph{X} augmentent, celles de \emph{Y} diminuent, et inversement. En guise d'exemple, pour les secteurs de recensement d'une métropole donnée, il est fort probable que le revenu médian des ménages soit associé négativement avec le taux de chômage. De nouveau, une droite résumerait efficacement cette relation.
\item
  pour le cas \textbf{c}, il y a une relation entre les deux variables, mais qui n'est pas linéaire. Le nuage de points entre les deux variables prend d'ailleurs une forme parabolique qui traduit une relation curvilinéaire. Concrètement, on observe une relation positive jusqu'à un certain seuil, puis une relation négative.
\item
  pour le cas \textbf{d}, la relation entre les deux variables est aussi curvilinéaire; d'abord négative, puis positive.
\end{itemize}

\begin{figure}

{\centering \includegraphics[width=0.85\linewidth]{images/bivariee/figure2} 

}

\caption{Relations linéaires et curvilinéaires entre deux variables continues}\label{fig:fig2}
\end{figure}

Prenons un exemple concret. Dans une étude portant sur l'équité environnementale et la végétation à Montréal, Pham \emph{et al.} \citeyearpar{PhamApparicioSeguin2012} ont montré qu'il existe une relation curvilinéaire entre l'âge médian des bâtiments résidentiels (axe des abscisses) et les couvertures végétales (axes des ordonnées) :

\begin{itemize}
\tightlist
\item
  la couverture de la végétation totale et celle des arbres augmentent quand l'âge médian des bâtiments croît jusqu'à atteindre un pic autour de 60 ans (autour de 1950). On peut supposer que les secteurs récemment construits, surtout ceux dans les banlieues, présentent des niveaux de végétation plus faibles. Au fur et au fur que le quartier vieillit, les arbres plantés lors du développement résidentiel deviennent matures --- canopée plus importante --, d'où l'augmentation des valeurs de la couverture végétale totale et de celle des arbres.
\item
  Par contre, dans les secteurs développés avant les années 1950, la densité du bâti est plus forte, laissant ainsi moins de place pour la végétation, ce qui explique une diminution des variables relatives à la couverture végétale (figure \ref{fig:fig3}).
\end{itemize}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{images/bivariee/figure3} 

}

\caption{Exemples de relations curvilinéaires}\label{fig:fig3}
\end{figure}

Dans les sous-sections suivantes, nous décrirons deux statistiques descriptives et exploratoires -- la covariance (section \ref{sect0412}) et la corrélation (section \ref{sect0413}) -- utilisées pour évaluer la \textbf{relation linéaire} entre deux variables continues. Ces deux mesures permettent de mesurer le degré d'association entre deux variables, sans que l'une soit la variable dépendante (variable à expliquer) et l'autre, la variable dépendante (variable explicative). Puis, nous décrirons la régression linéaire simple (section \ref{sect0414}) qui permet justement de prédire une variable dépendante (\emph{Y}) à partir d'une variable indépendante (\emph{X}).

\hypertarget{sect0412}{%
\subsection{Covariance}\label{sect0412}}

\hypertarget{sect04121}{%
\subsubsection{Formulation}\label{sect04121}}

La covariance\index{covariance} (eq. \eqref{eq:cov}), écrite \(cov(x,y)\), est égale à la moyenne du produit des écarts des valeurs des deux variables par rapport à leurs moyennes respectives :

\begin{equation} 
cov(x,y) = \frac{\sum_{i=1}^n (x_{i}-\bar{x})(y_{i}-\bar{y})}{n-1} = \frac{covariation}{n-1}
\label{eq:cov}
\end{equation}

avec \(n\) étant le nombre d'observations; \(\bar{x}\) et \(\bar{y}\) (prononcez x et y barre) étant les moyennes respectives des variables \emph{X} et \emph{Y}.

\hypertarget{sect04122}{%
\subsubsection{Interprétation}\label{sect04122}}

Le numérateur de l'équation \eqref{eq:cov} représente la covariation\index{covariance}, soit la somme du produit des déviations des valeurs \(x_{i}\) et \(y_{i}\) par rapport à leurs moyennes respectives (\(\bar{x}\) et \(\bar{y}\)). La covariance est donc la covariation divisée par le nombre d'observations, soit la moyenne de la covariation. Sa valeur peut être positive ou négative :

\begin{itemize}
\tightlist
\item
  positive quand les deux variables varient dans le même sens, c'est-à-dire que lorsque les valeurs de la variable \emph{X} s'éloignent de la moyenne, les valeurs de \emph{Y} s'éloignent aussi dans le même sens; et négative pour une situation inverse.
\item
  Quand la covariance est égale à 0, il n'y a pas de relation entre les variables \emph{X} et \emph{Y}. Plus sa valeur absolue est élevée, plus la relation entre les deux variables \emph{X} et \emph{Y} est importante.
\end{itemize}

Ainsi, la covariance\index{covariance} correspond à un centrage des variables, c'est-à-dire à soustraire à chaque valeur de la variable sa moyenne correspondante. L'inconvénient majeur de l'utilisation de la covariance est qu'elle est tributaire des unités de mesure des deux variables. Par exemple, si nous calculons la covariance entre le pourcentage de personnes à faible revenu et la densité de population (habitants au km\textsuperscript{2}) au niveau des secteurs de recensement de la région métropolitaine de Montréal, nous obtenons une valeur de covariance de 34934. En revanche, si la densité de population est exprimée en milliers d'habitants au km\textsuperscript{2}, la valeur de la covariance sera de 34,934, alors que la relation linéaire entre les deux variables reste la même tel qu'illustré à la figure \ref{fig:fig4}. Pour rémédier à ce problème, on privilégie l'utilisation du coefficient de corrélation.

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig4-1} 

}

\caption{Covariance et unités de mesure}\label{fig:fig4}
\end{figure}

\hypertarget{sect0413}{%
\subsection{Corrélation}\label{sect0413}}

\hypertarget{sect04131}{%
\subsubsection{Formulation}\label{sect04131}}

Le coefficient de corrélation de Pearson (\(r\)) est égal à la covariance (numérateur) divisée par le produit des écart-types des deux variables \emph{X} et \emph{Y} (dénominateur). Il représente une standardisation de la covariance. Autrement dit, le coefficient de corrélation repose sur un centrage (moyenne = 0) et une réduction (variance = 1) des deux variables, c'est-à-dire à soustraire à chaque valeur sa moyenne correspondante et à la diviser par son écart-type. Il correspond ainsi à la moyenne du produit des deux variables centrées réduites. Il s'écrit alors :

\begin{equation} 
r_{xy} = \frac{\sum_{i=1}^n (x_{i}-\bar{x})(y_{i}-\bar{y})}{(n-1)\sqrt{\sum_{i=1}^n(x_i - \bar{x})^2(y_i - \bar{y})^2}}=\sum_{i=1}^n\frac{ZxZy}{n-1}
\label{eq:cor}
\end{equation}

La syntaxe ci-dessous démontre que le coefficient de corrélation de Pearson est bien égal à la moyenne du produit de deux variables centrées-réduites.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"MASS"}\NormalTok{)}
\NormalTok{N <-}\StringTok{ }\DecValTok{1000}      \CommentTok{# nombre d'observations}
\NormalTok{moy_x <-}\StringTok{ }\DecValTok{50}   \CommentTok{# moyenne de x}
\NormalTok{moy_y <-}\StringTok{ }\DecValTok{40}   \CommentTok{# moyenne de y}
\NormalTok{sd_x <-}\StringTok{ }\DecValTok{10}    \CommentTok{# écart-type de x}
\NormalTok{sd_y <-}\StringTok{ }\DecValTok{8}     \CommentTok{# écart-type de y}
\NormalTok{rxy <-}\StringTok{ }\FloatTok{.80} \CommentTok{# corrélation entre X et Y}
\CommentTok{## création de deux variables fictives normalement distribuées et corrélées entre elles}
\CommentTok{# Création d'une matrice de covariance}
\NormalTok{cov <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\KeywordTok{c}\NormalTok{(sd_x}\OperatorTok{^}\DecValTok{2}\NormalTok{,  rxy}\OperatorTok{*}\NormalTok{sd_x}\OperatorTok{*}\NormalTok{sd_y, rxy}\OperatorTok{*}\NormalTok{sd_x}\OperatorTok{*}\NormalTok{sd_y, sd_y}\OperatorTok{^}\DecValTok{2}\NormalTok{), }\DataTypeTok{nrow=}\DecValTok{2}\NormalTok{)}
\CommentTok{# Création du tableau de données avec deux variables}
\NormalTok{df <-}\StringTok{ }\KeywordTok{as.data.frame}\NormalTok{(}\KeywordTok{mvrnorm}\NormalTok{(N, }\KeywordTok{c}\NormalTok{(moy_x, moy_y), cov))}
\CommentTok{# Centrage et réduction des deux variables}
\NormalTok{df}\OperatorTok{$}\NormalTok{zV1 <-}\StringTok{ }\KeywordTok{scale}\NormalTok{(df}\OperatorTok{$}\NormalTok{V1, }\DataTypeTok{center =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{scale =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{df}\OperatorTok{$}\NormalTok{zV2 <-}\StringTok{ }\KeywordTok{scale}\NormalTok{(df}\OperatorTok{$}\NormalTok{V2, }\DataTypeTok{center =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{scale =} \OtherTok{TRUE}\NormalTok{)}
\CommentTok{# Corrélation de Pearson}
\NormalTok{cor1 <-}\StringTok{ }\KeywordTok{cor}\NormalTok{(df}\OperatorTok{$}\NormalTok{V1, df}\OperatorTok{$}\NormalTok{V2)}
\CommentTok{# Moyenne du produit des variables centrées-réduites}
\NormalTok{cor2 <-}\StringTok{ }\KeywordTok{sum}\NormalTok{(df}\OperatorTok{$}\NormalTok{zV1}\OperatorTok{*}\NormalTok{df}\OperatorTok{$}\NormalTok{zV2) }\OperatorTok{/}\StringTok{ }\NormalTok{(}\KeywordTok{nrow}\NormalTok{(df)}\OperatorTok{-}\DecValTok{1}\NormalTok{)}
\KeywordTok{cat}\NormalTok{(}\StringTok{"Corrélation de Pearson = "}\NormalTok{,}\KeywordTok{round}\NormalTok{(cor1,}\DecValTok{5}\NormalTok{),}
    \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{Moyenne du produit des variables centrées-réduites ="}\NormalTok{, }\KeywordTok{round}\NormalTok{(cor2,}\DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Corrélation de Pearson =  0.80005 
## Moyenne du produit des variables centrées-réduites = 0.80005
\end{verbatim}

\hypertarget{sect04132}{%
\subsubsection{Interprétation}\label{sect04132}}

Le coefficient de corrélation \(r\) varie de −1 à 1 avec :

\begin{itemize}
\tightlist
\item
  0 quand il n'y a pas de relation linéaire entre les variables \emph{X} et \emph{Y}
\item
  −1 quand il y relation linéaire négative parfaite
\item
  et 1 quand il y a une relation linéaire positive parfaite.
\end{itemize}

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig5-1} 

}

\caption{Relations entre deux variables continues et coefficients de corrélation de Pearson}\label{fig:fig5}
\end{figure}

Concrètement, le signe du coefficient de corrélation indique si la relation est positive ou négative et la valeur absolue du coefficient indique le degré d'association entre les deux variables. Reste à savoir comment déterminer qu'une valeur de corrélation est faible, moyenne ou forte. En sciences sociales, on utilise habituellement les intervalles de valeurs reportées au tableau \ref{tab:tableIntervallesCorrelation}. Toutefois, ces seuils sont tout à fait arbitraires. En effet, dépendamment de la discipline de recherche (sciences sociales, sciences de la santé, sciences physiques, etc.), et des variables à l'étude, l'interprétation d'une valeur de corrélation peut varier. Par exemple, en sciences sociales, une valeur de corrélation de 0,2 sera considérée comme très faible alors qu'en sciences de la santé, elle pourrait être considérée comme intéressante. À l'opposé, une valeur de 0,9 en sciences physiques pourrait être considérée comme faible. Il convient alors d'utiliser ces intervalles avec précaution.

\begin{table}

\caption{\label{tab:tableIntervallesCorrelation}Intervalles pour l’interprétation du coefficient de corrélation habituellement utilisés en sciences sociales}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{lll}
\toprule
Corrélation & Négative & Positive\\
\midrule
Faible & de -0,3 à 0,0 & de 0,0 à 0,3\\
Moyenne & de -0,5 à -0,3 & de 0,3 à 0,5\\
Forte & de -1,0 à -0,5 & de 0,5 à 1,0\\
\bottomrule
\end{tabular}
\end{table}

Le coefficient de corrélation mis au carré représente le coefficient de détermination et indique la proportion de la variance de la variable \emph{Y} expliquée par la variable \emph{X} et inversement. Par exemple, un coefficient de corrélation de −0,70 signale que 49\% de la variance de la variable de \emph{Y} est expliquée par \emph{X} (figure \ref{fig:fig6}).

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig6-1} 

}

\caption{Coefficient de corrélation et proportion de la variance expliquée}\label{fig:fig6}
\end{figure}

\textbf{Condition d'application.} L'utilisation du coefficient de corrélation de Pearson nécessite que les deux variables continues soient normalement distribuées et qu'elles ne comprennent pas de valeurs aberrantes (extrêmes). D'ailleurs, plus le nombre d'observations sera réduit, plus la présence de valeurs aberrantes aura un impact important sur le résultat du coefficient de corrélation de Pearson. En guise d'exemple, dans le nuage de points à gauche de la figure \ref{fig:fig7}, il est possible d'identifier des valeurs extrêmes qui se démarquent nettement dans le jeu de données : six observations avec une densité de population supérieure à 20 000 habitants au km\textsuperscript{2} et deux observations avec un pourcentage de 65 ans et plus supérieur à 55\%. Si l'on supprime ces observations (ce qui est défendable dans ce contexte) -- soit moins d'un pourcent des observations du jeu de données initial --, la valeur du coefficient de corrélation passe de −0,158 à −0,194, signalant une augmentation du degré d'association entre les deux variables.

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig7-1} 

}

\caption{Illustation de l’effet des valeurs extrêmes sur le coefficient de Pearson}\label{fig:fig7}
\end{figure}

\hypertarget{sect04133}{%
\subsubsection{Corrélations pour des variables anormalement distribuées (coefficients de Spearman, Tau de kendall)}\label{sect04133}}

Lorsque les variables sont fortement anormalement distribuées, le coefficient de corrélation de Pearson est peu adapté pour analyser leurs relations linéaires. Il est alors conseillé d'utiliser deux statistiques non-paramétriques : principalement, le coefficient de corrélation de Spearman (\emph{rho}) et secondairement, le coefficient de Kendall (\(\tau\), prononcez Tau), qui varient aussi tous deux de −1 à 1.
Calculé sur les rangs des deux variables, \textbf{le coefficient de Spearman} est le rapport entre la covariance des deux variables de rangs sur les écart-types des variables de rangs. En d'autres termes, il représente simplement le coefficient de Pearson calculé sur les rangs des deux variables :

\begin{equation} 
r_{xy} = \frac{cov(rg_{x},rg_{y})}{\sigma_{rg_{x}}\sigma_{rg_{y}}}
\label{eq:spearman}
\end{equation}

La syntaxe ci-dessous démontre clairement que le coefficient de Spearman est bien le coefficient de Pearson calculé sur les rangs (\ref{sect04131}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/bivariee/sr_rmr_mtl_2016.csv"}\NormalTok{)}
\CommentTok{# Transformation des deux variables en rangs}
\NormalTok{df}\OperatorTok{$}\NormalTok{HabKm2_rang <-}\StringTok{ }\KeywordTok{rank}\NormalTok{(df}\OperatorTok{$}\NormalTok{HabKm2)}
\NormalTok{df}\OperatorTok{$}\NormalTok{A65plus_rang <-}\StringTok{ }\KeywordTok{rank}\NormalTok{(df}\OperatorTok{$}\NormalTok{A65plus)}
\CommentTok{# Coefficient de Spearman avec la fonction cor et la méthode spearman}
\KeywordTok{cat}\NormalTok{(}\StringTok{"Coefficient de Spearman = "}\NormalTok{, }
    \KeywordTok{round}\NormalTok{(}\KeywordTok{cor}\NormalTok{(df}\OperatorTok{$}\NormalTok{HabKm2, df}\OperatorTok{$}\NormalTok{A65plus, }\DataTypeTok{method =} \StringTok{"spearman"}\NormalTok{),}\DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Coefficient de Spearman =  -0.11953
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Coefficient de Pearson sur les variables transformées en rangs}
\KeywordTok{cat}\NormalTok{(}\StringTok{"Coefficient de Pearson calculé sur les variables transformées en rangs = "}\NormalTok{, }
    \KeywordTok{round}\NormalTok{(}\KeywordTok{cor}\NormalTok{(df}\OperatorTok{$}\NormalTok{HabKm2_rang, df}\OperatorTok{$}\NormalTok{A65plus_rang, }\DataTypeTok{method =} \StringTok{"pearson"}\NormalTok{),}\DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Coefficient de Pearson calculé sur les variables transformées en rangs =  -0.11953
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Vérification avec l'équation}
\KeywordTok{cat}\NormalTok{(}\StringTok{"Covariance divisée par le produit des écart-types sur les rangs :"}\NormalTok{,}
    \KeywordTok{round}\NormalTok{(}\KeywordTok{cov}\NormalTok{(df}\OperatorTok{$}\NormalTok{HabKm2_rang, df}\OperatorTok{$}\NormalTok{A65plus_rang) }\OperatorTok{/}\StringTok{ }\NormalTok{(}\KeywordTok{sd}\NormalTok{(df}\OperatorTok{$}\NormalTok{HabKm2_rang)}\OperatorTok{*}\KeywordTok{sd}\NormalTok{(df}\OperatorTok{$}\NormalTok{A65plus_rang)),}\DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Covariance divisée par le produit des écart-types sur les rangs : -0.11953
\end{verbatim}

Le \textbf{coefficient de Kendall} est une autre mesure non-paramétrique calculée comme suit :

\begin{equation} 
\tau = \frac{n_{c}-n_{d}}{\frac{1}{2}n(n-1)}
\label{eq:tau}
\end{equation}

avec \(n_{c}\) et \(n_{d}\) qui sont respectivement les nombres de paires d'observations \textbf{c}oncordantes et \textbf{d}iscordantes; et le dénominateur étant le nombre totale de paires d'observations. Des paires sont dites corcondantes quand les valeurs des deux observations vont dans les même sens pour les deux variables (\(x_{i}>x_{j}\) et \(y_{i}>y_{j}\) ou \(x_{i}<x_{j}\) et \(y_{i}<y_{j}\)), et discordantes quand elles vont en sens contraire (\(x_{i}>x_{j}\) et \(y_{i}<y_{j}\) ou \(x_{i}<x_{j}\) et \(y_{i}>y_{j}\)). Contrairement au calcul du coefficient de Spearman, celui de Kendall peut être chronophage : plus le nombre d'observations sera élevé, plus les temps de calcul et la mémoire utilisée sont importants. En effet, avec \emph{n}=1000, le nombre de paires d'observations (\({0.5*n(n-1)}\)) sera de 499500, contre près de 50 millions avec \emph{n}=10000 (49 995 000).

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig8-1} 

}

\caption{Comparaison des coefficients de Pearson, Spearman et Kendall sur deux variables anormalement distribuées}\label{fig:fig8}
\end{figure}

À la lecture des deux histogrammes ci-dessus, il est clair que les deux variables \emph{densité de population} et \emph{pourcentage de personnes ayant 65 ou plus} sont très anormalement distribuées. Dans ce contexte, l'utilisation du coefficient de Pearson peut nous amener à mésestimer la relation existant entre les deux variables. Notez que les coefficients de Spearman et de Kendall sont tous les deux plus faibles.

\hypertarget{sect04134}{%
\subsubsection{\texorpdfstring{Corrélations robustes (\emph{Biweight midcorrelation}, \emph{Percentage bend correlation} et la corrélation \emph{pi} de Shepherd)}{Corrélations robustes (Biweight midcorrelation, Percentage bend correlation et la corrélation pi de Shepherd)}}\label{sect04134}}

Dans l'exemple donné à la figure \ref{fig:fig7}, nous avions identifié des valeurs aberrantes que nous avons retirées du jeu de données. Cette pratique peut tout à fait se justifier quand les données sont erronées (un capteur de pollution renvoyant une valeur négative, un questionnaire rempli par un mauvais plaisantin, etc.), mais parfois, les cas extrêmes font partie du phénomène à analyser. Dans ce contexte, les identifier et les retirer peut paraître arbitraire. Une solution plus élégante est d'utiliser des méthodes dites \textbf{robustes}, c'est à dire moins sensibles aux valeurs extrêmes. Pour les corrélations, la \emph{Biweight midcorrelation} \citep{wilcox1994percentage} est au coefficient de Pearson ce que la médiane est à la moyenne. Il est donc pertinent de l'utiliser dans des jeux de données présentant potentiellement des valeurs extrêmes. Elle est calculée comme suit :

\begin{equation}
\begin{aligned}
&u_{i} = \frac{x_{i} - med(x)}{9 * (med(|x_{i} - med(x)|))} \text{ et } v_{i} = \frac{y_{i} - med(y)}{9 * (med(|y_{i} - med(y)|))}\\
&w_{i}^{(x)} = (1 - u_{i}^2)^2 I(1 - |u_{i}|) \text{ et } w_{i}^{(y)} = (1 - v_{i}^2)^2 I(1 - |v_{i}|)\\
&I(x) = 
\begin{cases}
1, \text{si} x = 1\\
0, \text{sinon}
\end{cases}\\
&\tilde{x}_{i} = \frac{(x_{i} - med(x))w_{i}^{(x)}}{\sqrt{(\sum_{j=1}^m)[(x_{j} - med(x))w_{j}^{(x)}]^2}} \text{ et } \tilde{y}_{i} = \frac{(y_{i} - med(y))w_{i}^{(y)}}{\sqrt{(\sum_{j=1}^m)[(y_{j} - med(y))w_{j}^{(y)}]^2}}\\
&bicor(x,y) = \sum_{i=1}^m \tilde{x_i}\tilde{y_i}
\end{aligned}
\label{eq:bicor}
\end{equation}

Comme le souligne l'équation \eqref{eq:bicor}, la \emph{Biweight midcorrelation} est basée sur les écarts à la médiane, plutôt que sur les écarts à la moyenne.

Assez proche de la \emph{Biweight midcorrelation}, la \emph{Percentage bend correlation} se base également sur la médiane des variables \emph{X} et \emph{Y}. Le principe général est de donner un poids plus faible dans le calcul de cette corrélation à un certain pourcentage des observations (20\% est généralement recommandé) dont la valeur est éloignée de la médiane. Pour une description complète de la méthode, vous pourrez lire l'article de \citet{wilcox1994percentage}.

Enfin, une autre option est l'utilisation de la corrélation \(pi\) de Sherphred \citep{Schwarzkopf2012}. Il s'agit simplement d'une méthode en deux étapes. Premièrement, les valeurs abberantes sont identifiées à l'aide d'une approche par \emph{bootstrap} utilisant la distance de Mahalanobis (calculant les écarts multivariés entre les observations). Ensuite, le coefficient de \emph{Spearman} est calculé sur les observations restantes.

Appliquons ces corrélations aux données précédentes. Notez que ce simple code d'une dizaine de lignes permet d'explorer rapidement la corrélation entre deux variables selon six mesures de corrélations.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"correlation"}\NormalTok{)}
\NormalTok{df1 <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/bivariee/sr_rmr_mtl_2016.csv"}\NormalTok{)}
\NormalTok{methods <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"pearson"}\NormalTok{,}\StringTok{"spearman"}\NormalTok{,}\StringTok{"biweight"}\NormalTok{,}\StringTok{"percentage"}\NormalTok{,}\StringTok{"shepherd"}\NormalTok{)}
\NormalTok{rs <-}\StringTok{ }\KeywordTok{lapply}\NormalTok{(methods,}\ControlFlowTok{function}\NormalTok{(m)\{}
\NormalTok{  test <-}\StringTok{ }\NormalTok{correlation}\OperatorTok{::}\KeywordTok{cor_test}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ df1, }\DataTypeTok{x=}\StringTok{"Hab1000Km2"}\NormalTok{,}\DataTypeTok{y=}\StringTok{"A65plus"}\NormalTok{,}\DataTypeTok{method =}\NormalTok{ m, }\DataTypeTok{ci=}\FloatTok{0.95}\NormalTok{)}
  \KeywordTok{return}\NormalTok{(}\KeywordTok{c}\NormalTok{(test}\OperatorTok{$}\NormalTok{r,test}\OperatorTok{$}\NormalTok{CI_low, test}\OperatorTok{$}\NormalTok{CI_high))}
\NormalTok{  \})}
\NormalTok{dfCorr <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\KeywordTok{do.call}\NormalTok{(rbind,rs))}
\KeywordTok{names}\NormalTok{(dfCorr) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"r"}\NormalTok{,}\StringTok{"IC_05"}\NormalTok{,}\StringTok{"CI_95"}\NormalTok{)}
\NormalTok{dfCorr}\OperatorTok{$}\NormalTok{method <-}\StringTok{ }\NormalTok{methods}
\NormalTok{kableExtra}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(dfCorr,}\DataTypeTok{digits =} \DecValTok{2}\NormalTok{, }
                  \DataTypeTok{caption =} \StringTok{'Comparaison de différentes corrélations pour les variables densité de population et pourcentage de personnes ayant 65 ans et plus'}\NormalTok{,}
                  \DataTypeTok{col.names=}\KeywordTok{c}\NormalTok{(}\StringTok{"r"}\NormalTok{,}\StringTok{"IC 5%"}\NormalTok{,}\StringTok{"IC 95%"}\NormalTok{, }\StringTok{"Méthode"}\NormalTok{))  }\OperatorTok{%>%}
\StringTok{  }\NormalTok{kableExtra}\OperatorTok{::}\KeywordTok{kable_styling}\NormalTok{(}\DataTypeTok{font_size =} \DecValTok{8}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:robcorr}Comparaison de différentes corrélations pour les variables densité de population et pourcentage de personnes ayant 65 ans et plus}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{r|r|r|l}
\hline
r & IC 5\% & IC 95\% & Méthode\\
\hline
-0.16 & -0.22 & -0.10 & pearson\\
\hline
-0.12 & -0.18 & -0.06 & spearman\\
\hline
-0.14 & -0.20 & -0.07 & biweight\\
\hline
-0.17 & -0.23 & -0.11 & percentage\\
\hline
-0.12 & -0.18 & -0.05 & shepherd\\
\hline
\end{tabular}
\end{table}

Il est intéressant de mentionner que ces trois corrélations sont rarement utilisées malgré leur pertinence dans de nombreux cas d'application. Nous faisons face ici à un cercle vicieux dans la recherche : les méthodes les plus connues sont les plus utilisées car elles sont plus facilement acceptées par les autres chercheurs. Des méthodes plus élaborées nécessitent davantage de justification et de discussion, ce qui peut conduire à de multiples sessions de corrections/resoumissions pour qu'un article soit accepté, malgré le fait qu'elles puissent être plus adaptées au jeu de données à l'étude.

\hypertarget{sect04135}{%
\subsubsection{Significativité des coefficients de corrélation}\label{sect04135}}

Quelle que soit la méthode utilisée, il convient de vérifier si le coefficient de corrélation est ou non statistiquement différent de 0. En effet, nous travaillons la plupart du temps avec des données d'échantillonage, et très rarement avec des populations complètes. En collectant un nouvel échantillon, aurions-nous obtenu des résultats différents ? Le calcul de ce degré de significativité nous permet de quantifier notre niveau de certitude quant à l'existance d'une corrélation entre nos deux variables, positive ou négative. Cet objectif est réalisé en calculant la valeur de \emph{t} et le nombre de degrés de liberté : \(t=\sqrt{\frac{n-2}{1-r^2}}\) et \(dl = n-2\) avec \(r\) et \(n\) étant le coefficient de corrélation et le nombre d'observations. De manière classique, on utilisera la table des valeurs critiques de la distribution de \(t\) : si la valeur de \(t\) est supérieure à la valeur critique (avec \emph{p} = 0,05 et le nombre de degré de liberté), alors le coefficient est significatif à 5\%. En d'autres termes, si la vraie corrélation entre les deux variables (calculable uniquement à partir des populations complètes) était 0, alors la probabilité de collecter notre échantillon aurait été inférieure à 5\%. Dans ce contexte, on peut raisonnablement rejeter l'hypothèse nulle (corrélation réelle de 0).

La courte syntaxe illustre comment calculer la valeur de \(t\), le nombre de degrés de liberté et la valeur de \emph{p} pour une corrélation donnée.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/bivariee/sr_rmr_mtl_2016.csv"}\NormalTok{)}
\NormalTok{r <-}\StringTok{ }\KeywordTok{cor}\NormalTok{(df}\OperatorTok{$}\NormalTok{A65plus, df}\OperatorTok{$}\NormalTok{LogTailInc)     }\CommentTok{# Corrélation}
\NormalTok{n <-}\StringTok{ }\KeywordTok{nrow}\NormalTok{(df)                           }\CommentTok{# Nombre d'observations}
\NormalTok{dl <-}\StringTok{ }\KeywordTok{nrow}\NormalTok{(df)}\OperatorTok{-}\DecValTok{2}                        \CommentTok{# degrés de liberté}
\NormalTok{t <-}\StringTok{  }\NormalTok{r}\OperatorTok{*}\KeywordTok{sqrt}\NormalTok{((n}\DecValTok{-2}\NormalTok{)}\OperatorTok{/}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\NormalTok{r}\OperatorTok{^}\DecValTok{2}\NormalTok{))             }\CommentTok{# Valeur de T}
\NormalTok{p <-}\StringTok{ }\DecValTok{2}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\KeywordTok{pt}\NormalTok{(}\KeywordTok{abs}\NormalTok{(t),dl))                }\CommentTok{# Valeur de p}
\KeywordTok{cat}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{Corrélation ="}\NormalTok{, }\KeywordTok{round}\NormalTok{(r, }\DecValTok{4}\NormalTok{),       }
    \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{Valeur de t ="}\NormalTok{, }\KeywordTok{round}\NormalTok{(t, }\DecValTok{4}\NormalTok{),}
    \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{Degrés de liberté ="}\NormalTok{, dl,}
    \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{p="}\NormalTok{, }\KeywordTok{round}\NormalTok{(p, }\DecValTok{4}\NormalTok{))        }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Corrélation = -0.0693 
## Valeur de t = -2.1413 
## Degrés de liberté = 949 
## p= 0.0325
\end{verbatim}

Plus simplement, la fonction \texttt{cor.test} permet d'obtenir en une seule ligne de code le coefficient de corrélation, l'intervalle de confiance à 95\% et les valeurs de \emph{t} et de \emph{p}, tel qu'illustré dans la syntaxe ci-dessous. Si l'intervalle de confiance est à cheval sur 0, c'est-à-dire que la borne inférieure est négative et la borne supérieure positive, alors le coefficient de corrélation n'est pas significatif au seuil choisi (95\% habituellement). Dans l'exemple ci-dessous, le relation linéaire entre les deux variables est significativement négative avec une corrélation de Pearson de −0,158 (P=0,000) et un intervalle de confiance de {[}−0,219 −0,095{]}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Intervalle de confiance à 95%}
\KeywordTok{cor.test}\NormalTok{(df}\OperatorTok{$}\NormalTok{HabKm2, df}\OperatorTok{$}\NormalTok{A65plus, }\DataTypeTok{conf.level =} \FloatTok{.95}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 	Pearson's product-moment correlation
## 
## data:  df$HabKm2 and df$A65plus
## t = -4.9318, df = 949, p-value = 9.616e-07
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.2194457 -0.0954687
## sample estimates:
##        cor 
## -0.1580801
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Vous pouvez accéder à chaque sortie de la fonction cor.test comme suit :}
\NormalTok{p <-}\StringTok{ }\KeywordTok{cor.test}\NormalTok{(df}\OperatorTok{$}\NormalTok{HabKm2, df}\OperatorTok{$}\NormalTok{A65plus)}
\KeywordTok{cat}\NormalTok{(}\StringTok{"Valeur de corrélation = "}\NormalTok{, }\KeywordTok{round}\NormalTok{(p}\OperatorTok{$}\NormalTok{estimate,}\DecValTok{3}\NormalTok{), }\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{,}
    \StringTok{"Intervalle à 95% = ["}\NormalTok{, }\KeywordTok{round}\NormalTok{(p}\OperatorTok{$}\NormalTok{conf.int[}\DecValTok{1}\NormalTok{],}\DecValTok{3}\NormalTok{), }\StringTok{" "}\NormalTok{, }\KeywordTok{round}\NormalTok{(p}\OperatorTok{$}\NormalTok{conf.int[}\DecValTok{2}\NormalTok{],}\DecValTok{3}\NormalTok{), }\StringTok{"]"}\NormalTok{, }\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{,}
    \StringTok{"Valeur de t = "}\NormalTok{, }\KeywordTok{round}\NormalTok{(p}\OperatorTok{$}\NormalTok{statistic,}\DecValTok{3}\NormalTok{), }\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{,}
    \StringTok{"Valeur de p = "}\NormalTok{, }\KeywordTok{round}\NormalTok{(p}\OperatorTok{$}\NormalTok{p.value,}\DecValTok{3}\NormalTok{), }\DataTypeTok{sep=}\StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Valeur de corrélation = -0.158
## Intervalle à 95% = [-0.219 -0.095]
## Valeur de t = -4.932
## Valeur de p = 0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Corrélation de Spearman}
\KeywordTok{cor.test}\NormalTok{(df}\OperatorTok{$}\NormalTok{HabKm2, df}\OperatorTok{$}\NormalTok{A65plus, }\DataTypeTok{method =} \StringTok{"spearman"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 	Spearman's rank correlation rho
## 
## data:  df$HabKm2 and df$A65plus
## S = 160482182, p-value = 0.0002202
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##        rho 
## -0.1195333
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Corrélation de Kendall}
\KeywordTok{cor.test}\NormalTok{(df}\OperatorTok{$}\NormalTok{HabKm2, df}\OperatorTok{$}\NormalTok{A65plus, }\DataTypeTok{method=}\StringTok{"kendall"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 	Kendall's rank correlation tau
## 
## data:  df$HabKm2 and df$A65plus
## z = -3.7655, p-value = 0.0001662
## alternative hypothesis: true tau is not equal to 0
## sample estimates:
##         tau 
## -0.08157061
\end{verbatim}

On pourra aussi modifier l'intervalle de confiance, par exemple à 90\% ou 99\%. Le choix de l'intervalle de confiance et du seuil de significativité doivent être définis avant l'étude. Il doit s'appuyer sur les standards de la littérature du domaine étudié, du niveau de preuve attendu et de la quantité de données.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Intervalle à 90%}
\KeywordTok{cor.test}\NormalTok{(df}\OperatorTok{$}\NormalTok{HabKm2, df}\OperatorTok{$}\NormalTok{A65plus, }\DataTypeTok{method =}\StringTok{"pearson"}\NormalTok{, }\DataTypeTok{conf.level =} \FloatTok{.90}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 	Pearson's product-moment correlation
## 
## data:  df$HabKm2 and df$A65plus
## t = -4.9318, df = 949, p-value = 9.616e-07
## alternative hypothesis: true correlation is not equal to 0
## 90 percent confidence interval:
##  -0.2096826 -0.1055995
## sample estimates:
##        cor 
## -0.1580801
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Intervalle à 99%}
\KeywordTok{cor.test}\NormalTok{(df}\OperatorTok{$}\NormalTok{HabKm2, df}\OperatorTok{$}\NormalTok{A65plus, }\DataTypeTok{method =}\StringTok{"pearson"}\NormalTok{, }\DataTypeTok{conf.level =} \FloatTok{.99}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 	Pearson's product-moment correlation
## 
## data:  df$HabKm2 and df$A65plus
## t = -4.9318, df = 949, p-value = 9.616e-07
## alternative hypothesis: true correlation is not equal to 0
## 99 percent confidence interval:
##  -0.23839910 -0.07561336
## sample estimates:
##        cor 
## -0.1580801
\end{verbatim}

\textbf{Corrélation et \emph{bootstrap}.} Dans le premier chapitre (LIEN BOOTSTRAP), nous avons abordé la notion de \emph{bootstrap}, soit des méthodes d'inférence statistique basées sur des réplications des données initiales par rééchantillonnage. Il est possible d'appliquer la même méthode aux corrélations afin d'obtenir un intervale de confiance avec \emph{r} réplications, tel qu'illustré à partir de la syntaxe ci-dessous.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"boot"}\NormalTok{)}
\NormalTok{df <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/bivariee/sr_rmr_mtl_2016.csv"}\NormalTok{)}
\CommentTok{# Fonction pour la corrélation}
\NormalTok{correlation <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(df, i, X, Y, }\DataTypeTok{cor.type=}\StringTok{"pearson"}\NormalTok{)\{}
  \CommentTok{# Paramètres de la fonction :}
  \CommentTok{# data : dataframe}
  \CommentTok{# X et Y : noms des variables X et Y}
  \CommentTok{# cor.type : type de corrélation : c("pearson","spearman","kendall")}
  \CommentTok{# i : indice qui sera utilisé par les réplications (à ne pas modifier)}
  \KeywordTok{cor}\NormalTok{(df[[X]][i], df[[Y]][i], }\DataTypeTok{method=}\NormalTok{cor.type)}
\NormalTok{\}}
\CommentTok{# Calcul du Bootstrap avec 5000 réplications}
\NormalTok{corBootstraped <-}\StringTok{ }\KeywordTok{boot}\NormalTok{(}\DataTypeTok{data=}\NormalTok{df, }\CommentTok{# nom du tableau}
                     \DataTypeTok{statistic =}\NormalTok{ correlation, }\CommentTok{# appel de la fonction à répliquer }
                     \DataTypeTok{R=}\DecValTok{5000}\NormalTok{, }\CommentTok{# nombre de réplications}
                     \DataTypeTok{X =} \StringTok{"A65plus"}\NormalTok{,}
                     \DataTypeTok{Y =}\StringTok{"HabKm2"}\NormalTok{, }
                     \DataTypeTok{cor.type=}\StringTok{"pearson"}\NormalTok{)}
\CommentTok{# Histogramme pour les valeurs de corrélation issues du Bootstrap}
\KeywordTok{plot}\NormalTok{(corBootstraped)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/fig9-1} 

}

\caption{Histogramme pour les valeurs de corrélation issues du Bootstrap}\label{fig:fig9}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Corrélation "bootstrapée"}
\NormalTok{corBootstraped}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## ORDINARY NONPARAMETRIC BOOTSTRAP
## 
## 
## Call:
## boot(data = df, statistic = correlation, R = 5000, X = "A65plus", 
##     Y = "HabKm2", cor.type = "pearson")
## 
## 
## Bootstrap Statistics :
##       original       bias    std. error
## t1* -0.1580801 -0.001157232  0.03926278
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Intervalle de confiance du bootstrap à 95%}
\KeywordTok{boot.ci}\NormalTok{(}\DataTypeTok{boot.out =}\NormalTok{ corBootstraped, }\DataTypeTok{conf =} \FloatTok{0.95}\NormalTok{, }\DataTypeTok{type =} \StringTok{"all"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
## Based on 5000 bootstrap replicates
## 
## CALL : 
## boot.ci(boot.out = corBootstraped, conf = 0.95, type = "all")
## 
## Intervals : 
## Level      Normal              Basic         
## 95%   (-0.2339, -0.0800 )   (-0.2392, -0.0855 )  
## 
## Level     Percentile            BCa          
## 95%   (-0.2307, -0.0769 )   (-0.2179, -0.0570 )  
## Calculations and Intervals on Original Scale
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Comparaison de l'intervalle classique basé sur la valeur de T}
\NormalTok{p <-}\StringTok{ }\KeywordTok{cor.test}\NormalTok{(df}\OperatorTok{$}\NormalTok{HabKm2, df}\OperatorTok{$}\NormalTok{A65plus)}
\KeywordTok{cat}\NormalTok{(}\KeywordTok{round}\NormalTok{(p}\OperatorTok{$}\NormalTok{estimate,}\DecValTok{5}\NormalTok{), }\StringTok{" ["}\NormalTok{, }\KeywordTok{round}\NormalTok{(p}\OperatorTok{$}\NormalTok{conf.int[}\DecValTok{1}\NormalTok{],}\DecValTok{4}\NormalTok{), }\StringTok{" "}\NormalTok{,}\KeywordTok{round}\NormalTok{(p}\OperatorTok{$}\NormalTok{conf.int[}\DecValTok{2}\NormalTok{],}\DecValTok{4}\NormalTok{), }\StringTok{"]"}\NormalTok{, }\DataTypeTok{sep=}\StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## -0.15808 [-0.2194 -0.0955]
\end{verbatim}

Le \emph{bootstrap} renvoie un coefficient de corrélation de Pearson de −0,158. Les intervalles de confiance obtenues à partir des différentes méthodes d'estimation (normale, basique, pourcentage et bca) ne sont pas à cheval sur 0, indiquant que le coefficient est significatif à 5\%.

\hypertarget{sect04136}{%
\subsubsection{Corrélation partielle}\label{sect04136}}

\begin{bloc_objectif}

\textbf{Quelle est la relation entre deux variables continues une fois pris en compte une ou plusieurs variables dites de contrôle ?} En études urbaines, on pourrait vouloir vérifier si deux variables sont ou non associées une fois contrôlée la densité de population ou encore la distance au centre-ville.

La corrélation partielle\index{corrélation partielle} permet d'évaluer la relation linéaire entre deux variables quantitatives continues, une fois contrôlé une ou plusieurs autres variables quantitatives (dites variables de contrôle).

\end{bloc_objectif}

Le coefficient de corrélation partielle peut être calculé pour les trois méthodes (Pearson, Spearman et Kendall). Variant aussi de −1 à 1, il est calculé comme suit :

\begin{equation} 
r_{ABC} = \frac{r_{AB}-r_{AC}r_{BC}}{\sqrt{(1-r_{AC}^2)(1-r_{BC}^2)}}
\label{eq:corpartielle}
\end{equation}

avec \emph{A} et \emph{B} étant les deux variables pour lesquelles on souhaite évaluer la relation linéaire, une fois contrôlée la variable \emph{C}; \(r\) étant le coefficient de corrélation (Pearson, Spearman ou Kendall) entre deux variables.

Dans l'exemple ci-dessous, nous voulons estimer la relation linéaire entre le pourcentage de personnes à faible revenu et la couverture végétale au niveau des îlots de l'île de Montréal, une fois contrôlée la densité de population. En effet, plus cette dernière sera forte, plus la couverture végétale sera faible (\(r\) de Pearson = −0,603). La valeur du \(r\) de Pearson s'élève à −0,546 entre le pourcentage de personnes à faible revenu dans la population totale de l'îlot et la couverture végétale. Une fois la densité de population contrôlée, il chute à −0,316. Pour calculer la corrélation partielle, on pourra utiliser la fonction \texttt{pcor.test} du package \textbf{ppcor}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"foreign"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"ppcor"}\NormalTok{)}
\NormalTok{dfveg <-}\StringTok{ }\KeywordTok{read.dbf}\NormalTok{(}\StringTok{"data/bivariee/IlotsVeg2006.dbf"}\NormalTok{)}
\CommentTok{# Corrélation entre les trois variables}
\KeywordTok{round}\NormalTok{(}\KeywordTok{cor}\NormalTok{(dfveg[, }\KeywordTok{c}\NormalTok{(}\StringTok{"VegPct"}\NormalTok{, }\StringTok{"Pct_FR"}\NormalTok{,}\StringTok{"LogDens"}\NormalTok{)], }\DataTypeTok{method=}\StringTok{"p"}\NormalTok{), }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         VegPct Pct_FR LogDens
## VegPct   1.000 -0.513  -0.563
## Pct_FR  -0.513  1.000   0.513
## LogDens -0.563  0.513   1.000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Corrélation partielle entre :}
\CommentTok{# la couverture végétale de l'îlot (%) et}
\CommentTok{# le pourcentage de personnes à faible revenu}
\CommentTok{# une fois contrôlée la densité de population}
\KeywordTok{pcor.test}\NormalTok{(dfveg}\OperatorTok{$}\NormalTok{Pct_FR, dfveg}\OperatorTok{$}\NormalTok{VegPct, dfveg}\OperatorTok{$}\NormalTok{LogDens, }\DataTypeTok{method=}\StringTok{"p"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     estimate       p.value statistic     n gp  Method
## 1 -0.3155194 8.093159e-235 -33.59772 10213  1 pearson
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Calcul de la corrélation partielle avec la formule :}
\NormalTok{corAB <-}\StringTok{ }\KeywordTok{cor}\NormalTok{(dfveg}\OperatorTok{$}\NormalTok{VegPct, dfveg}\OperatorTok{$}\NormalTok{Pct_FR, }\DataTypeTok{method =} \StringTok{"p"}\NormalTok{)}
\NormalTok{corAC <-}\StringTok{ }\KeywordTok{cor}\NormalTok{(dfveg}\OperatorTok{$}\NormalTok{VegPct, dfveg}\OperatorTok{$}\NormalTok{LogDens, }\DataTypeTok{method =} \StringTok{"p"}\NormalTok{)}
\NormalTok{corBC <-}\StringTok{ }\KeywordTok{cor}\NormalTok{(dfveg}\OperatorTok{$}\NormalTok{Pct_FR, dfveg}\OperatorTok{$}\NormalTok{LogDens, }\DataTypeTok{method =} \StringTok{"p"}\NormalTok{)}
\NormalTok{CorP  <-}\StringTok{ }\NormalTok{(corAB }\OperatorTok{-}\StringTok{ }\NormalTok{(corAC}\OperatorTok{*}\NormalTok{corBC)) }\OperatorTok{/}\StringTok{ }\KeywordTok{sqrt}\NormalTok{((}\DecValTok{1}\OperatorTok{-}\NormalTok{corAC}\OperatorTok{^}\DecValTok{2}\NormalTok{)}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\NormalTok{corBC}\OperatorTok{^}\DecValTok{2}\NormalTok{))}
\KeywordTok{cat}\NormalTok{(}\StringTok{"Corr. partielle avec ppcor  = "}\NormalTok{, }
    \KeywordTok{round}\NormalTok{(}\KeywordTok{pcor.test}\NormalTok{(dfveg}\OperatorTok{$}\NormalTok{Pct_FR,  dfveg}\OperatorTok{$}\NormalTok{VegPct, dfveg}\OperatorTok{$}\NormalTok{LogDens, }\DataTypeTok{method=}\StringTok{"p"}\NormalTok{)}\OperatorTok{$}\NormalTok{estimate,}\DecValTok{5}\NormalTok{),}
    \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{Corr. partielle (formule)  = "}\NormalTok{, }\KeywordTok{round}\NormalTok{(CorP, }\DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Corr. partielle avec ppcor  =  -0.31552 
## Corr. partielle (formule)  =  -0.31552
\end{verbatim}

\hypertarget{sect04137}{%
\subsubsection{Mise en œuvre dans}\label{sect04137}}

Comme vous l'aurez compris, il est possible d'arriver au même résultat dans par différents moyens. Pour calculer les corrélations, nous avons utilisé jusqu'à présent les fonctions de base \texttt{cor} et \texttt{cor.test} . Il est aussi possible de recourir à des fonctions d'autres \emph{packages}, dont notamment :

\begin{itemize}
\tightlist
\item
  \textbf{Hmisc} dont la fonction \texttt{rcorr} permet de calculer des corrélations de Pearson et Spearman (mais non celle de Kendall) avec la valeur de \emph{p}.
\item
  \textbf{psych} dont la fonction \texttt{corr.test} permet d'obtenir la matrice de corrélation (Pearson, Spearman et Kendall), les intervalles de confiance et les valeurs de \emph{p}.
\item
  \textbf{stargazer} pour créer des beaux tableaux d'une matrice de corrélation en \emph{Html} ou en \emph{LaTeX} ou en ASCII.
\item
  \textbf{apaTables} pour créer un tableau avec une matrice de corrélation dans un fichier Word.
\item
  \textbf{correlation} pour aller plus loin et explorer les corrélations bayesiennes, robustes, non-linéaires ou multiniveaux.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/bivariee/sr_rmr_mtl_2016.csv"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"Hmisc"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"stargazer"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"apaTables"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"dplyr"}\NormalTok{)}
\CommentTok{# Corrélations de Pearson et Spearman et valeurs de p }
\CommentTok{# avec la fonction rcorr de Hmisc pour deux variables}
\NormalTok{Hmisc}\OperatorTok{::}\KeywordTok{rcorr}\NormalTok{(df}\OperatorTok{$}\NormalTok{RevMedMen, df}\OperatorTok{$}\NormalTok{Locataire, }\DataTypeTok{type=}\StringTok{"pearson"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       x     y
## x  1.00 -0.78
## y -0.78  1.00
## 
## n= 951 
## 
## 
## P
##   x  y 
## x     0
## y  0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Hmisc}\OperatorTok{::}\KeywordTok{rcorr}\NormalTok{(df}\OperatorTok{$}\NormalTok{RevMedMen, df}\OperatorTok{$}\NormalTok{Locataire, }\DataTypeTok{type=}\StringTok{"spearman"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       x     y
## x  1.00 -0.91
## y -0.91  1.00
## 
## n= 951 
## 
## 
## P
##   x  y 
## x     0
## y  0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Matrice de corrélation avec la fonction rcorr de Hmisc pour plus de variables}
\CommentTok{# On crée un vecteur avec les noms des variables à sélectionner}
\NormalTok{Vars <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"RevMedMen"}\NormalTok{,}\StringTok{"Locataire"}\NormalTok{, }\StringTok{"LogTailInc"}\NormalTok{,}\StringTok{"A65plus"}\NormalTok{,}\StringTok{"ImgRec"}\NormalTok{, }\StringTok{"HabKm2"}\NormalTok{, }\StringTok{"FaibleRev"}\NormalTok{)}
\NormalTok{Hmisc}\OperatorTok{::}\KeywordTok{rcorr}\NormalTok{(df[, Vars] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            RevMedMen Locataire LogTailInc A65plus ImgRec HabKm2 FaibleRev
## RevMedMen       1.00     -0.78      -0.46   -0.07  -0.46  -0.49     -0.74
## Locataire      -0.78      1.00       0.56    0.00   0.64   0.71      0.88
## LogTailInc     -0.46      0.56       1.00   -0.07   0.82   0.48      0.62
## A65plus        -0.07      0.00      -0.07    1.00  -0.06  -0.16     -0.01
## ImgRec         -0.46      0.64       0.82   -0.06   1.00   0.56      0.68
## HabKm2         -0.49      0.71       0.48   -0.16   0.56   1.00      0.64
## FaibleRev      -0.74      0.88       0.62   -0.01   0.68   0.64      1.00
## 
## n= 951 
## 
## 
## P
##            RevMedMen Locataire LogTailInc A65plus ImgRec HabKm2 FaibleRev
## RevMedMen            0.0000    0.0000     0.0441  0.0000 0.0000 0.0000   
## Locataire  0.0000              0.0000     0.9594  0.0000 0.0000 0.0000   
## LogTailInc 0.0000    0.0000               0.0325  0.0000 0.0000 0.0000   
## A65plus    0.0441    0.9594    0.0325             0.0682 0.0000 0.6796   
## ImgRec     0.0000    0.0000    0.0000     0.0682         0.0000 0.0000   
## HabKm2     0.0000    0.0000    0.0000     0.0000  0.0000        0.0000   
## FaibleRev  0.0000    0.0000    0.0000     0.6796  0.0000 0.0000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# # Avec la fonction corr.test de psych pour avoir la matrice de corrélation}
\CommentTok{# # (Pearson, Spearman et Kendall), les intervalles de confiance et les valeurs de p}
\CommentTok{# print(psych::corr.test(df[, Vars], }
\CommentTok{#              method = "kendall", }
\CommentTok{#              ci=TRUE, alpha = 0.05), short=FALSE) }
\CommentTok{# Création d'un tableau pour une matrice de corrélation}
\CommentTok{# changer le paramètre type pour 'html' or 'LaTex'}
\NormalTok{p <-}\StringTok{ }\KeywordTok{cor}\NormalTok{(df[, Vars], }\DataTypeTok{method=}\StringTok{"pearson"}\NormalTok{)}
\KeywordTok{stargazer}\NormalTok{(p, }\DataTypeTok{title=}\StringTok{"Correlation Matrix"}\NormalTok{, }\DataTypeTok{type =} \StringTok{"text"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Correlation Matrix
## =========================================================================
##            RevMedMen Locataire LogTailInc A65plus ImgRec HabKm2 FaibleRev
## -------------------------------------------------------------------------
## RevMedMen      1      -0.785     -0.461   -0.065  -0.458 -0.489  -0.743  
## Locataire   -0.785       1       0.562    -0.002  0.645  0.708    0.879  
## LogTailInc  -0.461     0.562       1      -0.069  0.816  0.475    0.622  
## A65plus     -0.065    -0.002     -0.069      1    -0.059 -0.158  -0.013  
## ImgRec      -0.458     0.645     0.816    -0.059    1    0.561    0.678  
## HabKm2      -0.489     0.708     0.475    -0.158  0.561    1      0.642  
## FaibleRev   -0.743     0.879     0.622    -0.013  0.678  0.642      1    
## -------------------------------------------------------------------------
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# stargazer(p, title="Correlation Matrix", type = "html")}
\CommentTok{# stargazer(p, title="Correlation Matrix", type = "latex")}
\CommentTok{# Créer un tableau avec la matrice de corrélation }
\CommentTok{# dans un fichier Word (.doc)}
\NormalTok{apaTables}\OperatorTok{::}\KeywordTok{apa.cor.table}\NormalTok{(df[, }\KeywordTok{c}\NormalTok{(}\StringTok{"RevMedMen"}\NormalTok{,}\StringTok{"Locataire"}\NormalTok{,}\StringTok{"LogTailInc"}\NormalTok{)], }
                         \DataTypeTok{filename =} \StringTok{"data/bivariee/TitiLaMatrice.doc"}\NormalTok{,}
                         \DataTypeTok{show.conf.interval =} \OtherTok{TRUE}\NormalTok{,}
                         \DataTypeTok{landscape =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 
## Means, standard deviations, and correlations with confidence intervals
##  
## 
##   Variable      M        SD       1            2         
##   1. RevMedMen  66065.50 26635.27                        
##                                                          
##   2. Locataire  45.05    26.33    -.78**                 
##                                   [-.81, -.76]           
##                                                          
##   3. LogTailInc 5.54     4.82     -.46**       .56**     
##                                   [-.51, -.41] [.52, .60]
##                                                          
## 
## Note. M and SD are used to represent mean and standard deviation, respectively.
## Values in square brackets indicate the 95% confidence interval.
## The confidence interval is a plausible range of population correlations 
## that could have caused the sample correlation (Cumming, 2014).
## * indicates p < .05. ** indicates p < .01.
## 
\end{verbatim}

\begin{bloc_astuce}

\textbf{Une image vaut mille mots, surtout pour une matrice de corrélation !} Le package \textbf{corrplot} vous permet justement de construire de belles figures avec une matrice de corrélation (figures \ref{fig:figcorrplot1} et \ref{fig:figcorrplot2}). L'intérêt de ce type de figure est de repérer rapidemment des associations intéressantes lorsque l'on calcule les corrélations entre un grand nombre de variables.

\end{bloc_astuce}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"corrplot"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"ggpubr"}\NormalTok{)}
\NormalTok{df <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/bivariee/sr_rmr_mtl_2016.csv"}\NormalTok{)}
\NormalTok{Vars <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"RevMedMen"}\NormalTok{,}\StringTok{"Locataire"}\NormalTok{, }\StringTok{"LogTailInc"}\NormalTok{,}\StringTok{"A65plus"}\NormalTok{,}\StringTok{"ImgRec"}\NormalTok{, }\StringTok{"HabKm2"}\NormalTok{, }\StringTok{"FaibleRev"}\NormalTok{)}
\NormalTok{p <-}\StringTok{ }\KeywordTok{cor}\NormalTok{(df[, Vars], }\DataTypeTok{method=}\StringTok{"pearson"}\NormalTok{)}
\NormalTok{couleurs <-}\StringTok{ }\KeywordTok{colorRampPalette}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"#053061"}\NormalTok{, }\StringTok{"#2166AC"}\NormalTok{,}\StringTok{"#4393C3"}\NormalTok{, }\StringTok{"#92C5DE"}\NormalTok{,}
                               \StringTok{"#D1E5F0"}\NormalTok{, }\StringTok{"#FFFFFF"}\NormalTok{, }\StringTok{"#FDDBC7"}\NormalTok{, }\StringTok{"#F4A582"}\NormalTok{,}
                               \StringTok{"#D6604D"}\NormalTok{, }\StringTok{"#B2182B"}\NormalTok{, }\StringTok{"#67001F"}\NormalTok{))}
\KeywordTok{corrplot}\NormalTok{(p, }\DataTypeTok{addrect =} \DecValTok{3}\NormalTok{, }\DataTypeTok{method=}\StringTok{"number"}\NormalTok{, }\DataTypeTok{diag=}\OtherTok{FALSE}\NormalTok{, }\DataTypeTok{col=}\KeywordTok{couleurs}\NormalTok{(}\DecValTok{100}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/figcorrplot1-1} 

}

\caption{Matrice de corrélation avec corrplot (chiffres)}\label{fig:figcorrplot1}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fig2 <-}\StringTok{ }\KeywordTok{corrplot.mixed}\NormalTok{(p, }\DataTypeTok{lower=}\StringTok{"number"}\NormalTok{, }\DataTypeTok{lower.col =} \StringTok{"black"}\NormalTok{, }
                      \DataTypeTok{upper =} \StringTok{"ellipse"}\NormalTok{, }\DataTypeTok{upper.col=}\KeywordTok{couleurs}\NormalTok{(}\DecValTok{100}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/figcorrplot2-1} 

}

\caption{Matrice de corrélation avec corrplot (chiffres et ellipses)}\label{fig:figcorrplot2}
\end{figure}

\hypertarget{sect04138}{%
\subsubsection{Comment rapporter des valeurs de corrélations?}\label{sect04138}}

Bien qu'il n'y ait pas qu'une seule manière de reporter des corrélations, voici quelques lignes directrices pour vous guider :

\begin{itemize}
\tightlist
\item
  Signaler si la corrélation est faible, modérée ou forte.
\item
  Indiquer si la corrélation est positive ou négative. Toutefois, ce n'est pas une obligation car l'on peut rapidement le constater avec le signe du coefficient.
\item
  Mettre le \emph{r} et le \emph{p} en italique et en minuscules.
\item
  Deux décimales uniquement pour le \(r\) (sauf si une plus grande précision se justifie dans le domaine d'étude).
\item
  Trois décimales pour la valeur de \emph{p}. Si elle est inférieure à 0,001, écrire plutôt \emph{p} \textless{} 0,001.
\item
  Indiquer éventuellement le nombre de degrés de liberté, soit \(r(dl)=...\)
\end{itemize}

Voici des exemples :

\begin{itemize}
\tightlist
\item
  La corrélation entre les variables revenu médian des ménages et pourcentage de locataire est fortement négative (\emph{r} = −0,78, \emph{p} \textless{} 0,001).
\item
  La corrélation entre les variables revenu médian des ménages et pourcentage de locataire est forte (\emph{r}(949) = −0,78, \emph{p} \textless{} 0,001).
\item
  La corrélation entre les variables densité de population et pourcentage de logements de taille est modérée (\emph{r} = 0,48, \emph{p} \textless{} 0,001).
\item
  La corrélation entre les variables densité de population et pourcentage de 65 ans et plus n'est pas significative (\emph{r} = −0,08, \emph{p} = 0,07).
\end{itemize}

Pour un texte en anglais, référez-vous à : \url{https://www.socscistatistics.com/tutorials/correlation/default.aspx}.

\hypertarget{sect0414}{%
\subsection{Régression linéaire simple}\label{sect0414}}

\begin{bloc_objectif}

\textbf{Comment expliquer et prédire une variable continue en fonction d'une autre variable?} Répondre à cette question relève de la statistique inférentielle. Il s'agit en effet d'établir une équation simple du type \(Y = a + bX\), pour expliquer et prédire les valeurs d'une variable dépendante (\emph{Y}) à partir d'une variable indépendante (\emph{X}). L'équation de la régression est construite grâce à un jeu de données (un échantillon). À partir de cette équation, il est possible de prédire la valeur attendue de \emph{Y} pour n'importe quelle valeur de \emph{X}. On appelle cette équation un modèle, car elle cherche à représenter la réalité de façon simplifiée.

La régression linéaire simple se distingue ainsi de la \textbf{covariance} (section \ref{sect0412}) et de la \textbf{corrélation} (section \ref{sect0413}), relevant de la statistique bivariée descriptive et exploratoire.

Par exemple, la régression linéaire simple pourrait être utilisée pour expliquer les notes d'un groupe d'étudiants à un examen (variable dépendante \emph{Y}) en fonction du nombre d'heures qu'ils ont consacrés à la révision des notes de cours (variable indépendante \emph{X}). Une fois l'équation de régression déterminée et si le modèle est efficace, nous pourrons prédire les notes des étudiants inscrits au cours la session suivante en fonction du temps qu'ils prévoient de passer à étudier, et ce, avant même qu'ils aient passé l'examen.

Formulons un exemple d'application de la régression linéaire simple en études urbaines. Dans le cadre d'une étude sur les îlots de chaleur urbains, la température de surface (variable dépendante) pourrait être expliquée par la proportion de la superficie de l'îlot couverte par de la végétation (variable indépendante). On supposerait alors que plus cette proportion est importante, plus la température est faible et inversement, soit une relation linéaire négative. Si le modèle est efficace, nous pourrions prédire la température moyenne des îlots d'une autre municipalité pour laquelle nous ne disposons pas d'une carte de température, et repérer ainsi les îlots de chaleur potentiels. Bien entendu, il est peu probable que nous arrivions à prédire efficacement la température moyenne des îlots avec uniquement la couverture végétale comme variable explicative. En effet, bien d'autres caractéristiques de la forme urbaine peuvent influencer ce phénomène comme la densité du bâti, la couleur des toits, les occupations du sol présentes, l'effet des canyons urbains, etc. Il faudrait alors inclure non pas une, mais plusieurs variables explicatives (indépendantes).

Ainsi, on distinguera la \textbf{régression linéaire simple} (une variable indépendante, explicative) de la \textbf{régression linéaire multiple} (plusieurs variables indépendantes); cette dernière sera largement abordée au chapitre \ref{chap05}.

\end{bloc_objectif}

Dans cette section, nous décrirons succinctement la régression linéaire simple. Concrètement, nous verrons comment déterminer la droite de régression, interpréter ses différents paramètres du modèle et comment évaluer la qualité d'ajustement du modèle. Nous n'aborderons pas les hypothèses liées au modèle de régression linéaire des moindres carrés ordinaires (MCO), ni les conditions d'application. Ces éléments seront expliqués au chapitre \ref{chap05} consacré à la régression linéaire multiple.

\begin{bloc_attention}

\textbf{Corrélation, régression simple et causalité : attention aux raccourcis !}

Si une variable \emph{X} explique et prédit efficacement une variable \emph{Y}, cela ne veut pas dire pour autant que \emph{X} cause \emph{Y}. Autrement dit, la corrélation, l'association entre deux variables ne signifie qu'il existe un lien de causalité entre elles.

Premièrement, la variable explicative (\emph{X}, indépendante) doit absolument précéder la variable à expliquer (\emph{Y}, dépendante). Par exemple, l'âge (\emph{X}) peut influencer le sentiment de sécurité (\emph{Y}). Mais, le sentiment de sécurité ne peut en aucun cas influencer l'âge. Par conséquent, l'âge ne peut conceptuellement pas être la variable dépendante dans cette relation.

Deuxièmement, bien qu'une variable puisse expliquer efficacement une autre variable, elle peut être un \textbf{facteur confondant}. Prenons deux exemples bien connus :

\begin{itemize}
\item
  Avoir les doigts jaunes est associé au cancer du poumon. Bien entendu, les doigts jaunes ne causent pas le cancer : c'est un facteur confondant puisque fumer augmente les risques du cancer du poumon et jaunit aussi les doigts.
\item
  Dans un article intitulé \emph{Chocolate Consumption, Cognitive Function, and Nobel Laureates}, Messerli \citeyearpar{Messerli} a trouvé une corrélation positive entre la consommation de chocolat par habitant et le nombre de prix Nobel pour dix millions d'habitants pour 23 pays. Ce résultat a d'ailleurs été rapporté par de nombreux médias (\href{https://ici.radio-canada.ca/nouvelle/582457/chocolat-consommateurs-nobels}{Radio Canada}, \href{\%22https://www.lapresse.ca/vivre/sante/nutrition/201210/11/01-4582347-etude-plus-un-pays-mange-de-chocolat-plus-il-a-de-prix-nobel.php\%22}{La Presse}, \href{https://www.lepoint.fr/insolite/le-chocolat-dope-aussi-l-obtention-de-prix-nobel-12-10-2012-1516159_48.php}{Le Point}, etc.), sans pour autant que Messerli \citeyearpar{Messerli} et les journalistes concluent à un lien de causalité entre les deux variables. Tout chercheur sait que la consommation de chocolat ne permet pas d'obtenir des résultats intéressants et de publier dans des revues prestigieuses; c'est plutôt le café ! Plus sérieusement, il est probable que les pays les plus riches investissent davantage dans la recherche et obtiennent ainsi plus de prix Nobel. Dans les pays les plus riches, il est aussi probable que l'on consomme plus de chocolat, considéré comme un produit de luxe dans les pays les plus pauvres.
\end{itemize}

Pour approfondir le sujet sur la confusion entre \emph{corrélation, régression simple et causalité}, vous pourrez visionner cette courte \href{https://www.youtube.com/embed/A-_naeATJ6o}{vidéo ludique} de vulgarisation.

L'association entre deux variables peut aussi être simplement le fruit du hasard. Si l'on explore de très grandes quantités de données (avec un nombre impressionnant d'observations et de variables), soit une démarche relevant du \emph{data mining}, le hasard fera que l'on risque d'obtenir des corrélations surprenantes entre certaines variables. Prenons un exemple concret, admettons que l'on ait collecté 100 variables et que l'on calcule les corrélations entre chaque paire de variables. On obtient une matrice de corrélation de 100 x 100, à laquelle on peut enlever la diagonale et une moitié de la matrice, ce qui nous laisse un total de 4950 corrélations différentes. Admettons que l'on choisisse un seuil de significativité de 5\%, on doit alors s'attendre à ce que le hasard produise des résultats significatifs dans 5\% des cas. Sur 4950 corrélations, cela signifie qu'environ 247 corrélations seront significatives, et ce, indépendamment de la nature des données. Nous pouvons aisément l'illustrer avec la syntaxe suivante :

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"Hmisc"}\NormalTok{)}
\NormalTok{nbVars <-}\StringTok{ }\DecValTok{100} \CommentTok{# nous utilisons 100 variables générées aléatoirement pour l'expérience}
\NormalTok{nbExperiment <-}\StringTok{ }\DecValTok{1000} \CommentTok{# nous reproduirons 1000 fois l'expérience avec les 100 variables}
\CommentTok{# Le nombre de variables significatives par expérience est enregistrée dans Results}
\NormalTok{Results <-}\StringTok{ }\KeywordTok{c}\NormalTok{()}
\CommentTok{# iterons pour chaque expérimentation (1000 fois)}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{nbExperiment)\{}
\NormalTok{  Datas <-}\StringTok{ }\KeywordTok{list}\NormalTok{()}
  \CommentTok{# générons 100 variables aléatoires normalement distribuées}
  \ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{nbVars)\{}
\NormalTok{    Datas[[j]] <-}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{150}\NormalTok{)}
\NormalTok{  \}}
\NormalTok{  DF <-}\StringTok{ }\KeywordTok{do.call}\NormalTok{(}\StringTok{"cbind"}\NormalTok{,Datas)}
  \CommentTok{# calculons la matrice de corrélation pour les 100 variables}
\NormalTok{  cor_mat <-}\StringTok{ }\KeywordTok{rcorr}\NormalTok{(DF)}
  \CommentTok{# comptons combien de fois les corrélations étaient significatives}
\NormalTok{  Sign <-}\StringTok{ }\KeywordTok{table}\NormalTok{(cor_mat}\OperatorTok{$}\NormalTok{P}\OperatorTok{<}\FloatTok{0.05}\NormalTok{)}
\NormalTok{  NbPairs <-}\StringTok{ }\NormalTok{Sign[[}\StringTok{"TRUE"}\NormalTok{]]}\OperatorTok{/}\DecValTok{2}
  \CommentTok{# ajoutons les résultats dans Results}
\NormalTok{  Results <-}\StringTok{ }\KeywordTok{c}\NormalTok{(Results,NbPairs)}
\NormalTok{\}}
\CommentTok{# transformons Results en un dataframe}
\NormalTok{df <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{Values =}\NormalTok{ Results)}
\CommentTok{# affichons le résultat}
\KeywordTok{ggplot}\NormalTok{(df, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Values)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{..density..), }
                 \DataTypeTok{colour =} \StringTok{"black"}\NormalTok{, }
                 \DataTypeTok{fill =} \StringTok{"white"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{stat_function}\NormalTok{(}\DataTypeTok{fun =}\NormalTok{ dnorm, }\DataTypeTok{args =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{mean =} \KeywordTok{mean}\NormalTok{(df}\OperatorTok{$}\NormalTok{Values), }
                \DataTypeTok{sd =} \KeywordTok{sd}\NormalTok{(df}\OperatorTok{$}\NormalTok{Values)),}\DataTypeTok{color=}\StringTok{"blue"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_vline}\NormalTok{(}\DataTypeTok{xintercept =} \KeywordTok{mean}\NormalTok{(df}\OperatorTok{$}\NormalTok{Values),}\DataTypeTok{color=}\StringTok{"red"}\NormalTok{, }\DataTypeTok{size=}\FloatTok{1.2}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{annotate}\NormalTok{(}\StringTok{"text"}\NormalTok{, }\DataTypeTok{x=}\DecValTok{250}\NormalTok{, }\DataTypeTok{y =} \FloatTok{0.028}\NormalTok{, }
           \DataTypeTok{label =} \KeywordTok{paste}\NormalTok{(}\StringTok{"Nombre moyen de corrélations significatives}\CharTok{\textbackslash{}n}\StringTok{ }
\StringTok{                         sur 1000 replications :"}\NormalTok{,}
           \KeywordTok{round}\NormalTok{(}\KeywordTok{mean}\NormalTok{(df}\OperatorTok{$}\NormalTok{Values),}\DecValTok{0}\NormalTok{),}\DataTypeTok{sep=}\StringTok{""}\NormalTok{), }\DataTypeTok{hjust=}\StringTok{"left"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{xlab}\NormalTok{(}\StringTok{"Nombre de corrélations significatives"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{ylab}\NormalTok{(}\StringTok{"densité"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics[width=0.8\linewidth,]{images/bivariee/replication_hist} 

}

\caption{Corrélations significatives obtenues aléatoirement}\label{fig:replicationhist}
\end{figure}

\end{bloc_attention}

\hypertarget{sect04141}{%
\subsubsection{Principe de base de la régression linéaire simple}\label{sect04141}}

La régression linéaire simple vise à déterminer une droite (une fonction linéaire) qui résume le mieux la relation linéaire entre une variable dépendante (\emph{Y}) et une variable indépendante (\emph{X}) :
\begin{equation} 
\widehat{y_i} = \beta_{0} + \beta_{1}x_{i}
\label{eq:regsimple}
\end{equation}

avec \(\widehat{y_i}\) et \(x_{i}\) qui sont respectivement la valeur prédite de la variable indépendante et la valeur de la variable dépendante pour l'observation \(i\). \(\beta_{0}\) est la constante (\emph{intercept} en anglais), soit la valeur prédite de la variable \(Y\) quand \(X\) est égale à 0. \(\beta_{1}\) est le coefficient de régression pour la variable \emph{X}, soit la pente de la droite. Ce coefficient nous informe sur la relation entre les deux variables : s'il est positif, la relation est positive; s'il est négatif, la relation est négative, et proche de 0, la relation est nulle (la droite sera alors horizontale). Plus la valeur absolue de \(\beta_{1}\) est élevée, plus la pente est forte, et plus la variable \emph{Y} varie à chaque changement d'une unité de la variable \emph{X}.

Considérons un exemple fictif de dix municipalités d'une région métropolitaine pour lesquelles nous disposons de deux variables : le pourcentage d'actifs occupés se rendant au travail principalement à vélo et la distance de la municipalité au centre-ville (tableau \ref{tab:regfictives}).

\begin{table}
\caption{\label{tab:regfictives}Données fictives sur l'utilisation du vélo par municipalité}

\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{lrr}
\toprule
Municipalité & Vélo & KMCV\\
\midrule
A & 12,5 & 14,135\\
B & 13,5 & 10,065\\
C & 15,8 & 7,762\\
D & 15,9 & 11,239\\
E & 17,6 & 7,706\\
\bottomrule
\end{tabular}
\centering
\begin{tabular}[t]{lrr}
\toprule
Municipalité & Vélo & KMCV\\
\midrule
F & 18,5 & 7,195\\
G & 21,2 & 7,953\\
H & 23,0 & 4,293\\
I & 25,3 & 5,225\\
J & 30,2 & 2,152\\
\bottomrule
\end{tabular}
\end{table}

D'emblée, à la lecture du nuage de points (figure \ref{fig:figreg}), on décèle une forte relation linéaire négative entre les deux variables : plus la distance au centre-ville augmente, plus le pourcentage de cyclistes est faible, ce qui est confirmé par le coefficient de corrélation (\emph{r} = −0,86). La droite de régression (en rouge à la figure \ref{fig:figreg}) qui résume le mieux la relation entre \texttt{Vélo} (variable dépendante) et \texttt{KmCV} (variable indépendante) s'écrit alors : \textbf{Vélo = 30,603 − 1,448 x KmCV}.

La valeur du coefficient de régression (\(\beta_{1}\)) est de −1,448. Le signe de ce coefficient décrit une relation négative entre les deux variables. Ainsi, à chaque ajout d'une unité de la distance au centre-ville (exprimée en kilomètres), le pourcentage de cyclistes diminue de 1,448. Retenez que l'unité de mesure de la variable dépendante est très importante pour bien interpréter le coefficient de régression. En effet, si la distance au centre-ville n'était pas exprimée en kilomètres, mais plutôt en mètres, \(\beta_1\) sera égal à −0,001448. Dans la même optique, l'ajout de 10 km de distance entre une municipalité et le centre-ville fait diminuer le pourcentage de cyclistes de −14,48 points de pourcentage.

Avec, cette équation de régression, il est possible de prédire le pourcentage de cyclistes pour n'importe quelle municipalité de la région métropolitaine. Par exemple, pour des distances de 5, 10 ou 20 kilomètres, les pourcentages de cyclistes seraient de :

\begin{itemize}
\tightlist
\item
  \(\widehat{y_i} = 30,603 + (-1,448 \times 5 km) = 23,363\)
\item
  \(\widehat{y_i} = 30,603 + (-1,448 \times 10km) = 8,883\)
\item
  \(\widehat{y_i} = 30,603 + (-1,448 \times 20km) = 1,643\)
\end{itemize}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/figreg-1} 

}

\caption{Relation linéaire entre l'utilisation du vélo et la distance au centre-ville}\label{fig:figreg}
\end{figure}

\hypertarget{sect04142}{%
\subsubsection{Formulation de la droite de régression des moindres carrés ordinaires}\label{sect04142}}

Reste à savoir comment sont estimés les différents paramètres de l'équation, soit \(\beta_0\) et \(\beta_1\). À la figure \ref{fig:figreg2}, les points noirs représentent les valeurs observées (\(y_i\)) et les points bleus les valeurs prédites (\(\widehat{y_i}\)) par l'équation du modèle. Les traits noirs verticaux représentent pour chaque observation \(i\), l'écart entre la valeur observée et la valeur prédite, dénommé résidu (\(\epsilon_i\), prononcez epsilon de \emph{i} ou plus simplement le résidu pour \emph{i}, ou encore le terme d'erreur de \emph{i}). Si un point est au-dessus de la droite de régression, la valeur observée sera alors supérieure à la valeur prédite (\(y_i > \widehat{y_i}\)) et inversement, si le point est au-dessous de la droite (\(y_i < \widehat{y_i}\)). Plus cet écart (\(\epsilon_i\)) est important, plus l'observation s'éloigne de la prédiction du modèle, et par extension moins bon est le modèle. Au tableau \ref{tab:regfictives2}, vous constaterez que la somme des résidus est égale à zéro. La méthode des moindres carrés ordinaires (MCO) vise à minimiser les écarts au carré entre les valeurs observées (\(y_i\)) et prédites (\(\beta_0+\beta_1 x_i\), soit \(\widehat{y_i}\)) :

\begin{equation} 
min\sum_{i=1}^n{(y_i-(\beta_0+\beta_1 x_i))^2}
\label{eq:mco}
\end{equation}

Pour minimiser ces écarts, le coefficient de régression \(\beta_1\) représente le rapport entre la covariance entre \emph{X} et \emph{Y} et la variance de \emph{Y} (équation \eqref{eq:b1}), tandis que la constante \(\beta_0\) est la moyenne de la variable \emph{Y} moins le produit de la moyenne de \emph{X} et de son coefficient de régression (équation \eqref{eq:b0}).

\begin{equation} 
\beta_1 = \frac{\sum_{i=1}^n (x_{i}-\bar{x})(y_{i}-\bar{y})}{\sum_{i=1}^n (x_i-\bar{x})^2} = \frac{cov(X,Y)}{var(X)}
\label{eq:b1}
\end{equation}

\begin{equation} 
\beta_0 = \widehat{Y}-\beta_1 \widehat{X}
\label{eq:b0}
\end{equation}

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/figreg2-1} 

}

\caption{Droite de régression, valeurs observées, prédites et résidus}\label{fig:figreg2}
\end{figure}

\begin{table}

\caption{\label{tab:regfictives2}Valeurs observées, prédites et résidus}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{lrrrrr}
\toprule
Municipalité & Vélo & KMCV & Valeur prédite & Résidu & Résidu au carré\\
\midrule
A & 12,5 & 14,135 & 10,138 & 2,362 & 5,579\\
B & 13,5 & 10,065 & 16,031 & -2,531 & 6,406\\
C & 15,8 & 7,762 & 19,365 & -3,565 & 12,709\\
D & 15,9 & 11,239 & 14,331 & 1,569 & 2,462\\
E & 17,6 & 7,706 & 19,446 & -1,846 & 3,408\\
\addlinespace
F & 18,5 & 7,195 & 20,186 & -1,686 & 2,843\\
G & 21,2 & 7,953 & 19,089 & 2,111 & 4,456\\
H & 23,0 & 4,293 & 24,388 & -1,388 & 1,927\\
I & 25,3 & 5,225 & 23,038 & 2,262 & 5,117\\
J & 30,2 & 2,152 & 27,488 & 2,712 & 7,355\\
\addlinespace
Somme & -- & -- & -- & 0,000 & 52,262\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{sect04143}{%
\subsubsection{Mesurer la qualité d'ajustement du modèle}\label{sect04143}}

Les trois mesures les plus courantes pour évaluer la qualité d'ajustement d'un modèle de régression linéaire simple sont l'erreur quadratique moyenne (en anglais, \emph{root-mean-square error}, \emph{RMSE}), le coefficient de détermination (\(R^2\)) et la statistique \emph{F} de Fisher. Pour mieux appréhender le calcul de ces trois mesures, rappelons que l'équation de régression s'écrit :

\begin{equation} 
y_i = \beta_0 + \beta_1 x_1+ \epsilon_i \Rightarrow Y= \beta_0 + \beta_1 X + \epsilon
\label{eq:reg2}
\end{equation}

Elle comprend ainsi une partie de \emph{Y} qui est expliquée par le modèle et une autre partie non expliquée : \(\epsilon\) appelé habituellement le terme d'erreur. Ce terme d'erreur pourrait représenter d'autres variables explicatives qui n'ont pas été prises en compte pour prédire la variable indépendante ou une forme de variation aléatoire inexplicable présente lors de la mesure.

\begin{equation} 
Y  = \underbrace{\beta_0 + \beta_1 X}_{\mbox{partie expliquée par le modèle}}+ \underbrace{\epsilon}_{\mbox{partie non expliquée}}
\label{eq:reg3}
\end{equation}

Par exemple, pour la municipalité \emph{A} au tableau \ref{tab:regfictives2}, nous avons : \(y_A = \widehat{y}_A - \epsilon_A \Rightarrow 12.5 = 10.138+2.362\). Souvenez-vous que la variance d'une variable est la somme des écarts à la moyenne, divisée par le nombre d'observations. Par extension, il est alors possible de décomposer la variance de \emph{Y} comme suit :

\begin{equation} 
\underbrace{\sum_{i=1}^n (y_{i}-\bar{y})^2}_{\mbox{variance de Y}} = \underbrace{\sum_{i=1}^n (\widehat{y}_i-\bar{y})^2}_{\mbox{var. expliquée}} + \underbrace{\sum_{i=1}^n (y_{i}-\widehat{y})^2}_{\mbox{var. non expliquée}} \Rightarrow 
SCT = SCE + SCR
\label{eq:reg4}
\end{equation}

avec :

\begin{itemize}
\tightlist
\item
  \emph{SCT} est la somme des écarts au carré des valeurs observées à la moyenne (en anglais, \emph{total sum of squares})
\item
  \emph{SCE} est la somme des écarts au carré des valeurs prédites à la moyenne (en anglais, \emph{regression sum of squares})
\item
  \emph{SCR} est la somme des carrés des résidus (en anglais, \emph{sum of squared errors}).
\end{itemize}

Autrement dit, la variance totale est égale à la variance expliquée plus la variance non expliquée. Au tableau \ref{tab:computeR}, vous pouvez repérer les valeurs de \emph{SCT}, \emph{SCE} et \emph{SCR} et constater que 279,30 = 227,04 + 52,26 et 27,93 = 22,70 + 5,23.

\begin{table}

\caption{\label{tab:computeR}Calcul du coefficient de détermination}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{lrrrrrr}
\toprule
Municipalité & \$y\_i\$ & \$\textbackslash{}widehat\{y\}\_i\$ & \$\textbackslash{}epsilon\_i\$ & \$(y\_i-\textbackslash{}bar\{y\})\textasciicircum{}2\$ & \$(\textbackslash{}widehat\{y\}\_i-y\_i)\textasciicircum{}2\$ & \$\textbackslash{}epsilon\_i\textasciicircum{}2\$\\
\midrule
A & 12,50 & 10,14 & 2,36 & 46,92 & 84,86 & 5,58\\
B & 13,50 & 16,03 & -2,53 & 34,22 & 11,02 & 6,41\\
C & 15,80 & 19,37 & -3,57 & 12,60 & 0,00 & 12,71\\
D & 15,90 & 14,33 & 1,57 & 11,90 & 25,19 & 2,46\\
E & 17,60 & 19,45 & -1,85 & 3,06 & 0,01 & 3,41\\
\addlinespace
F & 18,50 & 20,19 & -1,69 & 0,72 & 0,70 & 2,84\\
G & 21,20 & 19,09 & 2,11 & 3,42 & 0,07 & 4,46\\
H & 23,00 & 24,39 & -1,39 & 13,32 & 25,38 & 1,93\\
I & 25,30 & 23,04 & 2,26 & 35,40 & 13,60 & 5,12\\
J & 30,20 & 27,49 & 2,71 & 117,72 & 66,22 & 7,36\\
\addlinespace
N & 10,00 & -- & -- & -- & -- & --\\
Somme & 193,50 & -- & 0,00 & 279,30 & 227,04 & 52,26\\
Moyenne & 19,35 & -- & 0,00 & 27,93 & 22,70 & 5,23\\
\bottomrule
\end{tabular}
\end{table}

\textbf{Calcul de l'erreur quadratique moyenne}

La somme des résidus au carré (\emph{SCR}) divisée par le nombre d'observations représente donc le carré moyen des erreurs (en anglais, \emph{mean square error - MSE}), soit la variance résiduelle du modèle (\(52,26 / 10 = 5,23\)). Plus sa valeur sera faible, plus le modèle sera efficace pour prédire la variable indépendante. L'erreur quadratique moyenne (en anglais, \emph{root-mean-square error - RMSE}) est simplement la racine carrée de la somme des résidus au carré divisée par le nombre d'observations (\(n\)) :

\begin{equation} 
RMSE = \frac{\sqrt{\sum_{i=1}^n (y_{i}-\widehat{y})^2}}{n}
\label{eq:reg5}
\end{equation}

Elle représente ainsi une \textbf{mesure absolue des erreurs} qui est exprimée dans l'unité de mesure de la variable dépendante. Dans le cas présent, on a : \(\sqrt{5,23}=2,29\). Cela signifie qu'en moyenne, l'écart absolu (ou erreur absolue) entre les valeurs observées et prédites est de 2,29 points de pourcentage. De nouveau, une plus faible valeur de \textbf{RMSE} indique un meilleur ajustement du modèle. Mais surtout, le RMSE permet d'évaluer avec quelle précision le modèle prédit la variable dépendante. Il est donc particulièrement important si l'objectif principal du modèle est de prédire des valeurs sur un échantillon d'observations pour lequel la variable dépendante est inconnue.

\textbf{Calcul du coefficient de détermination}

Nous avons largement démontré que la variance totale est égale à la variance expliquée plus la variance non expliquée. La qualité du modèle peut donc être évaluée avec le coefficient de détermination (\(R^2\)), soit le rapport entre les variances expliquée et totale :

\begin{equation} 
R^2 = \frac{SCE}{SCT} \mbox{ avec } R^2 \in \left[0,1\right]
\label{eq:reg6}
\end{equation}

Comparativement au RMSE qui est une mesure absolue, le coefficient de détermination est une \textbf{mesure relative} qui varie de 0 à 1. Il exprime la proportion de la variance de \emph{Y} qui est expliquée par la variable \emph{X}; autrement dit, plus sa valeur est élevée, plus \emph{X} influence / est capable de prédire \emph{Y}. Dans le cas présent, on a : \(R^2 = 227.04 / 279.3 = 0.8129\), ce qui signale que 81,3\% de la variance du pourcentage de cyclistes est expliquée par la distance au centre-ville. Tel que signalé dans la section \ref{sect04132}, la racine carrée du coefficient de détermination (\(R^2\)) est égale au coefficient de corrélation (\(r\)) entre les deux variables.

\textbf{Calcul de la statistique \emph{F} de Fisher}

La statistique \emph{F} de Fisher permet de vérifier la significativité globale du modèle.

\begin{equation} 
F = (n-2)\frac{R^2}{1-R^2} = (n-2)\frac{SCE}{SCR}
\label{eq:reg7}
\end{equation}

L'hypothèse nulle (h0 avec \(\beta_1=0\)) est rejetée si la valeur calculée de \emph{F} est supérieure à la valeur critique de la table \emph{F} avec \emph{(1, n-2)} degrés de liberté et un seuil \(\alpha\) (\emph{p}=0,05 habituellement) (voir le tableau des valeurs critiques de F, section \ref{annexe2}). Notez qu'on utilise rarement la table \emph{F} puisqu'avec la fonction \texttt{pf(f\ obtenu,\ 1,\ n-2,\ lower.tail\ =\ FALSE)} l'on obtient directement la valeur de \emph{p} associée à la valeur de \emph{F}. Concrètement, si le test \emph{F} est significatif (avec \emph{p}\textless0,05), plus la valeur de \emph{F} sera élevée, plus le modèle sera efficace (et plus le \(R^2\) sera également élevé).

Notez que la fonction \emph{summary} renvoie les résultats du modèle, dont notamment le test \emph{F} de Fisher.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# utiliser la fonction summary}
\KeywordTok{summary}\NormalTok{(modele)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = Velo ~ KmCV, data = data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.5652 -1.8062  0.0906  2.2241  2.7125 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  30.6032     2.0729  14.763 4.36e-07 ***
## KmCV         -1.4478     0.2456  -5.895 0.000364 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 2.556 on 8 degrees of freedom
## Multiple R-squared:  0.8129,	Adjusted R-squared:  0.7895 
## F-statistic: 34.75 on 1 and 8 DF,  p-value: 0.0003637
\end{verbatim}

Dans le cas présent, \(F = (10 - 2)\frac{0.8129}{1-0.8129} = (10-2)\frac{227.04}{52.26} = 34.75\) avec une valeur de \(p < 0.001\). Par conséquent, le modèle est significatif.

\hypertarget{sect04144}{%
\subsubsection{Mise en œuvre dans}\label{sect04144}}

Comment calculer une régression linéaire simple dans ? Rien de plus simple avec la fonction \texttt{lm(formula\ =\ y\ \textasciitilde{}\ x,\ data=\ dataframe)}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/bivariee/Reg.csv"}\NormalTok{, }\DataTypeTok{stringsAsFactors =}\NormalTok{ F)}
\CommentTok{## Création d'un objet pour le modèle}
\NormalTok{monmodele <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(Velo }\OperatorTok{~}\StringTok{ }\NormalTok{KmCV, df)}
\CommentTok{## Sorties du modèle avec la fonction summary}
\KeywordTok{summary}\NormalTok{(monmodele)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = Velo ~ KmCV, data = df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.5652 -1.8062  0.0906  2.2241  2.7125 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  30.6032     2.0729  14.763 4.36e-07 ***
## KmCV         -1.4478     0.2456  -5.895 0.000364 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 2.556 on 8 degrees of freedom
## Multiple R-squared:  0.8129,	Adjusted R-squared:  0.7895 
## F-statistic: 34.75 on 1 and 8 DF,  p-value: 0.0003637
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{## Calcul du MSE et du RMSE}
\NormalTok{MSE <-}\StringTok{ }\KeywordTok{mean}\NormalTok{(monmodele}\OperatorTok{$}\NormalTok{residuals}\OperatorTok{^}\DecValTok{2}\NormalTok{)}
\NormalTok{RMSE <-}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(MSE)}
\KeywordTok{cat}\NormalTok{(}\StringTok{"MSE="}\NormalTok{, }\KeywordTok{round}\NormalTok{(MSE, }\DecValTok{2}\NormalTok{), }\StringTok{"; RMSE="}\NormalTok{, }\KeywordTok{round}\NormalTok{(RMSE,}\DecValTok{2}\NormalTok{), }\DataTypeTok{sep=}\StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## MSE=5.23; RMSE=2.29
\end{verbatim}

\hypertarget{sect04145}{%
\subsubsection{Comment rapporter une régression linéaire simple}\label{sect04145}}

Nous avons calculé une régression linéaire simple pour prédire le pourcentage d'actifs occupés utilisant le vélo pour se rendre au travail en fonction de la distance au centre-ville (en kilomètres). Le modèle obtient un \emph{F} de Fisher significatif (\emph{F}(1,8)= 34,75, \emph{p} \textless{} 0,001) et un \(R^2\) de 0,813. Le pourcentage de cyclistes peut être prédit par l'équation suivante : 30,603 - 1,448 x (distance au centre-ville en km).

\hypertarget{sect042}{%
\section{Relation entre deux variables qualitatives}\label{sect042}}

\begin{bloc_objectif}

\textbf{Deux variables qualitatives sont-elles associées entre elles?} Plus spécifiquement, certaines modalités d'une variable qualitative sont-elles associées significativement à certaines modalités d'une variable qualitative.

Prenons l'exemple de deux variables qualitatives : l'une intitulée \emph{groupe d'âge} comprenant trois modalités (15 à 29 ans, 30 à 44 ans, 45 à 64 ans); l'autre intitulée \emph{mode de transport habituel pour se rendre au travail} comprenant quatre modalités (véhicule motorisé, transport en commun, vélo, marche).

Comparativement aux deux autres groupes, on pourrait supposer que les jeunes se déplacent proportionnellement plus en modes de transport actifs (vélo et marche) et en transports en commun. À l'inverse, il est possible que les 45 à 64 ans se déplacent majoritairement en véhicule motorisé.

Pour vérifier l'existence d'associations significatives entre les modalités de deux variables qualitatives, il est possible de construire un \textbf{tableau de contingence}\index{tableau de contingence} (section \ref{sect0421}), puis de réaliser le \textbf{test du khi\textsuperscript{2}}\index{khi2} (section \ref{sect0422}).

\end{bloc_objectif}

\hypertarget{sect0421}{%
\subsection{Construction de tableau de contingence}\label{sect0421}}

Les données du tableau de contingence ci-dessous décrivent 279 projets d'habitation à loyer modique (HLM) dans l'ancienne ville de Montréal, croisant les modalités de la période de construction (en colonnes) et de la taille (en ligne) des projets HLM \citep{TheseApparicio}. Les différents éléments du tableau sont décrits ci-dessous.

\begin{itemize}
\item
  \textbf{Les fréquences observées}, nommées communément \(f_{ij}\), correspondent aux observations appartenant à la fois à la \emph{i\textsuperscript{ème}} modalité de la variable en ligne et à la \emph{j\textsuperscript{ème}} modalité de la variable en colonne. À titre d'exemple, on compte 14 HLM construits entre 1985 et 1989 comprenant moins de 25 logements.
\item
  \textbf{Les marges} du tableau sont les totaux pour chaque modalité en ligne (\(n_{i.}\)) et en colonne (\(n_{j.}\)). En guise d'exemple, sur les 279 projets HLM, 53 comprennent de 25 à 49 logements et 56 ont été construites entre 1968 et 1974. Bien entenu, la somme des marges en ligne (\(n_{i.}\)) est égale au nombre total d'observations (\(n_{ij}\)), tout comme la somme de marges en colonne (\(n_{.j}\)).
\item
  \textbf{Trois pourcentages} sont disponibles (total, en ligne, en colonne). Ils sont respectivement la fréquence observée divisée par le nombre d'observations (\(f_{ij}/n_{ij}\times100\)), par la marge en ligne (\(f_{ij}/n_{i.} \times 100\)) et en colonne (\(f_{ij}/n_{.j}\times100\)). En guise d'exemple, 5\% des 279 projets HLM ont été construits entre 1985 et 1989 et comprennent moins de 25 logements (pourcentage total, soit 14/279×100). Aussi, plus de la moitié des habitations de moins de 25 logements ont été construits entre 1990 et 1994 (pourcentage en ligne, 41/80×100). Finalement, près de 36\% des logements construits avant 1975 ont 100 logements et plus (20/56×100).
\item
  \textbf{Les fréquences théoriques}, représentent les valeurs que l'on devrait observer théoriquement s'il y avait indépendance entre les modalités des deux variables : si la répartition des deux modalités des deux variables étaient dûes au hasard. Pour le croisement de deux modalités, la fréquence théorique est égale au produit des marges divisé par le nombre total d'observations (\(ft_{ij} = (n_{i.}n_{.j})/n_{ij}\)). Par exemple, la fréquence théorique pour le croisement des modalité \emph{moins de 25 logements} et \emph{avant 1975} est égale à : (80×56)/279 = 16,06. Nous observons ici que la valeur théorique (16,06) est bien supérieure à la valeur réelle (6). On observe donc moins de HLM de moins de 25 logements avant 1975 que ce que l'on pourrait attendre du hasard.
\item
  \textbf{La déviation} est la différence entre la fréquence observée et la fréquence théorique (\(f_{ij}-ft_{ij}\)). Plus la déviation est grande, plus on s'écarte d'une situation d'indépendance entre les deux modalités \emph{i} et \emph{j}. La somme des déviations sur une ligne ou sur une colonne est nulle. Si la déviation \emph{ij} est nulle, la fréquence théorique est égale à la fréquence observée, ce qui signifie qu'il y a indépendance entre les modalités \emph{i} et \emph{j}. Une déviation positive traduit, quant à elle, une attraction entre les modalités \emph{i} et \emph{j}, ou autrement dit, une surreprésentation du phénomène \emph{ij}; tandis qu'une déviation négative renvoie à une répulsion entre les modalités \emph{i} et \emph{j}, soit une sous-représentation du phénomène \emph{ij}. Dans le cas précédent, on observait 6 habitations de moins de 25 logements construits avant 1975 et une fréquence théorique de 16,0. La déviation est donc -10,06, soit une sous-représentation du phénomène.
\item
  \textbf{La contribution au khi\textsuperscript{2}} est égale à la déviation au carré divisée par la fréquence théorique : \(\chi_{ij}^2 = (f_{ij}-ft_{ij})^2/ft_{ij}\). Plus sa valeur est forte, plus il y a association entre les deux modalités. La somme des contributions au khi\textsuperscript{2} représente le \emph{khi\textsuperscript{2}} total pour l'ensemble du tableau de contingence (ici à 63,54) que nous abordons dans la section suivante.
\end{itemize}

\begin{verbatim}
## 
##    Cell Contents
## |-------------------------|
## |                   Count |
## |         Expected Values |
## | Chi-square contribution |
## |             Row Percent |
## |          Column Percent |
## |           Total Percent |
## |                Residual |
## |-------------------------|
## 
## Total Observations in Table:  279 
## 
##                | TabKhi2$Periode 
## TabKhi2$Taille | Av. 1975  |  1975-79  |  1980-84  |  1985-89  |  1990-94  | Row Total | 
## ---------------|-----------|-----------|-----------|-----------|-----------|-----------|
##      < 25 log. |        6  |       11  |        8  |       14  |       41  |       80  | 
##                |    16.06  |    13.76  |    13.76  |    13.48  |    22.94  |           | 
##                |     6.30  |     0.55  |     2.41  |     0.02  |    14.22  |           | 
##                |     7.50% |    13.75% |    10.00% |    17.50% |    51.25% |    28.67% | 
##                |    10.71% |    22.92% |    16.67% |    29.79% |    51.25% |           | 
##                |     2.15% |     3.94% |     2.87% |     5.02% |    14.70% |           | 
##                |   -10.06  |    -2.76  |    -5.76  |     0.52  |    18.06  |           | 
## ---------------|-----------|-----------|-----------|-----------|-----------|-----------|
##          25-49 |       10  |        5  |        8  |        8  |       22  |       53  | 
##                |    10.64  |     9.12  |     9.12  |     8.93  |    15.20  |           | 
##                |     0.04  |     1.86  |     0.14  |     0.10  |     3.05  |           | 
##                |    18.87% |     9.43% |    15.09% |    15.09% |    41.51% |    19.00% | 
##                |    17.86% |    10.42% |    16.67% |    17.02% |    27.50% |           | 
##                |     3.58% |     1.79% |     2.87% |     2.87% |     7.89% |           | 
##                |    -0.64  |    -4.12  |    -1.12  |    -0.93  |     6.80  |           | 
## ---------------|-----------|-----------|-----------|-----------|-----------|-----------|
##          50-99 |       20  |       21  |       22  |       21  |       15  |       99  | 
##                |    19.87  |    17.03  |    17.03  |    16.68  |    28.39  |           | 
##                |     0.00  |     0.92  |     1.45  |     1.12  |     6.31  |           | 
##                |    20.20% |    21.21% |    22.22% |    21.21% |    15.15% |    35.48% | 
##                |    35.71% |    43.75% |    45.83% |    44.68% |    18.75% |           | 
##                |     7.17% |     7.53% |     7.89% |     7.53% |     5.38% |           | 
##                |     0.13  |     3.97  |     4.97  |     4.32  |   -13.39  |           | 
## ---------------|-----------|-----------|-----------|-----------|-----------|-----------|
##       100 et + |       20  |       11  |       10  |        4  |        2  |       47  | 
##                |     9.43  |     8.09  |     8.09  |     7.92  |    13.48  |           | 
##                |    11.83  |     1.05  |     0.45  |     1.94  |     9.77  |           | 
##                |    42.55% |    23.40% |    21.28% |     8.51% |     4.26% |    16.85% | 
##                |    35.71% |    22.92% |    20.83% |     8.51% |     2.50% |           | 
##                |     7.17% |     3.94% |     3.58% |     1.43% |     0.72% |           | 
##                |    10.57  |     2.91  |     1.91  |    -3.92  |   -11.48  |           | 
## ---------------|-----------|-----------|-----------|-----------|-----------|-----------|
##   Column Total |       56  |       48  |       48  |       47  |       80  |      279  | 
##                |    20.07% |    17.20% |    17.20% |    16.85% |    28.67% |           | 
## ---------------|-----------|-----------|-----------|-----------|-----------|-----------|
## 
##  
## Statistics for All Table Factors
## 
## 
## Pearson's Chi-squared test 
## ------------------------------------------------------------
## Chi^2 =  63.54291     d.f. =  12     p =  5.063109e-09 
## 
## 
##  
##        Minimum expected frequency: 7.917563
\end{verbatim}

\hypertarget{sect0422}{%
\subsection{\texorpdfstring{Test du khi\textsuperscript{2}}{Test du khi2}}\label{sect0422}}

Avec le test du khi\textsuperscript{2}, on postule qu'il y a indépendance entre les modalités des deux variables qualitatives, soit l'hypothèse nulle (h0). Puis, on cacule le nombre de degrés de liberté : \(DL = (n-1)(l-1)\) avec \(l\) et \(n\) étant respectivement les nombres de modalités en ligne et en colonne. Pour notre tableau de contingence, nous avons 12 degrés de liberté : \((4-1)(5-1)=12\). À partir du nombre de degré de liberté et d'un seuil critique de significativité (prenons 5\% ici), nous pouvons trouver la valeur critique de khi\textsuperscript{2} dans le tableau des valeurs critiques du khi\textsuperscript{2} : 21,03 section \ref{annexe1}). Puisque la valeur du khi\textsuperscript{2} calculé dans le tableau de contingence est bien supérieure à celle obtenue dans le tableau des valeurs critiques (63,54), on peut rejeter l'hypothèse d'indépendance au seuil de 5\%. Autrement dit, si les deux variables n'étaient pas associées, nous aurions eu moins de 5\% de chances de collecter des données avec ce niveau d'association, ce qui nous permet de rejeter l'hypothèse nulle (absence d'association). Notez que le test reste significatif avec des seuils de 1\% (\emph{p}=0,01) et 0,1\% (\emph{p}=0,001) puisque les valeurs critiques sont de 26,22 et 32,91.

Bien entendu, une fois que l'on connait le nombre de degrés de liberté, on peut directement calculer les valeurs critiques pour différents seuils de signification et éviter ainsi de recourir à la table ci-dessus. Dans la même veine, on peut aussi calculer la valeur de \emph{p} d'un tableau de contingence en spécifiant le nombre de degrés de liberté et la valeur du khi\textsuperscript{2} obtenue.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cat}\NormalTok{(}\StringTok{"Valeurs critiques du khi2 avec le nombre de degrés de liberté"}\NormalTok{, }\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{,}
    \KeywordTok{round}\NormalTok{(}\KeywordTok{qchisq}\NormalTok{(}\DataTypeTok{p=}\FloatTok{0.95}\NormalTok{,  }\DataTypeTok{df=}\DecValTok{12}\NormalTok{, }\DataTypeTok{lower.tail =} \OtherTok{FALSE}\NormalTok{),}\DecValTok{3}\NormalTok{), }\StringTok{"avec p=0,05"}\NormalTok{, }\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{,}
    \KeywordTok{round}\NormalTok{(}\KeywordTok{qchisq}\NormalTok{(}\DataTypeTok{p=}\FloatTok{0.99}\NormalTok{,  }\DataTypeTok{df=}\DecValTok{12}\NormalTok{, }\DataTypeTok{lower.tail =} \OtherTok{FALSE}\NormalTok{),}\DecValTok{3}\NormalTok{), }\StringTok{"avec p=0,01"}\NormalTok{, }\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{,}
    \KeywordTok{round}\NormalTok{(}\KeywordTok{qchisq}\NormalTok{(}\DataTypeTok{p=}\FloatTok{0.999}\NormalTok{, }\DataTypeTok{df=}\DecValTok{12}\NormalTok{, }\DataTypeTok{lower.tail =} \OtherTok{FALSE}\NormalTok{),}\DecValTok{3}\NormalTok{), }\StringTok{"avec p=0,0001"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Valeurs critiques du khi2 avec le nombre de degrés de liberté 
##  5.226 avec p=0,05 
##  3.571 avec p=0,01 
##  2.214 avec p=0,0001
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cat}\NormalTok{(}\StringTok{"Valeurs de p du Khi2 obtenu (63.54291) avec 12 degrés de liberté :"}\NormalTok{, }\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{,}
    \KeywordTok{pchisq}\NormalTok{(}\DataTypeTok{q=}\FloatTok{63.54291}\NormalTok{, }\DataTypeTok{df=}\DecValTok{12}\NormalTok{, }\DataTypeTok{lower.tail =} \OtherTok{FALSE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Valeurs de p du Khi2 obtenu (63.54291) avec 12 degrés de liberté : 
##  5.063101e-09
\end{verbatim}

\begin{bloc_aller_loin}

Outre le khi\textsuperscript{2}, d'autres mesures d'association permettent de mesurer le degré d'association entre deux variables qualitatives. Les plus courantes sont reportées au tableau ci-dessous. À des fins de comparaison, le khi\textsuperscript{2} décrit précédemment est aussi reporté sur la première ligne du tableau.

\begin{longtable}[]{@{}lll@{}}
\toprule
\begin{minipage}[b]{0.17\columnwidth}\raggedright
Statistique\strut
\end{minipage} & \begin{minipage}[b]{0.15\columnwidth}\raggedright
Formule\strut
\end{minipage} & \begin{minipage}[b]{0.60\columnwidth}\raggedright
Propriété et interprétation\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.17\columnwidth}\raggedright
khi\textsuperscript{2}\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
\(\chi^2 = \sum \frac{(f_{ij}-ft_{ij})^2}{ft_{ij}}\)\strut
\end{minipage} & \begin{minipage}[t]{0.60\columnwidth}\raggedright
Mesure classique du Khi\textsuperscript{2} calculé à partir des différences entre les fréquences observées et attendues. Valeur de \emph{p} disponible.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
Ratio de vraissemblance du khi\textsuperscript{2}\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
\(G^2 = 2 \sum f_{ij} \ln{(\frac{f_{ij}}{ft_{ij}})}\)\strut
\end{minipage} & \begin{minipage}[t]{0.60\columnwidth}\raggedright
Calculé à partir du ratio entre les fréquences observées et attendues. Valeur de \emph{p} disponible.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
khi\textsuperscript{2} de Mantel-Haenszel\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
\(Q_{MH}=(N−1)r^2\)\strut
\end{minipage} & \begin{minipage}[t]{0.60\columnwidth}\raggedright
avec \(r\) étant le coefficient de corrélation entre les deux variables qualitatives; par exemple, entre les valeurs des modalités de 1 à 5 de la variable \emph{période de construction} et celles de 1 à 4 de la variable \emph{taille du projet} HLM. Ce coefficient est très utile quand les deux variables qualitatives ne sont pas nominales, mais \textbf{ordinales}. Valeur de \emph{p} disponible.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
Corrélation polychorique\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
obtenue itérativement par maximum de vraissemblance\strut
\end{minipage} & \begin{minipage}[t]{0.60\columnwidth}\raggedright
Dans le même esprit que le khi\textsuperscript{2} de Mantel-Haenszel, la corrélation polychorique s'applique à deux variables ordinales. Plus spécifiquement, elle formule le postulat que deux variables théoriques normalement distribuées ont été mesurées de façon approximative avec deux échelles ordinales. Par exemple, en psychologie, le sentiment de bien être et le sentiment de sécurité peuvent être conceptualisés comme deux variables continues normalement distribuées. Cependant, les mesurer directement est très difficile, on a donc recours à des échelles de Likert allant de 1 à 10. Pour cet exemple, il serait pertinent d'utiliser la corrélation polychorique. Comme une corrélation de Pearson, la corrélation polychorique varie de -1 à 1, une valeur négative indiquant une relation inverse entre les deux variables théoriques et inversement. Une valeur de \emph{p} peut être obtenue.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
Coefficient Phi\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
\(\phi=\sqrt{\frac{\chi^2}{n}}\)\strut
\end{minipage} & \begin{minipage}[t]{0.60\columnwidth}\raggedright
Simplement le Khi\textsuperscript{2} divisé par le nombre d'observations. Si les deux variables qualitatives comprennent deux modalités chacune (tableau 2x2 dimensions) alors \(\phi\) varie de −1 à 1; sinon de 0 à \(min(\sqrt{c-1}, \sqrt{l-1})\) avec \(c\) et \(l\) étant le nombre de modalités en colonne et en ligne. Par conséquent, ce coefficient est peu utile pour les tableaux de plus de 2x2 dimensions. Pas de valeur de \emph{p} disponible.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
V de Cramer\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
\(V=\sqrt{\frac{\chi^2/n}{min(c-1,l-1)}}\)\strut
\end{minipage} & \begin{minipage}[t]{0.60\columnwidth}\raggedright
Il représente un ajustement du coefficient Phi et varie de 0 à 1. Plus sa valeur est forte plus les deux variables sont associées. À la lecture des deux formules, vous constaterez que pour un tableau de 2 x 2, la valeur du V de Carmer sera égale à celle du Coefficient Phi. Pas de valeur de \emph{p} disponible.\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\end{bloc_aller_loin}

\hypertarget{sect0423}{%
\subsection{Mise en œuvre dans}\label{sect0423}}

Pour calculer le Khi\textsuperscript{2} entre deux variables qualitatives, on utilise la fonction de base : \texttt{chisq.test(x\ =\ ...,\ y\ =\ ...)} qui renvoie le nombre de degré de liberté, les valeurs du Khi\textsuperscript{2} et de \emph{p}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Importation du csv}
\NormalTok{dataHLM <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/bivariee/hlm.csv"}\NormalTok{)}
\CommentTok{# Calcul du Khi2 avec la fonction de base chisq.test}
\KeywordTok{chisq.test}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ dataHLM}\OperatorTok{$}\NormalTok{Taille, }\DataTypeTok{y =}\NormalTok{ dataHLM}\OperatorTok{$}\NormalTok{Periode)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 	Pearson's Chi-squared test
## 
## data:  dataHLM$Taille and dataHLM$Periode
## X-squared = 63.543, df = 12, p-value = 5.063e-09
\end{verbatim}

Pour la construction du tableau de contingence, deux options sont possibles dépendamment de la structuration de votre tableau de données initial. Premier cas de figure, votre tableau comprend une ligne par observation avec les différentes modalités dans deux colonnes (ici \emph{Periode} et \emph{Taille}). Dans la syntaxe ci-dessous, pour chacune des deux variables qualitatives, on crée un facteur afin de spécifier un intitulé à chaque modalité (\texttt{factor(levels\ =c(....),\ labels\ =\ c(..)}). Puis, on utilise la fonction \texttt{CrossTable} du package \textbf{gmodels}. Pour obtenir les fréquences théoriques, les contributions locales au Khi\textsuperscript{2} et les déviations, on spécifie les options suivantes : \texttt{expected=TRUE,\ chisq=TRUE,\ resid=TRUE}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"gmodels"}\NormalTok{)}
\CommentTok{#Premiers enregistrements du tableau}
\KeywordTok{head}\NormalTok{(dataHLM)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   Periode Taille
## 1       5      1
## 2       5      1
## 3       5      2
## 4       5      1
## 5       5      1
## 6       5      2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# La variable Periode comprend 5 modalités (de 1 à 5)}
\KeywordTok{table}\NormalTok{(dataHLM}\OperatorTok{$}\NormalTok{Periode)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  1  2  3  4  5 
## 56 48 48 47 80
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# La variable Periode comprend 4 modalités (de 1 à 4)}
\KeywordTok{table}\NormalTok{(dataHLM}\OperatorTok{$}\NormalTok{Taille)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  1  2  3  4 
## 80 53 99 47
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#Création d'un facteur pour les cinq modalités de la période de construction}
\NormalTok{dataHLM}\OperatorTok{$}\NormalTok{Periode <-}\StringTok{ }\KeywordTok{factor}\NormalTok{(dataHLM}\OperatorTok{$}\NormalTok{Periode, }
                          \DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{), }
                          \DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"<1975"}\NormalTok{, }
                                     \StringTok{"1975-1979"}\NormalTok{, }
                                     \StringTok{"1980-1984"}\NormalTok{, }
                                     \StringTok{"1985-1989"}\NormalTok{, }
                                     \StringTok{"1990-1994"}\NormalTok{))}
\CommentTok{#Création d'un facteur pour les quatre modalités de la taille des habitations}
\NormalTok{dataHLM}\OperatorTok{$}\NormalTok{Taille <-}\StringTok{ }\KeywordTok{factor}\NormalTok{(dataHLM}\OperatorTok{$}\NormalTok{Taille, }
                         \DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{), }
                         \DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"<25 log."}\NormalTok{, }
                                    \StringTok{"25-49"}\NormalTok{, }
                                    \StringTok{"50-99"}\NormalTok{, }
                                    \StringTok{"100 et +"}\NormalTok{))}
\CommentTok{# Pour construire un tableau de contingence on utilise la fonction CrossTable }
\CommentTok{# (package gmodels) les deux lignes ci-dessous sont mises en commentaire }
\CommentTok{# pour ne pas répéter le tableau}
\CommentTok{#CrossTable(x=dataHLM$Taille, y=dataHLM$Periode, digits = 2,}
\CommentTok{#           expected=TRUE, chisq = TRUE, resid = TRUE, format="SPSS")}
\end{Highlighting}
\end{Shaded}

Deuxième cas de figure, vous disposez déjà d'un tableau de contingence, soit les fréquences observées (\(f_{ij}\)). On n'utilise donc pas la fonction \texttt{CrossTable}, mais directement la fonction \texttt{chisq.test}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Importation des données}
\NormalTok{df <-}\StringTok{  }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/bivariee/data_transport.csv"}\NormalTok{, }\DataTypeTok{stringsAsFactors =} \OtherTok{FALSE}\NormalTok{)}
\NormalTok{df }\CommentTok{# Visualisation du tableau}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                                     ModeTransport  Homme  Femme
## 1 Automobile, camion ou fourgonnette - conducteur 689400 561830
## 2   Automobile, camion ou fourgonnette - passager  21315  40010
## 3                             Transport en commun 181435 238330
## 4                                          A pied  43715  54360
## 5                                      Bicyclette  24295  13765
## 6                                     Autre moyen   8395   6970
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Matrice <-}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{(df[, }\KeywordTok{c}\NormalTok{(}\StringTok{"Homme"}\NormalTok{,}\StringTok{"Femme"}\NormalTok{)])}
\KeywordTok{dimnames}\NormalTok{(Matrice) <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\KeywordTok{unique}\NormalTok{(df}\OperatorTok{$}\NormalTok{ModeTransport), }\DataTypeTok{Sexe=}\KeywordTok{c}\NormalTok{(}\StringTok{"Homme"}\NormalTok{,}\StringTok{"Femme"}\NormalTok{))}
\CommentTok{# Notez que vous pouvez saisir vos données directement si vous avez peu d'observations}
\NormalTok{Femme <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{689400}\NormalTok{, }\DecValTok{21315}\NormalTok{, }\DecValTok{181435}\NormalTok{, }\DecValTok{43715}\NormalTok{, }\DecValTok{24295}\NormalTok{, }\DecValTok{8395}\NormalTok{) }\CommentTok{# Vecteur de valeurs pour les femmes}
\NormalTok{Homme <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{561830}\NormalTok{, }\DecValTok{40010}\NormalTok{, }\DecValTok{238330}\NormalTok{, }\DecValTok{54360}\NormalTok{, }\DecValTok{13765}\NormalTok{, }\DecValTok{6970}\NormalTok{) }\CommentTok{# Vecteur de valeurs pour les hommes}
\NormalTok{Matrice <-}\StringTok{ }\KeywordTok{as.table}\NormalTok{(}\KeywordTok{cbind}\NormalTok{(Femme, Homme)) }\CommentTok{# Création du tableau}
\CommentTok{# Nom des deux variables et de leurs modalités respectives}
\KeywordTok{dimnames}\NormalTok{(Matrice) <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\DataTypeTok{transport=}\KeywordTok{c}\NormalTok{(}\StringTok{"Automobile (conducteur)"}\NormalTok{,}
                                      \StringTok{"Automobile (passager)"}\NormalTok{,}
                                      \StringTok{"Transport en commun"}\NormalTok{,                            }
                                      \StringTok{"A pied"}\NormalTok{,}
                                      \StringTok{"Bicyclette"}\NormalTok{,}
                                      \StringTok{"Autre moyen"}\NormalTok{),}
                          \DataTypeTok{sexe=}\KeywordTok{c}\NormalTok{(}\StringTok{"Homme"}\NormalTok{,}\StringTok{"Femme"}\NormalTok{))}
\CommentTok{# Test du Khi2}
\NormalTok{test <-}\StringTok{ }\KeywordTok{chisq.test}\NormalTok{(Matrice)}
\KeywordTok{print}\NormalTok{(test)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 	Pearson's Chi-squared test
## 
## data:  Matrice
## X-squared = 29134, df = 5, p-value < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Fréquences observées (Fij)}
\NormalTok{test}\OperatorTok{$}\NormalTok{observed}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                          sexe
## transport                  Homme  Femme
##   Automobile (conducteur) 689400 561830
##   Automobile (passager)    21315  40010
##   Transport en commun     181435 238330
##   A pied                   43715  54360
##   Bicyclette               24295  13765
##   Autre moyen               8395   6970
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Fréquences théoriques (FTij)}
\KeywordTok{round}\NormalTok{(test}\OperatorTok{$}\NormalTok{expected,}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                          sexe
## transport                  Homme  Femme
##   Automobile (conducteur) 643313 607917
##   Automobile (passager)    31530  29795
##   Transport en commun     215820 203945
##   A pied                   50425  47650
##   Bicyclette               19568  18492
##   Autre moyen               7900   7465
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Déviations (Fij - FTij)}
\KeywordTok{round}\NormalTok{(test}\OperatorTok{$}\NormalTok{observed}\OperatorTok{-}\NormalTok{test}\OperatorTok{$}\NormalTok{expected,}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                          sexe
## transport                  Homme  Femme
##   Automobile (conducteur)  46087 -46087
##   Automobile (passager)   -10215  10215
##   Transport en commun     -34385  34385
##   A pied                   -6710   6710
##   Bicyclette                4727  -4727
##   Autre moyen                495   -495
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Contributions au Khi2}
\KeywordTok{round}\NormalTok{((test}\OperatorTok{$}\NormalTok{observed}\OperatorTok{-}\NormalTok{test}\OperatorTok{$}\NormalTok{expected)}\OperatorTok{^}\DecValTok{2}\OperatorTok{/}\NormalTok{test}\OperatorTok{$}\NormalTok{expected,}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                          sexe
## transport                   Homme   Femme
##   Automobile (conducteur) 3301.74 3493.98
##   Automobile (passager)   3309.37 3502.05
##   Transport en commun     5478.22 5797.18
##   A pied                   892.81  944.80
##   Bicyclette              1141.71 1208.19
##   Autre moyen               31.04   32.85
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Marges en lignes et en colonnes}
\KeywordTok{colSums}\NormalTok{(Matrice)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  Homme  Femme 
## 968555 915265
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{rowSums}\NormalTok{(Matrice)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Automobile (conducteur)   Automobile (passager)     Transport en commun 
##                 1251230                   61325                  419765 
##                  A pied              Bicyclette             Autre moyen 
##                   98075                   38060                   15365
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Grand total}
\KeywordTok{sum}\NormalTok{(Matrice)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1883820
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Pourcentages}
\KeywordTok{round}\NormalTok{(Matrice}\OperatorTok{/}\KeywordTok{sum}\NormalTok{(Matrice)}\OperatorTok{*}\DecValTok{100}\NormalTok{,}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                          sexe
## transport                 Homme Femme
##   Automobile (conducteur) 36.60 29.82
##   Automobile (passager)    1.13  2.12
##   Transport en commun      9.63 12.65
##   A pied                   2.32  2.89
##   Bicyclette               1.29  0.73
##   Autre moyen              0.45  0.37
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Pourcentages en ligne}
\KeywordTok{round}\NormalTok{(Matrice}\OperatorTok{/}\KeywordTok{rowSums}\NormalTok{(Matrice)}\OperatorTok{*}\DecValTok{100}\NormalTok{,}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                          sexe
## transport                 Homme Femme
##   Automobile (conducteur) 55.10 44.90
##   Automobile (passager)   34.76 65.24
##   Transport en commun     43.22 56.78
##   A pied                  44.57 55.43
##   Bicyclette              63.83 36.17
##   Autre moyen             54.64 45.36
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Pourcentages en colonne}
\KeywordTok{round}\NormalTok{(Matrice}\OperatorTok{/}\KeywordTok{colSums}\NormalTok{(Matrice)}\OperatorTok{*}\DecValTok{100}\NormalTok{,}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                          sexe
## transport                 Homme Femme
##   Automobile (conducteur) 71.18 58.01
##   Automobile (passager)    2.33  4.37
##   Transport en commun     18.73 24.61
##   A pied                   4.78  5.94
##   Bicyclette               2.51  1.42
##   Autre moyen              0.92  0.76
\end{verbatim}

Pour obtenir les autres mesures d'association, on pourra utiliser la syntaxe suivante :

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/bivariee/hlm.csv"}\NormalTok{)}
\CommentTok{# Fonction pour calculer les autres mesures d'association}
\NormalTok{AutresMesuresKhi2 <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x, y)\{}
\NormalTok{  testChi2 <-}\StringTok{ }\KeywordTok{chisq.test}\NormalTok{(x, y) }\CommentTok{# Calcul du Chi2}
\NormalTok{  n <-}\StringTok{ }\KeywordTok{sum}\NormalTok{(testChi2}\OperatorTok{$}\NormalTok{observed)  }\CommentTok{# Nombre d'observations}
\NormalTok{  c <-}\StringTok{ }\KeywordTok{ncol}\NormalTok{(testChi2}\OperatorTok{$}\NormalTok{observed) }\CommentTok{# Nombre de colonnes}
\NormalTok{  l <-}\StringTok{ }\KeywordTok{nrow}\NormalTok{(testChi2}\OperatorTok{$}\NormalTok{observed) }\CommentTok{# Nombre de lignes}
\NormalTok{  dl <-}\StringTok{ }\NormalTok{(c}\DecValTok{-1}\NormalTok{)}\OperatorTok{*}\NormalTok{(l}\DecValTok{-1}\NormalTok{)            }\CommentTok{# Nombre de degrés de libertés}
\NormalTok{  chi2 <-}\StringTok{ }\NormalTok{testChi2}\OperatorTok{$}\NormalTok{statistic   }\CommentTok{# Khi2}
\NormalTok{  Pchi2 <-}\StringTok{ }\NormalTok{testChi2}\OperatorTok{$}\NormalTok{p.value    }\CommentTok{# P pour le Khi2}
  
  \CommentTok{#Ratio de vraissemblance du khi2}
\NormalTok{  G <-}\StringTok{ }\DecValTok{2}\OperatorTok{*}\KeywordTok{sum}\NormalTok{(testChi2}\OperatorTok{$}\NormalTok{observed}\OperatorTok{*}\KeywordTok{log}\NormalTok{(testChi2}\OperatorTok{$}\NormalTok{observed}\OperatorTok{/}\NormalTok{testChi2}\OperatorTok{$}\NormalTok{expected)) }\CommentTok{# G2}
\NormalTok{  PG <-}\StringTok{ }\KeywordTok{pchisq}\NormalTok{(G, }\DataTypeTok{df=}\NormalTok{dl, }\DataTypeTok{lower.tail =} \OtherTok{FALSE}\NormalTok{) }\CommentTok{# P pour le G22}
  
  \CommentTok{# khi2 de Mantel-Haenszel avec la librarie DescTools}
\NormalTok{  MHTest <-}\StringTok{ }\NormalTok{DescTools}\OperatorTok{::}\KeywordTok{MHChisqTest}\NormalTok{(testChi2}\OperatorTok{$}\NormalTok{observed)}
\NormalTok{  MH <-}\StringTok{ }\NormalTok{MHTest}\OperatorTok{$}\NormalTok{statistic}
\NormalTok{  PMH <-}\StringTok{ }\NormalTok{MHTest}\OperatorTok{$}\NormalTok{p.value}
  
  \CommentTok{# Coefficient de correlation Polychorique}
\NormalTok{  df <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\StringTok{"x"}\NormalTok{ =}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(x),}
                 \StringTok{"y"}\NormalTok{ =}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(y))}
\NormalTok{  polychoricCorr <-}\StringTok{ }\NormalTok{correlation}\OperatorTok{::}\KeywordTok{cor_test}\NormalTok{(df,}\StringTok{"x"}\NormalTok{,}\StringTok{"y"}\NormalTok{,}\DataTypeTok{method =} \StringTok{"polychoric"}\NormalTok{)}
\NormalTok{  polyR <-}\StringTok{ }\NormalTok{polychoricCorr}\OperatorTok{$}\NormalTok{rho}
\NormalTok{  polyP <-}\StringTok{ }\NormalTok{polychoricCorr}\OperatorTok{$}\NormalTok{p}
  
  \CommentTok{# Coefficient Phi et V de Cramer}
\NormalTok{  phi <-}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(chi2}\OperatorTok{/}\NormalTok{n)}
\NormalTok{  vc <-}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(chi2}\OperatorTok{/}\NormalTok{(n}\OperatorTok{*}\KeywordTok{min}\NormalTok{(c}\DecValTok{-1}\NormalTok{,l}\DecValTok{-1}\NormalTok{)))}
  
  \CommentTok{# Tableau pour les sorties}
\NormalTok{  dfsortie <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}
        \DataTypeTok{Statistique =} \KeywordTok{c}\NormalTok{(}\StringTok{"Khi2"}\NormalTok{, }
                        \StringTok{"Ratio de vraissemblance du  khi"}\NormalTok{, }
                        \StringTok{"Khi2 de Mantel-Haenszel"}\NormalTok{,}
                        \StringTok{"Corrélation Polychoric"}\NormalTok{,}
                        \StringTok{"Coefficient de Phi"}\NormalTok{,}
                        \StringTok{"V de Cramer"}\NormalTok{), }
        \DataTypeTok{Valeur =} \KeywordTok{round}\NormalTok{(}\KeywordTok{c}\NormalTok{(Pchi2, G, MH, polyR, phi, vc),}\DecValTok{3}\NormalTok{), }
        \DataTypeTok{P =} \KeywordTok{round}\NormalTok{(}\KeywordTok{c}\NormalTok{(Pchi2, PG, PMH, polyP , }\OtherTok{NA}\NormalTok{, }\OtherTok{NA}\NormalTok{),}\DecValTok{10}\NormalTok{))}
  \KeywordTok{return}\NormalTok{(dfsortie)}
\NormalTok{\}}

\NormalTok{kableExtra}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}\KeywordTok{AutresMesuresKhi2}\NormalTok{(df}\OperatorTok{$}\NormalTok{Periode, df}\OperatorTok{$}\NormalTok{Taille),}
          \DataTypeTok{digits =} \DecValTok{3}\NormalTok{,}
          \DataTypeTok{caption=}\StringTok{"Mesures d'association entre deux variables qualitatives"}\NormalTok{)  }\OperatorTok{%>%}
\StringTok{  }\NormalTok{kableExtra}\OperatorTok{::}\KeywordTok{kable_styling}\NormalTok{(}\DataTypeTok{font_size =} \DecValTok{8}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:unnamed-chunk-127}Mesures d'association entre deux variables qualitatives}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{l|r|r}
\hline
Statistique & Valeur & P\\
\hline
Khi2 & 0.000 & 0\\
\hline
Ratio de vraissemblance du  khi & 67.286 & 0\\
\hline
Khi2 de Mantel-Haenszel & 48.486 & 0\\
\hline
Corrélation Polychoric & -0.479 & 0\\
\hline
Coefficient de Phi & 0.477 & --\\
\hline
V de Cramer & 0.276 & --\\
\hline
\end{tabular}
\end{table}

\hypertarget{sect0424}{%
\subsection{Interprétation d'un tableau de contingence}\label{sect0424}}

Nous vous proposons une démarche très simple pour vérifier l'association entre deux variables qualitatives avec les étapes suivantes :

\begin{itemize}
\item
  On pose l'hypothèse nulle (h0), soit l'indépendance entre les deux variables. Si le Khi\textsuperscript{2} total du tableau de contingence est inférieur à la valeur critique du Khi\textsuperscript{2} avec \emph{p}=0,05 et le nombre de degrés de liberté de la table \emph{T}, alors il y a bien indépendance. La valeur de \emph{p} sera alors supérieure à 0,05. L'analyse s'arrête donc là ! Autrement dit, il n'est pas nécessaire d'analyser le contenu de votre tableau de contingence puisqu'il n'y pas d'associations significatives entre les modalités des deux variables. Vous pouvez simplement signaler que : selon les résultats du test du Khi\textsuperscript{2}, il n'y a pas d'association significative entre les deux variables (\(\chi\) = \ldots{} avec \emph{p}= \ldots).
\item
  S'il y a dépendance (\(khi_{observé}^2 > khi_{critique}^2\)), trouver les cellules \emph{ij} où les contributions au Khi\textsuperscript{2} sont les plus fortes, c'est-à-dire où les liens entre les modalités \emph{i} de la variable en ligne et les modalités \emph{j} de la variable en colonne sont les plus marqués. Pour ces cellules, le phénomène \emph{ij} est surreprésenté si la déviation est positive ou sous-représenté si la déviation est négative. Commentez ces associations et utilisez les pourcentages en lignes ou en colonnes pour appuyer vos propos.
\end{itemize}

\begin{bloc_astuce}

Pour repérer rapidement les cellules où les contributions au Khi\textsuperscript{2} sont les plus fortes, vous pouvez construire un graphique avec la fonction \textbf{mosaic} du \emph{package} \textbf{vcd}. À la figure \ref{fig:figVDC}, la taille des rectangles représentent les effectifs entre les deux modalités tandis que les associations sont représentées comme suit :
en gris lorsqu'elles ne sont pas significatives, en rouge pour des déviations significatives et négatives et en bleu pour des déviations significatives et positives.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(vcd)}
\KeywordTok{mosaic}\NormalTok{(}\OperatorTok{~}\StringTok{ }\NormalTok{Taille}\OperatorTok{+}\NormalTok{Periode, }\DataTypeTok{data=}\NormalTok{dataHLM,}\DataTypeTok{shade=}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{legend=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics[width=0.65\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/figVDC-1}

\end{bloc_astuce}

\textbf{Exemple d'interprétation.} « Les résultats du test du khi\textsuperscript{2} signale qu'il existe des associations entre les modalités de la taille et de la période de construction des projets d'habitation (\(\chi\) =63,5, \emph{p} \textless{} 0,001). Les fortes contributions au khi\textsuperscript{2} et le signe positif ou négatif des déviations correspondantes permettent de repérer cinq associations majeures entre les modalités de taille et de période de construction des projets HLM : \textbf{1)} la répulsion entre les projets d'habitation de moins de 25 logements et la période de construction 1964-1974; \textbf{2)} l'attraction entre les projets d'habitation de 100 logements et plus et la période de construction de 1969-1974; \textbf{3)} l'attraction entre les projets d'habitation de moins de 25 logements et la période de construction de 1990-1994; \textbf{4)} la répulsion entre les projets d'habitation de 50 à 99 logements et la période de construction 1990-1994; \textbf{5)} la répulsion entre les projets d'habitation de 100 logements et plus et la période de construction 1990-1994.
On observe donc une tendance bien marquée dans l'évolution du type de construction entre 1970 et 1994 : entre 1969 et 1974, on construit habituellement de grandes habitations dépassant souvent 100 logements; du milieu des années 1970 à la fin des années 1980, on privilégie la construction d'habitations de taille plus modeste, entre 50 et 100 logements; tandis qu'au début des années 1990, on opte plutôt pour des habitations de taille réduite (moins de 50 logements). Quelques chiffres à l'appui : sur les 56 habitations réalisées entre 1969 et 1974, 20 ont plus de 100 logements, 20 comprennent entre 50 et 99 logements et seules 10 ont moins de 25 logements. Près de la moitié des habitations construites entre 1975 et 1989 regroupent 50 à 99 logements (43,8\% pour la période 1975-1979, 45,8\% pour 1980-1984 et 44,7\% pour 1985-1989). Par contre, 51\% des logements érigés à partir de 1990 disposent de moins de 25 logements » (Apparicio, 2002, 117-118). Notez que cette évolution décroissante est aussi soutenue par le coefficient négatif de la corrélation polychorique.

Vous pouvez aussi construire un graphique pour appuyer vos constats, soit avec les pourcentages en ligne ou en colonne (figure \ref{fig:fighlm} tirée de \citet{apparicio2006}).

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{images/bivariee/figurehlm} 

}

\caption{Taille des ensembles HLM selon la période de construction}\label{fig:fighlm}
\end{figure}

\textbf{Comment rapporter succinctement les résultats d'un Test du Khi\textsuperscript{2}?}

Le test du Khi\textsuperscript{2} a été réalisé pour examiner la relation entre la taille et la période de construction des habitations HLM. Cette relation est significative : \(\chi^2\)(12, N = 279) = 63,5, \emph{p} \textless{} 0,001. Plus les projets ont été construits récemment, plus ils sont de taille réduite.

Pour un texte en anglais, vous pourrez consulter \url{https://www.socscistatistics.com/tutorials/chisquare/default.aspx}.

\hypertarget{sect043}{%
\section{Relation entre une variable quantitative et une variable qualitative à deux modalités}\label{sect043}}

\begin{bloc_objectif}

\textbf{Les moyennes de deux groupes de population sont-elles significativement différentes?} On souhaite ici comparer deux groupes de population en fonction d'une variable continue.
Par exemple, pour deux échantillons respectivement d'hommes et de femmes travaillant dans le même secteur d'activité, on pourrait souhaiter vérifier si les moyennes des salaires des hommes et des femmes sont différentes et ainsi vérifier la présence ou l'absence d'une iniquité systématique. En études urbaines, dans le cadre d'une étude sur un espace public, on pourrait vouloir vérifier si la différence des moyennes du sentiment de sécurité des femmes et des hommes est significative (c'est-à-dire différente de 0).

\textbf{Pour un même groupe, la moyenne de la différence d'un phémonène donné mesuré à deux moments est-elle ou non égale à zéro?} Autrement dit, on cherche à comparer un même groupe d'individus avant et après une expérimentation, ou dans deux contextes différents. Prenons un exemple d'application en études urbaines. Dans le cadre d'une étude sur la perception des risques associés à la pratique du vélo en ville, 50 individus utilisant habituellement l'automobile pour se rendre au travail sont recrutés. L'expérimentation pourrait consister à leur donner une formation sur la pratique du vélo en ville et à les accompagner quelques jours durant leurs déplacements domicile-travail. On évaluera la différence de leurs perceptions des risques associés à la pratique du vélo sur une échelle de 0 à 100 avant et après l'expérimentation. On pourrait supposer que la moyenne des différences est significativement négative, ce qui indiquerait que la perception du risque a diminué après l'expérimentation; autrement dit, la perception du risque serait plus faible en fin de période.

\end{bloc_objectif}

\hypertarget{sect0431}{%
\subsection{\texorpdfstring{Test \emph{t} et ses différentes variantes}{Test t et ses différentes variantes}}\label{sect0431}}

Le \textbf{t de student}, appelé aussi \textbf{test \emph{t}} (\emph{t-test} en anglais), est un test paramétrique permettant de comparer les moyennes de deux groupes (échantillons), qui peuvent être indépendantes ou non :

\begin{itemize}
\item
  \textbf{Échantillons indépendants (dits non appariés)}, les observations de deux groupes qui n'ont aucun lien entre eux. Par exemple, on souhaite vérifier si les moyennes du sentiment de sécurité des hommes et des femmes, ou encore si, les moyennes des loyers entre deux villes sont statistiquement différentes. Ainsi, les tailles des deux échantillons peuvent être différentes (\(n_a \neq n_b\)).
\item
  \textbf{Échantillons dépendants (dits appariés)}, les individus des deux groupes sont les mêmes et sont donc associés par paires. Autrement dit, on a deux séries de valeurs de taille identique \(n_a = n_b\) et \(n_{ai}\) est le même individu que \(n_{bi}\). Ce type d'analyse est souvent utilisée en études cliniques : pour \(n\) individus, on dispose d'une mesure quantitative de leur état de santé pour deux séries (l'une avant le traitement, l'autre une fois le traitement terminé). Cela permet de comparer les mêmes individus avant et après un traitement, une expérimentation; on parle alors d'étude, d'expérience et d'analyse pré-post. Concrètement, on cherche à savoir si la moyenne des différences des observations avant et après est significativement différente de 0. Si c'est le cas, on peut en conclure que l'expérimentation a eu un impact sur le phénomène mesuré (variable continue). Ce type d'analyse pré-post peut aussi être utilisé pour évaluer l'impact du réaménagement d'un espace public (rue commerciale, place publique, parc, etc.). Par exemple, on pourrait questionner le même échantillon de commerçants ou d'usagers avant et après le réaménagement d'une artère commerciale.
\end{itemize}

\textbf{Condition d'application}. Pour utiliser les tests de Student et de Welch, la variable continue doit être normalement distribuée. Si elle est fortement anormale, on utilisera le test non paramétrique de Wilcoxon (section \ref{sect0432}). Il existe trois principaux tests pour comparer les moyennes de deux groupes :

\begin{itemize}
\tightlist
\item
  Test de Student (test \emph{t}) avec échantillons indépendants et variances similaires (méthode \emph{pooled}). Les variances de deux groupes sont semblables quand leur ratio varie de 0,5 à 2 (\(0,5< (S^2_{X_A}/S^2_{X_B})<2\)).
\item
  Test de Welch (appelé aussi Satterthwaite) avec échantillons indépendants quand les variances des deux groupes sont dissemblables.
\item
  Test de Student (test \emph{t}) avec échantillons dépendants.
\end{itemize}

Il s'agit de vérifier si les moyennes des deux groupes sont statistiquement différentes avec les étapes suivantes :

\begin{itemize}
\tightlist
\item
  On pose l'hypothèse nulle (H0), soit que les moyennes des deux groupes \emph{A} et \emph{B} ne sont pas différentes (\(\bar{X}_{A}=\bar{X}_{B}\)) ou autrement dit, la différence des deux moyennes est nulle (\(\bar{X}_{A}-\bar{X}_{B}=0\)). L'hypothèse alternative (H1) est donc \(\bar{X}_{A}\ne\bar{X}_{B}\).
\item
  On calcule la valeur de \emph{t} et le nombre de degrés de liberté. La valeur de \emph{t} sera négative quand la moyenne du groupe A est inférieure au groupe B et inversement.
\item
  On compare la valeur absolue de \emph{t} (\(\mid T \mid\)) avec celle issue de la table des valeurs critiques T avec le bon nombre de degrés de liberté et en choisissant un degré de signification (habituellement, p = 0,05). Si (\(\mid t \mid\)) est supérieure à la valeur \emph{t} critique, alors les moyennes sont statistiquement différentes au degré de signification retenu.
\item
  Si les moyennes sont statistiquement différentes, on peut calculer la taille de l'effet.
\end{itemize}

\textbf{Cas 1. Test de student pour des échantillons indépendants avec variances égales (méthode \emph{pooled}).} La valeur de \emph{t} est le ratio entre la différence des moyennes des deux groupes (numérateur) et l'erreur-type groupée des deux échantillons (dénominateur) :

\(t = \frac{\bar{X}_{A}-\bar{X}_{B}}{\sqrt{\frac{S^2_p}{n_A}+\frac{S^2_p}{n_B}}}\) avec
\(S^2_p = \frac{(n_A-1)S^2_{X_A}+(n_B-1)S^2_{X_B}}{n_A+n_B-2}\)

avec \(n_A\),\(n_B\), \(S^2_{X_A}\) et \(S^2_{X_B}\) étant respectivement les nombres d'observations et les variances pour les groupes \emph{A} et \emph{B}, \(S^2_p\) étant la variance groupée des deux échantillons et \(n_A+n_B-2\) étant le nombre de degrés de liberté.

\textbf{Cas 2. Test de Welch pour des échantillons indépendants (avec variances différentes).} Le test de Welch est très similaire au test de student; seul le calcul de la valeur de \emph{T} est différent, pour tenir compte des variances respectives des groupes :

\(t = \frac{\bar{X}_{A}-\bar{X}_{B}}{\sqrt{\frac{S^2_A}{n_A}+\frac{S^2_B}{n_B}}}\) et \(dl = \frac{ \left( \frac{S^2_{X_A}}{n_A}+\frac{S^2_{X_B}}{n_B} \right)^2} {\frac{S^4_{X_A}}{n^2_A(n_A-1)}+\frac{S^4_{X_B}}{n^2_B(n_B-1)}}\)

Dans la syntaxe ci-dessous, nous avons écrit une fonction dénommée \texttt{test\_independants} permettant de calculer les deux tests pour des échantillons indépendants. Dans cette fonction, vous pourrez repérer comment sont calculés les moyennes, nombres d'observations et variances pour les deux groupes, le nombre de degrés de liberté, les valeurs de \emph{t} et de \emph{p} pour les deux tests. Puis, nous avons créé aléatoirement deux jeux de données relativement à la vitesse de déplacement de cyclistes utilisant un vélo personnel ou un vélo en libre service (généralement plus lourd et moins utilisé par des cyclistes expérimentés) :

\begin{itemize}
\item
  Au cas 1, 60 cyclistes utilisant un vélo personnel roulant en moyenne à 18 km/h (écart-type de 1,5) et 50 utilisateurs du système de vélo partage avec une vitesse moyenne de 15 km/h (écart-type de 1,5).
\item
  Au cas 2, 60 cyclistes utilisant un vélo personnel roulant en moyenne à 16 km/h (écart-type de 3) et 50 utilisateurs du système de vélo partage avec une vitesse moyenne de 15 km/h (écart-type de 1,5). Ce faible écart des moyennes, combiné à une plus forte variance va réduire la significativité de la différence entre les deux groupes.
\end{itemize}

D'emblée, l'analyse visuelle des boîtes à moustaches (figure \ref{fig:figttest1}) signale qu'au cas 1 contrairement au cas 2, les groupes sont plus homogènes (boîtes plus compactes) et les moyennes semblent différentes (les boîtes sont centrées différemment sur l'axe des ordonnées). Cela est confirmé par les résultats des tests.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"ggplot2"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"ggpubr"}\NormalTok{)}
\CommentTok{# fonction ------------------}
\NormalTok{tstudent_independants <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(A, B)\{}
\NormalTok{    x_a <-}\StringTok{ }\KeywordTok{mean}\NormalTok{(A)           }\CommentTok{# Moyenne du groupe A}
\NormalTok{    x_b <-}\StringTok{ }\KeywordTok{mean}\NormalTok{(B)           }\CommentTok{# Moyenne du groupe B}
\NormalTok{    var_a <-}\StringTok{ }\KeywordTok{var}\NormalTok{(A)          }\CommentTok{# Variance du groupe A}
\NormalTok{    var_b <-}\StringTok{ }\KeywordTok{var}\NormalTok{(B)          }\CommentTok{# Variance du groupe B}
\NormalTok{    sd_a <-}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(var_a)      }\CommentTok{# Écart-type du groupe A}
\NormalTok{    sd_b <-}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(var_b)      }\CommentTok{# Écart-type du groupe B}
\NormalTok{    ratio_v <-}\StringTok{ }\NormalTok{var_a }\OperatorTok{/}\StringTok{ }\NormalTok{var_b }\CommentTok{# ratio des variances}
\NormalTok{    n_a <-}\StringTok{ }\KeywordTok{length}\NormalTok{(A)         }\CommentTok{# nombre d'observation du groupe A}
\NormalTok{    n_b <-}\StringTok{ }\KeywordTok{length}\NormalTok{(B)         }\CommentTok{# nombre d'observation du groupe B}
    
    \CommentTok{# T-test (variances égales)}
\NormalTok{    dl_test <-}\StringTok{ }\NormalTok{n_a}\OperatorTok{+}\NormalTok{n_b}\DecValTok{-2}       \CommentTok{# degrés de liberté}
\NormalTok{    PooledVar <-}\StringTok{ }\NormalTok{(((n_a}\DecValTok{-1}\NormalTok{)}\OperatorTok{*}\NormalTok{var_a)}\OperatorTok{+}\NormalTok{((n_b}\DecValTok{-1}\NormalTok{)}\OperatorTok{*}\NormalTok{var_b))}\OperatorTok{/}\NormalTok{dl_test}
\NormalTok{    t_test <-}\StringTok{ }\NormalTok{(x_a}\OperatorTok{-}\NormalTok{x_b) }\OperatorTok{/}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(((PooledVar}\OperatorTok{/}\NormalTok{n_a)}\OperatorTok{+}\NormalTok{(PooledVar}\OperatorTok{/}\NormalTok{n_b)))}
\NormalTok{    p_test <-}\StringTok{  }\DecValTok{2}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\NormalTok{(}\KeywordTok{pt}\NormalTok{(}\KeywordTok{abs}\NormalTok{(t_test), dl_test)))     }
    \CommentTok{# Test Welch-Sattherwaite (variances inégales)}
\NormalTok{    t_welch <-}\StringTok{ }\NormalTok{(x_a}\OperatorTok{-}\NormalTok{x_b) }\OperatorTok{/}\StringTok{ }\KeywordTok{sqrt}\NormalTok{( (var_a}\OperatorTok{/}\NormalTok{n_a) }\OperatorTok{+}\StringTok{ }\NormalTok{(var_b}\OperatorTok{/}\NormalTok{n_b))}
\NormalTok{    dl_num =}\StringTok{ }\NormalTok{((var_a}\OperatorTok{/}\NormalTok{n_a) }\OperatorTok{+}\StringTok{ }\NormalTok{(var_b}\OperatorTok{/}\NormalTok{n_b))}\OperatorTok{^}\DecValTok{2}
\NormalTok{    dl_dem =}\StringTok{ }\NormalTok{((var_a}\OperatorTok{/}\NormalTok{n_a)}\OperatorTok{^}\DecValTok{2}\OperatorTok{/}\NormalTok{(n_a}\DecValTok{-1}\NormalTok{))  }\OperatorTok{+}\StringTok{ }\NormalTok{((var_b}\OperatorTok{/}\NormalTok{n_b)}\OperatorTok{^}\DecValTok{2}\OperatorTok{/}\NormalTok{(n_b}\DecValTok{-1}\NormalTok{))}
\NormalTok{    dl_welch =}\StringTok{ }\NormalTok{dl_num }\OperatorTok{/}\StringTok{ }\NormalTok{dl_dem }\CommentTok{# degrés de liberté}
\NormalTok{    p_welch <-}\StringTok{ }\DecValTok{2}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\NormalTok{(}\KeywordTok{pt}\NormalTok{(}\KeywordTok{abs}\NormalTok{(t_welch), dl_welch)))     }
    
    \KeywordTok{cat}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{ groupe A (n = "}\NormalTok{, n_a,}\StringTok{"), moy = "}\NormalTok{, }\KeywordTok{round}\NormalTok{(x_a,}\DecValTok{1}\NormalTok{),}\StringTok{", }
\StringTok{           variance = "}\NormalTok{, }\KeywordTok{round}\NormalTok{(var_a,}\DecValTok{1}\NormalTok{),}\StringTok{", écart-type = "}\NormalTok{, }\KeywordTok{round}\NormalTok{(sd_a,}\DecValTok{1}\NormalTok{),}
        \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{ groupe B (n = "}\NormalTok{, n_b,}\StringTok{"), moy = "}\NormalTok{, }\KeywordTok{round}\NormalTok{(x_b,}\DecValTok{1}\NormalTok{),}\StringTok{", }
\StringTok{          variance = "}\NormalTok{, }\KeywordTok{round}\NormalTok{(var_b,}\DecValTok{1}\NormalTok{),}\StringTok{", écart-type = "}\NormalTok{, }\KeywordTok{round}\NormalTok{(sd_b,}\DecValTok{1}\NormalTok{),}
        \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{ ratio variance = "}\NormalTok{,}\KeywordTok{round}\NormalTok{(ratio_v,}\DecValTok{2}\NormalTok{),}
        \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{ t-test (variances égales): t(dl = "}\NormalTok{, dl_test, }\StringTok{") = "}\NormalTok{,}\KeywordTok{round}\NormalTok{(t_test,}\DecValTok{4}\NormalTok{),}
         \StringTok{", p = "}\NormalTok{, }\KeywordTok{round}\NormalTok{(p_test,}\DecValTok{6}\NormalTok{),}
         \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{ t-Welch (variances inégales): t(dl = "}\NormalTok{, }\KeywordTok{round}\NormalTok{(dl_welch,}\DecValTok{3}\NormalTok{), }\StringTok{") = "}\NormalTok{,}
        \KeywordTok{round}\NormalTok{(t_welch,}\DecValTok{4}\NormalTok{), }\StringTok{", p = "}\NormalTok{, }\KeywordTok{round}\NormalTok{(p_welch,}\DecValTok{6}\NormalTok{),  }\DataTypeTok{sep=}\StringTok{""}\NormalTok{)    }
  
    \ControlFlowTok{if}\NormalTok{ (ratio_v }\OperatorTok{>}\StringTok{ }\FloatTok{0.5} \OperatorTok{&&}\StringTok{ }\NormalTok{ratio_v }\OperatorTok{<}\StringTok{ }\DecValTok{2}\NormalTok{)  \{}
      \KeywordTok{cat}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{ Variances similaires. Utilisez le test de Student !"}\NormalTok{)}
\NormalTok{      p <-}\StringTok{ }\NormalTok{p_test}
\NormalTok{    \} }\ControlFlowTok{else}\NormalTok{ \{}
      \KeywordTok{cat}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{ Variances dissemblables. Utilisez le test de Welch-Satterwaithe !"}\NormalTok{)}
\NormalTok{      p <-}\StringTok{ }\NormalTok{p_welch}
\NormalTok{    \}}
    
    \ControlFlowTok{if}\NormalTok{ (p }\OperatorTok{<=}\NormalTok{.}\DecValTok{05}\NormalTok{)\{}
      \KeywordTok{cat}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{ Les moyennes des deux groupes sont significativement différentes."}\NormalTok{)}
\NormalTok{    \} }\ControlFlowTok{else}\NormalTok{ \{}
      \KeywordTok{cat}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{ Les moyennes des deux groupes ne sont pas significativement différentes."}\NormalTok{)}
\NormalTok{    \}}
\NormalTok{\}}
\CommentTok{# CAS 1 : données fictives ------------------}
\CommentTok{# Création du groupe A : 60 observations avec une vitesse moyenne de 18 et un écart-type de 1,5}
\NormalTok{Velo1A <-}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{60}\NormalTok{,}\DecValTok{18}\NormalTok{,}\FloatTok{1.5}\NormalTok{)}
\CommentTok{# Création du groupe B : 50 observations avec une vitesse moyenne de 15 et un écart-type de 1,5}
\NormalTok{Velo1B <-}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{50}\NormalTok{,}\DecValTok{15}\NormalTok{,}\FloatTok{1.5}\NormalTok{)}
\NormalTok{df1 <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}
  \DataTypeTok{vitesse =} \KeywordTok{c}\NormalTok{(Velo1A,Velo1B), }
  \DataTypeTok{type =} \KeywordTok{c}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\StringTok{"Vélo personnel"}\NormalTok{,}\KeywordTok{length}\NormalTok{(Velo1A)), }\KeywordTok{rep}\NormalTok{(}\StringTok{"Vélo partage"}\NormalTok{,}\KeywordTok{length}\NormalTok{(Velo1B)))}
\NormalTok{)}
\NormalTok{boxplot1 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data=}\NormalTok{df1, }\DataTypeTok{mapping=}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{type,}\DataTypeTok{y=}\NormalTok{vitesse, }\DataTypeTok{colour=}\NormalTok{type)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_boxplot}\NormalTok{(}\DataTypeTok{width=}\FloatTok{0.2}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Données fictives (cas 1)"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{xlab}\NormalTok{(}\StringTok{"Type de vélo"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{ylab}\NormalTok{(}\StringTok{"Vitesse de déplacement (km/h)"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \StringTok{"none"}\NormalTok{)}
\CommentTok{# CAS 2 : données fictives ------------------}
\CommentTok{# Création du groupe A : 60 observations avec une vitesse moyenne de 18 et un écart-type de 3}
\NormalTok{Velo2A <-}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{60}\NormalTok{,}\DecValTok{16}\NormalTok{,}\DecValTok{3}\NormalTok{)}
\CommentTok{# Création du groupe B : 50 observations avec une vitesse moyenne de 15 et un écart-type de 1,5}
\NormalTok{Velo2B <-}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{50}\NormalTok{,}\DecValTok{15}\NormalTok{,}\FloatTok{1.5}\NormalTok{)}
\NormalTok{df2 <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}
  \DataTypeTok{vitesse =} \KeywordTok{c}\NormalTok{(Velo2A,Velo2B), }
  \DataTypeTok{type =} \KeywordTok{c}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\StringTok{"Vélo personnel"}\NormalTok{,}\KeywordTok{length}\NormalTok{(Velo2A)), }\KeywordTok{rep}\NormalTok{(}\StringTok{"Vélo partage"}\NormalTok{,}\KeywordTok{length}\NormalTok{(Velo2B)))}
\NormalTok{)}
\NormalTok{boxplot2 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data=}\NormalTok{df2, }\DataTypeTok{mapping=}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{type,}\DataTypeTok{y=}\NormalTok{vitesse, }\DataTypeTok{colour=}\NormalTok{type)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_boxplot}\NormalTok{(}\DataTypeTok{width=}\FloatTok{0.2}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Données fictives (cas 2)"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{xlab}\NormalTok{(}\StringTok{"Type de vélo"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{ylab}\NormalTok{(}\StringTok{"Vitesse de déplacement (km/h)"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \StringTok{"none"}\NormalTok{)}
\KeywordTok{ggarrange}\NormalTok{(boxplot1, boxplot2, }\DataTypeTok{ncol =} \DecValTok{2}\NormalTok{, }\DataTypeTok{nrow =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/figttest1-1} 

}

\caption{Boîtes à moustaches sur des échantillons fictifs non appariés}\label{fig:figttest1}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Appel de la fonction pour le cas 1}
\KeywordTok{tstudent_independants}\NormalTok{(Velo1A, Velo1B)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  groupe A (n = 60), moy = 18.1, 
##            variance = 2.7, écart-type = 1.7
##  groupe B (n = 50), moy = 14.7, 
##           variance = 2.5, écart-type = 1.6
##  ratio variance = 1.11
##  t-test (variances égales): t(dl = 108) = 10.7435, p = 0
##  t-Welch (variances inégales): t(dl = 106.155) = 10.7953, p = 0
##  Variances similaires. Utilisez le test de Student !
##  Les moyennes des deux groupes sont significativement différentes.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Appel de la fonction pour le cas 2}
\KeywordTok{tstudent_independants}\NormalTok{(Velo2A, Velo2B)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  groupe A (n = 60), moy = 16.5, 
##            variance = 8.4, écart-type = 2.9
##  groupe B (n = 50), moy = 15.3, 
##           variance = 2.1, écart-type = 1.4
##  ratio variance = 4.07
##  t-test (variances égales): t(dl = 108) = 2.5869, p = 0.011013
##  t-Welch (variances inégales): t(dl = 89.546) = 2.7348, p = 0.007524
##  Variances dissemblables. Utilisez le test de Welch-Satterwaithe !
##  Les moyennes des deux groupes sont significativement différentes.
\end{verbatim}

\hypertarget{sect04311}{%
\subsubsection{Principe de base et formulation pour des échantillons dépendants (appariés)}\label{sect04311}}

Nous disposons de plusieurs individus pour lesquelles nous avons mesuré un phénomène (variable continue) à deux temps différents : généralement avant et après une expérimentation (analyse pré-post). Il s'agit de vérifier si la moyenne des différences des observations avant et après la période est différente de 0. Pour ce faire, on réalise les étapes suivantes :

\begin{itemize}
\tightlist
\item
  On pose l'hypothèse nulle (H0), soit que la moyenne des différences entre les deux séries est égale à 0 (\(\bar{D} = 0\) avec \(d = {x}_{t_1}- {x}_{t_2}\)). L'hypothèse alternative (H1) est donc \(\bar{D} \ne 0\). Notez que l'on peut tester une autre valeur que 0.
\item
  On calcule la valeur de \emph{t} et le nombre de degrés de liberté. La valeur de \emph{t} sera négative quand la moyenne des différences entre \({X}_{t_1}\) et \({X}_{t_2}\) est négative et inversement.
\item
  On compare la valeur absolue de \emph{t} (\(\mid T \mid\)) avec celle issue de la table des valeurs critiques T avec le bon nombre de degrés de liberté et en choisissant un degré de signification (habituellement, p = 0,05). Si (\(\mid t \mid\)) est supérieure à la valeur \emph{t} critique, alors les moyennes sont statistiquement différentes au degré de signification retenu.
\end{itemize}

Pour le test de student avec des échantillons appariées, la valeur de \emph{t} se calcule comme suit :

\[t = \frac{\bar{D}-\mu_0}{\sigma_D / \sqrt{n}}\]
avec \(\bar{D}\) étant la moyenne des différences entre les observations appariées de la série A et de la série B, \(\sigma_D\) l'écart des différences, \emph{n} le nombre d'observations, et finalement \(\mu_0\) la valeur de l'hypothèse nulle que l'on veut tester (habituellement 0). Bien entendu, il est possible fixer une autre valeur pour \(\mu_0\) : par exemple, avec \(\mu_0 = 10\), on chercherait ainsi à vérifier si la moyenne des différences est significativement différente de 10. Le nombre de degrés de liberté sera égal à \(n-1\).

Dans la syntaxe ci-dessous, nous avons écrit une fonction dénommée \texttt{tstudent\_dependants} permettant de réaliser le test de student pour des échantillons appariés. Dans cette fonction, vous pourrez repérer comment sont calculés la différence entre les observations pairées, la moyenne et l'écart-type de cette différence, puis le nombre de degrés de liberté, les valeurs de \emph{t} et de \emph{p} pour les deux tests.

Pour illustrer l'utilisation de la fonction, nous avons créé aléatoirement deux jeux de données. Imaginons que ces données décrivent 50 personnes utilisant habituellement l'automobile pour se rendre au travail. Pour ces personnes, nous avons généré des valeurs du risque perçu de l'utilisation du vélo (de 0 à 100), et ce, avant et après une période de 20 jours ouvrables durant lesquels ils devaient impérativement se rendre au travail à vélo.

\begin{itemize}
\tightlist
\item
  Au cas 1, les valeurs de risque ont une moyenne de 70 avant l'expérimentation et de 50 après l'expérimentation, avec des écarts types de 5.
\item
  Au cas 2, les valeurs de risque ont une moyenne de 70 avant et 66 après, avec des écarts types de 5.
\end{itemize}

D'emblée, l'analyse visuelle des boîtes à moustaches (figure \ref{fig:figttest2}) pairées montrent que la perception du risque semble avoir nettement diminé après l'expérimentation pour le cas 1 mais pas pour le cas 2. Cela est confirmé par les résultats des tests.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"ggplot2"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"ggpubr"}\NormalTok{)}
\NormalTok{tstudent_dependants <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(A, B, }\DataTypeTok{mu=}\DecValTok{0}\NormalTok{)\{}
\NormalTok{  d <-}\StringTok{ }\NormalTok{A}\OperatorTok{-}\NormalTok{B           }\CommentTok{# différences entre les observations pairées}
\NormalTok{  moy <-}\StringTok{ }\KeywordTok{mean}\NormalTok{(d)     }\CommentTok{# Moyenne des différences}
\NormalTok{  e_t <-}\StringTok{ }\KeywordTok{sd}\NormalTok{(d)       }\CommentTok{# Écart-type des différences}
\NormalTok{  n   <-}\StringTok{ }\KeywordTok{length}\NormalTok{(A)   }\CommentTok{# nombre d'observations}
\NormalTok{  dl  <-}\StringTok{ }\NormalTok{n}\DecValTok{-1}         \CommentTok{# nombre de degrés de liberté (variances égales)}
  
\NormalTok{  t <-}\StringTok{ }\NormalTok{(moy}\OperatorTok{-}\StringTok{ }\NormalTok{mu) }\OperatorTok{/}\StringTok{ }\NormalTok{(e_t}\OperatorTok{/}\KeywordTok{sqrt}\NormalTok{(n)) }\CommentTok{# valeur de t}
\NormalTok{  p <-}\StringTok{  }\DecValTok{2}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\NormalTok{(}\KeywordTok{pt}\NormalTok{(}\KeywordTok{abs}\NormalTok{(t), dl)))}
  
  \KeywordTok{cat}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{ groupe A : moy = "}\NormalTok{, }\KeywordTok{round}\NormalTok{(}\KeywordTok{mean}\NormalTok{(A),}\DecValTok{1}\NormalTok{),}\StringTok{", var = "}\NormalTok{, }
         \KeywordTok{round}\NormalTok{(}\KeywordTok{var}\NormalTok{(A),}\DecValTok{1}\NormalTok{),}\StringTok{", sd = "}\NormalTok{, }\KeywordTok{round}\NormalTok{(}\KeywordTok{sqrt}\NormalTok{(}\KeywordTok{var}\NormalTok{(A)),}\DecValTok{1}\NormalTok{),}
      \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{ groupe B : moy = "}\NormalTok{, }\KeywordTok{round}\NormalTok{(}\KeywordTok{mean}\NormalTok{(B),}\DecValTok{1}\NormalTok{),}\StringTok{", var = "}\NormalTok{, }
         \KeywordTok{round}\NormalTok{(}\KeywordTok{var}\NormalTok{(B),}\DecValTok{1}\NormalTok{),}\StringTok{", sd = "}\NormalTok{, }\KeywordTok{round}\NormalTok{(}\KeywordTok{sqrt}\NormalTok{(}\KeywordTok{var}\NormalTok{(B)),}\DecValTok{1}\NormalTok{),}
      \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{ Moyenne des différences = "}\NormalTok{, }\KeywordTok{round}\NormalTok{(}\KeywordTok{mean}\NormalTok{(moy),}\DecValTok{1}\NormalTok{),}
      \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{ Ecart-type des différences = "}\NormalTok{, }\KeywordTok{round}\NormalTok{(}\KeywordTok{mean}\NormalTok{(e_t),}\DecValTok{1}\NormalTok{),}
      \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{ t(dl = "}\NormalTok{, dl, }\StringTok{") = "}\NormalTok{,}\KeywordTok{round}\NormalTok{(t,}\DecValTok{2}\NormalTok{),}
      \StringTok{", p = "}\NormalTok{, }\KeywordTok{round}\NormalTok{(p,}\DecValTok{3}\NormalTok{),  }\DataTypeTok{sep=}\StringTok{""}\NormalTok{)}
  
  \ControlFlowTok{if}\NormalTok{ (p }\OperatorTok{<=}\NormalTok{.}\DecValTok{05}\NormalTok{)\{}
    \KeywordTok{cat}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{ La moyenne des différences entre les échantillons est significative"}\NormalTok{)}
\NormalTok{  \}}
  \ControlFlowTok{else}\NormalTok{\{}
    \KeywordTok{cat}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{ La moyenne des différences entre les échantillons n'est pas significative"}\NormalTok{)}
\NormalTok{  \}}
\NormalTok{\}}
\CommentTok{# CAS 1 : données fictives ------------------}
\NormalTok{Avant1 <-}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{50}\NormalTok{,}\DecValTok{70}\NormalTok{,}\DecValTok{5}\NormalTok{)}
\NormalTok{Apres1 <-}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{50}\NormalTok{,}\DecValTok{50}\NormalTok{,}\DecValTok{5}\NormalTok{)}
\NormalTok{df1 <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{Avant=}\NormalTok{Avant1, }\DataTypeTok{Apres=}\NormalTok{Apres1)}
\NormalTok{boxplot1 <-}\StringTok{ }\KeywordTok{ggpaired}\NormalTok{(df1, }\DataTypeTok{cond1 =} \StringTok{"Avant"}\NormalTok{, }\DataTypeTok{cond2 =} \StringTok{"Apres"}\NormalTok{, }\DataTypeTok{fill =} \StringTok{"condition"}\NormalTok{, }
                     \DataTypeTok{palette =} \StringTok{"jco"}\NormalTok{, }\DataTypeTok{title =} \StringTok{"Données fictives (cas 1)"}\NormalTok{)}
\CommentTok{# CAS 2 : données fictives ------------------}
\NormalTok{Avant2 <-}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{50}\NormalTok{,}\DecValTok{70}\NormalTok{,}\DecValTok{5}\NormalTok{)}
\NormalTok{Apres2 <-}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{50}\NormalTok{,}\DecValTok{66}\NormalTok{,}\DecValTok{5}\NormalTok{)}
\NormalTok{df2 <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{Avant=}\NormalTok{Avant2, }\DataTypeTok{Apres=}\NormalTok{Apres2)}
\NormalTok{boxplot2 <-}\StringTok{ }\KeywordTok{ggpaired}\NormalTok{(df2, }\DataTypeTok{cond1 =} \StringTok{"Avant"}\NormalTok{, }\DataTypeTok{cond2 =} \StringTok{"Apres"}\NormalTok{, }\DataTypeTok{fill =} \StringTok{"condition"}\NormalTok{, }
                     \DataTypeTok{palette =} \StringTok{"jco"}\NormalTok{, }\DataTypeTok{title =} \StringTok{"Données fictives (cas 2)"}\NormalTok{)}
\KeywordTok{ggarrange}\NormalTok{(boxplot1, boxplot2, }\DataTypeTok{ncol =} \DecValTok{2}\NormalTok{, }\DataTypeTok{nrow =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/figttest2-1} 

}

\caption{Boites à moustaches sur des échantillons fictifs appariées}\label{fig:figttest2}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Test t : appel de la fonction tstudent_dependants}
\KeywordTok{tstudent_dependants}\NormalTok{(Avant1, Apres1, }\DataTypeTok{mu=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  groupe A : moy = 69.1, var = 19.7, sd = 4.4
##  groupe B : moy = 50, var = 30.9, sd = 5.6
##  Moyenne des différences = 19
##  Ecart-type des différences = 6.6
##  t(dl = 49) = 20.39, p = 0
##  La moyenne des différences entre les échantillons est significative
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tstudent_dependants}\NormalTok{(Avant2, Apres2, }\DataTypeTok{mu=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  groupe A : moy = 70.8, var = 25.1, sd = 5
##  groupe B : moy = 67, var = 23.5, sd = 4.8
##  Moyenne des différences = 3.8
##  Ecart-type des différences = 6.8
##  t(dl = 49) = 3.91, p = 0
##  La moyenne des différences entre les échantillons est significative
\end{verbatim}

\hypertarget{sect04312}{%
\subsubsection{Mesurer la taille de l'effet}\label{sect04312}}

Rappelons que la taille de l'effet permet d'évaluer la magnitude (force) de l'effet d'une variable (ici la variable qualitative à deux modalités) sur une autre (ici la variable continue). Dans le cas de comparaisons de moyennes (avec des échantillons pairées ou non), pour mesurer la taille d'effet, on utilise habituellement le \emph{d} de Cohen ou encore le \emph{g} de Hedges; le second étant un ajustement du premier. Notez que nous analyserons la taille de l'effet uniquement si le test student ou de Welch s'est révélé significatif (p\textless0,05).

\textbf{Pourquoi utiliser le \emph{d} de cohen?} Deux propriétés en font une mesure particulièrement intéressante. Premièrement, elle est facile à calculer puisque \emph{d} est le ratio entre la différence de deux moyennes de groupes (A, B) et l'écart-type combiné des deux groupes. Deuxièmement, \emph{d} représente ainsi une mesure standardisée de la taille de l'effet ; elle permet ainsi l'évaluation de la taille d'effet indépendamment de l'unité de mesure de la variable continue. Concrètement, cela signifie que quelle que soit l'unité de mesure de la variable continue \emph{X}, elle est toujours exprimée en unité d'écart-type de \emph{X}. Cette propriété facilite ainsi grandement les comparaisons entre des valeurs de \emph{d} calculées sur différentes combinaisons de variables (au même titre que le coefficient de variation ou le coefficient de corrélation par exemple). Pour des échantillons indépendants de tailles différentes, il s'écrit :

\[d = \frac{\bar{X}_{A}-\bar{X}_{B}}{\sqrt{\frac{(n_A-1)S^2_A+(n_B-1)S^2_B}{n_A+n_B-2}}}\]
avec \(n_A\),\(n_B\), \(S^2_{X_A}\) et \(S^2_{X_B}\) étant respectivement les nombres d'observations et les variances pour les groupes \emph{A} et \emph{B}, \(S^2_p\).

Si les échantillons sont de tailles identiques (\(n_A=n_B\)), alors \emph{d} peut s'écrire :
\[d = \frac{\bar{X}_{A}-\bar{X}_{B}}{\sqrt{(S^2_A+\S^2_A)/2}} = \frac{\bar{X}_{A}-\bar{X}_{B}}{(\sigma_A+\sigma_B)/2}\]
avec \(\sigma_A\) et \(\sigma_B\) étant les écart-types des deux groupes (rappel : l'écart-type est la racine carrée de la variance !).

Le \emph{g} de Hedge est simplement une correction de \emph{d}, particulièrement importante quand les échantillons sont de taille réduite.
\[g = d- \left(1- \frac{3}{4(n_A+n_B)-9} \right)\]

Moins utilisé en sciences sociales, mais surtout en études cliniques, le delta de Glass est simplement la différence des moyennes des groupes indépendants (numérateur) sur l'écar-type du deuxième groupe (démoninateur). Dans une étude clinique, on a habituellement un groupe qui subit un traitement (groupe de traitement) et un groupe qui a reçu un placebo (groupe de contrôle ou groupe témoin). L'effet de taille est ainsi évalué par rapport au groupe de contrôle :
\[\Delta = \frac{\bar{X}_{A}-\bar{X}_{B}}{\sigma_B}\]

Finalement, pour des échantillons dépendants (pairés), il s'écrit simplement \(d = \bar{D}/{\sigma_D}\) avec \(\bar{D}\) et \(\sigma_D\) étant la moyenne et l'écart-type des différences entre les observations.

\textbf{Commment interpréter le \emph{d} de cohen ?} Un effet sera considéré comme faible avec \(\lvert d \rvert\) à 0,2, modéré à 0,50 et fort à 0,80 \citep{cohen1992}. Notez que ces seuils ne sont que des conventions pour vous guider à interpréter la mesure de Cohen. D'ailleurs, dans son livre intitulé \emph{Statistical power analysis for the behavioral sciences}, il écrit : « all conventions are arbitrary. One can only demand of them that they not be unreasonable » \citep{cohen2013}. Plus récemment, \citep{sawilowsky2009} a ajouté d'autres seuils à ceux proposés par Cohen (tableau \ref{tab:tableconvcohen}).

\begin{table}

\caption{\label{tab:tableconvcohen}Conventions pour l’interprétation du d de Cohen}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{ll}
\toprule
Sawilowsky & Cohen\\
\midrule
0,1 : Très faible & \\
0,2 : Faible & 0,2 : Faible\\
0,5 : Moyen & 0,5 : Moyen\\
0,8 : Fort & 0,8 : Fort\\
1,2 : Très fort & \\
\addlinespace
2,0 : Énorme & \\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{sect04313}{%
\subsubsection{Mise en œuvre dans}\label{sect04313}}

Nous avons écrit précédemment les fonctions \texttt{tstudent\_independants} et \texttt{tstudent\_dependants} uniquement pour décomposer les différentes étapes de calcul des tests de Student et de Welch. Il existe des fonctions de base (\texttt{t.test} et \texttt{var.test}) qui permettent de réaliser l'un ou l'autre de ces deux tests avec une seule ligne de code.

La fonction \texttt{t.test} permet ainsi de calculer les test de Student et de Welch :

\begin{itemize}
\tightlist
\item
  \texttt{t.test(x\ \textasciitilde{}\ y,\ data=,\ mu\ =\ 0,\ paired\ =\ FALSE,\ var.equal\ =\ FALSE,\ \ conf.level\ =\ 0.95)} ou \texttt{t.test(x\ =,\ y\ =,\ mu\ =\ 0,\ paired\ =\ FALSE,\ var.equal\ =\ FALSE,\ \ conf.level\ =\ 0.95)}.
\item
  Le paramètre \texttt{paired} sera utilisé pour spécifier si les échantillons sont dépendants (\texttt{paired=TRUE}) ou indépendants (\texttt{paired=FALSE}).
\item
  Le paramètre \emph{var.equal} sera utilisé pour spécifier si les variances sont égales pour le test de Student (\texttt{var.equal=TRUE}) ou dissemblables pour le test de Welch (\texttt{var.equal=FALSE}).
\item
  \texttt{var.test(x,\ y)} ou \texttt{var.test(x\ \textasciitilde{}\ y,\ data=)} pour vérifier au préalable si les variances sont égales ou non et choisir ainsi un t de Student ou un t de Welch.
\end{itemize}

Les fonctions \texttt{cohens\_d} et \texttt{hedges\_g} du \emph{package} \textbf{effectsize} renvoient respectivement les mesures de \emph{d} de Cohen et du \emph{g} de Hedge :

\begin{itemize}
\item
  \texttt{cohens\_d(x\ \textasciitilde{}\ y,\ data\ =\ dataframe,\ paired\ =\ FALSE,\ pooled\_sd\ =\ TRUE)} ou \texttt{cohens\_d(x,\ y,\ data\ =\ dataframe,\ paired\ =\ FALSE,\ pooled\_sd\ =\ TRUE)} ou
\item
  \texttt{hedges\_g(x\ \textasciitilde{}\ y,\ data\ =\ dataframe,\ paired\ =\ FALSE,\ pooled\_sd\ =\ TRUE)} ou \texttt{hedges\_g(x,\ y,\ data\ =\ dataframe,\ paired\ =\ FALSE,\ pooled\_sd\ =\ TRUE)}
\item
  \texttt{glass\_delta(x\ \textasciitilde{}\ y,\ data\ =\ dataframe,\ paired\ =\ FALSE,\ pooled\_sd\ =\ TRUE)} ou \texttt{glass\_delta(x,\ y,\ data\ =\ dataframe,\ paired\ =\ FALSE,\ pooled\_sd\ =\ TRUE)}
\end{itemize}

Notez que pour toutes ces fonctions deux écritures sont possibles :

\begin{itemize}
\tightlist
\item
  \texttt{x\ \textasciitilde{}\ y,\ data=} avec un \texttt{dataframe} dans lequel \texttt{x} est une variable continue et \texttt{y} et un facteur binaire
\item
  \texttt{x,\ y} qui sont tous deux des vecteurs numériques (variable continue).
\end{itemize}

\textbf{Exemple de test pour des échantillons indépendants}

La figure \ref{fig:figlocataires} représente la cartographie du pourcentage de locataires par secteur de recensement (SR) pour la région métropolitaine de recensement de Montréal (RMR) en 2016, soit une variable continue. L'objectif est de vérifier si la moyenne de ce pourcentage des SR de l'agglomération de Montréal est significativement différente de celles de SR hors de l'agglomération.

Les résultats de la syntaxe ci-dessous signalent que le pourcentage de locataires par SR est bien supérieur dans l'agglomération (moyenne = 59,7\%; écart-type = 21,4\%) qu'en dehors de l'agglomération de Montréal (moyenne = 27,3\%; écart-type = 20,1\%); cette différence de 32,5 points de pourcentage est d'ailleurs significative et très forte (t = -23,95; p ˂ 0,001, d de Cohen = 1,54).

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{images/bivariee/FigureLocataires} 

}

\caption{Pourcentage de locataires par secteur de recensement, RMR de Montréal, 2016}\label{fig:figlocataires}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"foreign"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"effectsize"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"ggplot2"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"dplyr"}\NormalTok{)}
\CommentTok{# Importation du fichier}
\NormalTok{dfRMR <-}\StringTok{ }\KeywordTok{read.dbf}\NormalTok{(}\StringTok{"data/bivariee/SRRMRMTL2016.dbf"}\NormalTok{)}
\CommentTok{# Définition d'un facteur binaire                  }
\NormalTok{dfRMR}\OperatorTok{$}\NormalTok{Montreal <-}\StringTok{ }\KeywordTok{factor}\NormalTok{(dfRMR}\OperatorTok{$}\NormalTok{Montreal, }
                           \DataTypeTok{levels=}  \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{), }
                           \DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"Hors de Montréal"}\NormalTok{,}\StringTok{"Montréal"}\NormalTok{))}
\CommentTok{# Comparaison des moyennes ------------------------}
\CommentTok{#Boite à moustaches (boxplot)}
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ dfRMR, }\DataTypeTok{mapping=}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{Montreal,}\DataTypeTok{y=}\NormalTok{Locataire,}\DataTypeTok{colour=}\NormalTok{Montreal)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_boxplot}\NormalTok{(}\DataTypeTok{width=}\FloatTok{0.2}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position=}\StringTok{"none"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{xlab}\NormalTok{(}\StringTok{"Zone"}\NormalTok{)}\OperatorTok{+}\StringTok{ }\KeywordTok{ylab}\NormalTok{(}\StringTok{"Pourcentage de locataires"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Locataires par secteur de recensement"}\NormalTok{, }\DataTypeTok{subtitle=}\StringTok{"RMR de Montréal, 2016"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{livre_statistique_Phil_Jere_clean_files/figure-latex/unnamed-chunk-128-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# nombre d'observations, moyennes et écart-types pour les deux échantillons}
\KeywordTok{group_by}\NormalTok{(dfRMR, Montreal) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}
    \DataTypeTok{n =} \KeywordTok{n}\NormalTok{(),}
    \DataTypeTok{moy =} \KeywordTok{mean}\NormalTok{(Locataire, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{),}
    \DataTypeTok{ecarttype =} \KeywordTok{sd}\NormalTok{(Locataire, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 4
##   Montreal             n   moy ecarttype
##   <fct>            <int> <dbl>     <dbl>
## 1 Hors de Montréal   430  27.3      20.1
## 2 Montréal           521  59.7      21.4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# On vérifie si les variances sont égales avec la fonction var.test}
\CommentTok{# quand la valeur de P est inférieure à 0,05 alors les variances diffèrent}
\NormalTok{v <-}\StringTok{ }\KeywordTok{var.test}\NormalTok{(Locataire }\OperatorTok{~}\StringTok{ }\NormalTok{Montreal, }\DataTypeTok{alternative=}\StringTok{'two.sided'}\NormalTok{, }\DataTypeTok{conf.level=}\NormalTok{.}\DecValTok{95}\NormalTok{, }\DataTypeTok{data=}\NormalTok{dfRMR)}
\KeywordTok{print}\NormalTok{(v)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 	F test to compare two variances
## 
## data:  Locataire by Montreal
## F = 0.88156, num df = 429, denom df = 520, p-value = 0.1739
## alternative hypothesis: true ratio of variances is not equal to 1
## 95 percent confidence interval:
##  0.7361821 1.0573195
## sample estimates:
## ratio of variances 
##          0.8815563
\end{verbatim}

Le test indique que nous n'avons aucune raison de rejeter l'hypothèse nulle selon laquelle les variances sont égales. Pour l'île de Montréal, l'écart-type est de 21,4 et de 20,1 hors de l'île, soit une différence négligeable.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Calcul du T de Student ou du T de Welch}
\NormalTok{p <-}\StringTok{ }\NormalTok{v}\OperatorTok{$}\NormalTok{p.value}
\ControlFlowTok{if}\NormalTok{(p }\OperatorTok{>=}\StringTok{ }\FloatTok{0.05}\NormalTok{)\{}
  \KeywordTok{cat}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{ Les variances ne diffèrent pas !"}\NormalTok{,}
     \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{ On utilise le test de student avec l'option var.equal=TRUE"}\NormalTok{, }\DataTypeTok{sep=}\StringTok{""}\NormalTok{)}
    \KeywordTok{t.test}\NormalTok{(Locataire }\OperatorTok{~}\StringTok{ }\NormalTok{Montreal,  }\CommentTok{# variable continue ~ facteur binaire }
           \DataTypeTok{data=}\NormalTok{dfRMR,            }\CommentTok{# nom du dataframe}
           \DataTypeTok{conf.level=}\NormalTok{.}\DecValTok{95}\NormalTok{,        }\CommentTok{# intervalle de confiance pour la valeur de t}
           \DataTypeTok{paired =} \OtherTok{FALSE}\NormalTok{,        }\CommentTok{# échantillons non pairés (indépendants)}
           \DataTypeTok{var.equal=}\OtherTok{TRUE}\NormalTok{)        }\CommentTok{# variances égales}
\NormalTok{\} }\ControlFlowTok{else}\NormalTok{ \{}
  \KeywordTok{cat}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{ Les variances diffèrent !"}\NormalTok{,}
      \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{ On utilise le test de Welch avec l'option var.equal=FALSE"}\NormalTok{, }\DataTypeTok{sep=}\StringTok{""}\NormalTok{)}
  \KeywordTok{t.test}\NormalTok{(Locataire }\OperatorTok{~}\StringTok{ }\NormalTok{Montreal,   }\CommentTok{# variable continue ~ facteur binaire }
         \DataTypeTok{data=}\NormalTok{dfRMR,             }\CommentTok{# nom du dataframe}
         \DataTypeTok{conf.level=}\NormalTok{.}\DecValTok{95}\NormalTok{,         }\CommentTok{# intervalle de confiance pour la valeur de t}
         \DataTypeTok{paired =} \OtherTok{FALSE}\NormalTok{,         }\CommentTok{# échantillons non pairés (indépendants)}
         \DataTypeTok{var.equal=}\OtherTok{FALSE}\NormalTok{)        }\CommentTok{# variances différentes}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Les variances ne diffèrent pas !
##  On utilise le test de student avec l'option var.equal=TRUE
\end{verbatim}

\begin{verbatim}
## 
## 	Two Sample t-test
## 
## data:  Locataire by Montreal
## t = -23.95, df = 949, p-value < 2.2e-16
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -35.11182 -29.79341
## sample estimates:
## mean in group Hors de Montréal         mean in group Montréal 
##                       27.27340                       59.72601
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Effet de taille à analyser uniquement si le test est significatif}
\KeywordTok{cohens_d}\NormalTok{(Locataire }\OperatorTok{~}\StringTok{ }\NormalTok{Montreal, }\DataTypeTok{data =}\NormalTok{ dfRMR, }\DataTypeTok{paired =} \OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Cohen's d |         95% CI
## --------------------------
##     -1.56 | [-1.71, -1.41]
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{hedges_g}\NormalTok{(Locataire }\OperatorTok{~}\StringTok{ }\NormalTok{Montreal, }\DataTypeTok{data =}\NormalTok{ dfRMR, }\DataTypeTok{paired =} \OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Hedge's g |         95% CI
## --------------------------
##     -1.56 | [-1.70, -1.41]
\end{verbatim}

Notez que le \emph{d} de Cohen et le \emph{g} de Hedge sont très proches ici, rappelons que le second est une correction du premier pour des échantillons de taille réduite. Avec 951 observations, nous disposons d'un échantillon suffisamment grand pour que cette correction soit négligeable.

\textbf{Exemple de syntaxe pour un test de Student pour des échantillons dépendants}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"ggpubr"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"dplyr"}\NormalTok{)}
\NormalTok{Pre <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{79}\NormalTok{,}\DecValTok{71}\NormalTok{,}\DecValTok{81}\NormalTok{,}\DecValTok{83}\NormalTok{,}\DecValTok{77}\NormalTok{,}\DecValTok{74}\NormalTok{,}\DecValTok{76}\NormalTok{,}\DecValTok{74}\NormalTok{,}\DecValTok{79}\NormalTok{,}\DecValTok{70}\NormalTok{,}\DecValTok{66}\NormalTok{,}\DecValTok{85}\NormalTok{,}\DecValTok{69}\NormalTok{,}\DecValTok{69}\NormalTok{,}\DecValTok{82}\NormalTok{,}\DecValTok{69}\NormalTok{,}\DecValTok{81}\NormalTok{,}\DecValTok{70}\NormalTok{,}\DecValTok{83}\NormalTok{,}\DecValTok{68}\NormalTok{,}\DecValTok{77}\NormalTok{,}\DecValTok{76}\NormalTok{,}\DecValTok{77}\NormalTok{,}\DecValTok{70}\NormalTok{,}\DecValTok{68}\NormalTok{,}\DecValTok{80}\NormalTok{,}\DecValTok{65}\NormalTok{,}\DecValTok{65}\NormalTok{,}\DecValTok{75}\NormalTok{,}\DecValTok{84}\NormalTok{)}
\NormalTok{Post <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{56}\NormalTok{,}\DecValTok{47}\NormalTok{,}\DecValTok{40}\NormalTok{,}\DecValTok{45}\NormalTok{,}\DecValTok{49}\NormalTok{,}\DecValTok{51}\NormalTok{,}\DecValTok{54}\NormalTok{,}\DecValTok{47}\NormalTok{,}\DecValTok{44}\NormalTok{,}\DecValTok{54}\NormalTok{,}\DecValTok{42}\NormalTok{,}\DecValTok{56}\NormalTok{,}\DecValTok{45}\NormalTok{,}\DecValTok{45}\NormalTok{,}\DecValTok{48}\NormalTok{,}\DecValTok{55}\NormalTok{,}\DecValTok{59}\NormalTok{,}\DecValTok{58}\NormalTok{,}\DecValTok{56}\NormalTok{,}\DecValTok{41}\NormalTok{,}\DecValTok{56}\NormalTok{,}\DecValTok{51}\NormalTok{,}\DecValTok{45}\NormalTok{,}\DecValTok{55}\NormalTok{,}\DecValTok{49}\NormalTok{,}\DecValTok{49}\NormalTok{,}\DecValTok{48}\NormalTok{,}\DecValTok{43}\NormalTok{,}\DecValTok{60}\NormalTok{,}\DecValTok{50}\NormalTok{)}
\CommentTok{# Première façon de faire un tableau : avec deux colonnes Avant et Après}
\NormalTok{df1 <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{Avant=}\NormalTok{Pre, }\DataTypeTok{Apres=}\NormalTok{Post)}
\KeywordTok{head}\NormalTok{(df1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   Avant Apres
## 1    79    56
## 2    71    47
## 3    81    40
## 4    83    45
## 5    77    49
## 6    74    51
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggpaired}\NormalTok{(df1, }\DataTypeTok{cond1 =} \StringTok{"Avant"}\NormalTok{, }\DataTypeTok{cond2 =} \StringTok{"Apres"}\NormalTok{, }\DataTypeTok{fill =} \StringTok{"condition"}\NormalTok{, }\DataTypeTok{palette =} \StringTok{"jco"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{livre_statistique_Phil_Jere_clean_files/figure-latex/unnamed-chunk-130-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Nombre d'observations, moyennes et écart-types}
\KeywordTok{cat}\NormalTok{(}\KeywordTok{nrow}\NormalTok{(df1), }\StringTok{" observations"}\NormalTok{,}
    \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{POST. moy = "}\NormalTok{, }\KeywordTok{round}\NormalTok{(}\KeywordTok{mean}\NormalTok{(df1}\OperatorTok{$}\NormalTok{Avant),}\DecValTok{1}\NormalTok{), }\StringTok{", e.t. = "}\NormalTok{, }\KeywordTok{round}\NormalTok{(}\KeywordTok{sd}\NormalTok{(df1}\OperatorTok{$}\NormalTok{Avant),}\DecValTok{1}\NormalTok{),}
    \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{PRE.  moy = "}\NormalTok{, }\KeywordTok{round}\NormalTok{(}\KeywordTok{mean}\NormalTok{(df1}\OperatorTok{$}\NormalTok{Apres),}\DecValTok{1}\NormalTok{), }\StringTok{", e.t. = "}\NormalTok{, }\KeywordTok{round}\NormalTok{(}\KeywordTok{sd}\NormalTok{(df1}\OperatorTok{$}\NormalTok{Apres),}\DecValTok{1}\NormalTok{), }\DataTypeTok{sep=}\StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 30 observations
## POST. moy = 74.8, e.t. = 6.1
## PRE.  moy = 49.9, e.t. = 5.7
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{t.test}\NormalTok{(Pre, Post, }\DataTypeTok{paired =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 	Paired t-test
## 
## data:  Pre and Post
## t = 18.701, df = 29, p-value < 2.2e-16
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  22.11740 27.54926
## sample estimates:
## mean of the differences 
##                24.83333
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Deuxième façon de faire un tableau : avec une colonne pour la variable continue et une autre pour la variable qualitative}
\NormalTok{n <-}\StringTok{ }\KeywordTok{length}\NormalTok{(Pre)}\OperatorTok{*}\DecValTok{2}
\NormalTok{df2 <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}
       \DataTypeTok{id=}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{n),}
       \DataTypeTok{participant=}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\KeywordTok{length}\NormalTok{(Pre)),}
       \DataTypeTok{risque=}\KeywordTok{c}\NormalTok{(Pre,Post)}
\NormalTok{       )}
\NormalTok{df2}\OperatorTok{$}\NormalTok{periode <-}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(df2}\OperatorTok{$}\NormalTok{id }\OperatorTok{<=}\StringTok{ }\KeywordTok{length}\NormalTok{(Pre), }\StringTok{"Pré"}\NormalTok{, }\StringTok{"Post"}\NormalTok{)}
\KeywordTok{head}\NormalTok{(df2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   id participant risque periode
## 1  1           1     79     Pré
## 2  2           2     71     Pré
## 3  3           3     81     Pré
## 4  4           4     83     Pré
## 5  5           5     77     Pré
## 6  6           6     74     Pré
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# nombre d'observations, moyennes et écart-types pour les deux échantillons}
\KeywordTok{group_by}\NormalTok{(df2, periode) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}
    \DataTypeTok{n =} \KeywordTok{n}\NormalTok{(),}
    \DataTypeTok{moy =} \KeywordTok{mean}\NormalTok{(risque, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{),}
    \DataTypeTok{et =} \KeywordTok{sd}\NormalTok{(risque, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 4
##   periode     n   moy    et
##   <chr>   <int> <dbl> <dbl>
## 1 Post       30  49.9  5.67
## 2 Pré        30  74.8  6.10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggpaired}\NormalTok{(}\DataTypeTok{data=}\NormalTok{df2, }\DataTypeTok{x=} \StringTok{"periode"}\NormalTok{, }\DataTypeTok{y=}\StringTok{"risque"}\NormalTok{, }\DataTypeTok{fill =} \StringTok{"periode"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{livre_statistique_Phil_Jere_clean_files/figure-latex/unnamed-chunk-130-2.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{t.test}\NormalTok{(risque }\OperatorTok{~}\StringTok{ }\NormalTok{periode, }\DataTypeTok{data=}\NormalTok{df2, }\DataTypeTok{paired =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 	Paired t-test
## 
## data:  risque by periode
## t = -18.701, df = 29, p-value < 2.2e-16
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -27.54926 -22.11740
## sample estimates:
## mean of the differences 
##               -24.83333
\end{verbatim}

\hypertarget{sect04314}{%
\subsubsection{Comparer des moyennes pondérées}\label{sect04314}}

\begin{bloc_objectif}

En études urbaines et en géographie, le recours aux données agrégées (non individuelles) est fréquent, par exemple au niveau des secteurs de recensement (comprenant généralement entre 2500 à 8000 habitants). Dans ce contexte, un secteur de recensement plus peuplé devrait avoir un poids plus important dans l'analyse. Il est possible d'utiliser les versions pondérées des tests présentés précédemment. Prenons deux exemples pour illustrer le tout :

\begin{itemize}
\item
  Pour chaque secteur de recensement des îles de Montréal et de Laval, nous avons calculé la distance au parc le plus proche à travers le réseau de rues avec un Système d'Information Géographique (SIG). On souhaite vérifier si les enfants âgés de moins de 15 ans résidant sur l'île de Montréal bénéficient en moyenne d'une meilleure accessibilité au parc.
\item
  Dans une étude pour sur la concentration de polluants atmosphérique dans l'environnement autour des écoles primaires montréalaises, Carrier \emph{et al.} \citeyearpar{carrier2014} souhaitaient vérifier si les élèves fréquentant les écoles les plus défavorisés sont plus exposés au dioxyde d'azote (NO2) dans leur milieu scolaire. Pour ce faire, ils ont réalisé un test \emph{t} sur un tableau avec comme observations les écoles primaires et trois variables : la moyenne NO2 (variable continue), les quintiles extrêmes d'un indice de défavorisation (premier et dernier quintiles, variable qualitative) et le nombres d'élèves inscrits par école (variable pour la pondération).
\end{itemize}

Pour réaliser un test \emph{t} pondéré, nous pouvons utiliser la fonction \texttt{weighted\_ttest} du package \textbf{sjstats}.

\end{bloc_objectif}

En guise d'exemple appliqué, dans la syntaxe ci-dessous, nous avons refait le même test \emph{t} que précédemment (\texttt{Locataire\ \textasciitilde{}\ Montreal}) en pondérant chaque secteur de recensement par le nombre de logements qu'il comprend.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"sjstats"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"dplyr"}\NormalTok{)}
\CommentTok{# Calcul des statistiques pondérées}
\KeywordTok{group_by}\NormalTok{(dfRMR, Montreal) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}
    \DataTypeTok{n =} \KeywordTok{sum}\NormalTok{(Logement),}
    \DataTypeTok{MoyPond =} \KeywordTok{weighted_mean}\NormalTok{(Locataire, Logement),}
    \DataTypeTok{ecarttypePond =} \KeywordTok{weighted_sd}\NormalTok{(Locataire, Logement)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 4
##   Montreal              n MoyPond ecarttypePond
##   <fct>             <int>   <dbl>         <dbl>
## 1 Hors de Montréal 856928    28.4          19.9
## 2 Montréal         870354    60.0          20.8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Test t non pondéré}
\KeywordTok{t.test}\NormalTok{(Locataire }\OperatorTok{~}\StringTok{ }\NormalTok{Montreal, dfRMR, }
               \DataTypeTok{paired =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{var.equal =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{conf.level=}\NormalTok{.}\DecValTok{95}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 	Two Sample t-test
## 
## data:  Locataire by Montreal
## t = -23.95, df = 949, p-value < 2.2e-16
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -35.11182 -29.79341
## sample estimates:
## mean in group Hors de Montréal         mean in group Montréal 
##                       27.27340                       59.72601
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Test t pondérée}
\KeywordTok{weighted_ttest}\NormalTok{(Locataire }\OperatorTok{~}\StringTok{ }\NormalTok{Montreal }\OperatorTok{+}\StringTok{ }\NormalTok{Logement, dfRMR, }
               \DataTypeTok{paired =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{ci.lvl=}\NormalTok{.}\DecValTok{95}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Two-Sample t-test (two.sided)
## 
## # comparison of Locataire by Montreal
## # t=-23.91  df=928  p-value=0.000
## 
##   mean in group Hors de Montréal: 28.396
##   mean in group Montréal        : 60.003
##   difference of mean            : -31.608 [-34.202  -29.013]
\end{verbatim}

\hypertarget{sect04315}{%
\subsubsection{Comment rapporter un test de student ou de Welch?}\label{sect04315}}

Pour les différentes versions du test, il est important de rapporter la valeur de \emph{t}, la valeur de \emph{p} et les moyennes des groupes. Voici quelques exemples :

\textbf{Test de Student ou de Welch pour échantillons indépendants}

\begin{itemize}
\tightlist
\item
  Dans la région métropolitaine de Montréal en 2005, le revenu total des femmes (moyenne = 29117 dollars; écart-type = 258022) est bien inférieur à celui des homme (moyenne = 44463; écart-type = 588081). La différence entre les moyennes des deux sexes (-15345) en faveur des hommes est d'ailleurs significative (t = -27,09; \emph{p} ˂ 0,001).
\item
  Il y un effet significatif selon le sexe (t = -27,09; \emph{p} ˂ 0,001), le revenu total des hommes (moyenne= 44463; écart-type = 588081) étant bien supérieur à celui des femmes (moyenne = 29 117; écart-type = 258 022).
\item
  50 personnes se rendrent au travail à vélo (moyenne = 33,7, écart-type = 8,5) contre 60 en automobile (moyenne = 34, écart-type = 8,7); il n'y a pas de différence significative entre les moyennes d'âge des deux groupes (t(108) = -0,79, \emph{p} = 0,427).
\end{itemize}

\textbf{Test de Student échantillons dépendants (pairés)}

\begin{itemize}
\tightlist
\item
  On constaste une diminution significative de la perception du risque après l'activité (moyenne = 49,9, écart-type = 5,7) comparativement à avant (moyenne = 74,8, écart-type = 6,1), avec une différence de -24,8 (t(29) = -18,7, \emph{p} \textless{} 0,001).
\item
  Les résultats du pré-test (moyenne = 49,9, écart-type = 5,7) et du post-test (moyenne = 74,8, écart-type = 6,1) montrent qu'il y une diminution significative de la perception du risque (t(29) = -18,7, \emph{p} \textless{} 0,001).
\end{itemize}

Pour un texte en anglais, vous pourrez consulter
\url{https://www.socscistatistics.com/tutorials/ttest/default.aspx}.

\hypertarget{sect0432}{%
\subsection{Test non paramétrique de Wilcoxon}\label{sect0432}}

\begin{bloc_objectif}

Si la variable continue est fortement anormalement distribuée, il est déconseillé d'utiliser les tests de Student et de Welch. On privilégiera le test des rangs signés de Wilcoxon (\emph{Wilcoxon rank-sum test} en anglais). Attention, il est aussi appelé test U de Mann-Whitney. Ce test permet alors de vérifier si les deux groupes présentent des médianes différentes.

Pour ce faire, on utilise la fonction \texttt{wilcox.test} dans laquelle le paramètre \texttt{paired} permettra de spécifier si les échantillons sont indépendants ou non (\texttt{FALSE} ou \texttt{TRUE}).

\end{bloc_objectif}

Dans l'exemple suivant, nous analysons le pourcentage de locataires dans les secteurs de recensements de la région métropolitaine de Montréal. Plus spécifiquement, nous comparons ce pourcentage entre les secteurs présents sur l'île et les secteurs hors de l'île. Il s'agit donc d'un test avec des échantillons indépendants.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"foreign"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"dplyr"}\NormalTok{)}
\CommentTok{###############################}
\CommentTok{# Échantillons indépendants}
\CommentTok{###############################}
\NormalTok{dfRMR <-}\StringTok{ }\KeywordTok{read.dbf}\NormalTok{(}\StringTok{"data/bivariee/SRRMRMTL2016.dbf"}\NormalTok{)}
\CommentTok{# Définition d'un facteur binaire                  }
\NormalTok{dfRMR}\OperatorTok{$}\NormalTok{Montreal <-}\StringTok{ }\KeywordTok{factor}\NormalTok{(dfRMR}\OperatorTok{$}\NormalTok{Montreal, }
                           \DataTypeTok{levels=}  \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{), }
                           \DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"Hors de Montréal"}\NormalTok{,}\StringTok{"Montréal"}\NormalTok{))}
\CommentTok{# Calul du nombre d'observations, moyennes et écart-types des rangs pour les deux échantillons}
\KeywordTok{group_by}\NormalTok{(dfRMR, Montreal) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}
    \DataTypeTok{n =} \KeywordTok{n}\NormalTok{(),}
    \DataTypeTok{moy_rang =} \KeywordTok{mean}\NormalTok{(}\KeywordTok{rank}\NormalTok{(Locataire), }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{),}
    \DataTypeTok{med_rang =} \KeywordTok{median}\NormalTok{(}\KeywordTok{rank}\NormalTok{(Locataire), }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{),}
    \DataTypeTok{ecarttype_rang =} \KeywordTok{sd}\NormalTok{(}\KeywordTok{rank}\NormalTok{(Locataire), }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 5
##   Montreal             n moy_rang med_rang ecarttype_rang
##   <fct>            <int>    <dbl>    <dbl>          <dbl>
## 1 Hors de Montréal   430     216.     216.           124.
## 2 Montréal           521     261      261            151.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Test des rangs signés de Wilcoxon sur des échantillons indépendants}
\KeywordTok{wilcox.test}\NormalTok{(Locataire }\OperatorTok{~}\StringTok{ }\NormalTok{Montreal, dfRMR, }\DataTypeTok{paired =} \OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 	Wilcoxon rank sum test with continuity correction
## 
## data:  Locataire by Montreal
## W = 33716, p-value < 2.2e-16
## alternative hypothesis: true location shift is not equal to 0
\end{verbatim}

Nous observons bien ici une différence significative entre le pourcentage de locataires des secteurs de recensement sur l'île (rang médian = 216) et hors de l'île (rang médian = 261).

Pour le second exemple, nous générons deux jeux de données au hasard représentant une mesure d'une variable pré-traitement (\emph{pre}) et post-traitement (\emph{post}) pour un même échantillon.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{###############################}
\CommentTok{# Échantillons dépendants}
\CommentTok{###############################}
\NormalTok{pre <-}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\DecValTok{60}\OperatorTok{:}\DecValTok{80}\NormalTok{, }\DecValTok{50}\NormalTok{, }\DataTypeTok{replace=}\NormalTok{T)}
\NormalTok{post <-}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\DecValTok{30}\OperatorTok{:}\DecValTok{65}\NormalTok{, }\DecValTok{50}\NormalTok{, }\DataTypeTok{replace=}\NormalTok{T)}
\NormalTok{df1 <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{Avant=}\NormalTok{pre, }\DataTypeTok{Apres=}\NormalTok{post)}
\CommentTok{# Nombre d'observations, moyennes et écart-types}
\KeywordTok{cat}\NormalTok{(}\KeywordTok{nrow}\NormalTok{(df1), }\StringTok{" observations"}\NormalTok{,}
    \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{POST. median = "}\NormalTok{, }\KeywordTok{round}\NormalTok{(}\KeywordTok{median}\NormalTok{(df1}\OperatorTok{$}\NormalTok{Avant),}\DecValTok{1}\NormalTok{), }
             \StringTok{", moy = "}\NormalTok{, }\KeywordTok{round}\NormalTok{(}\KeywordTok{mean}\NormalTok{(df1}\OperatorTok{$}\NormalTok{Avant),}\DecValTok{1}\NormalTok{),}
    \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{PRE.  median = "}\NormalTok{, }\KeywordTok{round}\NormalTok{(}\KeywordTok{median}\NormalTok{(df1}\OperatorTok{$}\NormalTok{Apres),}\DecValTok{1}\NormalTok{), }
             \StringTok{", moy = "}\NormalTok{, }\KeywordTok{round}\NormalTok{(}\KeywordTok{mean}\NormalTok{(df1}\OperatorTok{$}\NormalTok{Apres),}\DecValTok{1}\NormalTok{), }\DataTypeTok{sep=}\StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 50 observations
## POST. median = 69.5, moy = 69.3
## PRE.  median = 50.5, moy = 49.2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{wilcox.test}\NormalTok{(df1}\OperatorTok{$}\NormalTok{Avant, df1}\OperatorTok{$}\NormalTok{Apres, }\DataTypeTok{paired =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 	Wilcoxon signed rank test with continuity correction
## 
## data:  df1$Avant and df1$Apres
## V = 1225, p-value = 1.133e-09
## alternative hypothesis: true location shift is not equal to 0
\end{verbatim}

À nouveau, nous obtenons une différence significative entre les deux variables.

\textbf{Comment rapporter un test de Wilcoxon?}

Lorsque l'on rapporte les résultats d'un test de Wilcoxon, il est important de signaler la valeur du test (W), le degré de signification (valeur de p) et éventuellement la médiane des rangs ou de la variable originale pour les deux groupes. Voici quelques exemples :

\begin{itemize}
\tightlist
\item
  Les résultats du test des rangs signés de Wilcoxon signalent que les rangs de l'île de Montréal sont significativement plus élevés que ceux de l'île de Laval (W = 1223, p ˂ 0,001).
\item
  Les résultats du test de Wilcoxon signalent que les rangs post-tests sont significativement plus faibles que ceux pré-test (W = 1273,5, p ˂ 0,001).
\item
  Les résultats du test de Wilcoxon signalent que la médiane des rangs pré-tests (médiane = 69) est significativement plus forte que celle du post-test (médiane = 50,5) (W = 1273,5, p ˂ 0,001).
\end{itemize}

\hypertarget{sect044}{%
\section{Relation entre une variable quantitative et une variable qualitative à plus de deux modalités}\label{sect044}}

\begin{bloc_objectif}

\textbf{Existe-il une relation entre une variable continue et une variable qualitative comprenant plus de deux modalités?} Pour répondre à cette question, on pourra recourir à deux méthodes : l'analyse de variance -- \textbf{ANOVA}, \emph{\textbf{AN}alysis Of \textbf{VA}riance} en anglais -- et le test non paramétrique de Kruskal-Wallis. La première permet de vérifier si les moyennes de plusieurs groupes d'une population donnée sont ou non significativement différentes; la seconde si leurs médianes sont différentes.

\end{bloc_objectif}

\hypertarget{sect0441}{%
\subsection{Analyse de variance}\label{sect0441}}

L'analyse de variance (ANOVA) est largement utilisée en psychologie, médecine et pharmacologie. Prenons un exemple classique en pharmacologie pour tester l'efficacité d'un médicament. Quatre groupes de population sont constitués :

\begin{itemize}
\tightlist
\item
  un premier groupe d'individus pour lequel on administre un placebo (un médicament sans substance active), soit le groupe de contrôle ou le groupe témoin;
\item
  un second groupe auquel l'on administre le médicament avec un faible dosage;
\item
  un troisième avec un dosage moyen;
\item
  un quatrième avec un dosage élevé.
\end{itemize}

La variable continue permettra d'évaluer l'évolution de l'état de santé des individus (par exemple, la variation du taux de globules rouges dans le sang avant et après le traitement). Si le traitement est efficace, on s'attendrait alors à ce que les moyennes des deuxième, troisième et quatrième groupes soient plus élevées que celle du groupe de contrôle. Les différences de moyennes entre les second, troisième et quatrième groupes permettront aussi de repérer quel dosage est le plus efficace. Si nous n'observons aucune différence significative entre les groupes, cela signifie que l'effet du médicamment ne diffère pas de l'effet d'un placébo.

L'ANOVA est aussi très utilisée en études urbaines, principalement pour vérifier si un phénomène urbain varie selon plusieurs groupes d'une population donnée ou régions géographiques. En guise d'exemple, le recours à l'ANOVA permettrait de répondre aux questions suivantes :

\begin{itemize}
\item
  les moyennes des niveaux d'exposition à un polluant atmosphérique (variable continue) varient-elles significativement selon le mode de transport utilisé (automobile, vélo, transport en commun) pour des trajets similaires en heures de pointe?
\item
  pour une métropole donnée, les moyennes des loyers (variable continue) sont-elles différentes entre les logements de la ville centre versus ceux localisés dans la première couronne et ceux de la seconde couronnes?
\end{itemize}

\hypertarget{sect04411}{%
\subsubsection{Le calcul des trois variances pour l'ANOVA}\label{sect04411}}

L'ANOVA repose sur le calcul de trois variances :

\begin{itemize}
\item
  \textbf{la variance totale} (\emph{VT}) de la variable dépendante continue, soit la somme des carrés des écarts à la moyenne de l'ensemble de la population (équation \eqref{eq:anova1});
\item
  la \textbf{variance intergroupe} (\emph{Var\textsubscript{inter}}) ou variance expliquée (\emph{VE}), soit la somme des carrés des écarts entre la moyenne de chaque groupe et la moyenne de l'ensemble du jeu de données multipliées par le nombre d'individus appartenant à chacun des groupes (équation \eqref{eq:anova2});
\item
  la \textbf{variance intragroupe} (\emph{Var\textsubscript{intra}}) ou variance non expliquée (\emph{VNE}), soit la somme des variances des groupes de la variable indépendante (équation \eqref{eq:anova3}).
\end{itemize}

\begin{equation} 
VT=\sum_{i=1}^n (y_{i}-\overline{y})^2
\label{eq:anova1}
\end{equation}

\begin{equation} 
Var_{inter} \mbox{ ou } VE=\sum_{i\in{g_1}}(\overline{y_{g_1}}-\overline{y})^2 + \sum_{i\in{g_2}}(\overline{y_{g_2}}-\overline{y})^2 + ... + \sum_{i\in{g_n}}(\overline{y_{g_k}}-\overline{y})^2
\label{eq:anova2}
\end{equation}

\begin{equation} 
Var_{intra} \mbox{ ou } VNE=\sum_{i\in{g_1}}(y_{i}-\overline{y_{g_1}})^2 + \sum_{i\in{g_2}}(y_{i}-\overline{y_{g_2}})^2 + ... + \sum_{i\in{g_n}}(y_{i}-\overline{y_{g_k}})^2 
\label{eq:anova3}
\end{equation}

avec \(\overline{y}\) est la moyenne de l'ensemble de la population; \(\overline{y_{g_1}}\), \(\overline{y_{g_1}}\), \(\overline{y_{g_k}}\) sont respectivements les moyennes des groupes 1 à \emph{k} (\emph{k} étant le nombre de modalités de la variables qualitative) .

La variance totale (\emph{VT}) est égale à la somme de la variance intergroupe (expliquée) et la variance intragroupe (non expliquée) (équation \eqref{eq:anova5}). Le ratio entre la variance intergroupe (expliquée) et la variance totale est dénommé \emph{Eta\textsuperscript{2}} (équation \eqref{eq:anova6}). Il varie de 0 à 1 et exprime la proportion de la variance de la variable continue qui est expliquée par les différentes modalités de la variable qualitative.

\begin{equation} 
VT = Var_{inter} + Var_{intra} \mbox{ ou } VT = VNE + VE
\label{eq:anova5}
\end{equation}

\begin{equation} 
\eta^2= \frac{Var_{inter}}{VT} \mbox{ ou }  \eta^2= \frac{VE}{VT}
\label{eq:anova6}
\end{equation}

\begin{bloc_astuce}

\textbf{La décomposition de la variance totale} -- égale à la somme des variances intragroupe et intergroupe -- est fondamentale en statistique. Nous verrons qu'elle est aussi utilisée pour évaluer la qualité d'une partition d'une population dans le chapitre sur les méthodes de classification (chapitre \ref{chap10}). En ANOVA, on retiendra que :

\begin{itemize}
\tightlist
\item
  plus la variance intragroupe est faible, plus les différents groupes sont homogènes;
\item
  plus la variance intergroupe est forte, plus les moyennes des groupes sont différentes et donc plus les groupes sont dissembables.
\end{itemize}

Autrement dit, plus la variance intergroupe (\textbf{dissimilarité} des groupes) est maximisée et corollairement plus la variance intragroupe (\textbf{homogénéité} de chacun des groupes) est minimisée, plus les groupes sont clairement distincts et plus l'ANOVA sera performante.

\end{bloc_astuce}

Examinons un premier jeu de données fictif sur la vitesse de déplacements de cyclistes (variable continue exprimée en km/h) et une variable qualitative comprenant trois groupes de cyclistes utilisant soit un vélo personnel (\emph{n\textsubscript{A}} = 5), soit en libre service (\emph{n\textsubscript{B}} = 7), soit électrique (\emph{n\textsubscript{C}} = 6) (tableau \ref{tab:aovfictive1}). D'emblée, on note que les moyennes de vitesse des trois groupes sont différentes : 17,6 km/h pour les cyclistes avec leur vélo personnel, 12,3 km/h les utilisateurs des vélos en libre service et 23,1 km/h pour les cyclistes avec un vélo électrique.

Pour chaque observation, la troisième colonne du tableau représente les écarts à la moyenne globale mis au carré, tandis que les colonnes suivantes représentent la déviation au carré de chaque observation à la moyenne de son groupe d'appartenance. Ainsi, pour la première observation, on a : \((16,900 - 17,339)^2 = 0,193\) et \((16,900 - 17,580)^2~ = 0,46\). La variance totale (\emph{VT}) est donc égale à la somme de la troisième colonne (424,663), tandis que la variance intragroupe (non expliquée, VNE) est égale à \(11,228+21,537+13,993=46,758\). Quant à la variance intergroupe (expliquée, VE), elle est égale à \(5\times(17,580-17,339)^2+7\times(12,257-17,339)^2+6\times(23,067-17,339)^2 = 377,904\).

On a donc \(VT = Var_{inter} + Var_{intra}\), soit \(424,663 = 377,904 + 46,758\) et \(\eta_2 = 377,904 / 424,663 = 0,89\). Cela signale que 89\% de la variance de la vitesse des cyclistes est expliquée par le type de vélo utilisé.

\begin{table}

\caption{\label{tab:aovfictive1}Données fictives et calcul des trois variances (cas 1)}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{lrrrrr}
\toprule
Type de vélo & km/h & \$(y\_\{i\}-\textbackslash{}overline\{y\})\textasciicircum{}2\$ & \$(y\_\{i\}-\textbackslash{}overline\{y\_\{A\}\})\textasciicircum{}2\$ & \$(y\_\{i\}-\textbackslash{}overline\{y\_\{B\}\})\textasciicircum{}2\$ & \$(y\_\{i\}-\textbackslash{}overline\{y\_\{C\}\})\textasciicircum{}2\$\\
\midrule
A. personnel & 16,900 & 0,193 & 0,462 & -- & --\\
A. personnel & 20,400 & 9,370 & 7,952 & -- & --\\
A. personnel & 16,100 & 1,535 & 2,190 & -- & --\\
A. personnel & 17,700 & 0,130 & 0,014 & -- & --\\
A. personnel & 16,800 & 0,290 & 0,608 & -- & --\\
\addlinespace
B. libre service & 13,400 & 15,515 & -- & 1,306 & --\\
B. libre service & 11,300 & 36,468 & -- & 0,916 & --\\
B. libre service & 14,000 & 11,148 & -- & 3,038 & --\\
B. libre service & 12,400 & 24,393 & -- & 0,020 & --\\
B. libre service & 13,700 & 13,242 & -- & 2,082 & --\\
\addlinespace
B. libre service & 8,500 & 78,126 & -- & 14,116 & --\\
B. libre service & 12,500 & 23,415 & -- & 0,059 & --\\
C. électrique & 22,900 & 30,926 & -- & -- & 0,028\\
C. électrique & 26,000 & 75,015 & -- & -- & 8,604\\
C. électrique & 23,600 & 39,202 & -- & -- & 0,284\\
\addlinespace
C. électrique & 21,000 & 13,404 & -- & -- & 4,271\\
C. électrique & 22,300 & 24,613 & -- & -- & 0,588\\
C. électrique & 22,600 & 27,679 & -- & -- & 0,218\\
grande moyenne & 17,339 & -- & -- & -- & --\\
moyenne groupe A & 17,580 & -- & -- & -- & --\\
\addlinespace
moyenne groupe B & 12,257 & -- & -- & -- & --\\
moyenne groupe C & 23,067 & -- & -- & -- & --\\
Variance totale & -- & 424,663 & -- & -- & --\\
Variance intragroupe & -- & -- & 11,228 & 21,537 & 13,993\\
\bottomrule
\end{tabular}
\end{table}

Examinons un deuxième jeu de données fictives pour lequel le type de vélo utilisé n'aurait que peu d'effet sur la vitesse des cyclistes (tableau \ref{tab:aovfictive2}). D'emblée, les moyennes des trois groupes semblent très similaires (19,3, 17,9 et 18,7). Les valeurs des trois variances sont les suivantes :

\begin{itemize}
\tightlist
\item
  la variance totale est égale à 121,756.
\item
  la variance intragroupe (non expliquée, VNE) est égale à \(9,140+50,254+56,275 = 115,669\)
\item
  la variance intragroupe (expliquée, VE) est égale à \(5\times(19,300-18,528)^2+7\times(17,871-18,528)^2+6\times(18,650-18,528)^2 = 6,087\).
\end{itemize}

On a donc \(VT = Var_{inter} + Var_{intra}\), soit \(121,756 = 6,087 + 115,669\) et \(\eta_2 = 6,087 / 121,756 = 0,05\). Cela signale que 5\% de la variance de la vitesse des cyclistes est uniquement expliquée par le type de vélo utilisé.

\begin{table}

\caption{\label{tab:aovfictive2}Données fictives et calcul des trois variances (cas 2)}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{lrrrrr}
\toprule
Type de vélo & km/h & \$(y\_\{i\}-\textbackslash{}overline\{y\})\textasciicircum{}2\$ & \$(y\_\{i\}-\textbackslash{}overline\{y\_\{A\}\})\textasciicircum{}2\$ & \$(y\_\{i\}-\textbackslash{}overline\{y\_\{B\}\})\textasciicircum{}2\$ & \$(y\_\{i\}-\textbackslash{}overline\{y\_\{C\}\})\textasciicircum{}2\$\\
\midrule
A. personnel & 17,500 & 1,056 & 3,24 & -- & --\\
A. personnel & 19,000 & 0,223 & 0,09 & -- & --\\
A. personnel & 19,700 & 1,374 & 0,16 & -- & --\\
A. personnel & 18,700 & 0,030 & 0,36 & -- & --\\
A. personnel & 21,600 & 9,439 & 5,29 & -- & --\\
\addlinespace
B. libre service & 13,700 & 23,307 & -- & 17,401 & --\\
B. libre service & 20,800 & 5,163 & -- & 8,577 & --\\
B. libre service & 15,100 & 11,750 & -- & 7,681 & --\\
B. libre service & 18,800 & 0,074 & -- & 0,862 & --\\
B. libre service & 21,500 & 8,834 & -- & 13,167 & --\\
\addlinespace
B. libre service & 16,500 & 4,112 & -- & 1,881 & --\\
B. libre service & 18,700 & 0,030 & -- & 0,687 & --\\
C. électrique & 16,600 & 3,716 & -- & -- & 4,203\\
C. électrique & 16,300 & 4,963 & -- & -- & 5,523\\
C. électrique & 15,600 & 8,572 & -- & -- & 9,303\\
\addlinespace
C. électrique & 20,000 & 2,167 & -- & -- & 1,822\\
C. électrique & 24,600 & 36,872 & -- & -- & 35,402\\
C. électrique & 18,800 & 0,074 & -- & -- & 0,022\\
grande moyenne & 18,528 & -- & -- & -- & --\\
moyenne groupe A & 19,300 & -- & -- & -- & --\\
\addlinespace
moyenne groupe B & 17,871 & -- & -- & -- & --\\
moyenne groupe C & 18,650 & -- & -- & -- & --\\
Variance totale & -- & 121,756 & -- & -- & --\\
Variance intragroupe & -- & -- & 9,14 & 50,254 & 56,275\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{sect04412}{%
\subsubsection{Le test de Fisher}\label{sect04412}}

Pour vérifier si les moyennes sont satistiquement différentes (autrement dit, si leur différence est significativement différente de 0), on a recours au test \emph{F} de Fisher. Pour ce faire, on pose l'hypothèse nulle (H\textsubscript{0}), soit que les moyennes des groupes sont égales; autrement dit que la variable qualitative n'a pas d'effet sur la variable continue (indépendance entre les deux variables). L'hypothèse alternative (H\textsubscript{1}) est donc que les moyennes sont différentes. Pour nos deux jeux de données fictives ci-dessus comprenant trois groupes, H\textsubscript{0} signifie que \(\overline{y_{A}}=\overline{y_{B}}=\overline{y_{C}}\). La statistique \emph{F} se calcule comme suit :

\begin{equation} 
F = \frac{\frac{Var{inter}}{k-1}}{\frac{Var{intra}}{n-k}}\mbox{ ou } F = \frac{\frac{VE}{k-1}}{\frac{VNE}{n-k}}
\label{eq:anovaF}
\end{equation}

avec \(n\) et \(k\) étant respectivement les nombres d'observations et de modalités de la variable qualitative. L'hypothèse nulle (les moyennes sont égales) sera rejetée si la valeur du \emph{F} calculé est supérieure à la valeur critique de la table \emph{F} avec les degrés de libertés \emph{(k-1, n-k)} et un seuil
\(\alpha\) (\emph{p}=0,05 habituellement) (voir le tableau des valeurs critiques de \emph{F}, section \ref{annexe2}). Notez qu'on utilise rarement la table \emph{F} puisqu'avec la fonction \texttt{aov} on calcule directement la valeur \emph{F} et celle de \emph{p} qui lui est associée. Concrètement, si le test \emph{F} est significatif (avec \emph{p}\textless0,05), plus la valeur de \emph{F} sera élevée, plus la différence entre les moyennes sera élevée.

Appliquons rapidement la démarche du test \emph{F} à nos deux jeux de données fictives qui comprennent 3 modalités pour la variable qualitative et 18 observations. Avec \(\alpha\)=0,05, 2 degrés de liberté (3-1) au numérateur et 15 au dénominateur (18-3), la valeur critique de F est de 3,68. On en conclut alors que :

\begin{itemize}
\tightlist
\item
  pour le cas A, le F calculé est égal à \(F = (377,904 /2) / (46,758 / 15) = 60,62\). Il est supérieur à la valeur F critique; les moyennes sont donc statistiquement différentes au seuil 0,05. Autrement dit, nous aurions eu moins de 5\% de chance d'obtenir un échantillon produisant ces résultats si en réalité la différence entre les moyenne était de 0.
\item
  pour le cas B, le F calculé est égal à \(F = (6,087/2)/ (115,669 / 15) = 0,39\). Il est inférieur à la valeur F critique; les moyennes ne sont donc pas statistiquement différentes au seuil 0,05.
\end{itemize}

\hypertarget{sect04414}{%
\subsubsection{Conditions d'application de l'ANOVA et solutions alternatives}\label{sect04414}}

Trois conditions d'application doivent être vérifiées avant d'effectuer une analyse de variance sur un jeu de données :

\begin{itemize}
\item
  \textbf{Normalité des groupes.} Le test de Fisher repose sur le postulat que les échantillons (groupes) sont normalement distribués. Pour le vérifier, on a recours au test de normalité de Shapiro--Wilk (section \ref{sect025413}). Notez toutefois que ce test est très restrictif, surtout pour des grands échantillons.
\item
  \textbf{Homoscédasticité}. La variance dans les échantillons doit être la même (homogénéité des variances). Pour vérifier cette condition, on utilisera les tests de Levene, de Bartlett ou de Breusch-Pagan.
\item
  \textbf{Indépendance des observations (pseudo-réplication).} Chaque individu doit appartenir à un et un seul groupe. En d'autres termes, les observations ne sont pas indépendantes si plusieurs mesures (variable continue) sont faites sur un même individu. Si c'est le cas, on utilisera alors une analyse de variance sur des mesures répétées (voir le bloc à la fin du chapitre).
\end{itemize}

\textbf{Quelles sont les conséquences si les conditions d'application ne sont pas respectées ?} La non vérification des conditions d'application cause deux problèmes distincts : elle affecte la puissance du test (sa capacité à détecter un effet, si celui-ci existe réellement) et le taux d'erreur de type 1 (la probabilité de trouver un résultat significatif alors qu'aucune relation n'existe réellement, soit un faut-positif) \citep{glass1972consequences, lix1996consequences}.

\begin{itemize}
\tightlist
\item
  Si la distribution est asymétrique plutôt que centrée (comme pour une distribution normale), la puissance et le taux d'erreur de type 1 sont tous les deux peu affectés car le test est non-orienté (la différence de moyennes peut être négative ou positive).
\item
  Si la distribution est leptocurtique (pointue, avec des extrémités de la distribution plus importantes, le taux d'erreur de type 1 est peu affecté, en revanche la puissance du test est réduite. L'inverse s'observe si la distribution est platicurtique (aplatie, c'est-à-dire avec des extrémités de la distribution plus réduites.
\item
  Si les groupes ont des variances différentes, le taux d'erreur de type 1 augmente légèrement.
\item
  Si les observations ne sont pas indépendantes, à la fois le taux d'erreurs de type 1 et la puissance du test sont fortement affectés.
\item
  Si les échantillons sont petits, les effets présentés ci-dessus sont démultipliés.
\item
  Si plusieurs conditions ne sont pas respectées, les conséquences présentées ci-dessus s'additionnent, voir se combinent.
\end{itemize}

\textbf{Que faire quand les conditions d'application relatives à la normalité ou à l'homoscédaticité ne sont vraiment pas respectées ?} Signalons d'emblée que le non respect de ces conditions ne change rien à la décomposition de la variance (VT=V\textsubscript{intra}+V\textsubscript{inter}). Cela signifie que vous pouvez toujours calculer Eta\textsuperscript{2}. Par contre, le test de Fisher ne peut pas être utilisé car il sera biaisé comme décrit précédemment. Quatre solutions sont envisageables :

\begin{itemize}
\item
  Lorsque les échantillons sont fortement anormalement distribués, certains auteurs vont simplement transformer leur variable en appliquant une fonction logarithme (le plus souvent) ou racine carré, inverse ou exponentielle, et reporter le test de fisher calculé sur cette transformation. Attention toutefois ! Transformer une variable ne va pas systématiquement la rapprocher d'une distribution normale et complique l'interprétation finale des résultats. Par conséquent, avant de recalculer votre test \emph{F}, il convient de réaliser un test de normalité de Shapiro--Wilk et un test d'homoscédasticité (Levene, Bartlett ou/et Breusch-Pagan) sur la variable continue transformée.
\item
  Détecter les observations qui contribuent le plus à l'anormalité et l'hétéroscédasticité, dites valeurs aberrantes (\emph{outliers} en anglais). Supprimez les et refaites votre ANOVA en vous assurant que les conditions sont désormais respectées. Notez que supprimer des observations peut être une pratique éthiquement questionnable en statistique. Si vos échantillons sont bien constitués et que la mesure collectée n'est pas erronée, pourquoi donc la supprimer? Si vous optez pour cette solution, prenez soin de comparer les résultats avant et après la suppression des valeurs aberrantes. Si les conditions sont respectées après suppression et que les résultats de l'ANOVA (Eta\textsuperscript{2} et test \emph{F} de Fisher) sont très semblables, conservez donc les résultats de l'ANOVA intitiale et signalez que vous avez procédez aux deux tests.
\item
  Lorsque les variances des groupes sont dissemblables, vous pouvez utiliser le test de Welch pour l'ANOVA au lieu du test \emph{F} de Fisher.
\item
  Dernière solution, lorsque les deux conditions ne sont vraiment pas respectées, utilisez le test non paramétrique de Kruskal-Wallis. Par analogie au \emph{t} de student, il correspond au test des rangs signés de Wilcoxon. Ce test est décrit dans la section suivante.
\end{itemize}

Vous l'aurez compris, dans de nombreux cas en statistique, les choix méthodologiques dépendent de la subjectivité du chercheur. Il faut s'adapter au jeu de données et à la culture statistique en vigueur dans votre champs d'étude. N'hésitez pas à réaliser plusieurs tests différents pour évaluer la robustesse de vos conclusions et fiez-vous en premier lieu à ceux pour lesquels votre jeu de données est le plus adapté.

\hypertarget{sect0442}{%
\subsection{Test non paramétrique de Kruskal-Wallis}\label{sect0442}}

Le test non paramétrique de Kruskal-Wallis est une alternative à l'ANOVA classique lorsque le jeu de données présente de graves problèmes de normalité et d'hétéroscédaticité. Cette méthode représente une ANOVA appliquée à une variable continue transformée préalablement en rangs. Du fait de la transformation en rangs, on ne vérifie plus si les moyennes sont différentes, mais bel et bien si les médianes de la variable continue sont différentes. Pour ce faire, on utilisera la fonction \texttt{kruskal.test}.

\hypertarget{sect0443}{%
\subsection{Mise en œuvre dans}\label{sect0443}}

Dans une étude récente, Apparicio \emph{et al.} \citeyearpar{apparicio2018exposure} ont comparé les expositions au bruit et à la pollution atmosphérique aux heures de pointe à Montréal en fonction du mode de transport utilisé. Pour ce faire, trois équipes de trois personnes ont été constituées : un cycliste, un automobiliste et un utilisateur du transport en commun, équipés de capteurs de pollution, de sonomètres, de vêtements biométriques et d'une montre GPS. Chaque matin, à huit heures précises, les membres de chaque équipe ont réalisé un trajet d'un quartier périphérique de Montréal vers un pôle d'enseignement (université) ou d'emploi localisé au centre-ville. Le trajet inverse était réalisé le soir à 17h. Au total, une centaine de trajets ont ainsi été réalisés. Des analyses de variance ont ainsi permis de comparer entre les trois modes (automobile, vélo et transport en commun) : les temps de déplacement, les niveaux d'exposition au bruit, les niveaux d'exposition au dioxyde d'azote et la dose totale inhalée de dioxyde d'azote. Nous vous proposons ici d'analyser une partie de ces données.

\hypertarget{premiuxe8re-anova-diffuxe9rences-entre-les-temps-de-duxe9placement}{%
\subsubsection{Première ANOVA : différences entre les temps de déplacement}\label{premiuxe8re-anova-diffuxe9rences-entre-les-temps-de-duxe9placement}}

Comme première analyse de variance, nous allons vérifier si les moyennes des temps de déplacement sont différentes entre les trois modes de transport.

Dans un premier temps, nous pouvons calculer les moyennes des différents groupes. On peut alors constater que les moyennes sont très sembables : 37,7 minutes pour l'automobile versus 38,4 et 41,6 pour le vélo et le transport en commun. Aussi, les variances des trois groupes sont relativement similaires.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"rstatix"}\NormalTok{)}
\CommentTok{# chargement des dataframes}
\KeywordTok{load}\NormalTok{(}\StringTok{"data/bivariee/dataPollution.RData"}\NormalTok{)}
\CommentTok{# Statistiques descriptives pour les groupes (moyenne et écart-type)}
\NormalTok{df_TrajetsDuree }\OperatorTok{%>%}\StringTok{                                 }\CommentTok{# Nom du dataframe}
\StringTok{    }\KeywordTok{group_by}\NormalTok{(Mode) }\OperatorTok{%>%}\StringTok{                                }\CommentTok{# Variable qualitative}
\StringTok{    }\KeywordTok{get_summary_stats}\NormalTok{(DureeMinute, }\DataTypeTok{type =} \StringTok{"mean_sd"}\NormalTok{)  }\CommentTok{# Variable continue }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 5
##   Mode    variable        n  mean    sd
##   <chr>   <chr>       <dbl> <dbl> <dbl>
## 1 1. Auto DureeMinute    33  37.7  12.8
## 2 2. Velo DureeMinute    33  38.4  15.2
## 3 3. TC   DureeMinute    33  41.6  11.4
\end{verbatim}

Pour visualiser la distribution des données pour les trois groupes, vous pouvez créer des graphiques de densité et en violons (figure \ref{fig:figAnova1a}). La juxtaposition des trois distributions montre que les distributions des valeurs pour les trois groupes sont globalement similaires. Cela est corroboré par le fait que les boîtes du graphique en violons sont situées à la même hauteur. Autrement dit, à la lecture des deux graphiques, ils ne semblent pas y avoir de différences significatives entre les trois groupes en terme de temps de déplacement.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"ggplot2"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"ggpubr"}\NormalTok{)}
\CommentTok{# Graphique de densité}
\NormalTok{GraphDens <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ df_TrajetsDuree, }
  \DataTypeTok{mapping=}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{DureeMinute,}\DataTypeTok{colour=}\NormalTok{Mode,}\DataTypeTok{fill=}\NormalTok{Mode)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_density}\NormalTok{(}\DataTypeTok{alpha=}\FloatTok{0.55}\NormalTok{,}\DataTypeTok{mapping=}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y=}\NormalTok{..scaled..))}\OperatorTok{+}
\StringTok{    }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title=}\StringTok{"a. graphique de densité"}\NormalTok{,}
         \DataTypeTok{x =} \StringTok{"Densité"}\NormalTok{,}
         \DataTypeTok{y =} \StringTok{"Durée du trajets (en minutes)"}\NormalTok{)}
\CommentTok{# Graphique en violons}
\NormalTok{GraphViolon <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(df_TrajetsDuree, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{Mode, }\DataTypeTok{y=}\NormalTok{DureeMinute)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_violin}\NormalTok{(}\DataTypeTok{fill=}\StringTok{"white"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_boxplot}\NormalTok{(}\DataTypeTok{width=}\FloatTok{0.1}\NormalTok{, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{Mode, }\DataTypeTok{y=}\NormalTok{DureeMinute,}\DataTypeTok{fill=}\NormalTok{Mode))}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title=}\StringTok{"b. Graphique en violons"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"Mode de transport"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{"Durée du trajets (en minutes)"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \StringTok{"none"}\NormalTok{)}
\KeywordTok{ggarrange}\NormalTok{(GraphDens, GraphViolon)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/figAnova1a-1} 

}

\caption{Graphiques de densité et en violons}\label{fig:figAnova1a}
\end{figure}

Nous pouvons vérifier si les échantillons sont normalement distribués avec la fonction \texttt{shapiro\_test} du package \textbf{rstatix}. À titre de rappel, l'hypothèse nulle (h0) de ce test est que la distribution est normale. Par conséquent, quand la valeur de \emph{P} associée à la statistique de Shapiro est supérieure à 0,05 alors on ne peut rejeter l'hypothèse d'une distribution normale (autrement dit, la distribution est anormale). À la lecture des sorties ci-dessous, seul le groupe des utilisateurs en transport en commun présente une distribution proche de la normalité (p=0,0504). Ce test étant très restrictif, il est fortement conseillé de visualiser le diagramme quantile-quantile pour chaque groupe (graphique QQ plot) (figure \ref{fig:figQqplot}). Ces graphiques sont utilisés pour déterminer visuellement si une distribution empirique (observées sur des données), s'approche d'une distribution théorique (ici la loi normale). Si effectivement les deux distributions sont proches, les points du diagramme devraient tous tomber sur une ligne droite parfaite. Un intervale de confiance (représenté ici en gris) peut être construit pour obtenir une interprétation plus nuancée. Dans notre cas, seules deux observations pour le vélo et deux autres pour l'automobile s'éloignent vraiment de la ligne droite. On peut considérer que ces trois distributions s'approchent d'une distribution normale.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"dplyr"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"ggpubr"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"rstatix"}\NormalTok{)}
\CommentTok{# Condition 1 : normalité des échantillons}
\CommentTok{# Test pour la normalité des échantillons (groupes) : test de Shapiro}
\NormalTok{ df_TrajetsDuree }\OperatorTok{%>%}\StringTok{          }\CommentTok{# Nom du dataframe}
\StringTok{   }\KeywordTok{group_by}\NormalTok{(Mode) }\OperatorTok{%>%}\StringTok{         }\CommentTok{# Variable qualitative}
\StringTok{   }\KeywordTok{shapiro_test}\NormalTok{(DureeMinute)  }\CommentTok{# Variable continue }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 4
##   Mode    variable    statistic         p
##   <chr>   <chr>           <dbl>     <dbl>
## 1 1. Auto DureeMinute     0.905 0.00729  
## 2 2. Velo DureeMinute     0.797 0.0000288
## 3 3. TC   DureeMinute     0.936 0.0504
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Graphiques qqplot pour les groupes}
\KeywordTok{ggqqplot}\NormalTok{(df_TrajetsDuree, }\StringTok{"DureeMinute"}\NormalTok{, }\DataTypeTok{facet.by =} \StringTok{"Mode"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/figQqplot-1} 

}

\caption{QQ Plot pour les groupes}\label{fig:figQqplot}
\end{figure}

Pour vérifier l'hypothèse d'homogénéité des variances, vous pouvez utiliser les tests de Levene, de Bartlett ou de Breusch-Pagan. Les valeurs de \emph{P}, toutes supérieures à 0,05, signalent que la condition d'homogénéité des variances est respectée.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"rstatix"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"lmtest"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"car"}\NormalTok{)}
\CommentTok{# Condition 2 : homogénéité des variances (homocédasticité)}
\KeywordTok{leveneTest}\NormalTok{(DureeMinute }\OperatorTok{~}\StringTok{ }\NormalTok{Mode, }\DataTypeTok{data =}\NormalTok{ df_TrajetsDuree)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Levene's Test for Homogeneity of Variance (center = median)
##       Df F value Pr(>F)
## group  2  0.2418 0.7857
##       96
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{bartlett.test}\NormalTok{(DureeMinute }\OperatorTok{~}\StringTok{ }\NormalTok{Mode, }\DataTypeTok{data =}\NormalTok{ df_TrajetsDuree)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 	Bartlett test of homogeneity of variances
## 
## data:  DureeMinute by Mode
## Bartlett's K-squared = 2.6718, df = 2, p-value = 0.2629
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{bptest}\NormalTok{(DureeMinute }\OperatorTok{~}\StringTok{ }\NormalTok{Mode, }\DataTypeTok{data =}\NormalTok{ df_TrajetsDuree)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 	studentized Breusch-Pagan test
## 
## data:  DureeMinute ~ Mode
## BP = 1.3322, df = 2, p-value = 0.5137
\end{verbatim}

Deux fonctions peuvent être utilisées pour calculer l'analyse de variance : la fonction de base \texttt{aov(variable\ continue\ \textasciitilde{}\ variable\ qualitative,\ data\ =\ votre\ dataframe)} ou bien la fonction \texttt{anova\_test(variable\ continue\ \textasciitilde{}\ variable\ qualitative,\ data\ =\ votre\ dataframe)} du package \textbf{rstatix}. Comparativement à \texttt{aov}, l'avantage de la fonction \texttt{anova\_test} est qu'elle calcule aussi le Eta\textsuperscript{2}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"rstatix"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"lmtest"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"car"}\NormalTok{)}
\CommentTok{# ANOVA avec la fonction aov}
\NormalTok{aov1 <-}\StringTok{ }\KeywordTok{aov}\NormalTok{(DureeMinute }\OperatorTok{~}\StringTok{ }\NormalTok{Mode, }\DataTypeTok{data =}\NormalTok{ df_TrajetsDuree)}
\KeywordTok{summary}\NormalTok{(aov1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             Df Sum Sq Mean Sq F value Pr(>F)
## Mode         2    287   143.2    0.82  0.444
## Residuals   96  16781   174.8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# calcul de Eta2 avec la fonction eta_sq du package lmtest}
\KeywordTok{eta_sq}\NormalTok{(aov1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   term etasq
## 1 Mode 0.017
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# ANOVA avec la fonction anova_test du package rstatix}
\KeywordTok{anova_test}\NormalTok{(DureeMinute }\OperatorTok{~}\StringTok{ }\NormalTok{Mode, }\DataTypeTok{data =}\NormalTok{ df_TrajetsDuree)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## ANOVA Table (type II tests)
## 
##   Effect DFn DFd    F     p p<.05   ges
## 1   Mode   2  96 0.82 0.444       0.017
\end{verbatim}

La valeur de \emph{P} associée à la statistique \emph{F} (0,444) nous permet de conclure qu'il n'y a pas de différences significatives entre les moyennes des temps de déplacements des trois modes de transport.

\hypertarget{deuxiuxe8me-anova-diffuxe9rences-entre-les-niveaux-dexposition-au-bruit}{%
\subsubsection{Deuxième ANOVA : différences entre les niveaux d'exposition au bruit}\label{deuxiuxe8me-anova-diffuxe9rences-entre-les-niveaux-dexposition-au-bruit}}

Dans ce second exercice, nous allons analyser les différences d'exposition au bruit. D'emblée, les statistiques descriptives révèlent que les moyennes sont dissemblables : 66,8 dB(A) pour l'automobile versus 68,8 et 74 pour le vélo et le transport en commun. Aussi, la variance du transport en commun est très différente des autres.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"rstatix"}\NormalTok{)}
\CommentTok{# chargement des dataframes}
\KeywordTok{load}\NormalTok{(}\StringTok{"data/bivariee/dataPollution.RData"}\NormalTok{)}
\CommentTok{# Statistiques descriptives pour les groupes (moyenne et écart-type)}
\NormalTok{ df_Bruit }\OperatorTok{%>%}\StringTok{                                 }\CommentTok{# Nom du dataframe}
\StringTok{   }\KeywordTok{group_by}\NormalTok{(Mode) }\OperatorTok{%>%}\StringTok{                                }\CommentTok{# Variable qualitative}
\StringTok{   }\KeywordTok{get_summary_stats}\NormalTok{(laeq, }\DataTypeTok{type =} \StringTok{"mean_sd"}\NormalTok{)  }\CommentTok{# Variable continue }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 5
##   Mode    variable     n  mean    sd
##   <chr>   <chr>    <dbl> <dbl> <dbl>
## 1 1. Auto laeq      1094  66.8  4.56
## 2 2. Velo laeq      1124  68.8  4.29
## 3 3. TC   laeq      1207  74.0  6.79
\end{verbatim}

À la lecture des graphiques de densité et en violon (figure \ref{fig:figAnova1b}), il semble clair que les niveaux d'exposition au bruit sont plus faibles pour les automobilistes et plus élevés pour les cyclistes et surtout les utilisateurs du transport en commun. En outre, la distribution des valeurs d'exposition au bruit dans le transport en commun semble bimodale. Cela s'explique par le fait que les niveaux de bruit sont beaucoup élevés dans le métro que dans les autobus.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"ggplot2"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"ggpubr"}\NormalTok{)}
\CommentTok{# Graphique en densité}
\NormalTok{GraphDens <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ df_Bruit, }
  \DataTypeTok{mapping=}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{laeq,}\DataTypeTok{colour=}\NormalTok{Mode,}\DataTypeTok{fill=}\NormalTok{Mode)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_density}\NormalTok{(}\DataTypeTok{alpha=}\FloatTok{0.55}\NormalTok{,}\DataTypeTok{mapping=}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y=}\NormalTok{..scaled..))}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title=}\StringTok{"a. graphique de densité"}\NormalTok{,}
       \DataTypeTok{x=}\StringTok{"Exposition au bruit (dB(A))"}\NormalTok{)}
\CommentTok{# Graphique en violons}
\NormalTok{GraphViolon <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(df_Bruit, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{Mode, }\DataTypeTok{y=}\NormalTok{laeq)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_violin}\NormalTok{(}\DataTypeTok{fill=}\StringTok{"white"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_boxplot}\NormalTok{(}\DataTypeTok{width=}\FloatTok{0.1}\NormalTok{, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{Mode, }\DataTypeTok{y=}\NormalTok{laeq,}\DataTypeTok{fill=}\NormalTok{Mode))}\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title=}\StringTok{"b. Graphique en violons"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"Mode de transport"}\NormalTok{,}
       \DataTypeTok{y=}\StringTok{"Exposition au bruit (dB(A))"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \StringTok{"none"}\NormalTok{)}
\KeywordTok{ggarrange}\NormalTok{(GraphDens, GraphViolon)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/figAnova1b-1} 

}

\caption{Graphique de densité et en violons}\label{fig:figAnova1b}
\end{figure}

Le test de Shapiro et les graphiques QQ plot (figure \ref{fig:figQqplot2}) rélèvent que les distributions des trois groupes sont anormales. Ce résultat n'est pas surprenant si l'on tient compte de la nature logarithmique de l'échelle décibel.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"dplyr"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"ggpubr"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"rstatix"}\NormalTok{)}
\CommentTok{# Condition 1 : normalité des échantillons}
\CommentTok{# Test pour la normalité des échantillons (groupes) : test de Shapiro}
\NormalTok{df_Bruit }\OperatorTok{%>%}\StringTok{          }\CommentTok{# Nom du dataframe}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(Mode) }\OperatorTok{%>%}\StringTok{         }\CommentTok{# Variable qualitative}
\StringTok{  }\KeywordTok{shapiro_test}\NormalTok{(laeq)  }\CommentTok{# Variable continue }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 4
##   Mode    variable statistic        p
##   <chr>   <chr>        <dbl>    <dbl>
## 1 1. Auto laeq         0.971 4.92e-14
## 2 2. Velo laeq         0.992 5.12e- 6
## 3 3. TC   laeq         0.966 3.34e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Graphiques qqplot pour les groupes}
\KeywordTok{ggqqplot}\NormalTok{(df_Bruit, }\StringTok{"laeq"}\NormalTok{, }\DataTypeTok{facet.by =} \StringTok{"Mode"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{livre_statistique_Phil_Jere_clean_files/figure-latex/figQqplot2-1} 

}

\caption{QQ Plot pour les groupes}\label{fig:figQqplot2}
\end{figure}

En outre, selon les valeurs des tests de Levene, de Bartlett ou de Breusch-Pagan, les variances ne sont pas égales.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"rstatix"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"lmtest"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"car"}\NormalTok{)}
\CommentTok{# Condition 2 : homogénéité des variances (homocédasticité)}
\KeywordTok{leveneTest}\NormalTok{(laeq }\OperatorTok{~}\StringTok{ }\NormalTok{Mode, }\DataTypeTok{data =}\NormalTok{ df_Bruit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Levene's Test for Homogeneity of Variance (center = median)
##         Df F value    Pr(>F)    
## group    2   190.3 < 2.2e-16 ***
##       3422                      
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{bartlett.test}\NormalTok{(laeq }\OperatorTok{~}\StringTok{ }\NormalTok{Mode, }\DataTypeTok{data =}\NormalTok{ df_Bruit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 	Bartlett test of homogeneity of variances
## 
## data:  laeq by Mode
## Bartlett's K-squared = 306.64, df = 2, p-value < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{bptest}\NormalTok{(laeq }\OperatorTok{~}\StringTok{ }\NormalTok{Mode, }\DataTypeTok{data =}\NormalTok{ df_Bruit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 	studentized Breusch-Pagan test
## 
## data:  laeq ~ Mode
## BP = 279.85, df = 2, p-value < 2.2e-16
\end{verbatim}

Étant donné que les deux conditions (normalité et homogénéité des variances) ne sont pas respectées, il serait préférable d'utiliser un test non paramétrique de Kruskal-Wallis. Calculons toutefois préalablement l'ANOVA classique et l'ANOVA de Welch puisque les variances ne sont pas égales). Les valeurs de \emph{P} des deux tests (Fisher et Welch) signalent que les moyennes d'exposition au bruit sont statistiquement différentes entre les trois modes de transport.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"rstatix"}\NormalTok{)}
\CommentTok{# ANOVA avec la fonction anova_test du package rstatix}
\KeywordTok{anova_test}\NormalTok{(laeq }\OperatorTok{~}\StringTok{ }\NormalTok{Mode, }\DataTypeTok{data =}\NormalTok{ df_Bruit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## ANOVA Table (type II tests)
## 
##   Effect DFn  DFd       F         p p<.05   ges
## 1   Mode   2 3422 544.214 6.12e-206     * 0.241
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# ANOVA avec le test de Welch puisque les variances ne sont pas égales}
\KeywordTok{welch_anova_test}\NormalTok{(laeq }\OperatorTok{~}\StringTok{ }\NormalTok{Mode, }\DataTypeTok{data =}\NormalTok{ df_Bruit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 7
##   .y.       n statistic   DFn   DFd         p method     
## * <chr> <int>     <dbl> <dbl> <dbl>     <dbl> <chr>      
## 1 laeq   3425      446.     2 2248. 9.47e-164 Welch ANOVA
\end{verbatim}

Une fois démontré que les moyennes sont différentes, le test de Tukey est particulièrement intéressant puisqu'il nous permet de repérer les différences de moyennes significatives deux à deux, tout en ajustant les valeurs de \emph{P} obtenues en fonction du nombre de comparaisons effectuées. Ci-dessous, on constate que toutes les paires sont statistiquement différentes et que la différence de moyennes entre les automobilistes et les cyclistes est de 1,9 dB(A) et surtout de 7,1 dB(A) entre les automobilistes et les usagers du transport en commun.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{aov2 <-}\StringTok{ }\KeywordTok{aov}\NormalTok{(laeq }\OperatorTok{~}\StringTok{ }\NormalTok{Mode, }\DataTypeTok{data =}\NormalTok{ df_Bruit)}
\CommentTok{# Test de Tukey pour comparer les moyennes entre elles}
\KeywordTok{TukeyHSD}\NormalTok{(aov2, }\DataTypeTok{conf.level =} \FloatTok{0.95}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = laeq ~ Mode, data = df_Bruit)
## 
## $Mode
##                     diff      lwr      upr p adj
## 2. Velo-1. Auto 1.941698 1.406343 2.477053     0
## 3. TC-1. Auto   7.113506 6.587309 7.639703     0
## 3. TC-2. Velo   5.171808 4.649307 5.694309     0
\end{verbatim}

Le calcul de test non paramétrique de Kruskal-Wallis avec la fonction \texttt{kruskal.test} démontre aussi que les médianes des groupes sont différentes (\emph{p}\textless{} 0,001). De manière comparable au test de Tukey, la fonction \texttt{pairwise.wilcox.test} permet aussi de repérer les différences significatives entre les paires de groupes. Pour conclure, tant l'ANOVA que le test non paramétrique de Kruskal-Wallis indiquent que les trois modes de transport sont significativement différents quant à l'exposition au bruit, avec des valeurs plus faibles pour les automobilistes comparativement aux cyclistes et aux usagers du transport en commun.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Test de Kruskal-Wallis}
\KeywordTok{kruskal.test}\NormalTok{(laeq }\OperatorTok{~}\StringTok{ }\NormalTok{Mode, }\DataTypeTok{data =}\NormalTok{ df_Bruit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 	Kruskal-Wallis rank sum test
## 
## data:  laeq by Mode
## Kruskal-Wallis chi-squared = 784.74, df = 2, p-value < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Calcul de la moyenne des rangs pour les trois groupes}
\NormalTok{df_Bruit}\OperatorTok{$}\NormalTok{laeqRank <-}\StringTok{ }\KeywordTok{rank}\NormalTok{(df_Bruit}\OperatorTok{$}\NormalTok{laeq)}
\NormalTok{df_Bruit }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(Mode) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{get_summary_stats}\NormalTok{(laeqRank, }\DataTypeTok{type =} \StringTok{"mean"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 4
##   Mode    variable     n  mean
##   <chr>   <chr>    <dbl> <dbl>
## 1 1. Auto laeqRank  1094 1188.
## 2 2. Velo laeqRank  1124 1572.
## 3 3. TC   laeqRank  1207 2320.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Compiraison des groupes avec la fonction pairwise.wilcox.test}
\KeywordTok{pairwise.wilcox.test}\NormalTok{(df_Bruit}\OperatorTok{$}\NormalTok{laeq, df_Bruit}\OperatorTok{$}\NormalTok{Mode, }\DataTypeTok{p.adjust.method =} \StringTok{"BH"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 	Pairwise comparisons using Wilcoxon rank sum test with continuity correction 
## 
## data:  df_Bruit$laeq and df_Bruit$Mode 
## 
##         1. Auto 2. Velo
## 2. Velo <2e-16  -      
## 3. TC   <2e-16  <2e-16 
## 
## P value adjustment method: BH
\end{verbatim}

\hypertarget{sect0444}{%
\subsection{Comment rapporter les résultats d'une ANOVA et du test de Kruskal-Wallis}\label{sect0444}}

Plusieurs éléments doivent être reportés pour détailler les résultats d'une ANOVA ou d'un test de Kruskal-Wallis : la valeur de \emph{F}, de \emph{W} (dans le cas d'une ANOVA de Welch) ou du χ2 (Kruskal-Wallis), les valeurs de \emph{P}, les moyennes ou médianes respectives des groupes et éventuellement un tableau détaillant les écarts intergroupes obtenus avec les test de Tuckey ou Wilcoxon par paires.

\begin{itemize}
\item
  Les résultats de l'analyse de variance à un facteur démontrent que le mode de transport utilisé n'a pas d'effet significatif sur le temps de déplacement en heures de pointe à Montréal (\emph{F}(2,96)=0,82, \emph{p}=0,444). En effet, pour des trajets de dix kilomètres entre un quartier périphérique et le centre-ville, les cyclistes (Moy=38,4, ET=15,2) arrivent en moyenne moins d'une minute après les automobilistes (Moy=37,7, ET=12,8) et les usagers du transport en commun moins de quatre minutes (Moy=41,6, ET=11,4).
\item
  Les résultats de l'analyse de variance à un facteur démontrent que le mode transport utilisé a un impact significatif sur le niveau d'exposition en heures de pointe à Montréal (\emph{F}(2,96)=544, \emph{p}\textless0,001 et \emph{Welch}(2,96)=446, \emph{p}\textless0,001). En effet, les usagers du transport en commun (Moy=74,0, ET=6,79) et les cyclistes (Moy=68,8, ET=4,3) sont significativement plus exposés au bruit que les automobilistes (Moy=66,8, ET=4,56).
\item
  Les résultats du test de Kruskal-Wallis démontre qu'il existe des différences significatives d'exposition au bruit entre les trois modes de transport (χ2(2) = 784,74, p\textless0,001) avec des moyennes de rangs de 1094 pour l'automobile, 1124 pour le vélo et 1207 pour le transport en commun.
\end{itemize}

\begin{bloc_aller_loin}

Nous avons vu que l'ANOVA permet de comparer les moyennes d'une variable continue à partir d'une variable qualitative comprenant plusieurs modalités (facteur) pour des observations indépendantes. Il y a un donc une seule variable dépendante (continue) et une seule variable indépendante. Sachez qu'il existe de nombreuses extensions de l'ANOVA classique :

\begin{itemize}
\item
  \textbf{une ANOVA à deux facteurs}, soit avec une variable dépendante continue et deux variables indépendantes qualitatives (\emph{two-way ANOVA} en anglais). On évalue ainsi les effets des deux variables (\emph{a}, \emph{b}) et de leur interaction (\emph{ab}) sur une variable continue.
\item
  \textbf{une ANOVA multifacteur} avec une variable dépendante continue et plus de deux variables indépendantes qualitatives. Par exemple, avec trois variables qualitatives pour expliquer la variable continue, on inclut les effets de chaque variable qualitative (\emph{a}, \emph{b}, \emph{c}) ainsi que de leurs interactions (\emph{ab}, \emph{ac}, \emph{bc}, \emph{abc}).
\item
  \textbf{L'analyse de covariance} (\textbf{ANCOVA}, \textbf{AN}alysis of \textbf{COVA}riance en anglais) comprend une variable dépendante continue, une variable indépendante qualitative (facteur) et plusieurs variables indépendantes continues dites covariables. L'objectif est alors de vérifier si les moyennes d'une variable dépendante sont différentes pour plusieurs groupes d'une population donnée, après avoir contrôlé l'effet d'une ou plusieurs variables continues. Par exemple, pour une métropole donnée, on pourra vouloir comparer les moyennes de loyers entre la ville-centre et ceux de la première et de la seconde couronnes (facteur), une fois contrôlée la taille de ces derniers (variable covariée continue). En effet, une partie de la variance des loyers s'explique certainement par la taille des logements.
\item
  \textbf{L'analyse de variance multivariée} (\textbf{MANOVA}, \emph{\textbf{M}ultivariate \textbf{AN}alysis of \textbf{VA}riance} en anglais) comprend deux variables dépendantes continues ou plus et une variable indépendante qualitative (facteur). Par exemple, on souheterait comparer les moyennes d'exposition au bruit et à différents polluants (dioxyde d'azote, particules fines, ozone) (variables dépendantes continues) selon le mode de transport utilisé (automobile, vélo, transport en commun, soit le facteur).
\item
  \textbf{L'analyse de covariance multivariée} (\textbf{MANCOVA}, \textbf{M}ultivariate \textbf{AN}alysis of \textbf{COVA}riance en anglais), soit une analyse qui comprend deux variables dépendantes continues ou plus (comme la MANOVA) et une variable qualitative comme variable indépendante (facteur) et un covariable continue ou plus.
\end{itemize}

Pour le test \emph{t}, nous avons vu qu'il peut s'appliquer soit à deux échantillons indépendants (non appariés), soit à deux échantillons dépendants (appariés). Notez qu'il existe aussi des extensions de l'ANOVA pour des échantillons pairés. On parle alors d'\textbf{analyse de variance sur des mesures répétées}. Par exemple, on pourrait évaluer la perception du sentiment de sécurité relativement à la pratique vélo d'hiver pour un échantillon de cyclistes ayant décidé de l'adopter récemment, et ce, à plusieurs moments : avant leur première saison, à la fin de leur premier hiver, à la fin de leur second hiver. Autre exemple, on pourrait sélectionner un échantillon d'individus (100 par exemple) pour lesquels on évaluerait leurs perceptions de l'environnement sonore dans différents lieux de la ville. Comme pour l'ANOVA classique (échantillons non appariés), il existe des extensions de l'ANOVA sur des mesures répétées permettant d'inclure plusieurs facteurs (groupes de population); on mesure alors une variable continue pour plusieurs groupes d'individus à différents moments ou conditions différentes. Il est aussi possible de réaliser une ANOVA pour des mesures répétées avec une ou plusieurs covariables continues.

Bref, si l'ANOVA était un roman, elle serait certainement « un monde sans fin » de Ken Follett! Notez toutefois que la SUPERNOVA, la BOSSANOVA et le CASANOVA ne sont pas des variantes de l'ANOVA!

\end{bloc_aller_loin}

\hypertarget{part-moduxe8les-de-ruxe9gression}{%
\part{Modèles de régression}\label{part-moduxe8les-de-ruxe9gression}}

\hypertarget{chap05}{%
\chapter{La régression linéaire multiple}\label{chap05}}

À juste titre, Bressoux \citeyearpar[pp 15]{bressoux2010} signale que « la causalité relève d'une interprétation théorique de la relation et celle-ci n'est jamais déterminée par les calculs statistiques ».

\hypertarget{chap06}{%
\chapter{Régressions linéaires généralisées (GLM)}\label{chap06}}

\hypertarget{sect061}{%
\section{Qu'est qu'un modèle GLM?}\label{sect061}}

\hypertarget{sect0611}{%
\subsection{Principes de base des GLM}\label{sect0611}}

\hypertarget{sect0612}{%
\subsection{Reformulation d'un modèle OLS sous forme GLM}\label{sect0612}}

\hypertarget{sect062}{%
\section{Les principaux modèles GLM utilisées}\label{sect062}}

\hypertarget{sect0621}{%
\subsection{Les régressions logistiques}\label{sect0621}}

\hypertarget{sect06211}{%
\subsubsection{Régression logit et probit simple}\label{sect06211}}

\hypertarget{sect06212}{%
\subsubsection{Régression logistique multinomiale}\label{sect06212}}

\hypertarget{sect06213}{%
\subsubsection{Régression logistique ordinale}\label{sect06213}}

\hypertarget{sect0623}{%
\subsection{Les régressions de type Poisson}\label{sect0623}}

\hypertarget{sect063}{%
\section{D'autres modèles GLM}\label{sect063}}

Student, Beta, GAMMA, Exponentiel

\hypertarget{chap07}{%
\chapter{Régressions à effets mixtes (GLMM) et régression multiniveaux}\label{chap07}}

\hypertarget{sect071}{%
\section{Principes de base des GLMM}\label{sect071}}

Notion de pseudo-réplications

Effets aléatoire \emph{versus} effets fixes

\hypertarget{sect072}{%
\section{Application à une variable continue}\label{sect072}}

\hypertarget{sect073}{%
\section{Régressions multiniveaux}\label{sect073}}

\hypertarget{chap08}{%
\chapter{Modèles généralisés additifs}\label{chap08}}

\hypertarget{sect081}{%
\section{Principes de base des GAM}\label{sect081}}

\hypertarget{sect082}{%
\section{Extensions des GAM}\label{sect082}}

\hypertarget{sect0821}{%
\subsection{GAMM}\label{sect0821}}

\hypertarget{sect0822}{%
\subsection{GAMMAR}\label{sect0822}}

\hypertarget{part-analyses-exploratoires-multivariuxe9es}{%
\part{Analyses exploratoires multivariées}\label{part-analyses-exploratoires-multivariuxe9es}}

\hypertarget{chap09}{%
\chapter{Méthodes factorielles}\label{chap09}}

\hypertarget{sect091}{%
\section{Un petit historique}\label{sect091}}

\hypertarget{sect092}{%
\section{Analyses de composantes principales (ACP)}\label{sect092}}

\hypertarget{sect093}{%
\section{Analyses factorielles de correspondances (AFC)}\label{sect093}}

\hypertarget{sect094}{%
\section{Analyses factorielles de correspondances multiples (AFM)}\label{sect094}}

\hypertarget{sect095}{%
\section{Analyses factorielles de correspondances mixte}\label{sect095}}

\hypertarget{chap10}{%
\chapter{Méthodes de classification non-supervisées}\label{chap10}}

\hypertarget{sect101}{%
\section{Un aperçu sur la multitude des méthodes de classications}\label{sect101}}

\hypertarget{sect102}{%
\section{Combinaisons méthodes factorielles et méthodes de classications}\label{sect102}}

\hypertarget{sect103}{%
\section{Classification ascendantes hiérachiques}\label{sect103}}

\hypertarget{sect104}{%
\section{Nuées dynamiques}\label{sect104}}

\hypertarget{sect1041}{%
\subsection{k-means}\label{sect1041}}

\hypertarget{sect1042}{%
\subsection{k-median}\label{sect1042}}

\hypertarget{sect1043}{%
\subsection{Les extensions en logique floues : c-means, c-median}\label{sect1043}}

\hypertarget{conclusion}{%
\chapter{Conclusion}\label{conclusion}}

\hypertarget{sect111}{%
\section{Synthèse des méthodes abordées}\label{sect111}}

\emph{Road map method}

\hypertarget{sect112}{%
\section{Autres méthodes non abordées}\label{sect112}}

\hypertarget{sect1121}{%
\subsection{Régressions par quantile}\label{sect1121}}

\hypertarget{sect1122}{%
\subsection{Régressions par panel}\label{sect1122}}

\hypertarget{sect1123}{%
\subsection{Régressions par Tobit}\label{sect1123}}

\hypertarget{sect1124}{%
\subsection{Analyses de survie}\label{sect1124}}

\hypertarget{sect1125}{%
\subsection{Équations structurelles}\label{sect1125}}

\hypertarget{sect113}{%
\section{Deux écoles de statistique inférielle : fréquentiste et bayésienne}\label{sect113}}

\hypertarget{sect114}{%
\section{Éthique en méthodes quantitatives}\label{sect114}}

\hypertarget{annexes}{%
\chapter{Annexes}\label{annexes}}

\hypertarget{annexe1}{%
\section{\texorpdfstring{Tableau des valeurs critiques de khi\textsuperscript{2}}{Tableau des valeurs critiques de khi2}}\label{annexe1}}

La courte syntaxe \includegraphics{Images/Rlogo.png} ci-dessous permet de générer un tableau avec les valeurs critiques du khi\textsuperscript{2} pour différents degrés de signification (valeurs de p).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(stargazer)}

\CommentTok{# vecteur pour les degrés de liberté de 1 à 30, puis 40 et 50}
\NormalTok{dl <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{30}\NormalTok{, }\DecValTok{40}\NormalTok{, }\DecValTok{50}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{250}\NormalTok{, }\DecValTok{500}\NormalTok{) }
\CommentTok{# la fonction qchisq permet d'obtenir la valeur théorique en fonction }
\CommentTok{# d'une valeur de p et d'un nombre de degrés de liberté}
\NormalTok{tableT <-}\StringTok{ }\KeywordTok{cbind}\NormalTok{(dl,}
                \DataTypeTok{p0.05 =}  \KeywordTok{round}\NormalTok{(}\KeywordTok{qchisq}\NormalTok{(}\DataTypeTok{p=}\FloatTok{0.95}\NormalTok{,  }\DataTypeTok{df=}\NormalTok{dl, }\DataTypeTok{lower.tail =} \OtherTok{FALSE}\NormalTok{),}\DecValTok{3}\NormalTok{),}
                \DataTypeTok{p0.01 =}  \KeywordTok{round}\NormalTok{(}\KeywordTok{qchisq}\NormalTok{(}\DataTypeTok{p=}\FloatTok{0.99}\NormalTok{,  }\DataTypeTok{df=}\NormalTok{dl, }\DataTypeTok{lower.tail =} \OtherTok{FALSE}\NormalTok{),}\DecValTok{3}\NormalTok{),}
                \DataTypeTok{p0.001 =} \KeywordTok{round}\NormalTok{(}\KeywordTok{qchisq}\NormalTok{(}\DataTypeTok{p=}\FloatTok{0.999}\NormalTok{, }\DataTypeTok{df=}\NormalTok{dl, }\DataTypeTok{lower.tail =} \OtherTok{FALSE}\NormalTok{),}\DecValTok{3}\NormalTok{))}
\CommentTok{# Impression du tableau avec la library stargazer}
\KeywordTok{stargazer}\NormalTok{(tableT, }\DataTypeTok{type=}\StringTok{"text"}\NormalTok{, }\DataTypeTok{summary=}\OtherTok{FALSE}\NormalTok{, }\DataTypeTok{rownames=}\OtherTok{FALSE}\NormalTok{, }\DataTypeTok{align =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{digits =} \DecValTok{3}\NormalTok{,}
          \DataTypeTok{title=}\StringTok{"Distribution des valeurs critiques du Khi2"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:tableCritiqueT}Distribution des valeurs critiques du khi2}
\centering
\begin{tabular}[t]{rrrr}
\toprule
dl & p=0,05 & p=0,01 & p=0,001\\
\midrule
1 & 0.004 & 0.000 & 0.000\\
2 & 0.103 & 0.020 & 0.002\\
3 & 0.352 & 0.115 & 0.024\\
4 & 0.711 & 0.297 & 0.091\\
5 & 1.145 & 0.554 & 0.210\\
\addlinespace
6 & 1.635 & 0.872 & 0.381\\
7 & 2.167 & 1.239 & 0.598\\
8 & 2.733 & 1.646 & 0.857\\
9 & 3.325 & 2.088 & 1.152\\
10 & 3.940 & 2.558 & 1.479\\
\addlinespace
11 & 4.575 & 3.053 & 1.834\\
12 & 5.226 & 3.571 & 2.214\\
13 & 5.892 & 4.107 & 2.617\\
14 & 6.571 & 4.660 & 3.041\\
15 & 7.261 & 5.229 & 3.483\\
\addlinespace
16 & 7.962 & 5.812 & 3.942\\
17 & 8.672 & 6.408 & 4.416\\
18 & 9.390 & 7.015 & 4.905\\
19 & 10.117 & 7.633 & 5.407\\
20 & 10.851 & 8.260 & 5.921\\
\addlinespace
21 & 11.591 & 8.897 & 6.447\\
22 & 12.338 & 9.542 & 6.983\\
23 & 13.091 & 10.196 & 7.529\\
24 & 13.848 & 10.856 & 8.085\\
25 & 14.611 & 11.524 & 8.649\\
\addlinespace
26 & 15.379 & 12.198 & 9.222\\
27 & 16.151 & 12.879 & 9.803\\
28 & 16.928 & 13.565 & 10.391\\
29 & 17.708 & 14.256 & 10.986\\
30 & 18.493 & 14.953 & 11.588\\
\addlinespace
40 & 26.509 & 22.164 & 17.916\\
50 & 34.764 & 29.707 & 24.674\\
100 & 77.929 & 70.065 & 61.918\\
250 & 214.392 & 200.939 & 186.554\\
500 & 449.147 & 429.388 & 407.947\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{annexe2}{%
\section{Tableau des valeurs critiques de F}\label{annexe2}}

La courte syntaxe \includegraphics{Images/Rlogo.png} ci-dessous permet de générer un tableau avec les valeurs critiques de F avec \emph{p}=0,05.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dl1 <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{25}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{50}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{500}\NormalTok{)}
\NormalTok{dl2 <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{30}\NormalTok{, }\DecValTok{40}\NormalTok{, }\DecValTok{50}\NormalTok{, }\DecValTok{100}\NormalTok{)}
\NormalTok{matrice <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\DataTypeTok{ncol=}\KeywordTok{length}\NormalTok{(dl1), }\DataTypeTok{nrow=}\KeywordTok{length}\NormalTok{(dl2), }\DataTypeTok{byrow =} \OtherTok{TRUE}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{(r }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\KeywordTok{length}\NormalTok{(dl1))\{}
  \ControlFlowTok{for}\NormalTok{(c }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\KeywordTok{length}\NormalTok{(dl2))\{}
\NormalTok{    matrice[c,r] <-}\StringTok{ }\KeywordTok{round}\NormalTok{(}\KeywordTok{qf}\NormalTok{(}\DataTypeTok{p=}\FloatTok{0.05}\NormalTok{, dl1[r], dl2[c], }\DataTypeTok{lower.tail =} \OtherTok{FALSE}\NormalTok{),}\DecValTok{2}\NormalTok{)}
\NormalTok{  \}}
\NormalTok{\}}

\NormalTok{tableF_p0}\FloatTok{.05}\NormalTok{ <-}\StringTok{ }\KeywordTok{as.data.frame}\NormalTok{(matrice, }\DataTypeTok{row.names =} \KeywordTok{paste0}\NormalTok{(}\StringTok{"dl2="}\NormalTok{,dl2, }\DataTypeTok{sep=}\StringTok{""}\NormalTok{))}
\KeywordTok{colnames}\NormalTok{(tableF_p0}\FloatTok{.05}\NormalTok{) <-}\StringTok{ }\KeywordTok{paste0}\NormalTok{(}\StringTok{"dl1="}\NormalTok{,dl1, }\DataTypeTok{sep=}\StringTok{""}\NormalTok{)}

\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
  \KeywordTok{head}\NormalTok{(tableF_p0}\FloatTok{.05}\NormalTok{, }\DataTypeTok{n=}\KeywordTok{nrow}\NormalTok{(tableF_p0}\FloatTok{.05}\NormalTok{)), }\DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
  \DataTypeTok{row.names =} \OtherTok{TRUE}\NormalTok{,}
  \DataTypeTok{caption =} \StringTok{'Distribution des valeurs critiques de F avec p=0,05'}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:tableCritiqueF}Distribution des valeurs critiques de F avec p=0,05}
\centering
\begin{tabular}[t]{lrrrrrrrrrrrrrrrrr}
\toprule
  & dl1=1 & dl1=2 & dl1=3 & dl1=4 & dl1=5 & dl1=6 & dl1=7 & dl1=8 & dl1=9 & dl1=10 & dl1=15 & dl1=20 & dl1=25 & dl1=30 & dl1=50 & dl1=100 & dl1=500\\
\midrule
dl2=1 & 161.45 & 199.50 & 215.71 & 224.58 & 230.16 & 233.99 & 236.77 & 238.88 & 240.54 & 241.88 & 245.95 & 248.01 & 249.26 & 250.10 & 251.77 & 253.04 & 254.06\\
dl2=2 & 18.51 & 19.00 & 19.16 & 19.25 & 19.30 & 19.33 & 19.35 & 19.37 & 19.38 & 19.40 & 19.43 & 19.45 & 19.46 & 19.46 & 19.48 & 19.49 & 19.49\\
dl2=3 & 10.13 & 9.55 & 9.28 & 9.12 & 9.01 & 8.94 & 8.89 & 8.85 & 8.81 & 8.79 & 8.70 & 8.66 & 8.63 & 8.62 & 8.58 & 8.55 & 8.53\\
dl2=4 & 7.71 & 6.94 & 6.59 & 6.39 & 6.26 & 6.16 & 6.09 & 6.04 & 6.00 & 5.96 & 5.86 & 5.80 & 5.77 & 5.75 & 5.70 & 5.66 & 5.64\\
dl2=5 & 6.61 & 5.79 & 5.41 & 5.19 & 5.05 & 4.95 & 4.88 & 4.82 & 4.77 & 4.74 & 4.62 & 4.56 & 4.52 & 4.50 & 4.44 & 4.41 & 4.37\\
\addlinespace
dl2=6 & 5.99 & 5.14 & 4.76 & 4.53 & 4.39 & 4.28 & 4.21 & 4.15 & 4.10 & 4.06 & 3.94 & 3.87 & 3.83 & 3.81 & 3.75 & 3.71 & 3.68\\
dl2=7 & 5.59 & 4.74 & 4.35 & 4.12 & 3.97 & 3.87 & 3.79 & 3.73 & 3.68 & 3.64 & 3.51 & 3.44 & 3.40 & 3.38 & 3.32 & 3.27 & 3.24\\
dl2=8 & 5.32 & 4.46 & 4.07 & 3.84 & 3.69 & 3.58 & 3.50 & 3.44 & 3.39 & 3.35 & 3.22 & 3.15 & 3.11 & 3.08 & 3.02 & 2.97 & 2.94\\
dl2=9 & 5.12 & 4.26 & 3.86 & 3.63 & 3.48 & 3.37 & 3.29 & 3.23 & 3.18 & 3.14 & 3.01 & 2.94 & 2.89 & 2.86 & 2.80 & 2.76 & 2.72\\
dl2=10 & 4.96 & 4.10 & 3.71 & 3.48 & 3.33 & 3.22 & 3.14 & 3.07 & 3.02 & 2.98 & 2.85 & 2.77 & 2.73 & 2.70 & 2.64 & 2.59 & 2.55\\
\addlinespace
dl2=11 & 4.84 & 3.98 & 3.59 & 3.36 & 3.20 & 3.09 & 3.01 & 2.95 & 2.90 & 2.85 & 2.72 & 2.65 & 2.60 & 2.57 & 2.51 & 2.46 & 2.42\\
dl2=12 & 4.75 & 3.89 & 3.49 & 3.26 & 3.11 & 3.00 & 2.91 & 2.85 & 2.80 & 2.75 & 2.62 & 2.54 & 2.50 & 2.47 & 2.40 & 2.35 & 2.31\\
dl2=13 & 4.67 & 3.81 & 3.41 & 3.18 & 3.03 & 2.92 & 2.83 & 2.77 & 2.71 & 2.67 & 2.53 & 2.46 & 2.41 & 2.38 & 2.31 & 2.26 & 2.22\\
dl2=14 & 4.60 & 3.74 & 3.34 & 3.11 & 2.96 & 2.85 & 2.76 & 2.70 & 2.65 & 2.60 & 2.46 & 2.39 & 2.34 & 2.31 & 2.24 & 2.19 & 2.14\\
dl2=15 & 4.54 & 3.68 & 3.29 & 3.06 & 2.90 & 2.79 & 2.71 & 2.64 & 2.59 & 2.54 & 2.40 & 2.33 & 2.28 & 2.25 & 2.18 & 2.12 & 2.08\\
\addlinespace
dl2=16 & 4.49 & 3.63 & 3.24 & 3.01 & 2.85 & 2.74 & 2.66 & 2.59 & 2.54 & 2.49 & 2.35 & 2.28 & 2.23 & 2.19 & 2.12 & 2.07 & 2.02\\
dl2=17 & 4.45 & 3.59 & 3.20 & 2.96 & 2.81 & 2.70 & 2.61 & 2.55 & 2.49 & 2.45 & 2.31 & 2.23 & 2.18 & 2.15 & 2.08 & 2.02 & 1.97\\
dl2=18 & 4.41 & 3.55 & 3.16 & 2.93 & 2.77 & 2.66 & 2.58 & 2.51 & 2.46 & 2.41 & 2.27 & 2.19 & 2.14 & 2.11 & 2.04 & 1.98 & 1.93\\
dl2=19 & 4.38 & 3.52 & 3.13 & 2.90 & 2.74 & 2.63 & 2.54 & 2.48 & 2.42 & 2.38 & 2.23 & 2.16 & 2.11 & 2.07 & 2.00 & 1.94 & 1.89\\
dl2=20 & 4.35 & 3.49 & 3.10 & 2.87 & 2.71 & 2.60 & 2.51 & 2.45 & 2.39 & 2.35 & 2.20 & 2.12 & 2.07 & 2.04 & 1.97 & 1.91 & 1.86\\
\addlinespace
dl2=21 & 4.32 & 3.47 & 3.07 & 2.84 & 2.68 & 2.57 & 2.49 & 2.42 & 2.37 & 2.32 & 2.18 & 2.10 & 2.05 & 2.01 & 1.94 & 1.88 & 1.83\\
dl2=22 & 4.30 & 3.44 & 3.05 & 2.82 & 2.66 & 2.55 & 2.46 & 2.40 & 2.34 & 2.30 & 2.15 & 2.07 & 2.02 & 1.98 & 1.91 & 1.85 & 1.80\\
dl2=23 & 4.28 & 3.42 & 3.03 & 2.80 & 2.64 & 2.53 & 2.44 & 2.37 & 2.32 & 2.27 & 2.13 & 2.05 & 2.00 & 1.96 & 1.88 & 1.82 & 1.77\\
dl2=24 & 4.26 & 3.40 & 3.01 & 2.78 & 2.62 & 2.51 & 2.42 & 2.36 & 2.30 & 2.25 & 2.11 & 2.03 & 1.97 & 1.94 & 1.86 & 1.80 & 1.75\\
dl2=25 & 4.24 & 3.39 & 2.99 & 2.76 & 2.60 & 2.49 & 2.40 & 2.34 & 2.28 & 2.24 & 2.09 & 2.01 & 1.96 & 1.92 & 1.84 & 1.78 & 1.73\\
\addlinespace
dl2=26 & 4.23 & 3.37 & 2.98 & 2.74 & 2.59 & 2.47 & 2.39 & 2.32 & 2.27 & 2.22 & 2.07 & 1.99 & 1.94 & 1.90 & 1.82 & 1.76 & 1.71\\
dl2=27 & 4.21 & 3.35 & 2.96 & 2.73 & 2.57 & 2.46 & 2.37 & 2.31 & 2.25 & 2.20 & 2.06 & 1.97 & 1.92 & 1.88 & 1.81 & 1.74 & 1.69\\
dl2=28 & 4.20 & 3.34 & 2.95 & 2.71 & 2.56 & 2.45 & 2.36 & 2.29 & 2.24 & 2.19 & 2.04 & 1.96 & 1.91 & 1.87 & 1.79 & 1.73 & 1.67\\
dl2=29 & 4.18 & 3.33 & 2.93 & 2.70 & 2.55 & 2.43 & 2.35 & 2.28 & 2.22 & 2.18 & 2.03 & 1.94 & 1.89 & 1.85 & 1.77 & 1.71 & 1.65\\
dl2=30 & 4.17 & 3.32 & 2.92 & 2.69 & 2.53 & 2.42 & 2.33 & 2.27 & 2.21 & 2.16 & 2.01 & 1.93 & 1.88 & 1.84 & 1.76 & 1.70 & 1.64\\
\addlinespace
dl2=40 & 4.08 & 3.23 & 2.84 & 2.61 & 2.45 & 2.34 & 2.25 & 2.18 & 2.12 & 2.08 & 1.92 & 1.84 & 1.78 & 1.74 & 1.66 & 1.59 & 1.53\\
dl2=50 & 4.03 & 3.18 & 2.79 & 2.56 & 2.40 & 2.29 & 2.20 & 2.13 & 2.07 & 2.03 & 1.87 & 1.78 & 1.73 & 1.69 & 1.60 & 1.52 & 1.46\\
dl2=100 & 3.94 & 3.09 & 2.70 & 2.46 & 2.31 & 2.19 & 2.10 & 2.03 & 1.97 & 1.93 & 1.77 & 1.68 & 1.62 & 1.57 & 1.48 & 1.39 & 1.31\\
\bottomrule
\end{tabular}
\end{table}

  \bibliography{book.bib}

\printindex

\end{document}
