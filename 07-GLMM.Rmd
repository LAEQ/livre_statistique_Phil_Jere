# Régressions à effets mixtes (GLMM) et régression multiniveaux  {#chap07}

Dans les deux chapitres précédents, nous avons consécutivement présenté la méthode de la régression linéaire simple (LM) ainsi que son extension : les modèles linéaires généralisés (GLM). Dans ce chapitre, nous poursuivons sur cette voie avec deux nouvelles extensions : les modèles généralisés à effet mixtes et les modèles multiniveaux.

## Introduction

### Indépendance des observations et effets de groupes

Nous avons vu dans les précédents chapitres que l'indépendance des observations est une condition d'application commune à l'ensemble des modèles de régression. Cette condition implique ainsi que chaque unité d'observation de notre jeu de données est indépendante des autres ; en d'autres termes, qu'elle ne soit associée à aucune autre observation par un lien de dépendance. Prenons un exemple concret pour illustrer ce concept. Admettons que nous nous intéressons à la performance scolaire d'élèves de secondaire à Montréal. Pour cela, nous collectons la moyenne des résultats aux examens du Ministère de tous les élèves des différentes commissions scolaires de l'île de Montréal. Chaque élève appartient à une classe spécifique, et chaque classe se situe dans une école spécifique. Les classes constituent des environnements particuliers, la performance des élèves y est influencée par un ensemble de facteurs comme l'enseignant et les relations avec les autres élèves. Deux élèves provenant d'une même classe sont donc liés par une forme de structure propre à leur classe et ne peuvent pas être considérés comme indépendants. De même, l'école constitue un environnement particulier pouvant influencer la performance des élèves du fait de moyens financiers plus importants ou d'une localisation minimisant certaines nuisances à l'apprentissage comme le bruit. À nouveau, deux élèves provenant d'une même école partagent une forme de structure qui cette fois-ci est propre à leur école. Si nous collections des données pour l'ensemble du Canada, nous pourrions étendre ce raisonnement aux villes dans lesquelles les écoles se situent et aux provinces.

Dans cet exemple, la dépendance entre les données est provoquée par un effet de groupe : il est possible de rassembler les observations dans des ensembles (classes et écoles) influençant vraisemblablement la variable étudiée (performance scolaire). Les effets des classes et des écoles ne sont cependant pas intrinsèques aux élèves. En effet, il est possible de changer un élève de classe ou d'école, mais pas de changer son sexe, ou sa situation familiale. Il est ainsi possible de distinguer la population des élèves, la population des classes, et la population des écoles (\@ref(fig:glmmecoles)). Ces effets de groupes sont plus la règle que l'exception dans l'analyse de données en sciences sociales ce qui met à mal l'hypothèse d'indépendance des observations. Notez que les effets de groupes ne sont pas les seules formes de structures remettant en cause l'indépendance des observations. Il existe également des structures temporelles (deux observations proches dans le temps ont plus de chances de se ressembler) et spatiales (deux observations proches dans l'espace ont plus de chances de se ressembler). Cependant, le cas de la dépendance temporelle et spatiale n'est pas couvert dans ce livre, car complexes et elles mériteraient un ouvrage dédié.

```{r glmmecoles, echo=FALSE, fig.align='center', fig.cap="Structure hiérarchique entre élèves, classes et écoles", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}
library(dplyr)
knitr::include_graphics('images/glmm/Hierarchie_Ecoles.png', dpi = NA)
```

::: {.bloc_aller_loin data-latex=""}
**La notion de pseudo-réplication**

Les effets de dépendance causés par des structures de groupes, temporelles ou spatiales sont regroupées sous le terme de pseudo-réplication. Il est intéressant de se pencher sur la signification de ce mot pour comprendre le problème intrinsèque causé par la dépendance entre les observations et son impact sur l'inférence.

Reprenons l'exemple des élèves et de la performance scolaire et admettons que nous souhaitons estimer la moyenne générale de l'ensemble des élèves sur l'île de Montréal, mais que nous ne disposons pas du jeu de données complet. Nous devons donc collecter un échantillon suffisamment grand pour estimer la moyenne pour l'ensemble de cette population. Raisonnons en termes de quantité d'informations. Si nous ne disposons d'aucune observation (nous n'avons encore interrogé aucun élève), cette quantité est de 0. Si nous interrogeons un premier élève, nous obtenons une donnée supplémentaire et donc un point d'information supplémentaire (+1). Admettons maintenant que nous collectons 30 observations dans une école, 10 dans une seconde et 5 dans une troisième. A priori, nous pourrions dire que nous avons ajouté 45 points d'information à notre total de connaissance. Ce serait le cas si les observations étaient indépendantes les unes des autres. Dans un tel contexte, chaque observation ajoute la même quantité d'information. Cependant, puisque les élèves issus d'une même école ont plus de chance de se ressembler, interroger les élèves d'une même école apporte moins d'information. Notez que plus la ressemblance entre les élèves d'une même école est forte, plus la quantité d'information est réduite. Nous sommes donc loin de disposer d'une quantité d'information égale à 45. Chaque réplication de l'expérience (demander à un élève sa moyenne annuelle) n'apporte pas autant d'information qu'attendu si les observations étaient indépendantes, c'est pourquoi on parle de **pseudo-réplication**.

La pseudo-réplication impacte directement l'inférence statistique puisque le calcul des différents tests statistiques assume que chaque observation apporte autant d'information que les autres. En cas de présence de pseudo-réplication, la quantité d'information présente dans l'échantillon est plus petite qu'attendu. Il est possible de voir cela comme une forme de surestimation de la taille de l'échantillon. En cas de pseudo-réplication nous disposons en réalité de moins de données que ce que l'on attendrait d'un échantillon de cette taille si les observations étaient indépendantes. La conséquence est la sous-estimation de la variabilité réelle des données et l'augmentation des risques de trouver des effets significatifs dans l'échantillon alors qu'ils ne le sont pas pour l'ensemble de la population.

:::

### Terminologie : effets fixes et effets aléatoires

Puisque les effets des classes et des écoles ne sont pas propres aux élèves, il convient de les introduire différemment dans les modèles de régression. Nous appelons un effet fixe, un effet qui est propre aux observations que nous étudions et un effet aléatoire, un effet provoqué par une structure externe (effet de groupe, effet temporel, effet spatial). Un modèle combinant à la fois des effets fixes et des effets aléatoires est appelé un modèle à effets mixtes, ou GLMM pour *Generalized Linear Mixed Model*. En sciences sociales, on utilise aussi souvent le terme de modèle hiérarchique ou multiniveau. Tous les modèles que nous avons ajustés dans les sections précédentes ne comprenaient que des effets fixes alors qu'à plusieurs reprises, des effets aléatoires induits par l'existence de structure de groupe auraient pu (dû) être utilisés. Prenons pour exemple le modèle logistique binomial visant à prédire la probabilité d'utiliser le vélo comme mode de transport pour son trajet le plus fréquent (REF). La variable multinomiale *Pays*, représentant le pays dans lequel les personnes interrogées résident a été introduite comme un effet fixe. Cependant, l'effet du pays ne constitue pas une caractéristique propre aux individus, il s'agit davantage d'un agrégat complexe mêlant culture, météorologie, orientation des politiques publiques et formes urbaines. À l'inverse, le sexe ou l'âge sont bien des caractéristiques intrinsèques des individus et peuvent être considérés comme des effets fixes.

Notez que l'utilisation du terme effet aléatoire peut porter à confusion, car différentes utilisations en sont faites en fonction du champ d'études. Parmi les différentes définitions relevées par @gelman2005analysis d'un effet aléatoire, il est possible de retrouver les suivantes : 

* Les effets fixes sont identiques pour tous les individus alors que les effets aléatoires varient (définition 1).

* Les effets sont fixes s'ils sont intéressants en eux-mêmes, et les effets sont aléatoires si on s'intéresse à la population dont ils sont issus (définition 2).

* Lorsqu'un échantillon couvre une grande part de la population, la variable correspondante est un effet fixe. Si l'échantillon couvre une faible part de la population, l'effet est aléatoire (définition 3).

* Si l'effet est supposé provenir d'une variable aléatoire, alors il s'agit d'un effet aléatoire (définition 4).

* Les effets fixes sont estimés par la méthode des moindres carrés par maximum de vraisemblance alors que les effets aléatoires sont estimés avec régularisation (*shrinkage*) (définition 5).

Il est ainsi possible de se retrouver dans des cas où un effet serait classé comme fixe selon une définition et aléatoire selon une autre. La deuxième définition suppose même qu'un effet peut être aléatoire ou fixe selon l'objectif central de l'étude. La dernière définition a l'avantage d'être mathématique, mais ne permet pas de décider si un effet doit être traité comme aléatoire ou fixe. Nous ne proposons pas ici de clore le débat, mais plutôt de donner quelques pistes de réflexion pour décider si un effet doit être modélisé comme fixe ou aléatoire :

* Est-ce que l'effet en question est propre aux individus étudiés ou est externe aux individus. S'il est propre aux individus, il s'agit plus certainement d'un effet fixe. À titre d'exemple, on ne peut pas changer le sexe d'un individu, mais on peut certainement changer sa ville de résidence.
* Existe-t-il un nombre bien arrêté de catégories possibles pour l'effet en question ? Si oui, il s'agit plus certainement d'un effet fixe. Toujours avec le même exemple, il y a un nombre bien arrêté de catégories pour la variable sexe, mais pour la variable pays, de nombreuses autres valeurs auraient pu être ajoutées. Il est également possible de se demander s'il semble cohérent d'effectuer un échantillonnage sur les catégories en question. Dans le cas des pays, nous pourrions mener une étude à l'échelle des pays et collecter des données sur un échantillon de l'ensemble des pays. Il existe donc une population de pays, ce que nous ne pouvons pas affirmer pour la variable sexe.
* L'effet en question est direct ou indirect ? Dans le second cas, l'effet en question est un agglomérat complexe découlant de plusieurs processus n'ayant pas été mesurés directement, ce qui correspond davantage à un effet aléatoire. Ainsi, l'effet du pays de résidence des individus sur leur probabilité d'utiliser le vélo est bien une agglomération complexe d'effets (culture, météorologie, orientation des politiques publiques, formes urbaines, etc.) n'ayant pas tous été mesurés. À l'inverse, l'âge d'un individu a bien un effet direct sur sa probabilité d'utiliser le vélo.
* L'effet est-il le même pour tous les individus, ou doit-il varier selon le groupe dans lequel l'individu se situe ? Si un effet doit varier en fonction d'un groupe, il s'apparente davantage à un effet aléatoire. Pour reprendre l'exemple de l'âge, nous pourrions décider que cette caractéristique des individus n'a peut-être pas le même impact en fonction du pays dans lequel vit l'individu et l'ajouter au modèle comme un effet aléatoire.

Vous comprendrez donc qu'une partie non négligeable du choix entre effet fixe ou aléatoire réside dans le cadre théorique à l'origine du modèle. Maintenant que cette distinction conceptuelle a été détaillée, nous pouvons passer à la présentation statistique des modèles GLMM.

## Principes de base des GLMM {#sect071}

Un GLMM est donc un modèle GLM introduisant à la fois des effets fixes et des effets aléatoires. Si l'on ne considère que les effets de groupes, un GLMM peut avoir trois formes : constantes aléatoires, pentes aléatoires et constantes et pentes aléatoires. Nous présentons ces trois formes ici en reprenant l'exemple théorique ci-dessus avec des élèves intégrés dans des classes pour lesquels nous nous intéressons à leur niveau de performance à l'examen ministériel de mathématique.

### GLMM avec constantes aléatoires

Il s'agit de la forme la plus simple d'un GLMM, plus spécifiquement, elle autorise le modèle à avoir une constante différente pour chaque catégorie d'une variable multinomiale. En d'autres termes, nous tentons d'ajouter dans le modèle l'idée que chaque classe a une moyenne différente en termes de performance à l'examen de mathématique. Il est possible assez facilement de visualiser ce que cela signifie avec un exemple graphique. Admettons que nous modélisons le score obtenu par des élèves de secondaire à l'examen ministériel de mathématique à partir d'une autre variable continue représentant le temps de travail moyen par semaine en dehors des heures de classe et d'une variable catégorielle représentant dans quelle classe se trouve chaque élève. Notez qu'il ne s'agit pas ici de vraies données, mais de simples simulations utilisées à titre d'illustration. Si nous ne tenons pas compte des classes nous pouvons ajuster une simple régression linéaire entre nos deux variables continues comme le propose la figure \@ref(fig:randominter1).

```{r randominter1, echo=FALSE, fig.align='center', fig.cap="Influence du temps de travail sur la performance scolaire d'élèves", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}

set.seed(11)

## Générer des effets aléatoires
groups <-  c("A","B","C","D","E","F","G","H")
sig2 <- matrix(c(12, 0.1,
                 0.1, 0.5), 
               nrow = 2, ncol = 2)
mu2 <- c(inter = 0, coeff = 0)
df2 <- data.frame(data.frame(MASS::mvrnorm(n = length(groups), mu = mu2, Sigma = sig2)))
df2$name <- groups

colors <- hcl.colors(length(groups), palette = "Dynamic")
names(colors) <- groups

## Générer des données
n <- 300
df <- data.frame(
  X = rnorm(n,8,2),
  group = sample(df2$name,size = n, replace = T)
)

df3 <- merge(df,df2, by.x="group",by.y="name")
df3$Y <- 65 + df3$X*(1.5+df3$coeff) + df3$inter + rnorm(n = n, mean = 0, sd = 8)
df3$Y2 <- ifelse(df3$Y>=100, 100, df3$Y)

## Afficher le tout !
ggplot(data = df3)+
  geom_point(aes(x = X, y = Y2, color = group), size = 1) + 
  geom_smooth(aes(x = X, y = Y2),method='lm', formula= y~x, se=F, color = "black", size = 1.2)+
  scale_color_manual(values = colors)+
  labs(y = "Note à l'examen (%)", x = "Temps de travail (heures)", color = "Classe")
```

On constate que notre modèle semble bien identifier la relation positive entre le temps de travail et le niveau de performance, mais la droite de régression est très éloignée de chaque point, nous avons donc énormément d'erreurs de prédiction et donc des résidus importants. Jusqu'ici nous avons vu que nous pouvions ajouter un prédicteur et intégrer l'effet des classes comme un effet fixe.

```{r randominter2, echo=FALSE, fig.align='center', fig.cap="Influence du temps de travail sur la performance scolaire d'élèves en tenant compte de l'effet de leur classe (effet fixe)", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}

model <- lm(Y2 ~ X + group, data = df3)
b1 <- model$coefficients[[2]]
diffs <- c(0,model$coefficients[c(3:length(model$coefficients))])
diffs <- diffs + model$coefficients[[1]]

df4 <- data.frame(
  inter = diffs,
  slope = b1,
  group = names(colors)
)

ggplot(data = df3)+
  geom_point(aes(x = X, y = Y2, color = group), alpha = 0.8, size = 1)+
  geom_abline(data = df4, mapping = aes(intercept = inter, slope = slope, color = group),size = 1.2)+ 
  scale_color_manual(values =colors)+
  labs(y = "Note à l'examen (%)", x = "Temps de travail (heures)", color = "Classe")
```

Cet ajustement constitue une nette amélioration du modèle. Prenons un instant pour reformuler clairement notre modèle à effets fixes : 

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma)\\
&g(\mu) = \beta_0 + \beta_1 x_1 + \sum^k_{j=1}{\beta_j x_{2j}}\\
&g(x) = x
\end{aligned}
(\#eq:glmm1)
\end{equation}
\normalsize

avec $x_1$ le temps de travail et $x_2$ la classe ayant *k-1* modalités (puisqu'une modalité est la référence). Nous  ajustons ainsi un coefficient pour chaque classe qui va avoir pour effet de tirer vers le haut ou vers le bas la prédiction du modèle en fonction de la classe. Cet effet est pour l'instant fixe, mais conceptuellement, nous avons déterminés dans les sections précédentes qu'il serait conceptuellement plus approprié de le traiter comme un effet aléatoire.

Passons à présent à la reformulation de ce modèle en transformant l'effet fixe de la classe en effet aléatoire.

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma_e)\\
&g(\mu) = \beta_0 + \beta_1 x_1 + \upsilon \\
&\upsilon \sim Normal(0, \sigma_{\upsilon})) \\
&g(x) = x
\end{aligned}
(\#eq:glmm2)
\end{equation}
\normalsize

Remarquez que l'effet fixe de la classe $\sum^k_{j=1}{\beta_j x_{2j}}$ a été remplacé par $\upsilon$ qui est un terme aléatoire propre aux classes et qui suit une distribution normale centrée sur 0. En d’autres termes, cela signifie que l'effet des classes sur la performance des élèves suit une distribution normale et que si l'on moyennait l'effet de toutes classes, cet effet serait de 0. Nous ne modélisons donc plus l'effet moyen de chaque classe comme dans le modèle à effets fixes, mais la variabilité de l'effet des classes : $\sigma_{\upsilon}$. Notre modèle a donc deux variances, une au niveau des élèves ($\sigma_e$) et une au niveau de classes ($\sigma_{\upsilon}$). Cette particularité explique souvent pourquoi ce type de modèle est appelé un modèle hiérarchique ou un modèle de partition de la variance. Cette information est particulièrement intéressante car elle permet de calculer dans le cas d'un GLMM gaussien, la part de la variance présente au niveau des élèves et celle au niveau des classes.

Selon cette formulation, les constantes propres à chaque classe sont issues d'une distribution normale (nous reviendrons d'ailleurs sur ce choix plus tard), mais elles n'apparaissent pas directement dans le modèle. Ces paramètres ne sont plus estimés directement dans le modèle, mais a posteriori à partir des prédictions du modèle, et sont appelés *Best Linear Unbiased Predictor* (BLUP). Ces dernières précisions devraient d'ailleurs mieux vous aider à comprendre l'origine des définitions 1, 2 et 4 que nous avions mentionnées précédemment.

```{r randominter3, echo=FALSE, fig.align='center', fig.cap="Influence du temps de travail sur la performance scolaire d'élèves en tenant compte de l'effet de leur classe (effet aléatoire)", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}
library(lme4)

model2 <- lmer(Y2 ~ X + (1|group), data = df3)

coeffs <- coef(model2)$group
df5 <- data.frame(
  inter = coeffs[,1],
  slope = coeffs[,2],
  group = rownames(coeffs)
)

ggplot(data = df3)+
  geom_point(aes(x = X, y = Y2, color = group), alpha = 0.8, size = 1)+
  geom_abline(data = df5, mapping = aes(intercept = inter, slope = slope, color = group),size = 1.2)+ 
  scale_color_manual(values = colors)+
  labs(y = "Score à l'examen (%)", x = "Temps de travail (heures)", color = "Classe")
```

En comparant les deux graphiques, la différence ne saute pas aux yeux; vous pourriez alors légitimement vous demander pourquoi tous ces efforts et cette complexité théorique pour une différence d'ajustement minime ? Trois arguments permettent de justifier l'utilisation de constantes aléatoire plutôt que d'effets fixes dans notre cas.

#### Resserrement (*shrinkage*) et mutualisation (*partial pooling*)

Le premier intérêt d'utiliser un effet aléatoire réside dans sa méthode d'estimation qui diffère largement d'un effet fixe. Il est assez facile de se représenter intuitivement la différence entre les deux. Dans le cas de nos élèves et de nos classes, lorsque l'effet des classes est estimé avec un effet fixe, l'effet de chaque classe est déterminé de façon totalement indépendante des autres classes. En d'autres termes, il n'est possible d'en apprendre plus sur une classe qu'en collectant des données dans cette classe (*separate pooling*). Si l'effet des classes est estimé comme un effet aléatoire, alors l'information entre les classes est mutualisée (*partial pooling*). L'idée étant que l'information que l'on apprend sur des élèves dans une classe est au moins en partie valide dans les autres classes également. Cette méthode d'estimation est particulièrement intéressante si nous ne disposons que de peu d'observations dans une classe puisque nous pouvons apprendre au moins une partie de l'effet de cette classe à partir des données des autres classes. Ceci n'est pas possible dans le cas d'un effet fixe où l'on traite chaque classe en silo. @mcelreath2020statistical écrit à ce sujet qu'un effet fixe « n'a pas de mémoire » et qu'il oublie tout ce qu'il a appris sur les classes lorsqu'il passe à une nouvelle classe. La conséquence de cette mutualisation de l'information est un resserrement (*shrinkage*) des effets des classes autour de leur moyenne. Cela signifie que les tailles des effets de chaque classe sont plus petites dans le cas d'un effet aléatoire que d'un effet fixe. Utiliser des effets aléatoires conduit donc à une estimation plus conservative de l'effet des classes. Nous pouvons le visualiser en comparant les effets de classes dans le modèle à effets mixtes et le modèle à effet fixes. La figure \@ref(fig:randominter5) montre clairement que les effets aléatoires tendent à se rapprocher (resserrement) de leur moyenne (ligne noire) et donc à renvoyer des effets moins extrêmes pour chaque classe. Cette explication est directement en lien avec la définition 5 d'un effet aléatoire vu précédemment.

```{r randominter5, echo=FALSE, fig.align='center', fig.cap="Comparaison des effets des classes pour le modèle à effets fixes versus le modèle effets aléatoires", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}
library(MuMIn)

r2s <- r.squaredGLMM(model2)

df6 <- data.frame(
  fixed = df4$inter,
  random = df5$inter,
  group = df4$group
)

ggplot() + 
  geom_point(data = df4, mapping = aes(x = inter, y = group,  color = "fixed")) +
  geom_point(data = df5, mapping = aes(x = inter, y = group, color = "random")) + 
  geom_vline(xintercept = mean(df4$inter)) + 
  labs(x = "effet de la classe", y = "classe", color = "type d'effet") + 
  scale_color_manual(values = c("fixed" = "red", random = "blue"), labels = c("fixe", "aléatoire"))

sigma_u <- as.data.frame(VarCorr(model2))$sdcor[[1]]
sigma_e <- as.data.frame(VarCorr(model2))$sdcor[[2]]
```
#### Prédiction pour de nouveaux groupes

Une autre retombée directe de la mutualisation de l'information est la capacité de modèle à envisager les effets plausibles pour de nouvelles classes. En effet, puisque nous avons approximé l'effet des classes sous forme d'une distribution normale dont nous connaissons la moyenne (0) et l'écart type ($\sigma_{\upsilon}$), nous pouvons simuler des données pour de nouvelles classes, ce que ne permet pas un effet fixe. Ce constat est d'ailleurs directement lié à la définition 3 des effets aléatoires vue précédemment. Dans notre cas, $\sigma_{\upsilon}$ = `r tofr(round(sigma_u,3))`, ce qui nous permet d'affirmer que dans 95% des classes, l'effet de la classe sur la performance scolaire doit se trouver entre -1.96 $\times$ `r tofr(round(sigma_u,3))` et +1,96 $\times$ `r tofr(round(sigma_u,3))`, soit l'intervalle [`r tofr(round(-1.96*sigma_u,3))`, `r tofr(round(1.96*sigma_u,3))`].

#### Partition de la variance

Un autre avantage net de l'effet aléatoire est l'estimation du paramètre $\sigma_{\upsilon}$, soit la variance au niveau des écoles. Ce dernier permet de calculer un indicateur très intéressant, soit l'**indice de corrélation intraclasse (ICC)** :

\footnotesize
\begin{equation}
ICC = \frac{\sigma_{\upsilon}}{\sigma_{\upsilon} + \sigma_{e}}
(\#eq:glmm3)
\end{equation}
\normalsize

Il s'agit donc du pourcentage de la variance présente au niveau des classes, qui peut être interprété comme le niveau de corrélation (de ressemblance) entre les élèves d'une même classe.

Dans notre cas, l'écart type est de `r tofr(round(sigma_u,3))` au niveau des classes et de `r tofr(round(sigma_e,3))` au niveau des élèves. Nous pouvons donc calculer l'ICC au niveau des classes avec la formule précédente : `r tofr(round(sigma_u,3))` / (`r tofr(round(sigma_u,3))` + `r tofr(round(sigma_e,3))`) = `r tofr(round(sigma_u /(sigma_u + sigma_e),3))`. Cela signifie que le niveau de corrélation entre deux élèves d'une même classe est de `r tofr(round(sigma_u /(sigma_u + sigma_e),3))` ou encore que `r tofr(round(sigma_u /(sigma_u + sigma_e),3)*100)`% de la variance de *Y* se situe au niveau des classes, ce qui est conséquent. Une telle information ne peut être extraite d'un modèle avec seulement des effets fixes. Notez ici que l'ICC peut être calculé pour chaque niveau d'un modèle à effet mixte. Dans notre exemple nous n'avons qu'un seul niveau au-dessus des élèves, soit les classes, mais nous pourrions étendre cette logique à des écoles par exemple. Notez également que cette formule de l'ICC n'est valide que pour un modèle pour lequel la distribution de la variable *Y* est normale. Des développements apparaissent pour proposer d'autres formulations adaptées à d'autres distributions (imaginons le cas d'une distribution de Poisson n'ayant pas de paramètre de variance !), mais il est également possible d'estimer l'ICC à partir des simulations issues du modèle [@NakagawaICC ; @aly2014reliability ; @stryhn2006interpretation ; @wu2012comparison]. L'idée générale reste d'expliquer la partition de la variance dans le modèle.

En plus de l'ICC, il est également possible de calculer les **R^2^ marginal et conditionnel** du modèle. Le premier représente la variance expliquée par le modèle si seulement les effets fixes sont pris en compte, et le second si les effets fixes et aléatoires sont pris en compte. Distinguer les deux sources d'information permet de mieux cerner dans notre cas l'importance du rôle des écoles dans la performance des élèves. Dans notre cas, nous obtenons un R^2^ marginal de `r tofr(round(r2s[[1]],3))` et un R^2^ conditionnel de `r tofr(round(r2s[[2]],3))`, ce qui nous confirme à nouveau que le rôle joué par la classe dans le niveau de performance est loin d'être négligeable.

### GLMM avec pentes aléatoires

Dans cette seconde version du GLMM, nous n'envisageons plus de faire varier une constante en fonction des classes, mais un coefficient en fonction des classes. Admettons ici que nous voulions tester si l'effet du temps de travail ($x_1$) sur la performance scolaire (*Y*) n'est pas constant partout et que dans certaines classes, le temps de travail par semaine et dehors de l'école est plus efficace que d'autres. L'idée sous-jacente est que nous n'observons pas de différence en termes de moyenne entre deux classes, mais en termes d'effet pour notre variable $x_1$. À nouveau, nous pourrions nous contenter d'effet un fixe pour intégrer cette idée dans notre modèle. Pour cela, nous avons simplement à ajouter une interaction entre notre variable quantitative temps de travail et notre variable qualitative classe. Nous obtenons le résultat décrit par la figure \@ref(fig:randomslope). Notez ici que la constante est bien la même pour chaque classe (l'ensemble des lignes s'intersecte à 0 sur l'axe des x), et que seule la pente change.

```{r randomslope, echo=FALSE, fig.align='center', fig.cap="Influence du temps de travail sur la performance scolaire d'élèves en interraction avec la classe (effet fixe)", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}

model <- lm(Y2 ~ X + X:group, data = df3)
inter <- model$coefficients[[1]]
b1 <- model$coefficients[[2]]
diffs <- c(0,model$coefficients[c(3:length(model$coefficients))])
diffs <- b1 + diffs

df4 <- data.frame(
  inter = inter,
  slope = diffs,
  group = names(colors)
)

ggplot(data = df3)+
  geom_point(aes(x = X, y = Y2, color = group), alpha = 0.8, size = 1)+
  geom_abline(data = df4, mapping = aes(intercept = inter, slope = slope, color = group),size = 1.2)+ 
  scale_color_manual(values =colors)+
  labs(y = "Score à l'examen (%)", x = "Temps de travail (heures)", color = "Classe") + 
  xlim(0,max(df3$X)+1)
```

La formulation de ce modèle à effets fixes seulement est la suivante : 

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma)\\
&g(\mu) = \beta_0 + \beta_1 x_1 + \sum^k_{j=1}{\beta_j x_{2j} x_1}\\
&g(x) = x
\end{aligned}
(\#eq:glmm4)
\end{equation}
\normalsize

On constate donc que nous avons un effet principal $\beta_1$ décrivant le lien entre temps de travail et le score obtenu à l'examen pour l'ensemble des élèves, ainsi qu'un bonus ou un malus sur cet effet $\beta_j$ s'appliquant en fonction de l'école. Nous pouvons reformuler ce modèle pour inclure cet effet spécifique par école comme un effet aléatoire.

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma_e)\\
&g(\mu) = \beta_0 + \beta_1 x_1 + \upsilon x_1 \\
&\upsilon \sim Normal(0,\sigma_{\upsilon})\\
&g(x) = x
\end{aligned}
(\#eq:glmm5)
\end{equation}
\normalsize

Nous formulons ici un modèle dans lequel la classe modifie l'impact de la variable temps d'étude sur la variable score à l'examen. L'effet moyen de $x_1$ est capté par le coefficient $\beta_1$, les bonus ou malus ajouté à cet effet par la classe sont issues d'une distribution normale centrée sur 0 avec un écart type $sigma_{\upsilon}$. À nouveau, l'idée est que si l'on moyennait l'effet de toutes les écoles, nous obtiendrions 0. À nouveau, le fait de modéliser cet effet comme un effet aléatoire nous permet de partitionner la variance, de mutualiser l'information entre les classes et de resserer l'estimation des effets des classes.

Les résultats pour ce second modèle sont présentés à la figure \@ref(fig:randomslope2), et une comparaison entre les estimations des effets fixes et des effets aléatoires est présentée à la figure \@ref(fig:randomslope3). Nous pouvons ainsi constater à nouveau l'effet de resseremment provoqué par l'effet aléatoire.

```{r randomslope2, echo=FALSE, fig.align='center', fig.cap="Influence du temps de travail sur la réussite scolaire d'élèves en interraction avec la classe (effet aléatoire)", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}

model2 <- lmer(Y2 ~ X + (-1+X|group), data = df3)
coeffs <- coef(model2)$group

df5 <- data.frame(
  inter = coeffs[,1],
  slope = coeffs[,2],
  group = rownames(coeffs)
)

ggplot(data = df3)+
  geom_point(aes(x = X, y = Y2, color = group), alpha = 0.8, size = 1)+
  geom_abline(data = df5, mapping = aes(intercept = inter, slope = slope, color = group),size = 1.2)+ 
  scale_color_manual(values =colors)+
  labs(y = "Score à l'examen (%)", x = "Temps de travail (heure)", color = "Classe") + 
  xlim(0,max(df3$X)+1)
```

```{r randomslope3, echo=FALSE, fig.align='center', fig.cap="Influence du temps de travail sur la réussite scolaire d'élèves en interraction avec la classe (effet aléatoire)", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}

df6 <- data.frame(
  fixed = df4$slope,
  random = df5$slope,
  group = df4$group
)

ggplot() + 
  geom_point(data = df4, mapping = aes(x = slope, y = group,  color = "fixed")) +
  geom_point(data = df5, mapping = aes(x = slope, y = group, color = "random")) + 
  geom_vline(xintercept = mean(df4$slope)) + 
  labs(x = "effet du temps de travail", y = "classe", color = "type d'effet") + 
  scale_color_manual(values = c("fixed" = "red", random = "blue"), labels = c("fixe", "aléatoire"))

rs2 <- r.squaredGLMM(model2)

```

Lorsque l'on intègre des pentes aléatoires dans un modèle, on fait face au problème suivant : la variance associée aux pentes aléatoire n'est pas fixe, mais proportionnelle à la variable *X* autorisée à varier. Si l'on compare la figure \@ref(fig:randominter3) (constantes aléatoires) et la figure \@ref(fig:randomslope2) (pentes aléatoires), on constate bien que la dispersion des prédictions du modèle (représentées par les lignes) augmente dans le cas de pentes aléatoires et reste identique dans le cas des constantes aléatoires. La conséquence pratique est qu'il existe potentiellement un nombre infini de valeur possible pour l'ICC. Dans ce contexte, il est préférable de laisser de coté cet indicateur et de ne reporter que les R^2^ marginal et conditionnel. Dans notre cas, nous obtenons les valeurs `r tofr(round(rs2[[1]],3))` et `r tofr(round(rs2[[2]],3))`, ce qui confirme une fois encore que le rôle joué par la classe est loin d'être négligeable puisqu'il permet d'expliquer près de `r tofr(round(rs2[[2]],3)*100)`% supplémentaire de variance comparativement au seuls effets fixes expliquant `r tofr(round(rs2[[1]],3)*100)`% de la variance du score obtenu à l'examen.


### GLMM avec constantes et pentes aléatoires

Vous l'aurez certainement deviné en lisant le titre de cette section, mais il est tout à fait possible de combiner à la fois des constantes et des pentes aléatoires dans un modèle. Cela augmente bien sûr la complexité du modèle et introduit quelques subtilités comme la notion de distribution normale multivariée, mais chaque chose en son temps.

Si l'on reprend notre exemple avec nos élèves et nos classes, combiner à la fois des constantes et des pentes aléatoires revient à formuler l'hypothèse que chaque classe a un effet sur la moyenne de la performance de ses élèves mais également un effet sur l'efficacté du temps de travail sur la performance. Il serait possible de créer un modèle avec uniquement des effets fixes tenant compte de ces deux aspects en ajoutant dans le modèle la variable multinomiale classe ainsi que son interraction avec la variable temps de travail. La formulation de ce modèle à effets fixes est la suivante : 

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma)\\
&g(\mu) = \beta_0 + \beta_1 x_1 + \sum^k_{j=1}{\beta_{2j}  x_{2j} + \beta_{3j} x_{2j}  x_1}\\
&g(x) = x
\end{aligned}
(\#eq:glmm6)
\end{equation}
\normalsize

Nous pouvons représenter les résultats de ce modèle avec la figure \@ref(fig:fullrandom1)

```{r fullrandom1, echo=FALSE, fig.align='center', fig.cap="Influence du temps de travail sur la performance scolaire d'élèves en tenant compte de l'effet de leur classe et de l'impact de la classe sur l'efficacité du temps de travail (effet fixe)", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}

model <- lm(Y2 ~ X*group, data = df3)
b1 <- model$coefficients[[2]]
inter <- model$coefficients[[1]]
inters <- c(0,model$coefficients[3:(2+length(colors)-1)])
coeffs <- c(0,model$coefficients[(2+length(colors)):length(model$coefficients)])

df4 <- data.frame(
  inter = inters + inter,
  slope = b1 + coeffs,
  group = names(colors)
)

ggplot(data = df3)+
  geom_point(aes(x = X, y = Y2, color = group), alpha = 0.8, size = 1)+
  geom_abline(data = df4, mapping = aes(intercept = inter, slope = slope, color = group),size = 1.2)+ 
  scale_color_manual(values =colors)+
  labs(y = "Note à l'examen (%)", x = "Temps de travail (heures)", color = "Classe")
```

Nous reformulons à présent ce modèle pour intégrer l'effet moyen de chaque classe (constante) et l'effet des classes sur l'efficacité du temps de travail (pente) comme deux effets aléatoires : 

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma)\\
&g(\mu) = \beta_0 + \upsilon_1 + (\beta_1 + \upsilon_2) x_1\\
&\left(\begin{array}{l}
\upsilon_{1} \\
\upsilon_{2}
\end{array}\right) \sim \mathcal{N}\left(\left(\begin{array}{l}
0 \\
0
\end{array}\right),\left(\begin{array}{cc}
\sigma_{\upsilon_1} & \sigma_{\upsilon_1\upsilon_2} \\
 \sigma_{\upsilon_1\upsilon_2} & \sigma_{\upsilon_1}
\end{array}\right)\right) \\
&g(x) = x
\end{aligned}
(\#eq:glmm7)
\end{equation}
\normalsize

Pas de panique ! Cette écriture peut être interprétée de la façon suivante : 

Les modèles comprends deux effets aléatoires, l'un faisant varier la constante en en fonction de l'école ($\upsilon_1$) et l'autre l'effet de l'école sur l'efficacité du temps de travail ($\upsilon_2$). Ces deux effets sont issus d'une distribution normale bivariée (une dimension par effet aléatoire). Cette distribution normale bivariée a donc deux moyennes et ces deux moyennes sont à 0 car comme nous l'avons vu dans les modèles précédents. Elle dispose également d'une variance par effet aléatoire ($\sigma_{\upsilon_1}$ et $\sigma_{\upsilon_2}$) et d'une covariance entre les deux effets aléatoires ($\sigma_{\upsilon_1\upsilon_2}$). Cette covariance permet de tenir compte du fait que potentiellement, les écoles avec une constante plus élevées pourraient systématique avoir un effet plus élevé ou plus faible sur l'efficacité du temps de travail. Cette formulation implique donc d'ajuster trois paramètres de variance : $\sigma_{\upsilon_1}$, $\sigma_{\upsilon_2}$ et $\sigma_{\upsilon_1\upsilon_2}$. Il peut arriver que nous ne disposions pas d'assez de données pour estimer ces trois paramètres, ou que estimons pour des raisons théorique, aucune corrélation ne soit attendue entre $\sigma_{\upsilon_1}$ et $\sigma_{\upsilon_2}$, dans ce cas, il est possible de fixer $\sigma_{\upsilon_1\upsilon_2}$ à 0, ce qui revient à indiquer au modèle que  $\sigma_{\upsilon_1}$ et $\sigma_{\upsilon_2}$ proviennent de deux distributions normales distinctes, nous pouvons donc écrire : 

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma)\\
&g(\mu) = \beta_0 + \upsilon_1 + (\beta_1 + \upsilon_2) x_1\\
&\left(\begin{array}{l}
\upsilon_{1} \\
\upsilon_{2}
\end{array}\right) \sim \mathcal{N}\left(\left(\begin{array}{l}
0 \\
0
\end{array}\right),\left(\begin{array}{cc}
\sigma_{\upsilon_1} & 0 \\
 0 & \sigma_{\upsilon_1}
\end{array}\right)\right) \\
&g(x) = x
\end{aligned}
(\#eq:glmm8)
\end{equation}
\normalsize

Ce qui est indentique à : 

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma)\\
&g(\mu) = \beta_0 + \upsilon_1 + (\beta_1 + \upsilon_2) x_1\\
&\upsilon_{1} \sim Normal(0,\sigma_{\upsilon_1}) \\
&\upsilon_{2} \sim Normal(0,\sigma_{\upsilon_2}) \\
&g(x) = x
\end{aligned}
(\#eq:glmm9)
\end{equation}
\normalsize

Nous avons déjà abordé la notion de covariance dans la section \@ref(sect041). Pour rappel, la covariance dépend de l'unité de base des deux variables sur laquelle elle est calculée. Ici il s'agit d'un coefficient et d'une constante, on préfère donc généralement la standardiser pour obtenir la corrélation entre les deux effets : 

\footnotesize
\begin{equation}
corr(\upsilon_1;\upsilon_2) = \frac{\sigma_{\upsilon_1\upsilon_2}}{\sqrt{\sigma_{\upsilon_1}}\sqrt{\sigma_{\upsilon_2}}}
(\#eq:glmm10)
\end{equation}
\normalsize

Si cette corrélation est positive, cela signifierait dans notre cas que dans les classes ayant tendance à avoir un effet positif sur la performance scolaire ont tendance à également positivement influencer l'efficacité du temps de travail. À l'inverse, une corrélation négative signifierait que l'efficacité du temps de travail a tendance à être plus faible dans les classes où la performance scolaire moyenne est élevée. Si la corrélation n'est pas significative, c'est que les deux effets sont indépendants l'un de l'autre.

Pour cet exemple, nous conservons la première formulation afin de montrer comment interpréter $\sigma_{\upsilon_1\upsilon_2}$, mais nous ne disposons probablement pas de suffisamment de classes différentes pour estimer correctement ces trois paramètres. Les résultats de ce modèle sont représentés à la figure \@ref(fig:fullrandom2).

```{r fullrandom2, echo=FALSE, fig.align='center', fig.cap="Influence du temps de travail sur la performance scolaire d'élèves en tenant compte de l'effet de leur classe et de l'impact de la classe sur l'efficacité du temps de travail (effet fixe)", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}

df3$x <- scale(df3$X,center = T, scale = T)

model2 <- lmer(Y2 ~ X + (X|group), data = df3,
              control = lmerControl(optimizer = "bobyqa"))
coeffs <- coef(model2)$group

df5 <- data.frame(
  inter = coeffs[,1],
  slope = coeffs[,2],
  group = rownames(coeffs)
)

ggplot(data = df3)+
  geom_point(aes(x = X, y = Y2, color = group), alpha = 0.8, size = 1)+
  geom_abline(data = df5, mapping = aes(intercept = inter, slope = slope, color = group),size = 1.2)+ 
  scale_color_manual(values =colors)+
  labs(y = "Note à l'examen (%)", x = "Temps de travail (heures)", color = "Classe")

covmod <- VarCorr(model2)$group[1,2]
sigma1 <- VarCorr(model2)$group[1,1]
sigma2 <- VarCorr(model2)$group[2,2]
```

Nous pouvons ainsi constater que pour ce troisième modèle, l'effet de resserrement est bien plus prononcé que pour les modèles précédents (\@ref(fig:fullrandom3)). Si l'on se fie au modèle à effets fixes (figure : \@ref(fig:fullrandom1)), alors l'impact de l'école sur l'efficacité du temps de travail est très important. Le modèle à effet aléatoire en revanche, identifie que la différence de moyenne entre les écoles est importante, mais la différence en terme d'efficacité du temps de travail est beaucoup plus anecdotique.

```{r fullrandom3, echo=FALSE, fig.align='center', fig.cap="Comparaison des effets fixes et aléatoires pour le modèle intégrant l'effet des classes et l'interaction entre les classes et le tempsd de travail", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='90%'}

plot1 <- ggplot() + 
  geom_point(data = df4, mapping = aes(x = inter, y = group,  color = "fixed")) +
  geom_point(data = df5, mapping = aes(x = inter, y = group, color = "random")) + 
  geom_vline(xintercept = mean(df4$inter)) + 
  labs(x = "constante", y = "classe", color = "type d'effet") + 
  scale_color_manual(values = c("fixed" = "red", random = "blue"), labels = c("fixe", "aléatoire"))

plot2 <- ggplot() + 
  geom_point(data = df4, mapping = aes(x = slope, y = group,  color = "fixed")) +
  geom_point(data = df5, mapping = aes(x = slope, y = group, color = "random")) + 
  geom_vline(xintercept = mean(df4$slope)) + 
  labs(x = "pente", y = "classe", color = "type d'effet") + 
  scale_color_manual(values = c("fixed" = "red", random = "blue"), labels = c("fixe", "aléatoire"))

ggarrange(plot1,plot2,ncol = 2, nrow = 1, common.legend = T)
rs2 <- r.squaredGLMM(model2)
```

Notre modèle estime la valeur de $\sigma_{\upsilon_1}$ à `r tofr(round(sigma1, 3))`, celle de $\sigma_{\upsilon_2}$ à `r tofr(round(sigma2, 3))` et celle de $\sigma_{\upsilon_1\upsilon_2}$ à `r tofr(round(covmod, 3))`. La corrélation entre les deux effets est donc de `r tofr(round(covmod/(sqrt(sigma1)*sqrt(sigma2)), 3))` ce qui est relativement faible. (Pour l'anecdocte, notez que la valeur originale de corrélation entre ces deux effets était de 0,1 lorsque nous avons simulés ces données, notre modèle est a donc bien été capable de retrouver le paramètre original.). À nouveau, puisque nous avons des pentes aléatoires dans ce modèle, nous ne pouvons pas calculer l'ICC, nous pouvons cependant rapporter les R^2^ marginal et conditionnel. Leurs valeurs respectives sont `r tofr(round(r2s[[1]],3))` et `r tofr(round(r2s[[2]],3))` ce qui nous confirme une nouvelle fois que l'ajout d'effets aléatoires contribue à expliquer une partie importante de la variance de la performance scolaire.

Pour terminer cette section, comparons brièvement les trois modèles (constantes aléatoire, pentes aléatoires et constantes et pentes aléatoires) pour déterminer lequel est le mieux ajusté à nos données. Nous ajoutons également un quatrième modèle dans lequel les deux effets aléatoires sont présents mais non corrélés ($\sigma_{\upsilon_1\upsilon_2}=0$). Le tableau \@ref(tab:fullrandom4) nous permet de constater que l'ajout des constantes aléatoires joue un rôle essentiel dans le premier modèle : le R^2^ conditionnel est plus que deux fois supérieur au R^2^ marginal. Cependant, l'ajout des pentes aléatoires dans les trois autres modèles apporte finalement très peu d'information, nous laissant penser que l'effet de la classe sur le temps de travail est faible voir inexistant.

```{r fullrandom4, echo=FALSE, message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='90%'}
model1 <- lmer(Y2 ~ X + (1|group), data = df3)
model2 <- lmer(Y2 ~ X + (-1+X|group), data = df3)
model3 <- lmer(Y2 ~ X + (X|group), data = df3,
              control = lmerControl(optimizer = "bobyqa"))
model4 <- lmer(Y2 ~ X + (X||group), data = df3,
              control = lmerControl(optimizer = "bobyqa"))

models <- list(model1,model2,model3,model4)

tableau <- data.frame(
  name = c("constante aléatoire", "pente aléatoire", "pente et constante aléatoire corrélées", "pente et constante aléatoire non-corrélées"),
  aic = round(sapply(models, function(i){AIC(i)}),1),
  r2m = round(sapply(models, function(i){r.squaredGLMM(i)[[1]]}),2),
  r2c = round(sapply(models, function(i){r.squaredGLMM(i)[[2]]}),2)
)

show_table(tableau,
          caption = 'Comparaison des trois modèles à effets aléatoires',
          col.names=c("modèle","AIC","R^2^ marginal","R^2^ conditionnel"),
          align= c("l","r", "r", "r"))

```

## Conditions d'applicatin des GLMM {#sect072}


Comparaison des formulations fixe : coefficient pour variable binaire / interaction binaire et continue / combinaison des deux

shrinkage, partial pooling, distributon de l'effet aleatoire, deux niveaux dans le modele, structure de covariance

Encadre sur le nombre de parametre (moins de parametres dans un modele a effet mixte que dans un modele a effet fixe)

### Distinction entre effets fixes et effets aléatoires

les questions a se poser pour decider si un effet est fixe ou aleatoire

### Analyse d'un GLMM

Idem que pour un GLM, mais avec : 

ICC, R2 marginal, R2 conditionnel, observation des Random Intercept et Random Coeffs. Analyse des correlations entre random intercept et Random coeff. Normalite de la distribution des effets aleatoire (ou autre distribution).

## Application à une variable continue {#sect073}


## Régressions multiniveaux {#sect074}
