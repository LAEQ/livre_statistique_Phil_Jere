# Régressions à effets mixtes (GLMM) et régression multiniveaux  {#chap07}

Dans les deux chapitres précédents, nous avons consécutivement présenté la méthode de la régression linéaire simple (LM) ainsi que son extension : les modèles linéaires généralisés (GLM). Dans ce chapitre, nous poursuivons sur cette voie avec deux nouvelles extensions : les modèles généralisés à effet mixtes et les modèles multiniveaux.

## Introduction

### Indépendance des observations et effets de groupes

Nous avons vu dans les précédents chapitres que l'indépendance des observations est une condition d'application commune à l'ensemble des modèles de régression. Cette condition implique ainsi que chaque unité d'observation de notre jeu de données est indépendante des autres ; en d'autres termes, qu'elle ne soit associée à aucune autre observation par un lien de dépendance. Prenons un exemple concret pour illustrer cette notion. Admettons que nous nous intéressons à la performance scolaire d'élèves de secondaire à Montréal. Pour cela, nous collectons la moyenne des résultats aux examens du Ministère de tous les élèves des différentes commissions scolaires de l'île de Montréal. Chaque élève appartient à une classe spécifique, et chaque classe se situe dans une école spécifique. Les classes constituent des environnements particuliers, la performance des élèves y est influencée par un ensemble de facteurs comme l'enseignant et les relations entre les élèves d'une même classe. Deux élèves provenant d'une même classe sont donc liés par une forme de structure propre à leur classe et ne peuvent pas être considérés comme indépendants. De même, l'école constitue un environnement particulier pouvant influencer la performance des élèves du fait de moyens financiers plus importants, de la mise en place de programmes spéciaux, de la qualité des infrastructures (bâtiment, gymnase, cour d'école) ou d'une localisation minimisant certaines nuisances à l'apprentissage comme le bruit. À nouveau, deux élèves provenant d'une même école partagent une forme de structure qui cette fois-ci est propre à leur école. Si nous collections des données pour l'ensemble du Canada, nous pourrions étendre ce raisonnement aux villes dans lesquelles les écoles se situent et aux provinces.

Dans cet exemple, la dépendance entre les données est provoquée par un effet de groupe : il est possible de rassembler les observations dans des ensembles (classes et écoles) influençant vraisemblablement la variable étudiée (performance scolaire). Les effets des classes et des écoles ne sont cependant pas intrinsèques aux élèves. En effet, il est possible de changer un élève de classe ou d'école, mais pas de changer son sexe, ou sa situation familiale. Il est ainsi possible de distinguer la population des élèves, la population des classes, et la population des écoles (\@ref(fig:glmmecoles)). Ces effets de groupes sont plus la règle que l'exception dans l'analyse de données en sciences sociales, ce qui met à mal l'hypothèse d'indépendance des observations. Notez que les effets de groupes ne sont pas les seules formes de structures remettant en cause l'indépendance des observations. Il existe également des structures temporelles (deux observations proches dans le temps ont plus de chances de se ressembler) et spatiales (deux observations proches dans l'espace ont plus de chances de se ressembler). Cependant, le cas de la dépendance temporelle et spatiale n'est pas couvert dans ce livre, car complexes et elles mériteraient un ouvrage dédié.

```{r glmmecoles, echo=FALSE, fig.align='center', fig.cap="Structure hiérarchique entre élèves, classes et écoles", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}
knitr::include_graphics('images/glmm/Hierarchie_Ecoles.png', dpi = NA)
```

::: {.bloc_aller_loin data-latex=""}
**La notion de pseudo-réplication**

Les effets de dépendance causés par des structures de groupes, temporelles ou spatiales sont regroupées sous le terme de pseudo-réplication. Il est intéressant de se pencher sur la signification de ce mot pour comprendre le problème intrinsèque causé par la dépendance entre les observations et son impact sur l'inférence.

Reprenons l'exemple des élèves et de la performance scolaire et admettons que nous souhaitons estimer la moyenne générale de l'ensemble des élèves sur l'île de Montréal, mais que nous ne disposons pas du jeu de données complet. Nous devons donc collecter un échantillon suffisamment grand pour estimer la moyenne pour l'ensemble de cette population. Raisonnons en termes de quantité d'informations. Si nous ne disposons d'aucune observation (nous n'avons encore interrogé aucun élève), cette quantité est de 0. Si nous interrogeons un premier élève, nous obtenons une donnée supplémentaire et donc un point d'information supplémentaire (+1). Admettons maintenant que nous collectons 30 observations dans une école, 10 dans une seconde et 5 dans une troisième. A priori, nous pourrions dire que nous avons ajouté 45 points d'information à notre total de connaissance. Ce serait le cas si les observations étaient indépendantes les unes des autres. Dans un tel contexte, chaque observation ajoute la même quantité d'information. Cependant, puisque les élèves issus d'une même école ont plus de chance de se ressembler, interroger les élèves d'une même école apporte moins d'information. Notez que plus la ressemblance entre les élèves d'une même école est forte, plus la quantité d'information est réduite. Nous sommes donc loin de disposer d'une quantité d'information égale à 45. Chaque réplication de l'expérience (demander à un élève sa moyenne annuelle) n'apporte pas autant d'information qu'attendu si les observations étaient indépendantes, c'est pourquoi on parle de **pseudo-réplication**.

La pseudo-réplication impacte directement l'inférence statistique puisque le calcul des différents tests statistiques assume que chaque observation apporte autant d'information que les autres. En cas de présence de pseudo-réplication, la quantité d'information présente dans l'échantillon est plus petite qu'attendu. Il est possible de voir cela comme une forme de surestimation de la taille de l'échantillon. En cas de pseudo-réplication nous disposons en réalité de moins de données que ce que l'on attendrait d'un échantillon de cette taille si les observations étaient indépendantes. La conséquence est la sous-estimation de la variabilité réelle des données et l'augmentation des risques de trouver des effets significatifs dans l'échantillon alors qu'ils ne le sont pas pour l'ensemble de la population.

:::

### Terminologie : effets fixes et effets aléatoires

Puisque les effets des classes et des écoles ne sont pas propres aux élèves, il convient de les introduire différemment dans les modèles de régression. Nous appelons un effet fixe, un effet qui est propre aux observations que nous étudions et un effet aléatoire, un effet provoqué par une structure externe (effet de groupe, effet temporel, effet spatial). Un modèle combinant à la fois des effets fixes et des effets aléatoires est appelé un **modèle à effets mixtes**, ou GLMM pour *Generalized Linear Mixed Model*. En sciences sociales, on utilise aussi souvent le terme de modèle hiérarchique ou multiniveau. Tous les modèles que nous avons ajustés dans les sections précédentes ne comprenaient que des effets fixes alors qu'à plusieurs reprises, des effets aléatoires induits par l'existence de structure de groupe auraient pu (dû) être utilisés. Prenons pour exemple le modèle logistique binomial visant à prédire la probabilité d'utiliser le vélo comme mode de transport pour son trajet le plus fréquent (REF). La variable multinomiale *Pays*, représentant le pays dans lequel les personnes interrogées résident a été introduite comme un effet fixe. Cependant, l'effet du pays ne constitue pas une caractéristique propre aux individus, il s'agit plutôt d'un agrégat complexe mêlant culture, météorologie, orientation des politiques publiques et formes urbaines. À l'inverse, le sexe ou l'âge sont bien des caractéristiques intrinsèques des individus et peuvent être considérés comme des effets fixes.

Notez que l'utilisation du terme effet aléatoire peut porter à confusion, car différentes utilisations en sont faites en fonction du champ d'études. Parmi les différentes définitions relevées par @gelman2005analysis d'un effet aléatoire, il est possible de retrouver les suivantes : 

* Les effets fixes sont identiques pour tous les individus alors que les effets aléatoires varient (définition 1).

* Les effets sont fixes s'ils sont intéressants en eux-mêmes, et les effets sont aléatoires si on s'intéresse à la population dont ils sont issus (définition 2).

* Lorsqu'un échantillon couvre une grande part de la population, la variable correspondante est un effet fixe. Si l'échantillon couvre une faible part de la population, l'effet est aléatoire (définition 3).

* Si l'effet est supposé provenir d'une variable aléatoire, alors il s'agit d'un effet aléatoire (définition 4).

* Les effets fixes sont estimés par la méthode des moindres carrés par maximum de vraisemblance alors que les effets aléatoires sont estimés avec régularisation (*shrinkage*) (définition 5).

Il est ainsi possible de se retrouver dans des cas où un effet serait classé comme fixe selon une définition et aléatoire selon une autre. La deuxième définition suppose même qu'un effet peut être aléatoire ou fixe selon l'objectif central de l'étude. La dernière définition a l'avantage d'être mathématique, mais ne permet pas de décider si un effet doit être traité comme aléatoire ou fixe. Nous ne proposons pas ici de clore le débat, mais plutôt de donner quelques pistes de réflexion pour décider si un effet doit être modélisé comme fixe ou aléatoire :

* Est-ce que l'effet en question est propre aux individus étudiés ou est externe aux individus. S'il est propre aux individus, il s'agit plus certainement d'un effet fixe. À titre d'exemple, on ne peut pas changer le sexe d'un individu, mais on peut certainement changer sa ville de résidence.
* Existe-t-il un nombre bien arrêté de catégories possibles pour l'effet en question ? Si oui, il s'agit plus certainement d'un effet fixe. Toujours avec le même exemple, il y a un nombre bien arrêté de catégories pour la variable sexe, mais pour la variable pays, de nombreuses autres valeurs auraient pu être ajoutées. Il est également possible de se demander s'il semble cohérent d'effectuer un échantillonnage sur les catégories en question. Dans le cas des pays, nous pourrions mener une étude à l'échelle des pays et collecter des données sur un échantillon de l'ensemble des pays. Il existe donc une population de pays, ce que nous ne pouvons pas affirmer pour la variable sexe.
* L'effet en question est direct ou indirect ? Dans le second cas, l'effet en question est un agglomérat complexe découlant de plusieurs processus n'ayant pas été mesurés directement, ce qui correspond davantage à un effet aléatoire. Ainsi, l'effet du pays de résidence des individus sur leur probabilité d'utiliser le vélo est bien une agglomération complexe d'effets (culture, météorologie, orientation des politiques publiques, formes urbaines, etc.) n'ayant pas tous été mesurés. À l'inverse, l'âge d'un individu a bien un effet direct sur sa probabilité d'utiliser le vélo.
* L'effet est-il le même pour tous les individus, ou doit-il varier selon le groupe dans lequel l'individu se situe ? Si un effet doit varier en fonction d'un groupe, il s'apparente davantage à un effet aléatoire. Pour reprendre l'exemple de l'âge, nous pourrions décider que cette caractéristique des individus n'a peut-être pas le même impact en fonction du pays dans lequel vit l'individu et l'ajouter au modèle comme un effet aléatoire.

Vous comprendrez donc qu'une partie non négligeable du choix entre effet fixe ou aléatoire réside dans le cadre théorique à l'origine du modèle. Maintenant que cette distinction conceptuelle a été détaillée, nous pouvons passer à la présentation statistique des modèles GLMM.

## Principes de base des GLMM {#sect071}

Un GLMM est donc un modèle GLM introduisant à la fois des effets fixes et des effets aléatoires. Si l'on ne considère que les effets de groupes, un GLMM peut avoir trois formes : constantes aléatoires, pentes aléatoires et constantes et pentes aléatoires. Nous présentons ces trois formes ici en reprenant l'exemple théorique ci-dessus avec des élèves intégrés dans des classes pour lesquels nous nous intéressons à leur niveau de performance à l'examen ministériel de mathématique.

### GLMM avec constantes aléatoires

Il s'agit de la forme la plus simple d'un GLMM, plus spécifiquement, elle autorise le modèle à avoir une constante différente pour chaque catégorie d'une variable multinomiale. En d'autres termes, nous tentons d'ajouter dans le modèle l'idée que chaque classe a une moyenne différente en termes de performance à l'examen de mathématique. Il est possible assez facilement de visualiser ce que cela signifie avec un exemple graphique. Admettons que nous modélisons le score obtenu par des élèves de secondaire à l'examen ministériel de mathématique à partir d'une autre variable continue représentant le temps de travail moyen par semaine en dehors des heures de classe et d'une variable catégorielle représentant dans quelle classe se trouve chaque élève. Notez qu'il ne s'agit pas ici de vraies données, mais de simples simulations utilisées à titre d'illustration. Si nous ne tenons pas compte des classes nous pouvons ajuster une simple régression linéaire entre nos deux variables continues comme le propose la figure \@ref(fig:randominter1).

```{r randominter1, echo=FALSE, fig.align='center', fig.cap="Influence du temps de travail sur la performance scolaire d'élèves", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}

set.seed(11)
library(ggplot2)

## Générer des effets aléatoires
groups <-  c("A","B","C","D","E","F","G","H")
sig2 <- matrix(c(12, 0.1,
                 0.1, 0.5), 
               nrow = 2, ncol = 2)
mu2 <- c(inter = 0, coeff = 0)
df2 <- data.frame(data.frame(MASS::mvrnorm(n = length(groups), mu = mu2, Sigma = sig2)))
df2$name <- groups

colors <- hcl.colors(length(groups), palette = "Dynamic")
names(colors) <- groups

## Générer des données
n <- 300
df <- data.frame(
  X = rnorm(n,8,2),
  group = sample(df2$name,size = n, replace = T)
)

df3 <- merge(df,df2, by.x="group",by.y="name")
df3$Y <- 65 + df3$X*(1.5+df3$coeff) + df3$inter + rnorm(n = n, mean = 0, sd = 8)
df3$Y2 <- ifelse(df3$Y>=100, 100, df3$Y)

## Afficher le tout !
ggplot(data = df3)+
  geom_point(aes(x = X, y = Y2, color = group), size = 1) + 
  geom_smooth(aes(x = X, y = Y2),method='lm', formula= y~x, se=F, color = "black", size = 1.2)+
  scale_color_manual(values = colors)+
  labs(y = "Note à l'examen (%)", x = "Temps de travail (heures)", color = "Classe")
```

On constate que notre modèle semble bien identifier la relation positive entre le temps de travail et le niveau de performance, mais la droite de régression est très éloignée de chaque point, nous avons donc énormément d'erreurs de prédiction et donc des résidus importants. Jusqu'ici nous avons vu que nous pouvions ajouter un prédicteur et intégrer l'effet des classes comme un effet fixe.

```{r randominter2, echo=FALSE, fig.align='center', fig.cap="Influence du temps de travail sur la performance scolaire d'élèves en tenant compte de l'effet de leur classe (effet fixe)", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}

model <- lm(Y2 ~ X + group, data = df3)
b1 <- model$coefficients[[2]]
diffs <- c(0,model$coefficients[c(3:length(model$coefficients))])
diffs <- diffs + model$coefficients[[1]]

df4 <- data.frame(
  inter = diffs,
  slope = b1,
  group = names(colors)
)

ggplot(data = df3)+
  geom_point(aes(x = X, y = Y2, color = group), alpha = 0.8, size = 1)+
  geom_abline(data = df4, mapping = aes(intercept = inter, slope = slope, color = group),size = 1.2)+ 
  scale_color_manual(values =colors)+
  labs(y = "Note à l'examen (%)", x = "Temps de travail (heures)", color = "Classe")
```

Cet ajustement constitue une nette amélioration du modèle. Prenons un instant pour reformuler clairement notre modèle à effets fixes : 

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma)\\
&g(\mu) = \beta_0 + \beta_1 x_1 + \sum^k_{j=1}{\beta_j x_{2j}}\\
&g(x) = x
\end{aligned}
(\#eq:glmm1)
\end{equation}
\normalsize

avec $x_1$ le temps de travail et $x_2$ la classe ayant *k-1* modalités (puisqu'une modalité est la référence). Nous  ajustons ainsi un coefficient pour chaque classe qui va avoir pour effet de tirer vers le haut ou vers le bas la prédiction du modèle en fonction de la classe. Cet effet est pour l'instant fixe, mais conceptuellement, nous avons déterminé dans les sections précédentes qu'il serait conceptuellement plus approprié de le traiter comme un effet aléatoire.

Passons à présent à la reformulation de ce modèle en transformant l'effet fixe de la classe en effet aléatoire.

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma_e)\\
&g(\mu) = \beta_0 + \beta_1 x_1 + \upsilon \\
&\upsilon \sim Normal(0, \sigma_{\upsilon})) \\
&g(x) = x
\end{aligned}
(\#eq:glmm2)
\end{equation}
\normalsize

Remarquez que l'effet fixe de la classe $\sum^k_{j=1}{\beta_j x_{2j}}$ a été remplacé par $\upsilon$ qui est un terme aléatoire propre aux classes et qui suit une distribution normale centrée sur 0. En d’autres termes, cela signifie que l'effet des classes sur la performance des élèves suit une distribution normale et que si l'on moyennait l'effet de toutes classes, cet effet serait de 0. Nous ne modélisons donc plus l'effet moyen de chaque classe comme dans le modèle à effets fixes, mais la variabilité de l'effet des classes, soit $\sigma_{\upsilon}$. Notre modèle a donc deux variances, une au niveau des élèves ($\sigma_e$) et une au niveau de classes ($\sigma_{\upsilon}$). Cette particularité explique souvent pourquoi ce type de modèle est appelé un modèle hiérarchique ou un modèle de partition de la variance. Cette information est particulièrement intéressante car elle permet de calculer dans le cas d'un GLMM gaussien, la part de la variance présente au niveau des élèves et celle au niveau des classes.

Selon cette formulation, les constantes propres à chaque classe sont issues d'une distribution normale (nous reviendrons d'ailleurs sur ce choix plus tard), mais elles n'apparaissent pas directement dans le modèle. Ces paramètres ne sont plus estimés directement dans le modèle, mais a posteriori à partir des prédictions du modèle, et sont appelés *Best Linear Unbiased Predictor* (BLUP). Ces dernières précisions devraient d'ailleurs mieux vous aider à comprendre l'origine des définitions 1, 2 et 4 que nous avions mentionnées précédemment.

```{r randominter3, echo=FALSE, fig.align='center', fig.cap="Influence du temps de travail sur la performance scolaire d'élèves en tenant compte de l'effet de leur classe (effet aléatoire)", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}
library(lme4)

model2 <- lmer(Y2 ~ X + (1|group), data = df3)

coeffs <- coef(model2)$group
df5 <- data.frame(
  inter = coeffs[,1],
  slope = coeffs[,2],
  group = rownames(coeffs)
)

ggplot(data = df3)+
  geom_point(aes(x = X, y = Y2, color = group), alpha = 0.8, size = 1)+
  geom_abline(data = df5, mapping = aes(intercept = inter, slope = slope, color = group),size = 1.2)+ 
  scale_color_manual(values = colors)+
  labs(y = "Score à l'examen (%)", x = "Temps de travail (heures)", color = "Classe")
```

En comparant les deux graphiques, la différence ne saute pas aux yeux; vous pourriez alors légitimement vous demander pourquoi tous ces efforts et cette complexité théorique pour une différence d'ajustement minime ? Trois arguments permettent de justifier l'utilisation de constantes aléatoire plutôt que d'effets fixes dans notre cas.

#### Resserrement (*shrinkage*) et mutualisation (*partial pooling*)

Le premier intérêt d'utiliser un effet aléatoire réside dans sa méthode d'estimation qui diffère largement d'un effet fixe. Il est assez facile de se représenter intuitivement la différence entre les deux. Dans le cas de nos élèves et de nos classes, lorsque l'effet des classes est estimé avec un effet fixe, l'effet de chaque classe est déterminé de façon totalement indépendante des autres classes. En d'autres termes, il n'est possible d'en apprendre plus sur une classe qu'en collectant des données dans cette classe (*separate pooling*). Si l'effet des classes est estimé comme un effet aléatoire, alors l'information entre les classes est mutualisée (*partial pooling*). L'idée étant que l'information que l'on apprend sur des élèves dans une classe est au moins en partie valide dans les autres classes également. Cette méthode d'estimation est particulièrement intéressante si nous ne disposons que de peu d'observations dans une classe puisque nous pouvons apprendre au moins une partie de l'effet de cette classe à partir des données des autres classes. Ceci n'est pas possible dans le cas d'un effet fixe où l'on traite chaque classe en silo. @mcelreath2020statistical écrit à ce sujet qu'un effet fixe « n'a pas de mémoire » et qu'il oublie tout ce qu'il a appris sur les classes lorsqu'il passe à une nouvelle classe. La conséquence de cette mutualisation de l'information est un resserrement (*shrinkage*) des effets des classes autour de leur moyenne. Cela signifie que les tailles des effets de chaque classe sont plus petites dans le cas d'un effet aléatoire que d'un effet fixe. Utiliser des effets aléatoires conduit donc à une estimation plus conservative de l'effet des classes. Nous pouvons le visualiser en comparant les effets de classes dans le modèle à effets mixtes et le modèle à effet fixes. La figure \@ref(fig:randominter5) montre clairement que les effets aléatoires tendent à se rapprocher (resserrement) de leur moyenne (ligne noire) et donc à renvoyer des effets moins extrêmes pour chaque classe. Cette explication est directement en lien avec la définition 5 d'un effet aléatoire vu précédemment.

```{r randominter5, echo=FALSE, fig.align='center', fig.cap="Comparaison des effets des classes pour le modèle à effets fixes versus le modèle effets aléatoires", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}
library(MuMIn)

r2s <- r.squaredGLMM(model2)

df6 <- data.frame(
  fixed = df4$inter,
  random = df5$inter,
  group = df4$group
)

ggplot() + 
  geom_point(data = df4, mapping = aes(x = inter, y = group,  color = "fixed")) +
  geom_point(data = df5, mapping = aes(x = inter, y = group, color = "random")) + 
  geom_vline(xintercept = mean(df4$inter)) + 
  labs(x = "effet de la classe", y = "classe", color = "type d'effet") + 
  scale_color_manual(values = c("fixed" = "red", random = "blue"), labels = c("fixe", "aléatoire"))

sigma_u <- as.data.frame(VarCorr(model2))$sdcor[[1]]
sigma_e <- as.data.frame(VarCorr(model2))$sdcor[[2]]
```
#### Prédiction pour de nouveaux groupes

Une autre retombée directe de la mutualisation de l'information est la capacité de modèle à envisager les effets plausibles pour de nouvelles classes. En effet, puisque nous avons approximé l'effet des classes sous forme d'une distribution normale dont nous connaissons la moyenne (0) et l'écart type ($\sigma_{\upsilon}$), nous pouvons simuler des données pour de nouvelles classes, ce que ne permet pas un effet fixe. Ce constat est d'ailleurs directement lié à la définition 3 des effets aléatoires vue précédemment. Dans notre cas, $\sigma_{\upsilon}$ = `r tofr(round(sigma_u,3))`, ce qui nous permet d'affirmer que dans 95% des classes, l'effet de la classe sur la performance scolaire doit se trouver entre -1.96 $\times$ `r tofr(round(sigma_u,3))` et +1,96 $\times$ `r tofr(round(sigma_u,3))`, soit l'intervalle [`r tofr(round(-1.96*sigma_u,3))`, `r tofr(round(1.96*sigma_u,3))`].

#### Partition de la variance

Un autre avantage net de l'effet aléatoire est l'estimation du paramètre $\sigma_{\upsilon}$, soit la variance au niveau des écoles. Ce dernier permet de calculer un indicateur très intéressant, soit l'**indice de corrélation intraclasse (ICC)** :

\footnotesize
\begin{equation}
ICC = \frac{\sigma_{\upsilon}}{\sigma_{\upsilon} + \sigma_{e}}
(\#eq:glmm3)
\end{equation}
\normalsize

Il s'agit donc du pourcentage de la variance présente au niveau des classes, qui peut être interprété comme le niveau de corrélation (de ressemblance) entre les élèves d'une même classe.

Dans notre cas, l'écart type est de `r tofr(round(sigma_u,3))` au niveau des classes et de `r tofr(round(sigma_e,3))` au niveau des élèves. Nous pouvons donc calculer l'ICC au niveau des classes avec la formule précédente : `r tofr(round(sigma_u,3))` / (`r tofr(round(sigma_u,3))` + `r tofr(round(sigma_e,3))`) = `r tofr(round(sigma_u /(sigma_u + sigma_e),3))`. Cela signifie que le niveau de corrélation entre deux élèves d'une même classe est de `r tofr(round(sigma_u /(sigma_u + sigma_e),3))` ou encore que `r tofr(round(sigma_u /(sigma_u + sigma_e),3)*100)`% de la variance de *Y* se situe au niveau des classes, ce qui est conséquent. Une telle information ne peut être extraite d'un modèle avec seulement des effets fixes. Notez ici que l'ICC peut être calculé pour chaque niveau d'un modèle à effet mixte. Dans notre exemple, nous n'avons qu'un seul niveau au-dessus des élèves, soit les classes, mais nous pourrions étendre cette logique à des écoles par exemple. Notez également que cette formule de l'ICC n'est valide que pour un modèle pour lequel la distribution de la variable *Y* est normale. Des développements apparaissent pour proposer d'autres formulations adaptées à d'autres distributions (imaginons le cas d'une distribution de Poisson n'ayant pas de paramètre de variance !), mais il est également possible d'estimer l'ICC à partir des simulations issues du modèle [@NakagawaICC ; @aly2014reliability ; @stryhn2006interpretation ; @wu2012comparison]. L'idée générale reste d'expliquer la partition de la variance dans le modèle.

En plus de l'ICC, il est également possible de calculer les **R^2^ marginal et conditionnel** du modèle. Le premier représente la variance expliquée par le modèle si seulement les effets fixes sont pris en compte, et le second si les effets fixes et aléatoires sont pris en compte. Distinguer les deux sources d'information permet de mieux cerner dans notre cas l'importance du rôle des écoles dans la performance des élèves. Dans notre cas, nous obtenons un R^2^ marginal de `r tofr(round(r2s[[1]],3))` et un R^2^ conditionnel de `r tofr(round(r2s[[2]],3))`, ce qui nous confirme à nouveau que le rôle joué par la classe dans le niveau de performance est loin d'être négligeable.

### GLMM avec pentes aléatoires

Dans cette seconde version du GLMM, nous n'envisageons plus de faire varier une constante en fonction des classes, mais un coefficient en fonction des classes. Admettons ici que nous voulions tester si l'effet du temps de travail ($x_1$) sur la performance scolaire (*Y*) n'est pas constant partout et que dans certaines classes, le temps de travail par semaine et dehors de l'école est plus efficace que d'autres. L'idée sous-jacente est que nous n'observons pas de différence en termes de moyenne entre deux classes, mais en termes d'effet pour notre variable $x_1$. À nouveau, nous pourrions nous contenter d'effet un fixe pour intégrer cette idée dans notre modèle. Pour cela, nous avons simplement à ajouter une interaction entre notre variable quantitative temps de travail et notre variable qualitative classe. Nous obtenons le résultat décrit par la figure \@ref(fig:randomslope). Notez ici que la constante est bien la même pour chaque classe (l'ensemble des lignes s'intersecte à 0 sur l'axe des x), et que seule la pente change.

```{r randomslope, echo=FALSE, fig.align='center', fig.cap="Influence du temps de travail sur la performance scolaire d'élèves en interraction avec la classe (effet fixe)", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}

model <- lm(Y2 ~ X + X:group, data = df3)
inter <- model$coefficients[[1]]
b1 <- model$coefficients[[2]]
diffs <- c(0,model$coefficients[c(3:length(model$coefficients))])
diffs <- b1 + diffs

df4 <- data.frame(
  inter = inter,
  slope = diffs,
  group = names(colors)
)

ggplot(data = df3)+
  geom_point(aes(x = X, y = Y2, color = group), alpha = 0.8, size = 1)+
  geom_abline(data = df4, mapping = aes(intercept = inter, slope = slope, color = group),size = 1.2)+ 
  scale_color_manual(values =colors)+
  labs(y = "Score à l'examen (%)", x = "Temps de travail (heures)", color = "Classe") + 
  xlim(0,max(df3$X)+1)
```

La formulation de ce modèle à effets fixes seulement est la suivante : 

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma)\\
&g(\mu) = \beta_0 + \beta_1 x_1 + \sum^k_{j=1}{\beta_j x_{2j} x_1}\\
&g(x) = x
\end{aligned}
(\#eq:glmm4)
\end{equation}
\normalsize

On constate donc que nous avons un effet principal $\beta_1$ décrivant le lien entre temps de travail et le score obtenu à l'examen pour l'ensemble des élèves, ainsi qu'un bonus ou un malus sur cet effet $\beta_j$ s'appliquant en fonction de la classe. Nous pouvons reformuler ce modèle pour inclure cet effet spécifique par classe comme un effet aléatoire.

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma_e)\\
&g(\mu) = \beta_0 + \beta_1 x_1 + \upsilon x_1 \\
&\upsilon \sim Normal(0,\sigma_{\upsilon})\\
&g(x) = x
\end{aligned}
(\#eq:glmm5)
\end{equation}
\normalsize

Nous formulons ici un modèle dans lequel la classe modifie l'impact de la variable temps d'étude sur la variable note à l'examen. L'effet moyen de $x_1$ est capté par le coefficient $\beta_1$, les bonus ou malus ajoutés à cet effet par la classe sont issues d'une distribution normale centrée sur 0 avec un écart type, soit $\sigma_{\upsilon}$. À nouveau, l'idée est que si l'on moyennait l'effet de toutes les écoles, nous obtiendrions 0. Aussi, le fait de modéliser cet effet comme un effet aléatoire nous permet de partitionner la variance, de mutualiser l'information entre les classes et de resserrer l'estimation des effets des classes.

Les résultats pour ce second modèle sont présentés à la figure \@ref(fig:randomslope2), et une comparaison entre les estimations des effets fixes et des effets aléatoires est présentée à la figure \@ref(fig:randomslope3). Nous pouvons ainsi constater à nouveau l'effet de resserrement provoqué par l'effet aléatoire.


```{r randomslope2, echo=FALSE, fig.align='center', fig.cap="Influence du temps de travail sur la réussite scolaire d'élèves en interraction avec la classe (effet aléatoire)", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}

model2 <- lmer(Y2 ~ X + (-1+X|group), data = df3)
coeffs <- coef(model2)$group

df5 <- data.frame(
  inter = coeffs[,1],
  slope = coeffs[,2],
  group = rownames(coeffs)
)

ggplot(data = df3)+
  geom_point(aes(x = X, y = Y2, color = group), alpha = 0.8, size = 1)+
  geom_abline(data = df5, mapping = aes(intercept = inter, slope = slope, color = group),size = 1.2)+ 
  scale_color_manual(values =colors)+
  labs(y = "Score à l'examen (%)", x = "Temps de travail (heure)", color = "Classe") + 
  xlim(0,max(df3$X)+1)
```

```{r randomslope3, echo=FALSE, fig.align='center', fig.cap="Influence du temps de travail sur la réussite scolaire d'élèves en interraction avec la classe (effet aléatoire)", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}

df6 <- data.frame(
  fixed = df4$slope,
  random = df5$slope,
  group = df4$group
)

ggplot() + 
  geom_point(data = df4, mapping = aes(x = slope, y = group,  color = "fixed")) +
  geom_point(data = df5, mapping = aes(x = slope, y = group, color = "random")) + 
  geom_vline(xintercept = mean(df4$slope)) + 
  labs(x = "effet du temps de travail", y = "classe", color = "type d'effet") + 
  scale_color_manual(values = c("fixed" = "red", random = "blue"), labels = c("fixe", "aléatoire"))

rs2 <- r.squaredGLMM(model2)

```

Lorsque l'on intègre des pentes aléatoires dans un modèle, on fait face au problème suivant : la variance associée aux pentes aléatoires n'est pas fixe, mais proportionnelle à la variable *X* autorisée à varier. Si l'on compare la figure \@ref(fig:randominter3) (constantes aléatoires) et la figure \@ref(fig:randomslope2) (pentes aléatoires), on constate bien que la dispersion des prédictions du modèle (représentées par les lignes) augmente dans le cas de pentes aléatoires et reste identique dans le cas des constantes aléatoires. La conséquence pratique est qu'il existe potentiellement un nombre infini de valeurs possibles pour l'ICC. Dans ce contexte, il est préférable de laisser de côté cet indicateur et de ne reporter que les R^2^ marginal et conditionnel. Dans notre cas, nous obtenons les valeurs `r tofr(round(rs2[[1]],3))` et `r tofr(round(rs2[[2]],3))`, ce qui confirme une fois encore que le rôle joué par la classe est loin d'être négligeable puisqu'il permet d'expliquer près de `r tofr(round(rs2[[2]],3)*100)`% supplémentaire de variance comparativement aux seuls effets fixes expliquant `r tofr(round(rs2[[1]],3)*100)`% de la variance du score obtenu à l'examen.

### GLMM avec constantes et pentes aléatoires

Vous l'aurez certainement deviné en lisant le titre de cette section : il est tout à fait possible de combiner à la fois des constantes et des pentes aléatoires dans un modèle. Cela augmente bien sûr la complexité du modèle et introduit quelques subtilités comme la notion de distribution normale multivariée, mais chaque chose en son temps.

Si l'on reprend notre exemple avec nos élèves et nos classes, combiner à la fois des constantes et des pentes aléatoires revient à formuler l'hypothèse que chaque classe a un effet sur la moyenne de la performance de ses élèves, mais également un effet sur l'efficacité du temps de travail sur la performance. Il serait possible de créer un modèle avec uniquement des effets fixes tenant compte de ces deux aspects en ajoutant dans le modèle la variable multinomiale classe ainsi que son interaction avec la variable temps de travail. La formulation de ce modèle à effets fixes est la suivante :


\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma)\\
&g(\mu) = \beta_0 + \beta_1 x_1 + \sum^k_{j=1}{\beta_{2j}  x_{2j} + \beta_{3j} x_{2j}  x_1}\\
&g(x) = x
\end{aligned}
(\#eq:glmm6)
\end{equation}
\normalsize

Nous pouvons représenter les résultats de ce modèle avec la figure \@ref(fig:fullrandom1).

```{r fullrandom1, echo=FALSE, fig.align='center', fig.cap="Influence du temps de travail sur la performance scolaire d'élèves en tenant compte de l'effet de leur classe et de l'impact de la classe sur l'efficacité du temps de travail (effet fixe)", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}

model <- lm(Y2 ~ X*group, data = df3)
b1 <- model$coefficients[[2]]
inter <- model$coefficients[[1]]
inters <- c(0,model$coefficients[3:(2+length(colors)-1)])
coeffs <- c(0,model$coefficients[(2+length(colors)):length(model$coefficients)])

df4 <- data.frame(
  inter = inters + inter,
  slope = b1 + coeffs,
  group = names(colors)
)

ggplot(data = df3)+
  geom_point(aes(x = X, y = Y2, color = group), alpha = 0.8, size = 1)+
  geom_abline(data = df4, mapping = aes(intercept = inter, slope = slope, color = group),size = 1.2)+ 
  scale_color_manual(values =colors)+
  labs(y = "Note à l'examen (%)", x = "Temps de travail (heures)", color = "Classe")
```

Nous reformulons à présent ce modèle pour intégrer l'effet moyen de chaque classe (constante) et l'effet des classes sur l'efficacité du temps de travail (pente) comme deux effets aléatoires : 

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma)\\
&g(\mu) = \beta_0 + \upsilon_1 + (\beta_1 + \upsilon_2) x_1\\
&\left(\begin{array}{l}
\upsilon_{1} \\
\upsilon_{2}
\end{array}\right) \sim \mathcal{N}\left(\left(\begin{array}{l}
0 \\
0
\end{array}\right),\left(\begin{array}{cc}
\sigma_{\upsilon_1} & \sigma_{\upsilon_1\upsilon_2} \\
 \sigma_{\upsilon_1\upsilon_2} & \sigma_{\upsilon_1}
\end{array}\right)\right) \\
&g(x) = x
\end{aligned}
(\#eq:glmm7)
\end{equation}
\normalsize

Pas de panique ! Cette écriture peut être interprétée de la façon suivante.

Les modèles comprend deux effets aléatoires, l'un faisant varier la constante en fonction de l'école ($\upsilon_1$) et l'autre l'effet de l'école sur l'efficacité du temps de travail ($\upsilon_2$). Ces deux effets sont issus d'une distribution normale bivariée (une dimension par effet aléatoire). Cette distribution normale bivariée a donc deux moyennes et ces deux moyennes sont à 0, car comme nous l'avons vu dans les modèles précédents IL MANQUE QUELQUES CHOSE A LA PHRASE. Elle dispose également d'une variance par effet aléatoire ($\sigma_{\upsilon_1}$ et $\sigma_{\upsilon_2}$) et d'une covariance entre les deux effets aléatoires ($\sigma_{\upsilon_1\upsilon_2}$). Cette covariance permet de tenir compte du fait que potentiellement, les écoles avec une constante plus élevée pourraient systématique avoir un effet plus élevé ou plus faible sur l'efficacité du temps de travail. Cette formulation implique donc d'ajuster trois paramètres de variance : $\sigma_{\upsilon_1}$, $\sigma_{\upsilon_2}$ et $\sigma_{\upsilon_1\upsilon_2}$. Il peut arriver que nous ne disposions pas d'assez de données pour estimer ces trois paramètres, ou que nous estimons pour des raisons théoriques qu'aucune corrélation ne soit attendue entre $\sigma_{\upsilon_1}$ et $\sigma_{\upsilon_2}$. Dans ce cas, il est possible de fixer $\sigma_{\upsilon_1\upsilon_2}$ à 0, ce qui revient à indiquer au modèle que  $\sigma_{\upsilon_1}$ et $\sigma_{\upsilon_2}$ proviennent de deux distributions normales distinctes, nous pouvons donc écrire :

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma)\\
&g(\mu) = \beta_0 + \upsilon_1 + (\beta_1 + \upsilon_2) x_1\\
&\left(\begin{array}{l}
\upsilon_{1} \\
\upsilon_{2}
\end{array}\right) \sim \mathcal{N}\left(\left(\begin{array}{l}
0 \\
0
\end{array}\right),\left(\begin{array}{cc}
\sigma_{\upsilon_1} & 0 \\
 0 & \sigma_{\upsilon_1}
\end{array}\right)\right) \\
&g(x) = x
\end{aligned}
(\#eq:glmm8)
\end{equation}
\normalsize

Ce qui est identique à : 

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma)\\
&g(\mu) = \beta_0 + \upsilon_1 + (\beta_1 + \upsilon_2) x_1\\
&\upsilon_{1} \sim Normal(0,\sigma_{\upsilon_1}) \\
&\upsilon_{2} \sim Normal(0,\sigma_{\upsilon_2}) \\
&g(x) = x
\end{aligned}
(\#eq:glmm9)
\end{equation}
\normalsize

Nous avons déjà abordé la notion de covariance dans la section \@ref(sect041). Pour rappel, la covariance dépend de l'unité de base des deux variables sur laquelle elle est calculée. Ici il s'agit d'un coefficient et d'une constante, on préfère donc généralement la standardiser pour obtenir la corrélation entre les deux effets : 

\footnotesize
\begin{equation}
corr(\upsilon_1;\upsilon_2) = \frac{\sigma_{\upsilon_1\upsilon_2}}{\sqrt{\sigma_{\upsilon_1}}\sqrt{\sigma_{\upsilon_2}}}
(\#eq:glmm10)
\end{equation}
\normalsize

Si cette corrélation est positive, cela signifierait dans notre cas que dans les classes ayant tendance à avoir un effet positif sur la performance scolaire ont tendance à également positivement influencer l'efficacité du temps de travail. À l'inverse, une corrélation négative signifierait que l'efficacité du temps de travail a tendance à être plus faible dans les classes où la performance scolaire moyenne est élevée. Si la corrélation n'est pas significative, c'est que les deux effets sont indépendants l'un de l'autre.

Pour cet exemple, nous conservons la première formulation afin de montrer comment interpréter $\sigma_{\upsilon_1\upsilon_2}$, mais nous ne disposons probablement pas de suffisamment de classes différentes pour estimer correctement ces trois paramètres. Les résultats de ce modèle sont représentés à la figure \@ref(fig:fullrandom2).

```{r fullrandom2, echo=FALSE, fig.align='center', fig.cap="Influence du temps de travail sur la performance scolaire d'élèves en tenant compte de l'effet de leur classe et de l'impact de la classe sur l'efficacité du temps de travail (effet fixe)", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}

df3$x <- scale(df3$X,center = T, scale = T)

model2 <- lmer(Y2 ~ X + (X|group), data = df3,
              control = lmerControl(optimizer = "bobyqa"))
coeffs <- coef(model2)$group

df5 <- data.frame(
  inter = coeffs[,1],
  slope = coeffs[,2],
  group = rownames(coeffs)
)

ggplot(data = df3)+
  geom_point(aes(x = X, y = Y2, color = group), alpha = 0.8, size = 1)+
  geom_abline(data = df5, mapping = aes(intercept = inter, slope = slope, color = group),size = 1.2)+ 
  scale_color_manual(values =colors)+
  labs(y = "Note à l'examen (%)", x = "Temps de travail (heures)", color = "Classe")

covmod <- VarCorr(model2)$group[1,2]
sigma1 <- VarCorr(model2)$group[1,1]
sigma2 <- VarCorr(model2)$group[2,2]
```

Nous pouvons ainsi constater que pour ce troisième modèle, l'effet de resserrement est bien plus prononcé que pour les modèles précédents (\@ref(fig:fullrandom3)). Si l'on se fie au modèle à effets fixes (figure : \@ref(fig:fullrandom1)), alors l'impact de l'école sur l'efficacité du temps de travail est très important. En revanche, le modèle à effet aléatoire identifie que la différence de moyenne entre les écoles est importante, mais la différence en termes d'efficacité du temps de travail est beaucoup plus anecdotique.

```{r fullrandom3, echo=FALSE, fig.align='center', fig.cap="Comparaison des effets fixes et aléatoires pour le modèle intégrant l'effet des classes et l'interaction entre les classes et le tempsd de travail", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='90%'}
library(ggpubr)
plot1 <- ggplot() + 
  geom_point(data = df4, mapping = aes(x = inter, y = group,  color = "fixed")) +
  geom_point(data = df5, mapping = aes(x = inter, y = group, color = "random")) + 
  geom_vline(xintercept = mean(df4$inter)) + 
  labs(x = "constante", y = "classe", color = "type d'effet") + 
  scale_color_manual(values = c("fixed" = "red", random = "blue"), labels = c("fixe", "aléatoire"))

plot2 <- ggplot() + 
  geom_point(data = df4, mapping = aes(x = slope, y = group,  color = "fixed")) +
  geom_point(data = df5, mapping = aes(x = slope, y = group, color = "random")) + 
  geom_vline(xintercept = mean(df4$slope)) + 
  labs(x = "pente", y = "classe", color = "type d'effet") + 
  scale_color_manual(values = c("fixed" = "red", random = "blue"), labels = c("fixe", "aléatoire"))

ggarrange(plot1,plot2,ncol = 2, nrow = 1, common.legend = T)
rs2 <- r.squaredGLMM(model2)
```

Notre modèle estime les valeurs de $\sigma_{\upsilon_1}$ à `r tofr(round(sigma1, 3))`, de $\sigma_{\upsilon_2}$ à `r tofr(round(sigma2, 3))` et de $\sigma_{\upsilon_1\upsilon_2}$ à `r tofr(round(covmod, 3))`. La corrélation entre les deux effets est donc de `r tofr(round(covmod/(sqrt(sigma1)*sqrt(sigma2)), 3))` ce qui est relativement faible (pour l'anecdote, notez que la valeur originale de corrélation entre ces deux effets était de 0,1 lorsque nous avons simulé ces données, notre modèle est a donc bien été capable de retrouver le paramètre original). À nouveau, puisque nous avons des pentes aléatoires dans ce modèle, nous ne pouvons pas calculer l'ICC; nous pouvons cependant rapporter les R^2^ marginal et conditionnel. Leurs valeurs respectives sont `r tofr(round(r2s[[1]],3))` et `r tofr(round(r2s[[2]],3))`, ce qui nous confirme une nouvelle fois que l'ajout d'effets aléatoires contribue à expliquer une partie importante de la variance de la performance scolaire.

Pour terminer cette section, comparons brièvement les trois modèles (constantes aléatoires, pentes aléatoires, constantes et pentes aléatoires) pour déterminer lequel est le mieux ajusté à nos données. Nous ajoutons également un quatrième modèle dans lequel les deux effets aléatoires sont présents, mais non corrélés ($\sigma_{\upsilon_1\upsilon_2}=0$). Le tableau \@ref(tab:fullrandom4) nous permet de constater que l'ajout des constantes aléatoires joue un rôle essentiel dans le premier modèle : le R^2^ conditionnel est plus que deux fois supérieures au R^2^ marginal. Cependant, l'ajout des pentes aléatoires dans les trois autres modèles apporte finalement très peu d'information, nous laissant penser que l'effet de la classe sur le temps de travail est faible voire inexistant.


```{r fullrandom4, echo=FALSE, message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='90%'}
model1 <- lmer(Y2 ~ X + (1|group), data = df3)
model2 <- lmer(Y2 ~ X + (-1+X|group), data = df3)
model3 <- lmer(Y2 ~ X + (X|group), data = df3,
              control = lmerControl(optimizer = "bobyqa"))
model4 <- lmer(Y2 ~ X + (X||group), data = df3,
              control = lmerControl(optimizer = "bobyqa"))

models <- list(model1,model2,model3,model4)

tableau <- data.frame(
  name = c("Constantes aléatoires", "Pentes aléatoires", "Pentes et constantes aléatoires corrélées", "Pentes et constantes aléatoires non-corrélées"),
  aic = round(sapply(models, function(i){AIC(i)}),1),
  r2m = round(sapply(models, function(i){r.squaredGLMM(i)[[1]]}),2),
  r2c = round(sapply(models, function(i){r.squaredGLMM(i)[[2]]}),2)
)

show_table(tableau,
          caption = 'Comparaison des trois modèles à effets aléatoires',
          col.names=c("modèle","AIC","R^2^ marginal","R^2^ conditionnel"),
          align= c("l","r", "r", "r"))

```

### Effet aléatoire avec design croisé ou imbriqué

Lorsque les données analysées avec un GLMM comportent plus de deux niveaux, il est crucial de se demander si leur structure est imbriquée (*nested*) ou croisée (*crossed*). Le cas de la structure stratifiée est certainement le plus facile à comprendre.

Si nous reprenons l'exemple de la figure \@ref(fig:glmmecoles) avec les élèves intégrés dans des classes elles-mêmes intégrées dans des écoles, nous avons une structure de données à trois niveaux : élève / classe / école. Si l'on s'intéresse aux classes, nous pouvons être certains qu'une classe ne peut être présente que dans une seule et une seule école, formant ainsi une **structure imbriquée**. 

Admettons à présent que nous ne nous intéressons pas à la classe dans laquelle se situe l'élève, mais plutôt à son enseignant. Admettons également que les enseignants peuvent donner des cours dans plusieurs écoles. Nous nous retrouvons dans un cas de figure où un enseignant peut se situer dans plusieurs écoles, ce qui diffère du cas précédent où chaque classe appartient à une seule école. Dans ce second cas, on parle d'une **structure croisée** plutôt qu'imbriquée.

Si les professeurs enseignent dans toutes les écoles, il est possible de dire que le design d'étude est croisé complet ou croisé partiel si les professeurs n'enseignent que dans certaines écoles. La figure \@ref(fig:crossednested) résume graphiquement ces trois situations.

```{r crossednested, echo=FALSE, fig.align='center', fig.cap="Différentes structures de données hiérarchiques (imbriquée versus croisées)", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='50%'}
knitr::include_graphics('images/glmm/glmm_croise-nested.png', dpi = NA)
```

Il est important de bien saisir la structure de son jeu de données, car l'estimation d'un modèle avec effets imbriqués ou croisés peut donner des résultats parfois significativement différents. De plus, un modèle imbriqué est généralement moins difficile à ajuster qu'un modèle croisé. En effet, dans un modèle imbriqué, deux élèves venant de deux écoles différentes sont jugés indépendants. Dans un modèle croisé, deux élèves provenant de deux écoles différentes peuvent tout de même partager une dépendance du fait qu'ils ont pu avoir le même professeur. La structure de dépendance (et donc de la matrice de covariance des effets aléatoires) est ainsi plus complexe pour un modèle croisé.

Pour illustrer graphiquement cette différence dans la prise en compte de la dépendance entre les observations, nous utilisons un exemple originalement proposé par [Josh Errickson](https://errickson.net/stats-notes/vizrandomeffects.html#nested_random_effects). Cet exemple se base sur le jeu de données `Oxide` du *package* **nlme**. Ce jeu de données mesure la variabilité de l'épaisseur de la couche d'oxyde de semiconducteurs pour lesquels nous connaissons leur lot et leur plaquette (*wafer*). L'idée étant que l'épaisseur de cette couche peut varier en fonction de la plaquette sur laquelle on la mesure et en fonction du lot dont elle provient. Puisqu'une plaquette ne peut provenir que d'un seul lot, il faudrait idéalement utiliser une structure imbriquée. Nous allons cependant créer deux modèles pour comparer l'impact de la structure imbriquée et croisée. Notez ici que ce jeu de données comprend 72 observations (mesure de l'épaisseur de la couche d'oxyde), réparties dans neuf lots avec trois plaquettes par lot. Il est possible de synthétiser l'organisation plaquette / lot avec la figure \@ref(fig:plaquette1).

```{r plaquette1, echo=FALSE, fig.align='center', fig.cap="Structure imbriquée des données d'oxide de package nlme", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}
knitr::include_graphics('images/glmm/plaquettes1.png', dpi = NA)
```

La figure \@ref(fig:crossednested1) présente la matrice de corrélation (de dépendance) entre les observations du jeu de données selon un modèle dans lequel les effets aléatoires sont imbriqués. Nous pouvons constater la présence d'une première diagonale noire au centre. Elle représente la corrélation entre chaque observation et elle-même et vaut donc systématiquement 1. Les neuf grands blocs représentent les neuf lots et les sous-blocs représentent les plaquettes. Nous constatons ainsi que la corrélation de deux observations au sein d'un même lot est plus faible (gris clair) que la corrélation entre deux observations au sein du même lot et de la même plaquette (gris foncé).

```{r crossednested1, echo = FALSE, fig.align='center', fig.cap="Matrice complète de covariance d'un modèle avec structure imbriquée", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}
library(lme4)
library(nlme)
data(Oxide)

## fonction pour visualiser les matrices de covariance
rescov <- function(model, data) {
  var.d <- crossprod(getME(model,"Lambdat"))
  Zt <- getME(model,"Zt")
  vr <- sigma(model)^2
  var.b <- vr*(t(Zt) %*% var.d %*% Zt)
  sI <- vr * Diagonal(nrow(data))
  var.y <- var.b + sI
  invisible(var.y)
}

# ajustement du modèle
mod1 <- lmer(Thickness ~ 1 + (1|Lot/Wafer), data = Oxide)

# représentation de la matrice
rc1 <- rescov(mod1, Oxide)
image(rc1)
```

Dans ces données, les plaquettes sont toujours numérotées de 1 à 3, quel que soit le lot de provenance. Nous pouvons donc faire croire au modèle que la plaquette 1 (et les autres également) est présente dans chacun des lots (figure \@ref(fig:plaquette1)).

```{r plaquette2, echo=FALSE, fig.align='center', fig.cap="Structure imbriquée VS croisée", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}
knitr::include_graphics('images/glmm/plaquettes2.png', dpi = NA)
```

Avec cette représentation, nous imposons une structure croisée au modèle. La figure \@ref(fig:crossednested2) présente la matrice de corrélation obtenu pour ce second modèle.

```{r crossednested2, echo = FALSE, fig.align='center', fig.cap="Matrice complète de covariance d'un modèle avec structure croisée", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}
mod2 <- lmer(Thickness ~ 1 + (1|Lot) + (1|Wafer), data = Oxide)
rc2 <- rescov(mod2, Oxide)
image(rc2)
```

Comme nous pouvons l'observer, le modèle a ajusté une corrélation plus importante pour les observations provenant d'un même lot (grands carrés gris foncé), et une corrélation plus faible pour les observations provenant d'une même plaquette. Notez au passage que ce second modèle est erroné considérant que la réelle structure de nos données est imbriquée.

Notez donc que si votre modèle comprend plus de deux niveaux, vous devez vous vous demander : la structure entre mes différents niveaux est-elle imbriquée (chaque élément du niveau n se trouve dans un seul élément du groupe n+1) ou croisée (dans tous les autres cas).


## Conditions d'applicatoin des GLMM {#sect072}

Puisque les GLMM sont une extension des GLM, ils partagent l'essentiel des conditions d'application de ces derniers. Pour simplifier, si vous ajustez un modèle GLMM avec une distribution Gamma, vous devrez réaliser les mêmes tests que ceux pour un simple GLM avec distribution Gamma.

Une question importante se pose souvent lorsque l'on ajuste des modèles GLMM : **combien de groupes faut-il au minimum aux différents niveaux ?** En effet, pour estimer les différentes variances, nous devons disposer de suffisamment de groupes différents. Dans le cas d'un modèle avec uniquement une constante aléatoire, il est fréquent de lire que l'on doit disposer au minimum de cinq groupes différents [@gelman2006data], en dessous de ce minimum, traiter l'effet comme aléatoire plutôt que fixe apporte très peu d'information. De plus l'estimation des variances pour chaque groupe sera très imprécise donnant potentiellement des valeurs inexactes pour le ICC et polluant l'interprétation. Avec moins de groupes, il est certainement plus judicieux d'ajuster seulement un effet fixe. Dans un modèle avec plusieurs effets aléatoires et plusieurs variances / covariances à estimer, ce nombre doit être augmenté proportionnellement, à moins que les effets aléatoires ne soient estimés indépendants les uns des autres. Notez ici que si l'enjeu du modèle était d'estimer avec une certaine précision les paramètres de variances, il faudrait compter au minimum une centaine de groupes.

Puisque les GLMM font intervenir la distribution normale aux niveaux supérieurs du modèle, il est nécessaire de vérifier si les hypothèses qu'elle implique sont respectées. Il s'agit essentiellement de deux hypothèses : les effets aléatoires suivent bien une distribution normale (univariée ou multivariée), et la variance au sein des groupes est bien homogène.

### Vérifier la distribution des effets aléatoires

Reprenons la formulation d'un modèle simple avec seulement deux niveaux et seulement une constante aléatoire.

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma_e)\\
&g(\mu) = \beta_0 + \beta_1 x_1 + \upsilon \\
&\upsilon \sim Normal(0, \sigma_{\upsilon})) \\
&g(x) = x
\end{aligned}
\end{equation}
\normalsize

Ce modèle formule l'hypothèse que la constante aléatoire $\upsilon$ provient d'une distribution normale avec une moyenne de 0 et un écart type $\sigma_{\upsilon}$. La première étape du diagnostic est donc de vérifier si les constantes aléatoires suivent bien une distribution normale, ce que l'on peut faire habituellement avec un diagramme quantile-quantile. Si nous reprenons notre exemple avec nos données de performance scolaire des sections précédentes, nous obtenons la figure \@ref(fig:diagglmm1). Puisque les points tombent bien approximativement sur la ligne rouge, nous pouvons conclure que cette condition d'application est bien respectée. Notez qu'il est également possible d'utiliser ici un des tests vus dans le chapitre \@ref(chap02) pour tester formellement la distribution des constantes aléatoires, mais nous disposons rarement de suffisamment de valeurs différentes.

```{r diagglmm1, echo = FALSE, fig.align='center', fig.cap="Distribution normale univariée des constantes aléatoires", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}
model2 <- lmer(Y2 ~ X + (1|group), data = df3)

qplot(sample = ranef(model2)$group[,1])+
  geom_qq_line(line.p = c(0.25, 0.75),
               color = "red", size=0.8, linetype="dashed")+
  labs(title="Diagramme quantile-quantile",
     x="Valeurs théoriques",
     y = "Constantes aléatoires")
```

Cette vérification est bien-sûr à appliquer à chacun des niveaux (en dehors du niveau de base) du modèle étudié.

Si nous nous intéressons maintenant au modèle avec constantes et pentes aléatoires, nous avons deux cas de figure :

* notre modèle inclut une covariance entre les constantes et les pentes ; elles proviennent donc d'une distribution normale bivariée.

* notre modèle considère que les pentes et les constantes comme indépendantes; elles proviennent donc de deux distributions normales distinctes.

Le second cas est de loin le plus simple puisqu'il nous suffit simplement de réaliser un graphique de type Quantile-Quantile pour les deux effets aléatoires séparément. Dans le premier cas, il nous adapter notre stratégie pour vérifier si les deux effets aléatoires suivent conjointement une distribution normale multivariée. Pour cela, nous devons dans un premier temps observer séparément puisque chaque variable provenant d'une distribution normale multivariée suit elle-même une distribution normale univariée  [@burdenski2000evaluating]. Nous pouvons dans un second temps observer une version tridimensionnelle du graphique Quantile-Quantile. Pour l'illustrer, nous reprenons le modèle sur la performance scolaire intégrant des pentes et des constantes aléatoires avec une covariance estimée entre les deux.

La figure \@ref(fig:diagglmm2) représente donc les deux graphiques Quantile-Quantile et les deux semblent indiquer que nos effets aléatoires suivent bien une distribution normale. Quant à la la figure \@ref(fig:diagglmm3), elle la distribution normale bivariée attendue et les valeurs des effets aléatoires. Les différentes ellipses concentriques représentent les percentiles de cette distribution. Seulement 5% des points devraient se trouver dans la première ellipse et 95% des points devraient se trouver dans la quatrième ellipse. En revanche, seulement 20% des points devraient se trouver dans le dernier anneau et seulement 5% des points en dehors de cet anneau. Il faut donc tenter de distinguer si les points sont plus ou moins centrés que ce que l'on attend. Dans notre cas, ils semblent suivre un patron cohérent avec notre distribution normale bivariée. Dans le cas contraire, cela signifierait que le modèle doit être révisé.

```{r diagglmm2, echo = FALSE, fig.align='center', fig.cap="Multiples distributions normales univariées des constantes et pentes aléatoires", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}
model2 <- lmer(Y2 ~ X + (X|group), data = df3,
              control = lmerControl(optimizer = "bobyqa"))

re_effects <- ranef(model2)$group

q1 <- qplot(sample = re_effects[,1])+
  geom_qq_line(line.p = c(0.25, 0.75),
               color = "red", size=0.8, linetype="dashed")+
  labs(x="Valeurs théoriques",
     y = "Constantes aléatoires")

q2 <- qplot(sample = re_effects[,2])+
  geom_qq_line(line.p = c(0.25, 0.75),
               color = "red", size=0.8, linetype="dashed")+
  labs(x="Valeurs théoriques",
     y = "Pentes aléatoires")

ggarrange(q1,q2)
```


```{r diagglmm3, echo = FALSE, fig.align='center', fig.cap="Multiple distributions normales univariées des constantes et pentes aléatoires", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}
cor_mat <- VarCorr(model2)[[1]]

re_effects <- data.frame(ranef(model2)$group)
names(re_effects) <- c("constante","pente")

library(ellipse)

levels <- c(0.05,0.25,0.75,0.95)

els <- lapply(levels, function(i){
  el <- data.frame(ellipse(cor_mat,center = c(0,0), level = i))
  names(el) <- c("x","y")
  return(el)
})

ggplot() + 
  geom_path(data = els[[1]], aes(x = x, y = y, color = "a")) + 
  geom_path(data = els[[2]], aes(x = x, y = y, color = "b")) + 
  geom_path(data = els[[3]], aes(x = x, y = y, color = "c")) +
  geom_path(data = els[[4]], aes(x = x, y = y, color = "d")) + 
  geom_point(data = re_effects, aes(x = constante, y = pente))+
  scale_color_manual(values = c("a"="#90e0ef",
                                "b"="#00b4d8",
                                "c"="#0077b6",
                                "d"="#03045e"),
                     labels = c("5%","25%","75%","95%"))


```

### Homogénéité des variances au sein des groupes

Dans le chapitre sur les GLM \@ref(chap06) nous avons vu que chaque distribution a sa propre définition de la variance. Pour rappel, un modèle gaussien assume une variance constante, un modèle de Poisson assume une variance égale à son espérance, alors qu'un modèle Gamma assume une variance proportionnelle au carré de son espérance divisée par un paramètre de forme, etc. Nous devions donc pour chaque GLM vérifier graphiquement si la variance présente dans les données originales était proche de la variance attendue par le modèle. Dans un modèle GLMM, le même exercice doit être fait pour chaque groupe aux différents niveaux du modèle. 

À titre d'exemple, dans notre exemple sur la performance scolaire, notre variable *Y* a été modélisée avec une distribution normale. Le modèle assume donc une uniformité de sa variance (homoscédasticité). La figure \@ref(fig:glmmvariance) nous montre ainsi qu'elle que soit la classe, la dispersion des points semble bien respecter la variance attendue par le modèle (représentée par les lignes noires).


```{r glmmvariance, echo=FALSE, fig.align='center', fig.cap="Homogénéité de la variance pour les différents groupes d'un modèle GLMM Gaussien", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='95%'}
library(lme4)

model2 <- lmer(Y2 ~ X + (1|group), data = df3)

# Extraction des prédictions du modèle
mus <- predict(model2, type = "response")
sigma_model <- sigma(model2)

# Création d'un dataframe pour contenir les prédictions et les vraies valeurs
df1 <- data.frame(
  mus = mus,
  reals = df3$Y2,
  group = df3$group
)

df1$group <- as.factor(df1$group)

# Calcul de l'intervalle de confiance à 95% selon la distribution normale
# et stockage dans un second dataframe
seqa <- seq(70,95,5)
df2 <- data.frame(
  mus = seqa,
  lower = qnorm(p = 0.025, mean = seqa, sd = sigma_model),
  upper = qnorm(p = 0.975, mean = seqa, sd = sigma_model)
)

# Affichage des valeurs réelles et prédites (en rouge)
# et de leur variance selon le modèle (en noir)
ggplot() + 
  geom_point(data = df1, 
             mapping = aes(x = mus, y = reals),
             color ="red", size = 0.5) + 
  geom_errorbar(data = df2,
                mapping = aes(x = mus, ymin = lower, ymax = upper),
                width = 0.2, color = rgb(0.4,0.4,0.4)) + 
  labs(x = 'valeurs prédites',
       y = "valeurs réelles") + 
  facet_wrap(vars(group), ncol=3)

```

## Inférence dans les modèles GLMM

Une des questions importantes que l'on se pose lorsque l'on construit un modèle est toujours : est-ce que les différents effets présents dans le modèle ont un impact significativement différent de zéro sur la variable dépendante ? Cette étape d'inférence est plus compliquée pour les modèles GLMM que dans les modèles GLM à cause de la présence d'effets aléatoires. Ces derniers brouillent le comptage du nombre de paramètres et par extension du nombre de degré de liberté des modèles. Pour un effet aléatoire, il est possible de déterminer que le nombre de degrés de liberté est de 1 puisque nous ajustons un seul paramètre supplémentaire (la variance de cet effet aléatoire). Selon un autre point de vue, il serait possible d'affirmer que le nombre de degrés de liberté est de k-1 (avec k le nombre de groupes dans cet effet aléatoire), ce que nous utilisons habituellement pour un effet fixe. L'enjeu du nombre de degrés de liberté est crucial, car il impacte directement l'estimation des valeurs de *P* pour l'ensemble des coefficients du modèle. Avec un nombre de degrés de liberté plus petit, les valeurs de *P* seront plus faibles et les effets "plus significatifs". Le sujet est d'ailleurs l'objet d'une telle controverse que les auteurs de certains *package* comme **lme4** (un des *packages* les plus utilisés pour ajuster des GLMM) ont fait le choix de ne renvoyer aucune valeur de *P* dans les résultats des modèles. L'article de @bolker2009generalized propose une explication détaillée et relativement accessible du problème (en plus d'une excellente introduction aux GLMM), en se basant sur leurs recommandations, il est possible de séparer le problème de l'inférence dans les GLMM en trois sous problèmes : 

* Quel est le degré de significativité des effets fixes ?
* Quel est le degré de significativité général de l'effet aléatoire dans le modèle ?
* Quels sont les degrés de significativité de chaque constante / pente aléatoires ?


### Inférence pour les effets fixes

Trois approches peuvent être envisagées pour déterminer si un effet fixe est significatif ou non. Elles font appel à trois approches théoriques différentes (test de Wald, comparaison de modèle et bootsrapping) et peuvent donc donner des résultats différents. À titre exploratoire, il peut être intéressant de toutes les tester, mais certaines peuvent être préférées ou au contraire rejetées en fonction de votre champ de recherche.

#### Tests de Wald

Nous avions vu pour les modèles LM et GLM que les valeurs de *P* étaient calculées à partir de scores obtenus en divisant le coefficient par son erreur standard. Une approche similaire peut être utilisée pour les modèles GLMM, avec le test F. Cependant, la question du nombre de degrés de liberté à utiliser comme dénominateur reste. Plusieurs approches peuvent être envisagées pour déterminer ce nombre de degrés de liberté : 

* Utiliser comme valeurs 1 et *k−1*, il s'agit des deux extrêmes possibles, si les coefficients sont significatifs dans les deux cas, nous pouvons rapporter que leurs effets sont significatifs.
* Estimer le nombre de degrés de liberté avec la méthode de Kenward-Roger et ensuite calculer les tests *F*. Cependant, cette méthode n'est valide que si le modèle GLMM a une distribution gaussienne.
* Estimer le nombre de degrés de liberté avec la méthode de Satterthwaite et ensuite calculer les tests *F*.


#### Rapports de vraisemblance

Si le modèle comprend suffisamment d'observations (par suffisamment comprenez au moins une centaine d'observations par paramètre), il est également possible d'utiliser une série de tests de rapport de vraisemblance pour vérifier si l'apport de chaque variable indépendante contribue à améliorer significativement le modèle.

#### Bootstrapping

L'approche par *Bootstrapping* (*parametric-bootstrap* ou *semi-parametric-bootstrap*) permet de calculer pour les différents paramètres d'un modèle un intervalle de confiance. L'idée étant de réajuster un grand nombre de fois le modèle sur des sous-échantillons des données pour saisir la variabilité des différents paramètres du modèle. Si les intervalles de confiance ainsi construits ne comprennent pas zéro, il est possible de dire que cet effet est significatif. À nouveau, cette méthode n'est valide que si le jeu de données comporte suffisamment d'observations. L'intérêt de cette approche est qu'elle ne postule pas d'hypothèse sur la distribution des paramètres qui ont la fâcheuse tendance à ne pas suivre une distribution normale dans le cas des GLMM.

### Inférence pour les effets aléatoires, impact global

Pour déterminer si un effet aléatoire a un impact significatif dans un modèle, il est recommandé d'utiliser un test de rapport de vraisemblance entre un modèle sans l'effet aléatoire et un modèle avec l'effet aléatoire. L'analyse des différences entre les valeurs de déviance, AIC et BIC peut également aider à déterminer si l'ajout de l'effet aléatoire est justifié. Il est également possible de considérer les valeurs du ICC et du R^2^ conditionnel. Notez ici que si vous avez une très bonne raison théorique d'ajouter l'effet aléatoire dans votre modèle et suffisamment d'observations / groupes pour l'ajuster, il peut être pertinent de laisser l'effet aléatoire dans le modèle même si tous les indicateurs mentionnés précédemment indiquent qu'il contribue faiblement au modèle. Le retirer risquerait en effet de donner l'impression que les autres paramètres du modèle sont plus significatifs qu'ils ne le sont en réalité.

Notez que l'approche par Bootstraping décrite pour les effets fixes peut aussi être utilisées ici pour obtenir un intervalle de confiance pour l'ICC et pour le R^2^ conditionnel. 

### Inférence pour les effets aléatoires, constantes et pentes

Pour rappel, dans l'approche fréquentiste présentée ici, les valeurs des constantes et des pentes aléatoires ne sont pas à proprement parler des paramètres du modèle : elles sont estimées a posteriori (BLUP). Pour déterminer si ces constantes et pentes sont significativement différentes de zéro et significativement différentes les unes des autres, il est possible de calculer les intervalles de confiance de chacune d'entre elles par Bootstrap ou par profilage. Si la constante du groupe *j* a zéro dans son intervalle de confiance, on peut alors déclarer que le groupe *j* en question ne semble pas varier du reste de la population en termes de moyenne. Si la pente *l* du groupe *j* a zéro dans son intervalle de confiance, on peut alors déclarer que le groupe *j* en question ne semble pas varier du reste de la population pour l'effet *l*.

## conclusion sur les GLMM

Les GLMM sont donc une extension des GLM nous offrant une grande flexibilité de modélisation (variabilité des pentes et des constantes en fonction de groupes) et nous permettant d'analyser la partition de la variance entre plusieurs niveaux présents dans nos données. Cependant, cette flexibilité implique des modèles plus complexes avec un travail de diagnostic et d'interprétation plus long et potentiellement plus ardu.


## GLMM : application dans R {#sect073}

Pour cet exemple de GLMM, nous proposons de réanalyser les données présentées dans la section \@ref(sect06211) sur le modèle logistique binomial. Pour rappel, nous modélisions la probabilité qu'un individu utilise le vélo comme mode de transport pour son trajet le plus fréquent en utilisant une enquête réalisée auprès de près de 26000 européens. Initialement, nous avions intégré les pays comme un effet fixe, or nous savons à présent qu'il serait plus judicieux de les traiter comme un effet aléatoire. Nous comparons deux modèles, un pour lequel seulement la constante varie par pays et un second dans lequel la pente pour l'âge varie également par pays. L'hypothèse étant que dans certain pays, l'impact de l'âge sur l'utilisation du vélo pourrait être réduit dans certains pays ou la culture du vélo est plus présente. Cette hypothèse implique également la présence potentielle d'une corrélation inverse entre la constante et la pente de chaque pays : un pays avec une probabilité plus élevé de base d'utiliser la vélo a probablement un impact réduit sur l'effet de l'âge.

Pour ajuster ces modèles, nous utilisons le *package* **lme4**, permettant d'ajuster des modèles GLMM avec des distribution gaussienne, gamma, poisson et binomial. Lorsque d'autres distributions sont nécessaires, il est possible de se tourner vers le *package* **gamlss**. Notez cependant que les effets aléatoires de **gamlss** sont estimés avec une méthode appelée PQL très flexible mais qui peut produire des résultats erronés dans certains cas [@bolker2009generalized].

Afin de limiter les répétitions, nous ne recalculons pas ici le VIF et nous excluons d'emblée les observations aberrante (provenant de Malte, Chypre ou avec des temps de trajets supérieurs à 400 minutes).

### Ajustement du modèle avec uniquement une constante aléatoire

Nous commençons donc par ajuster un premier modèle avec une constante aléatoire en fonction du Pays. Dans la plupart des *packages* intégrant des effets aléatoires, la syntaxe suivante est utilisée pour stipuler une constante aléatoire : `+ (1|Pays)`. Concrètement, nous tentons d'ajuster le modèle décrit pas l'équation \@ref(eq:glmmbinom1)

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Binomial(p)\\
&g(p) = \beta_0 + \beta_1 x_1 + \upsilon \\
&\upsilon \sim Normal(0, \sigma_{\upsilon})) \\
&g(x) = log(\frac{x}{1-x}
\end{aligned}
(\#eq:glmmbinom1)
\end{equation}
\normalsize

Il s'agit simplement d'un modèle logistique binomial dans lequel nous avons rajouter une constante aléatoire : $\upsilon$. Dans notre cas, elle varie pas Pays. La syntaxe dans R pour produire ce modèle est la suivante.

```{r message=FALSE, warning=FALSE, out.width='50%'}
# Chargement des données
dfenquete <- read.csv("data/glm/enquete_transport_UE.csv")
dfenquete$Pays <- relevel(as.factor(dfenquete$Pays), ref = "Germany")

# Retirer les observations aberrantes
dfenquete2 <- subset(dfenquete, (dfenquete$Pays %in% c("Malta", "Cyprus")) == F & 
                  dfenquete$Duree < 400)

# Ajustement du modèle
library(lme4)

# necessité ici de centrer réduire ces variables pour permettre au modèle de converger
dfenquete2$Age2 <- scale(dfenquete2$Age,center = T, scale = T)
dfenquete2$Duree2 <- scale(dfenquete2$Duree,center = T, scale = T)

modele1 <- glmer(y ~Sexe + Age2 + Education + StatutEmploi + Revenu +
              Residence + Duree2 + ConsEnv + (1|Pays),
            family = binomial(link="logit"),
            control = glmerControl(optimizer = "bobyqa"),
            data = dfenquete2)
```

Nous réaliserons l'ensemble des diagnostic dans une section dédiée en fin de chapitre, nous nous concentrons ici sur l'interprétation des résultats du modèle. Notez cependant que le diagnostic devrait **précéder** l'interprétation comme nous l'avons vu dans la section sur les modèles GLM.

Vous noterez ici que nous avons centré-réduit les variables `Age` et `Duree`. Il est souvent nécessaire de réaliser cette étape en amont pour s'assurer que le modèle converge sans trop de difficulté. Dans notre cas, si ces deux variables sont laissées dans leur échelle d'origine, la fonction `glmer` ne parvient pas à trouver de solution. Notez que cette transformation n'affecte que la valeur relative de leurs coefficients respectifs.

La fonction `summary` nous donne accès à un premier ensemble d'informations

```{r message=FALSE, warning=FALSE, out.width='50%'}
summary(modele1)
```

La première partie de ce résumé nous rappelle la formule utilisée pour le modèle et nous indique différent indicateurs de qualité d'ajustement comme le AIC, le BIC et la déviance. Nous avons ensuite une partie dédiée aux effets aléatoires (`Random Effects`) et une partie dédiée aux effets fixes (`Fixed effects`). Cette dernière s'interprète de la même manière que pour un modèle à effet fixe, n'oubliez cependant pas d'utiliser la fonction exponentielle pour obtenir les rapports de cotes (fonction de lien logistique).

#### Rôle joué par l'effet aléatoire

Comme vous pouvez le constater, la section `Random Effects` ne comprend qu'un seul paramètre : la variance de l'effet pays. Nous pouvons ainsi écrire que l'effet du pays suit une distribution normale avec une moyenne de 0 et une variance $\sigma^2$ de `r tofr(round(VarCorr(modele1)[[1]][[1]],3))`. Pour aller plus loin dans cet analyse, nous pouvons calculer le coefficient de corrélation intraclasse (ICC). Cependant, puisque notre modèle est binomial et non gaussien, nous ne disposons pas d'une variance au niveau des individus, il est donc possible à la place d'utiliser la variance théorique du modèle : $\frac{\pi^2}{3}$. Nous calculons ainsi notre ICC : 

```{r message=FALSE, warning=FALSE, out.width='50%'}
# extraction de la variance des Pays
var_pays <- VarCorr(modele1)[[1]][[1]]

# calcul de l'ICC
var_pays / (((pi**2)/3) + var_pays)
```

Nous pouvons parvenir au même résultat en utilisant la fonction `icc` du *package* **performance**.

```{r message=FALSE, warning=FALSE, out.width='50%'}
library(performance)

# calcul de l'ICC
icc(modele1)
```

Notez que cette fonction distingue un ICC ajusté et un ICC conditionnel. Le premier correspond à l'ICC que nous avons présenté jusrqu'ici et que jous avons calculé à la main. L'ICC conditionnel inclue dans son estimation la variance présente dans les effets fixes. Un fort écart entre ces deux ICC indiquerait que les effets fixes sont capables de capturer une très forte variance dans les données ce qui pourrait remettre en cause la pertinence de l'effet aléatoire. Dans notre cas, la différence entre les deux est très faible.

En plus du ICC, nous pouvons calculer les R^2^ marginal et conditionnel. Pour cela, nous devons faire appel au *package* **MuMIn**.

```{r message=FALSE, warning=FALSE, out.width='50%'}
library(MuMIn)
r.squaredGLMM(modele1)
```

Dans notre cas, la fonction nous renvoie  la fois les R^2^ obtenu en utilisant la variance théorique du modèle ($\frac{\pi^2}{3}$ dans notre cas) et la variance estimée par la méthode delta. La seconde est plus conservative dans ce cas, mais les deux résultats indiquent que les effets aléatoires expliquent une part importante de la variance comparativement aux effets fixes. Notez également que la fonction `r2` du *package* **performance** peut calculer ces deux R^2^, mais seulement en utilisant la variance théorique.

#### significativité de l'effet aléatoire

Nous souhaitons déterminer ici si notre effet aléatoire contribue à significativement améliorer le modèle. Pour cela, nous effectuons un test de rapport de vraisemblance entre le modèle sans l'effet aléatoire (un simple GLM ici) et le modèle complet. Nous utilisons pour cela la fonction `anova` : 

```{r message=FALSE, warning=FALSE, out.width='50%'}
# ajustement d'un modèle sans l'effet aléatoire
model_simple <- glm(y ~Sexe + Age2 + Education + StatutEmploi + Revenu +
              Residence + Duree2 + ConsEnv,
            family = binomial(link="logit"),
            data = dfenquete2)

# comparaison des deux modèles
anova(modele1,model_simple)
```

Le test indique clairement que le modèle complet est mieux ajusté. Le AIC, le BIC et la déviance sont tous grandement réduits et le test est largement significatif.

Pour aller plus loin, nous pouvons utiliser une approche Bootstrap pour calculer un intervalle de confiance pour la variance de l'effet aléatoire, le ICC et le R^2^ conditionnel. Nous utilisons pour cela la fonction `bootMer`. Si vous essayez de lancer cette syntaxe, vous constaterez qu'elle prend énormément de temps, ce qui s'explique par le grand nombre de fois ou le modèle doit être réajusté. Nous vous recommandons donc de bien enregistrer vos résultats après l'exécution de la fonction.

```{r message=FALSE, warning=FALSE, out.width='50%'}
# definition d'une fonction pour extraire les valeurs qui nous intéresse
extractor <- function(mod){
  vari <- VarCorr(mod)[[1]][[1]]
  ICC <- vari / (vari + (pi**2/3))
  r2cond <- performance::r2(mod)[[1]]
  return(c("vari"=vari,"icc"=ICC,"r2cond"=r2cond))
}

valeurs <- bootMer(modele1,FUN = extractor,nsim = 3, use.u = F, type="parametric")
```

## Régressions multiniveaux {#sect074}
