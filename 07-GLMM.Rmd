# Régressions à effets mixtes (GLMM) et régression multiniveaux  {#chap07}

Dans les deux chapitres précédent, nous avons consécutivement présenté la méthode de la régression linéaire simple (LM) ainsi que son extension : les modèles linéaires généralisés. Dans ce chapitre, nous poursuivons sur cette voie avec un nouveau développement : les modèles généralisés à effet mixtes et le modèles multiniveaux.

## Introduction

### Indépendance des observations et effets de groupes

Nous avons vu dans les précédents chapitres que l'indépendance des observations est une condition d'application commune à l'ensemble des modèles de régression. Cette condition implique ainsi que chaque unité d'observation de notre jeu de données est indépendante des autres ; en d'autres termes, qu'elle ne soit associée à aucune autre observation par un lien de dépendance. Prenons un exemple concret pour illustrer ce concept. Admettons que nous nous intéressons à la réussites scolaire d'élève de secondaire à Montréal. Pour cela, nous collectons la moyenne des résultats aux examens ministériaux de tous les élèves des différentes commissions scolaires de l'Île de Montréal. Chaque élève appartient à une classe sépcifique, et chaque classe se trouve dans une école spécifique. Les classes constituent des environnements particuliers, la réussite des élèves y est influencée par un ensemble de facteur comme l'enseignant et les relations avec les autres élèves. Deux élèves provenant d'une même classe sont donc liés par une forme de structure propre à leur classe et ne peuvent pas être considérés comme indépendants. De même, l'école constitue un environnement particulier pouvant influencer la réussite des élèves du fait de moyens financiers plus important ou d'une localisation minimisant certaines nuisances à l'apprentissage comme le bruit. À nouveau, deux élèves provenant d'une même école partage une forme de structure qui cette fois-ci est propre à leur école. Si nous collections des données pour l'ensemble du Canada, nous pourrions étendre ce raisonnemment aux villes dans lesquelles les écoles se situent et au provinces.

Dans cet exemple, la dépendance entre les données est provoquée par un effet de groupe : il est possible de rassembler les observations dans des ensembles (classes et écoles) influençant vraissemblablement la variable étudiée (réussite scolaire). Les effets des classes et des écoles ne sont cependant pas intrinsèque aux élèves. En effet, il est possible de changer un élève de classe ou d'école, mais pas de changer son sexe, ou sa situation familiale. Il est ainsi possible de distinguer la population des élèves, la population des classes, et la population des écoles (\@ref(fig:glmmecoles)). Ces effets de groupes sont plus la règles que l'exception dans l'analyse de données en sciences sociales ce qui met à mal l'hypothèse d'indépendance des observations. Notez que les effets de groupes ne sont pas les seules formes de structures remettant en cause l'indépendance des observations. Il existe également des structures temporelles (deux observations proches dans le temps ont plus de chances de se ressembler) et spatiales (deux observations proches dans l'espace ont plus de chances de se ressembler). Cependant, le cas de la dépendance temporelle et spatiale n'est pas couverte dans ce livre car complexes et elles mériteraient un ouvrage dédié.

```{r glmmecoles, echo=FALSE, fig.align='center', fig.cap="Structure hiérarchique entre élèves, classes et écoles", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}
library(dplyr)
knitr::include_graphics('images/glmm/Hierarchie_Ecoles.png', dpi = NA)
```

::: {.bloc_aller_loin data-latex=""}
**La notion de pseudo-réplication**

Les effets de dépendance causés par des structures de groupes, temporelles ou spatiales sont regroupées sous le terme de pseudo-réplication. Il est intéressant de se pencher sur la signification de ce mot pour comprendre le problème intrinsèque causé par la dépendance entre les observations et son impact sur l'inférence.

Reprenons l'exemple des élèves et de la réussite scolaire et admettons que nous souhaitons estimer la moyenne générale de l'ensemble des élèves sur l'Île de Montréal mais que nous ne disposons pas du jeu de données complet. Nous devons donc collecter un échantillon suffisamment grand pour estimer la moyenne pour l'ensemble de cette population. Raisonnons en terme de quantité d'informations. Si nous ne disposons d'aucune observation (nous n'avons encore interrogé aucun élève), cette quantité est de 0. Si nous interrogeons un premier élève nous obtenons une données supplémentaire et donc un point d'information supplémentaire (+1). Admettons maintenant que nous collectons 30 observations dans une école, 10 dans une seconde et 5 dans une troisième. À priori, nous pourrions dire que nous avons ajouté 45 points d'information à notre total de connaissance. Ce serait le cas si chacune des observations étaient indépendantes les unes des autres. Dans un tel contexte, chaque observation ajoute la même quantité d'information. Cependant, puisque les élèves issus d'une même école ont plus de chance de se ressembler, interroger les élèves d'une même école apporte moins d'information. Notez que plus la ressemblance entre les élèves d'une même école est forte, plus la quantité d'information est réduite. Nous sommes donc loin de disposer d'une quantité d'information égale à 45. Chaque réplication de l'expérience (demander à un élève sa moyenne annuelle) n'apporte pas autant d'information qu'attendu si les observations étaient indépendantes, c'est pourquoi on parle de **pseudo-réplication**.

La pseudo-réplication impacte directement l'inférence statistique puisque le calcul des différents tests statistiques assume que chaque observation apporte autant d'information que les autres. En cas de présence de pseudo-réplication, la quantité d'information présente dans l'échantillon est plus petite qu'attendu. Il est possible de voir cela comme une forme de surestimation de la taille de l'échantillon. En cas de pseudo-réplication nous disposons en réalité de moins de données que ce que l'on attendrait d'un échantillon de cette taille si les observations étaient indépendantes. La conséquence est la sous-estimation de la variabilité réelle des données et l'augmentation des risques de trouver des effets significatifs dans l'échantillon alors qu'ils ne le sont pas pour l'ensemble de la population.
:::

### Terminologie : effets fixes et effets aléatoires

Puisque les effets des classes et des écoles ne sont pas propres aux élèves, il convient de les introduire différemment dans les modèles de régression. Nous appelons un effet fixe, un effet qui est propre aux observations que nous étudions et un effet aléatoire, un effet provoqué par une structure externe (effet de groupe, effet temporel, effet spatial). Un modèle combinant à la fois des effets fixes et des effets aléatoires est appelé un modèle à effets mixtes, ou GLMM pour *Generalized Linear Mixed Model*. En science sociale, on utilise aussi souvent le terme de modèle hiérachique ou miltiniveau. Tous les modèles que nous avons ajusté dans les sections précédentes ne comprennaient que des effets fixes alors qu'à plusieurs reprises, des effets aléatoires induis par l'existence de structure de groupes auraient pu (dû) être utilisés. Prenons pour exemple le modèle logistique binomial visant à prédire la probabilité d'utiliser le vélo comme mode de transport pour son trajet le plus fréquent (REF). La variable multinomiale *Pays*, représentant le pays dans lequel les personnes interrogées résident a été introduite comme un effet fixe. Cependant, l'effet du pays ne constitue pas une caractéristique propre aux individus, il s'agit davantage d'un agrégat complexe mélant culture, météorologie, orientation des politiques publiques et formes urbaines. À l'inverse, le sexe ou l'âge sont bien des caractéristiques intrinsèques des individus et peuvent être considérés comme des effets fixes.

Notez que l'utilisation du terme effet aléatoire peut porter à confusion car différente utilisation en sont faites en fonction du champ d'étude. Parmis les différentes définitions relevées par @gelman2005analysis d'un effet aléatoire, il est possible de retrouver les suivantes : 

* Les effets fixes sont identiques pour tous les individus alors que les effets aléatoires varient (définition 1)

* Les effets sont fixes s'ils sont intéressant en eux-mêmes, et les effets sont aléatoires si on s'intéresse à la population dont ils sont issus (définition 2)

* Lorsqu'un échantillon couvre une grande part de la population, la variable correspondante est un effet fixe. Si l'échantillon couvre une faible part de la population, l'effet est aléatoire (définition 3)

* Si l'effet est supposé provenir d'une variable aléatoire, alors il s'agit d'un effet aléatoire (définition 4)

* Les effets fixes sont estimés par la méthode des moindres carrés our par maximum de vraissemblance alors que les effets aléatoires sont estimés avec régularisation (*shrinkage*) (définition 5).

Il est ainsi possible de se retrouver dans des cas où un effet serait classé comme fixe selon une définition et aléatoire selon une autre. La deuxième définition suppose même qu'un effet peut être aléatoire ou fixe selon l'objectif central de l'étude. La dernière définition a l'avantage d'être mathématique, mais ne permet pas de décider si un effet doit être traité comme aléatoire ou fixe. Nous ne proposons pas ici de clore se débat, mais plutôt de donner quelques pistes de réflexion pour décider si un effet doit être modélisé comme fixe ou aléatoire : 

* Est-ce que l'effet en question est propre aux individus étudiés ou est externe aux individus. S'il est propre aux individus, il s'agit plus certainement d'un effet fixe. À titre d'exemple, on ne peut pas changer le sexe d'un individu, mais on peut certainement changer sa ville de résidence.
* Existe-t-il un nombre bien arrêté de catégories possibles pour l'effet en question ? Si oui, il s'agit plus certainement d'un effet fixe. Toujours avec le même exemple, il y a un nombre bien arrêté de catégories pour la variable sexe, mais pour la variable Pays, de nombreuses autres valeurs auraient pu être ajoutées. Il est également possible de se demander s'il semble cohérent d'effectuer un échantillonage sur les catégories en question. Dans le cas des pays, nous pourrions mener une étude à l'échelle des pays et collecter des données sur un échantillon de l'ensemble des pays. Il existe donc une population de pays, ce que nous ne pouvons pas affirmer pour la variable sexe.
* L'effet en question est direct ou indirect ? Dans le second cas, l'effet en question est un agglomérat complexe découlant de plusieurs processus n'ayant pas été mesurés directement, ce qui correspond davantage à un effet aléatoire. Ainsi, l'effet du pays de résidence des individus sur leur probabilité d'utiliser le vélo est bien une agglomération complexe d'effets (culture, météorologie, orientation des politiques publiques, formes urbaines, etc.) n'ayant pas tous été mesurés. À l'inverse, l'âge d'un individu a bien un effet direct sur sa probabilité d'utiliser le vélo.
* L'effet est-il le même pour tous les individus, ou doit-il varier selon le groupe dans lequel l'individu se situe ? Si un effet doit varier en fonction d'un groupe, il s'apparente davantage à un effet aléatoire. Pour reprendre l'exemple de l'âge, nous pourrions décider que cette caractéristiques des individus n'a peut être pas le même impact en fonction du pays dans lequel vis l'individu et l'ajouter au modèle comme un effet aléatoire.

Vous comprendrez donc qu'une partie non négligeable du choix entre effet fixe ou aléatoire réside dans le cadre théorique à l'origine du modèle. Maintenant que cette distinction conceptuelle a été détaillée, nous pouvons passer à la présentation statistique des modèles GLMM.

## Principes de base des GLMM {#sect071}

Un GLMM est donc un modèle GLM introduisant à la fois des effets fixes et des effets aléatoires. Si l'on ne considère que les effets de groupes, un GLMM peut avoir trois formes : constantes aléatoires, pentes aléatoires et constances et pentes aléatoires. Nous présentons ces trois formes ici en reprenant l'exemple théorique ci-dessus avec des élèves intégérés dans des classes pour lesquels nous nous intéressons à leur niveau de réussite à l'examen ministériel de mathématique.

### GLMM avec constantes aléatoires

Il s'agit de la forme la plus simple d'un GLMM, plus spécifiquement, elle autorise le modèle à avoir une constante différente pour chaque catégorie d'une variable multinomiale. En d'autres termes, nous tentons d'ajouter dans le modèle l'idée que chaque classe a une moyenne différente en terme de réussite à l'examen de mathématique. Il est possible assez facilement de visualiser ce que cela signifie avec un exemple graphique. Admettons que nous modélisons le score obtenu par des élèves de secondaire à l'examen ministériel de mathématique à partir d'une autre variable continue représentant le temps de travail moyen par semaine en dehors des heures de classes et d'une variable catégorielle représentant dans quelle classe se trouve chaque élève. (Notez qu'il ne s'agit pas ici de vrais données, mais de simples simulations utilisées à titre d'illustration). Si nous ne tenons pas compte des classes nous pouvons ajuster une simple régression linéaire entre nos deux variables continues comme le propose la figure \@ref(fig:randominter1).

```{r randominter1, echo=FALSE, fig.align='center', fig.cap="Influence du temps de travail sur la réussite scolaire d'élèves", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}

set.seed(11)

## generere des effets aleatoires
groups <-  c("A","B","C","D","E","F","G","H")
sig2 <- matrix(c(12, 0.1,
                 0.1, 0.5), 
               nrow = 2, ncol = 2)
mu2 <- c(inter = 0, coeff = 0)
df2 <- data.frame(data.frame(MASS::mvrnorm(n = length(groups), mu = mu2, Sigma = sig2)))
df2$name <- groups

colors <- hcl.colors(length(groups), palette = "Dynamic")
names(colors) <- groups

## generer des donnees
n <- 300
df <- data.frame(
  X = rnorm(n,8,2),
  group = sample(df2$name,size = n, replace = T)
)

df3 <- merge(df,df2, by.x="group",by.y="name")
df3$Y <- 65 + df3$X*(1.5+df3$coeff) + df3$inter + rnorm(n = n, mean = 0, sd = 8)
df3$Y2 <- ifelse(df3$Y>=100, 100, df3$Y)

## afficher le tout !
ggplot(data = df3)+
  geom_point(aes(x = X, y = Y2, color = group), size = 1) + 
  geom_smooth(aes(x = X, y = Y2),method='lm', formula= y~x, se=F, color = "black", size = 1.2)+
  scale_color_manual(values = colors)+
  labs(y = "Score à l'examen (%)", x = "Temps de travail (heure)", color = "Classe")
```

On constate ainsi que notre modèle semble bien identifier la relation positive entre le temps de travail et le niveau de réussite, mais la droite de régression est très éloignée de chaque point, nous avons donc énormément d'erreur de prédiction et de résidus. Jusqu'ici nous avons vu que nous pouvions ajouter un prédicteur et intégrer l'effet des classes comme un effet fixe.

```{r randominter2, echo=FALSE, fig.align='center', fig.cap="Influence du temps de travail sur la réussite scolaire d'élèves en tenant compte de l'effet de leur classe (effet fixe)", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}

model <- lm(Y2 ~ X + group, data = df3)
b1 <- model$coefficients[[2]]
diffs <- c(0,model$coefficients[c(3:length(model$coefficients))])
diffs <- diffs + model$coefficients[[1]]

df4 <- data.frame(
  inter = diffs,
  slope = b1,
  group = names(colors)
)

ggplot(data = df3)+
  geom_point(aes(x = X, y = Y2, color = group), alpha = 0.8, size = 1)+
  geom_abline(data = df4, mapping = aes(intercept = inter, slope = slope, color = group),size = 1.2)+ 
  scale_color_manual(values =colors)+
  labs(y = "Score à l'examen (%)", x = "Temps de travail (heure)", color = "Classe")
```

Cet ajustement constitue une nette amélioration du modèle. Prenons un instant pour reformuler clairement notre modèle à effets fixes : 

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma)\\
&g(\mu) = \beta_0 + \beta_1 \times x_1 + \sum^k_{j=0}{\beta_j \times x_{2k}}\\
&g(x) = x
\end{aligned}
\end{equation}
\normalsize

avec $x_1$ le temps de travail et $x_2$ la classe ayant k-1 modalités. Nous ainsi ajustons un coefficient pour chaque classe qui va avoir pour effet de tirer vers le haut ou vers le bas la prédiction du modèle en fonction de la classe. Cet effet est pour l'instant fixe, mais conceptuellement, nous avons déterminés dans les sections précédentes qu'il serait conceptuellement plus approprié de le traiter comme un effet aléatoire.

Passons à présent à la reformulation de ce modèle en transformant l'effet fixe de la classe en effet aléatoire.

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma_e)\\
&g(\mu) = \beta_0 + \beta_1 \times x_1 + \upsilon \\
&\upsilon \sim Normal(0, \sigma_{\upsilon})) \\
&g(x) = x
\end{aligned}
\end{equation}
\normalsize

Vous noterez que l'effet fixe de la classe $\sum^k_{j=0}{\beta_j \times x_{2k}}$ a été remplacé par $\upsilon$. $\upsilon$ est un terme aléatoire, propre aux classes et suivant une distribution normale centrée sur 0. Cela signifie que l'effet des classes sur la réussite des élèves suit une distribution normale et que si l'on moyennait l'effet de toutes classes, cet effet serait de 0. Nous ne modélisons donc plus l'effet moyen de chaque classe comme dans le modèle à effets fixes, mais la variabilité de l'effet des classes : $\sigma_{\upsilon}$. Notre modèle a donc deux variances, une au niveau des élèves ($\sigma_e$) et une au niveau de classes ($\sigma_{\upsilon}$). Cette particularité explique souvent pourquoi ce type de modèle est appelé un modèle hiérarchique ou un modèle de partition de la variance. Cette information est particulièrement intéressante car elle nous permettra de calculer dans le cas d'un GLMM Gaussien, la part de la variance présente au niveau des éléves et celle présente au niveau des classes.

Selon cette formulation, les constantes propres à chaque classe sont issues d'une distribution normale (nous reviendrons d'ailleurs sur ce choix plus tard), mais elles n'apparaissent pas directement dans le modèle. Ces paramètres ne sont en réalité plus estimés directement dans le modèle, mais à postériori à partir des prédictions du modèle, et sont appelés les *Best Linear Unbiased Predictor* (*BLUP* pour les intimes). Ces dernières précisions devraient d'ailleur mieux vous aider à comprendre l'origine des définitions 1,2 et 4 que nous avions mentionées précédemment. 

```{r randominter3, echo=FALSE, fig.align='center', fig.cap="Influence du temps de travail sur la réussite scolaire d'élèves en tenant compte de l'effet de leur classe (effet aléatoire)", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}
library(lme4)

model2 <- lmer(Y2 ~ X + (1|group), data = df3)

coeffs <- coef(model2)$group
df5 <- data.frame(
  inter = coeffs[,1],
  slope = coeffs[,2],
  group = rownames(coeffs)
)

ggplot(data = df3)+
  geom_point(aes(x = X, y = Y2, color = group), alpha = 0.8, size = 1)+
  geom_abline(data = df5, mapping = aes(intercept = inter, slope = slope, color = group),size = 1.2)+ 
  scale_color_manual(values = colors)+
  labs(y = "Score à l'examen (%)", x = "Temps de travail (heure)", color = "Classe")
```

En comparant les deux graphiques, la différence ne saute pas directement aux yeux, vous pourriez donc légitimement vous demander, pourquoi tous ces efforts et cette complexité théorique pour une différence d'ajustement minime ? Trois arguments permettent de justifier l'utilisation de constantes aléatoire plutôt que d'effets fixes dans notre cas.

#### Resserrement (shrinkage) et mutualisation (partial pooling)

Le premier intérêt ici d'utiliser un effet aléatoire réside dans sa méthode d'estimation qui diffère largement d'un effet fixe. Il est assez facile de se représenter intuitivement la différence entre les deux. Dans le cas de nos éléves et de nos classe, lorsque l'effet des classes est estimé avec un effet fixe, l'effet de chaque classe est déterminé de façon totalement indépendante des autres classes. En d'autres termes, il n'est possible d'en apprendre plus sur une classe qu'en collectant des données dans cette classe (*separate pooling*). Si l'effet des classes est estimé comme un effet aléatoire, alors l'information entre les classes est mutualisée (partial pooling). L'idée étant que l'information que l'on apprend sur des élèves dans une classe est au moins en partie valide dans les autres classes également. Cette méthode d'estimation est particulièrement intéressante si nous ne disposons que de peu d'observations dans une classe puisque nous pouvons apprendre au moins une partie de l'effet de cette classe à partir des données des autres classes. Ceci n'est pas possible dans le cas d'un effet fixe où l'on traite chaque classe en silo. @mcelreath2020statistical écrit à ce sujet qu'un effet fixe "n'a pas de mémoire" et qu'il oublie tout ce qu'il a appris sur les classes lorsqu'il passe à une nouvelle classe. La conséquence de cette mutualisation de l'information est un resserrement (*shrinkage*) des effets des classes autours de leur moyenne. Cela signifie que les tailles des effets de chaque classe sont plus petits dans le cas d'un effet aléatoire que d'un effet fixe. Utiliser des effets aléatoires conduit donc à une estimation plus concervative de l'effet des classes. Nous pouvons le visualiser en comparant les effets de classes dans le modèle à effets mixtes et le modèle à effet fixes. La figure \@ref(fig:randominter5) montre clairement que les effets aléatoires tendent à se rapprocher (resserrement) de leur moyenne (ligne noire) et donc à renvoyer des effets moins extrèmes pour chaque classe. Cette explication est directement en lien avec la définition 5 d'un effet aléatoire vu précédemment.

```{r randominter5, echo=FALSE, fig.align='center', fig.cap="Comparaison des effets des classes pour le modèles à effets fixes VS aléatoires", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='50%'}
library(MuMIn)

r2s <- r.squaredGLMM(model2)

df6 <- data.frame(
  fixed = df4$inter,
  random = df5$inter,
  group = df4$group
)

ggplot() + 
  geom_point(data = df4, mapping = aes(x = inter, y = group,  color = "fixed")) +
  geom_point(data = df5, mapping = aes(x = inter, y = group, color = "random")) + 
  geom_vline(xintercept = mean(df4$inter)) + 
  labs(x = "effet de la classe", y = "classe", color = "type d'effet") + 
  scale_color_manual(values = c("fixed" = "red", random = "blue"), labels = c("fixe", "aléatoire"))

sigma_u <- as.data.frame(VarCorr(model2))$sdcor[[1]]
sigma_e <- as.data.frame(VarCorr(model2))$sdcor[[2]]
```
#### Prédiction pour de nouveaux groupes

Une autre retombée directe de la mutualisation de l'information est la capacité de modèle à envisager les effets plausibles pour de nouvelles classes. En effet, puisque nous avons approximé l'effet des classes sous forme d'une distribution normale dont nous connaissons la moyenne (0) et l'écart type ($\sigma_{\upsilon}$), nous pouvons simuler des données pour de nouvelles classes, ce que ne permet pas un effet fixe. Ce constat est d'ailleurs directement lié à la définition 3 des effets aléatoires vu précédemment. Dans notre cas, $\sigma_{\upsilon}$ = `r round(sigma_u,3)`, ce qui nous permet d'affirmer que dans 95% des classes, l'effet de la classe sur la réussite scolaire doit se trouver entre -1,96 x `r round(sigma_u,3)` et +1.96 x `r round(sigma_u,3)`, soit l'intervale [`r round(-1.96*sigma_u,3)`,`r round(1.96*sigma_u,3)`].

#### Partition de la variance

Un autre avantage net de l'effet aléatoire est l'estimation du paramètre $\sigma_{\upsilon}$, soit la variance au niveau des écoles. Ce dernier nous permet de calculer un indicateur très intéressant le **ICC** ou l'**indice de corrélation intraclasse** : 

\footnotesize
\begin{equation}
ICC = \frac{\sigma_{\upsilon}}{\sigma_{\upsilon} + \sigma_{e}}
\end{equation}
\normalsize

Il s'agit donc du pourcentage de la variance présente au niveau des classes, qui peut être interprété comme le niveau de corrélation (de ressemblance) entre les élèves d'une même classe.

Dans notre cas l'écart type au niveau des classes est de `r cat(round(sigma_u,3))`, et de `r round(sigma_e,3)` au niveau des élèves. Nous pouvons donc calculer l'ICC au niveau des classes avec la formule précédentes : `r round(sigma_u,3)` / (`r round(sigma_u,3)` + `r round(sigma_e,3)`) = `r round(sigma_u /(sigma_u + sigma_e),3)`. Cela signifie que le niveau de corrélation entre deux élèves d'une même classe est de `r round(sigma_u /(sigma_u + sigma_e),3)` ou encore que `r round(sigma_u /(sigma_u + sigma_e),3)*100` % de la variance de *Y* se situe au niveau des classes, que  ce qui est conséquent. Une telle information ne peut être extraite d'un modèle avec seulement des effets fixes. Notez ici que l'ICC peut être calculé pour chaque niveau d'un modèle à effet mixte. Dans notre exemple nous n'avons qu'un seul niveau au dessus des élèves, soit les classes, mais nous pourrions étendre cette logique à des écoles par exemple. Notez également que cette formule de l'ICC n'est valide que pour un modèle pour lequel la distribution de la variable *Y* est normale. Des développements apparaissent pour proposer d'autre formulations adaptées à d'autres distributions (imaginons le cas d'une distribution de Poisson n'ayant pas de paramètre de variance !), mais il est également possible d'estimer le ICC à partir des simulations issues du modèle [@NakagawaICC ; @aly2014reliability ; @stryhn2006interpretation ; @wu2012comparison]. L'idée générale reste d'expliquer la partition de la variance dans le modèle.

En plus de l'ICC, il est également possible de calculer les **R^2^ marginal et conditionnel** du modèle. Le premier représente la variance expliquée par le modèle si seulement les effets fixes sont pris en compte, et le second si les effets fixes et aléatoires sont pris en compte. Distinguer les deux sources d'information permet de mieux cerner dans notre cas l'importance du rôle des écoles dans la réussite des élèves. Dans notre cas, nous obtenons un R^2^ marginal de `r round(r2s[[1]],3)` et un R^2^ conditionnel de `r round(r2s[[2]],3)` ce qui nous confirme à nouveau que le rôle joué par la classe dans le niveau de réussite est loin d'être négligeable.

### GLMM avec pentes aléatoires

Dans cette seconde version du GLMM, nous n'envisageons plus de faire varier une constante en fonction des classes, mais un coefficient en fonction des classes. Admettons ici que nous voulions tester si l'effet du temps de travail ($x_1$) sur la réussite scolaire (*Y*) n'est pas constant partout, et que dans certaines classes le temps de travail par semaine et dehors de l'école est plus efficace que d'autres. L'idée sous-jacente est que nous n'observons pas de différence en terme de moyenne entre deux classes, mais en terme d'effet pour notre variable $x_1$. À nouveau, nous pourrions nous contenter d'effet un fixe pour intégrer cette idée dans notre modèle. Pour cela, nous avons simplement à ajouter une interaction entre notre variable quantitative temps de travail et notre variable qualitative classe. Nous obtenons le résultat décrit par la figure \@ref(fig:@randomslope).

```{r randomslope, echo=FALSE, fig.align='center', fig.cap="Influence du temps de travail sur la réussite scolaire d'élèves en interraction avec la classe (effet fixe)", message=FALSE, warning=FALSE, auto_pdf=TRUE, out.width='70%'}

model <- lm(Y2 ~ X + X:group, data = df3)
inter <- model$coefficients[[1]]
b1 <- model$coefficients[[2]]
diffs <- c(0,model$coefficients[c(3:length(model$coefficients))])
diffs <- b1 + diffs

df4 <- data.frame(
  inter = inter,
  slope = diffs,
  group = names(colors)
)

ggplot(data = df3)+
  geom_point(aes(x = X, y = Y2, color = group), alpha = 0.8, size = 1)+
  geom_abline(data = df4, mapping = aes(intercept = inter, slope = slope, color = group),size = 1.2)+ 
  scale_color_manual(values =colors)+
  labs(y = "Score à l'examen (%)", x = "Temps de travail (heure)", color = "Classe") + 
  xlim(0,max(df3$X)+1)
```

La formulation de ce modèle à effets fixes seulement est la suivante : 

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma)\\
&g(\mu) = \beta_0 + \beta_1 \times x_1 + \sum^k_{j=0}{\beta_j \times x_{2k} \times x_1}\\
&g(x) = x
\end{aligned}
\end{equation}
\normalsize

On constate donc que nous avons un effet principal $beta_1$ décrivant le lien entre temps de travail et le score obtenu à l'examen pour l'ensemble des élèves, ainsi qu'un bonus ou un malus sur cet effet $\beta_j$ s'appliquant en fonction de l'école. Nous pouvons reformuler ce modèle pour inclure cet effet spécifique par école comme un effet aléatoire.

\footnotesize
\begin{equation}
\begin{aligned}
&Y \sim Normal(\mu,\sigma_e)\\
&g(\mu) = \beta_0 + \beta_1 \times x_1 + \upsilon \times x_1 \\
&\upsilon \sim Normal(0,\sigma_{\upsilon})
&g(x) = x
\end{aligned}
\end{equation}
\normalsize

Dans le même esprit que pour le modèle 

plusieurs formes : intercept aleatoire / pente aleatoire / pente et intercept aleatoire

Comparaison des formulations fixe : coefficient pour variable binaire / interaction binaire et continue / combinaison des deux

shrinkage, partial pooling, distributon de l'effet aleatoire, deux niveaux dans le modele, structure de covariance

Encadre sur le nombre de parametre (moins de parametres dans un modele a effet mixte que dans un modele a effet fixe)

### distinction effets fixes et effets aleatoires

les questions a se poser pour decider si un effet est fixe ou aleatoire

### Analyse d'un GLMM

Idem que pour un GLM, mais avec : 

ICC, R2 marginal, R2 conditionnel, observation des Random Intercept et Random Coeffs. Analyse des correlations entre random intercept et Random coeff. Normalite de la distribution des effets aleatoire (ou autre distribution).

## Application à une variable continue {#sect072}


## Régressions multiniveaux {#sect073}
