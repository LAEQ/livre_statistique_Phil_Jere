# Statistiques descriptives univariées

Dans ce chapitre, nous décrirons la notion de variable, permettant l’opérationnalisation d’un concept. Comprendre les différents types de variables est essentiel en statistiques. En effet, en fonction du type de variable à l'étude, les tests d’hypothèses et les méthodes de statistique inférentielle que l’on pourra appliquer seront différents. Nous distinguerons ainsi cinq types de variables : nominale, ordinale, discrète, continue et semi-quantitative. Nous présenterons ensuite les différentes statistiques descriptives univariées qui peuvent s’appliquer à ces types de variables.

A<sub>2</sub>

<span class="revision_prop">Suppression</span>
<span class="revision_rem">Ajout de texte</span>


::: {.bloc_package .bloc_package_png data-latex="{blocs/package}"}
Dans cette section, nous utiliserons principalement les packages suivants (À MODIFIER PLUS TARD) : 

* Pour créer des graphiques :
  - **ggplot2**, le seul, l'unique
  - **ggpubr**, pour combiner des graphiques et réaliser des diagrammes quantiles-quantiles
* Pour manipuler des données : 
  - **dplyr**, avec les fonctions *group_by*, *summarize* et les pipes *%>%*
* Pour les corrélations ((section \@ref(sect311))) : 
  - **correlation**, de l'ensemble de package **easy_stats**, offrant une large gamme de méthodes de corrélations
  - **boot** pour réaliser des corrélations avec *bootstrap* 
  - **Hmisc** pour calculer des corrélations de Pearson et Spearman
  - **ppcor**, notamment pour des corrélations partielles
  - **psych** pour obtenir une matrice de  corrélation (Pearson, Spearman et Kendall), les intervalles de confiance et les valeurs de p.
  - **stargazer** pour créer des beaux tableaux d’une matrice de corrélation en Html ou en LaTeX ou en ASCII.
  - **corrplot**, pour créer des graphiques de matrices de corrélation
* Pour le tableau de contignence ((section \@ref(sect312))) :
  - **gmodels**, pour construire des tableaux de contingence et * Calculer les test *t* et ses différentes variantes ((section \@ref(sect313))) :
* Pour les test *t* : 
  - **sjstats** pour réaliser des test *t* pondérés
  - **effectsize**, pour calculer les tailles d'effet de tests de *t*
* Pour la section sur les ANOVA ((section \@ref(sect314))) : 
  - **car**, pour les ANOVA classiques
  - *lmtest* pour le test de Breusch-Pagan d'homogénéité des variances 
  - **rstatix**, intégrant de nombreux tests classiques (comme le test de Shapiro) avec **tidyverse**

:::


## Notion de variable {#sect21}

### La variable : l'opérationnalisation d'un concept {#sect211}

Une variable permet d'opérationnaliser un concept, soit une « idée générale et abstraite que se fait l'esprit humain d'un objet de pensée concret ou abstrait, et qui lui permet de rattacher à ce même objet les diverses perceptions qu'il en a, et d'en organiser les connaissances » ([Larousse](https://www.larousse.fr/dictionnaires/francais/concept/17875?q=concept#17749){target="_blank"}). Pour valider un modèle théorique, il convient alors d'opérationnaliser ses différentes concepts et d'établir les relations qu'ils partagent. L'opérationnalisation d'un concept nécessite soit de mesurer (dans un intervalle de valeurs, c'est-à-dire de manière quantitative), soit de qualifier (avec plusieurs catégories, c'est-à-dire de manière qualitative) un phénomène. 

Selon [Statistique Canada](https://www.statcan.gc.ca/fra/concepts/variable){target="_blank"}, « une variable est une caractéristique d'une unité statistique que l'on observe et pour laquelle une valeur numérique ou une catégorie d'une classification peut être attribuée ». Il convient alors de bien saisir à quelle unité statistique s'applique les valeurs d'une variable : des personnes, des ménages, des municipalités, etc. 

Prenons deux exemples concrets tirées du Recensement de 2016 de Statistique Canada :

* Le concept **famille de recensement** est défini comme étant « un couple marié et les enfants, le cas échéant, du couple et/ou de l'un ou l'autre des conjoints; un couple en union libre et les enfants, le cas échéant, du couple et/ou de l'un ou l'autre des partenaires; ou un parent seul, peu importe son état matrimonial, habitant avec au moins un enfant dans le même logement et cet ou ces enfants. Tous les membres d'une famille de recensement particulière habitent le même logement. Un couple peut être de sexe opposé ou de même sexe. Les enfants peuvent être des enfants naturels, par le mariage, par l'union libre ou par adoption, peu importe leur âge ou leur état matrimonial, du moment qu'ils habitent dans le logement sans leur propre conjoint marié, partenaire en union libre ou enfant. Les petits-enfants habitant avec leurs grands-parents, alors qu'aucun des parents n'est présent, constituent également une famille de recensement » ([Statistique Canada](https://www12.statcan.gc.ca/census-recensement/2016/ref/dict/fam004-fra.cfm){target="_blank"}). À partir de cette définition, les familles de recensement peuvent être qualifiées selon plusieurs modalités : couples mariés sans enfant, couples mariés avec enfants, couples en union libre sans enfant, couples en union libre avec enfant, famille monoparentale (avec un parent de sexe féminin), famille monoparentale (avec un parent de sexe masculin).
* Le concept de **revenu d'emploi** est défini comme étant « tous les revenus reçus sous forme de traitements, salaires et commissions d'un travail rémunéré ou le revenu net d'un travail autonome dans une entreprise agricole ou non agricole non constituée en société et/ou dans l'exercice d'une profession au cours de la période de référence. Pour le Recensement de 2016, la période de référence est l'année civile 2015 pour toutes les variables de revenu » ([Statistique Canada](https://www12.statcan.gc.ca/census-recensement/2016/ref/dict/pop027-fra.cfm){target="_blank"}). Il est donc mesurée en dollars pour chaque individu de 15 ans et plus. Pour l'ensemble de la population de 15 ans et plus, il est être ensuite classer en déciles de revenu d'emploi, soit en dix groupes ([Statistique Canada](https://www12.statcan.gc.ca/census-recensement/2016/ref/dict/pop204-fra.cfm"}).

::: {.bloc_attention .bloc_attention_png data-latex="{blocs/attention}"}
**Maîtriser la définition des variables que vous utilisez : un enjeu crucial ! **

Nous avons vu qu'une variable est l'opérationnalisation d'un concept. Par conséquent, ne pas maîtriser la définition d'une variable revient à ne pas bien saisir le concept sous-jacent qu'elle tente de mesurer. Si vous exploitez des données secondaires – par exemple, issues d'un recensement de population ou d'une enquête longitudinale ou transversale –, il faut impérativement lire les définitions des variables que vous souhaiteriez utiliser. Ne pas le faire, risque d'aboutir à :

* une mauvaise opérationnalisation de votre modèle théorique, même si votre analyse est bien menée statistiquement parlant. Autrement dit, vous risquez de ne pas sélectionner les bonnes variables. Prenons un exemple concret. Vous avez construit un modèle théorique dans lequel vous souhaitez inclure une un concept sur la langue des personnes. Dans le recensement canadien de 2016, plusieurs variables relatives à langue sont disponibles : [connaissance des langues officielles](https://www12.statcan.gc.ca/census-recensement/2016/ref/dict/pop055-fra.cfm){target="_blank"},
[langue parlée à la maison](https://www12.statcan.gc.ca/census-recensement/2016/ref/dict/pop042-fra.cfm){target="_blank"}, [langue maternelle](https://www12.statcan.gc.ca/census-recensement/2016/ref/dict/pop095-fra.cfm){target="_blank"}, [première langue officielle parlée](https://www12.statcan.gc.ca/census-recensement/2016/ref/dict/pop034-fra.cfm){target="_blank"},  [connaissance des langues non officielles](https://www12.statcan.gc.ca/census-recensement/2016/ref/dict/pop054-fra.cfm){target="_blank"} et [langue de travail](https://www12.statcan.gc.ca/census-recensement/2016/ref/dict/pop059-fra.cfm){target="_blank"} ([Statistique Canada, 2019](https://www12.statcan.gc.ca/census-recensement/2016/ref/guides/003/98-500-x2016003-fra.cfm){target="_blank"}). La sélection de l'une de ces variables doit être faite de manière rigoureuse, c'est-à-dire en lien avec votre cadre théorique et suite une bonne compréhension des définitions des variables. Dans une étude sur le marché du travail, on sélectionnerait probablement la variable *sur la connaissance des langues officielles du Canada*, afin d'évaluer son effet sur l'employablité, toutes choses étant égales par ailleurs. Dans une autre étude portant sur la réussite ou la performance scolaire, il est probable qu'on utilise plutôt la *langue maternelle*.

* une mauvaise interprétation et discussion de vos résultats en lien avec votre cadre théorique.
* une mauvaise identification des pistes de recherche.

Finalement, la définition d'une variable peut évoluer à travers plusieurs recensements de population : la société évolue, les variables aussi ! Par conséquent, si vous comptez utiliser plusieurs années de recensement dans un même étude, assurez-vous que les définitions des variables soient similaires d'un jeu de données à l'autre et qu'elles mesurent ainsi la même chose. 

**Comprendre les variables utilisées dans un article scientifique : un exercice indispensable dans l'élaboration d'une revue de littérature**

Une lecture rigoureuse d'un article scientifique suppose, entre autres, de bien comprendre les concepts et variables mobilisés. Il convient alors de lire attentivement la section méthodologique (pas uniquement la section des résultats ou pire le résumé), sans quoi vous risquez d'aboutir à une revue de littérature approximative. 
Ayez aussi un **regard critique** sur les variables visant à opérationnaliser les  concepts clés de l'étude. Certains concepts sont très difficiles à traduire en variables; leurs opérationalisations (mesures) peuvent ainsi faire l'objet de vifs débats parmi les chercheurs. Très succinctement, c'est notamment le cas du concept de capital social. D'une part, les définitions et ancrages sont biens différents selon Bourdieu (sociologue, ancrage au niveau des individus) et Putman (politologue, ancrage au niveau des collectivités). D'autre part, aucun consensus ne semble clairement se dégager quant à la définition de variables permettant de le mesurer efficacement (de manière quantitative).   

**Variable de substitution (*proxy* variable en anglais)**

À mes débuts en recherche (premier auteur du livre), une brillante collègue géographe, renommée dans son champ de recherche, m'a affirmée : « on fait la moins pire des recherches ! ». Secoué par cette affirmation, elle m'expliqua ensuite que les données disponibles sont parfois imparfaites pour répondre avec précision à une question de recherche; on peut toujours les exploiter, tout en signalant honnêtemment leurs faiblesses et limites, et ce, tant pour les données que les variables utilisées. Ce fut le début d'une longue collaboration débouchant sur une multitude de *moins pires recherches*.

* Des bases de données peuvent être en effet imparfaites. Par exemple, en criminologie, des chercheur.e.s exploitant des données policières signalent habituellement la limite du **chiffre noir** : les données policières comprennent uniquement les crimes et délits découverts par la police et occultent ainsi les crimes non-découverts; ils ne peuvent ainsi refléter la criminalité réelle sur un territoire donné.

* Des variables peuvent aussi être imparfaites. Dans un jeu de données, il est fréquent qu'une variable opérationnalisant un concept précis ne soit pas disponible ou qu'elle n'est tout simplement pas été  mesurée. On cherchera alors une variable de substitution (*proxy*) pour la remplacer. Prenons un exemple concret portant sur l'exposition des cyclistes à la pollution atmosphérique ou au bruit routier. L'une des principaux facteurs d'exposition à ces pollutions est le trafic routier : plus ce dernier est élevé, plus le cycliste risque de rouler dans un environnement bruyant et pollué. Toutefois, il est rare de disposer de mesures du trafic en temps réel qui nécessitent des comptages de véhicules pendant le trajet des cyclistes (par exemple, à partir de vidéos captées par une caméra fixée sur le guidon). Pour pallier à l'absence de mesures directes, plusieurs auteurs utilisent des variables de substitution de la densité du trafic, comme la typologie des types d'axes (primaire, secondaire, tertiaire, rue locale, etc.), supposant ainsi qu'un axe primaire supporte un volume de véhicules supérieur à un axe secondaire...
:::

### Les types de variables {#sect212}
On distingue habituellement les variables qualitatives (nominale ou ordinale) des variables quantitatives (discrète ou continue). Tel qu'illustré à la figure \@ref(fig:figunivarie1), l'opérationnalisation du concept en variable est réalisée par différents mécanismes visant à qualifier, classer, compter ou mesurer afin de caractériser les unités statistiques (observations) d'une population ou d'un échantillon.

```{r figunivarie1, fig.align='center', echo=FALSE, include=identical(knitr:::pandoc_to(), 'html'), auto_pdf = TRUE, fig.cap="Les types de variables",  out.width='70%'}
knitr::include_graphics('images/univariee/figure1.jpg', dpi = NA)
```

#### Les variables qualitatives {#sect2121}

**Une variable nominale** permet de **qualifier** des observations (individus) à partir de plusieurs catégories, dénommées modalités. Par exemple, la variable _couleur des yeux_ pourrait comprendre les modalités _bleu_, _marron_, _vert_ tandis que le *types de familles* compendrait les modalités _couple marié_, _couple en union libre_ et _famille monoparentale_.

**Une variable ordinale** permet de **classer** des observations à partir de plusieurs modalités hiérarchisées. L'exemple le plus connu est certainement l'échelle de Likert très utilisée dans les sondages évaluant le degré d'accord d'une personne à une affirmation avec les modalités suivantes : _tout à fait d'accord_, _d'accord_, _ni en désaccord ni d'accord_, _pas d'accord_ et _pas du tout d'accord_. Une multitude de variantes sont toutefois possibles pour classer la fréquence d'un phénomène (_Très souvent_, _souvent_, _parfois_, _rarement_, _jamais_), l'importance accordée à un phénomène (_Pas du tout important_, _peu important_, _plus ou moins important_, _Important_, _très important_) ou la proximité perçue d'un lieu (_Très éloigné_, _loin_, _plus ou moins proche_, _proche_, _très proche_).

En fonction du nombre de modalités qu'elle comprend, une variable qualitative (nominale ou ordinale) est soit **dichtomique (binaire)** (deux modalités), soit **polytomique** (plus de deux modalités). Par exemple, dans le recensement canadien, le *sexe* est une variable binaire (avec les modalités *sexe masculin*, *sexe féminin*), tandis que le *genre* est une variable polytomique (avec les modalités *genre masculin*, *genre féminin* et *diverses identités de genre*).

::: {.bloc_attention .bloc_attention_png data-latex="{blocs/attention}"}
Les variables nominales et ordinales sont habituellement encodées avec des valeurs numériques entières (par exemple, 1 pour _couples marié_, 2 pour _couple en union libre_ et 3 pour _famille monoparentale_). Toutefois, aucune opération arithmétique (moyenne ou écart-type par exemple) n'est possible sur ces valeurs. Dans ![](images/Rlogo.png), on utilisera un facteur pour attribuer un intitulé à chacune des valeurs numériques de la variable qualitative :

`df$Famille <- factor(df$Famille, c(1,2,3), labels = c("couples marié","couple en union libre", "famille monoparentale"))`

On calculera toutefois les fréquences des différentes modalités pour une variable nominale ou ordinale. Il est aussi possible de calculer la médiane sur une variable ordinale.
:::

#### Les variables quantitatives {#sect2122}

**Une variable discrète** permet de **compter** un phénomène dans un ensemble fini de valeurs, comme le nombre d'accidents impliquant un cycliste à une intersection sur une période cinq ans ou encore le nombre de vélos en libre service disponibles à une station. Il existe ainsi une variable binaire sous-jacente : la présence ou non d'un accident à l'intersection ou d'un vélo ou non à la station pour laquelle on opère un comptage. Habituellement, une variable discrète ne peut prendre que des valeurs entières (sans décimales), comme le nombre de personnes fréquentant un parc.

**Une variable continue** permet de **mesurer** un phénomène avec un nombre infini de valeurs réelles (avec décimales) dans un intervalle donné. Par exemple, une variable relative à la distance de dépassement d'un cycliste par un véhicule motorisé pourrait varier de 0 à 5 mètres ($X \in \left[0,5\right]$); toutefois cette distance peut être de 0,759421 ou de 4,785612 mètres. Le nombre de décimales de la valeur réelle dépendra de la précision et de la fiabilité de la mesure. Pour un capteur de distance de dépassement, le nombre de décimales dépendra de la précision du lidar ou du sonar de l'appareil; aussi, l'utilisation de trois décimales – soit une précision au millimètre – risque d'être largement suffisant pour mesurer la distance de dépassement. Une variable continue est soit une variable d'intervalle, soit une variable de rapport. Les **variables d'intervalle** ont une échelle relative, c'est-à-dire que les intervalles entre les valeurs de la variables ne sont pas constants; elles n'ont pas de vrai zéro. Ses valeurs peuvent être manipulées uniquement par addition et soustraction et non par multiplication et soustraction. La variable d'intervalle la plus connue est certainement celle de la température. S'il fait 10 degrés Celsius à Montréal et 30°C à Mumbai (soit 50 et 86 degrés en Fahrenheit), on peut affirmer qu'il y a 20°C ou 36°F d'écart entre les deux villes, mais on ne peut pas affirmer qu'il fait trois fois plus chaud à Mumbai. Presque toutes les mesures statistiques sur une variable d'intervalle peuvent être calculées, excepté le coefficient de variation et la moyenne géométrique puisqu'il n'y a pas de vrai zéro et d'intervalles constants entre les valeurs.  À l'inverse, les **variables de rapport** ont une échelle absolue, c'est-à-dire que les intervalles entre les valeurs sont constants et elles ont un vrai zéro. Elles peuvent ainsi manipuler par addition, soutraction, multiplication et division. Par exemple, le prix d'un produit exprimé dans une unité monétaire ou la distance exprimée dans le système métrique sont des variables de rapport. Un vélo dont le prix affiché est de 1000$ est bien deux fois plus cher qu'un autre à 500$, une piste cyclable hors rue à 25 mètres d'un tronçon routier le plus proche est bien quatre fois plus proche qu'un autre à 100 mètres.

**Une variable semi-quantitative**, appelée aussi variable quantitative ordonnée, est une variable discrète ou continue dont les valeurs ont été regroupées en classes hiérarchisées. Par exemple, l'âge est une variable continue pouvant être transformée avec les groupes d'âge ordonnés suivants : *moins 25 ans*, *25 à 44 ans*, *45 à 64 ans* et *65 ans et plus*.


## Les types de bases de données {#sect22}

* **Donnée primaires *versus* données secondaires**

* **Population versus échantillon**

POPULATION ET ÉCHANTILLON : voir Tabanick et Field

* **Données individuelles versus données agrégées**

DÉCOUPAGE GÉOGRAPHIQUE ET UNIVERS GÉOGRAPHIQUE
Notion d'erreur écologique

* **Données longitudinales versus données transversale**

* **Fusion de données**

## Retour sur la statistique descriptive et la statistique inférentielle (ENCADRÉ)  {#sect23}

## La notion de distribution (JÉRÉMY) {#sect24}



## Statistiques descriptives sur des variables quantitatives (PHILIPPE) {#sect25}

### Les paramètres de tendance centrale {#sect251}

Trois mesures de tendance centrale permettent de résumer rapidement une variable quantitative :

* la **moyenne arithmétique** est simplement la somme des données d'une variable divisée par le nombre d'observations ($n$), soit $\frac{\sum_{i=1}^n x_i}{n}$ notée $\mu$ (prononcez *mu*) pour des données pour une population et $\bar{x}$ (prononcez *x barre*) pour un échantillon.
* la **médiane** est la valeur qui coupe la distribution d'une variable d'une population ou d'un échantillon en deux parties égales. Autrement dit, 50% des valeurs des observations lui sont supérieures et 50% lui sont inférieures.
* le **mode** est la valeur la plus fréquente parmi un ensemble d'observations pour une variable. Il s'applique ainsi des variables discrètes (avec un nombre fini de valeurs discrètes dans un intervalle donné) et non à des variables continues (avec un nombre infini de valeurs réelles dans un intervalle donné). Prenons deux variables, l'une discrète relative au nombre d'accidents par intersection (avec $X \in \left[0,20\right]$) et l'autre continue relative à la distance de dépassement (en mètres) d'un cycliste par un véhicule motorisé (avec $X \in \left[0,5\right]$). Pour la première, le mode – la valeur la plus fréquente – est certainement 0. Pour la seconde, identifier le mode n'est pas pertinent puisqu'il peut y un nombre infini de valeurs entre 0 et 5 mètres.

Il convient de ne pas confondre moyenne et médiane ! Dans le tableau \@ref(tab:tableRevMoyMed), nous avons reporté les valeurs moyennes et médianes des revenus ménages pour les municipalités de l'île de Montréal en 2015. Par exemple, les 8685 ménages résidant à Wesmount disposaient en moyenne d'un revenu de 295099\$; la moitié de ces 8685 ménages avaient un revenu inférieur à 100153\$  et l'autre moitié un revenu supérieur à cette valeur (médiane). Cela démontre clairement que la moyenne peut être grandement affectée par des valeurs extrêmes (faibles ou fortes); autrement dit, plus l'écart entre les valeurs de la moyenne et la médiane est importante, plus les données de la variable sont inégalement réparties. À Westmount, soit la municipalité la plus nantie de l'île de Montréal, les valeurs extrêmes sont des ménages avec des revenus très élevés tirant fortement la moyenne vers le haut. À l'inverse, le faible écart entre les valeurs moyenne et médiane dans la municipalité de Montréal-Est (58594\$ versus 50318\$) soulignent que les revenus des ménages sont plus également répartis. Cela explique que pour comparer les revenus totaux ou d'emploi entre différents groupes (selon le sexe, le groupe d'âge, le niveau d'éducation, la municipalité ou région métropolitaine, etc.), on prévilégie habituellement l'utilisation des revenus médians.

```{r tableRevMoyMed, echo=FALSE, message=FALSE, warning=FALSE}
df <-  read.csv("data/univariee/revenu.csv")
df2 <- df[, c("Muni","NMenages","RevMoyM","RevMedM")]

knitr::kable(df2,
  format.args = list(decimal.mark = ",", big.mark = " "),   
  col.names = c("Municipalité","Nombre de ménages", "Revenu moyen","Revenu médian"),
  caption = "Revenus moyens et médians des ménages en dollars, municipalités de l'île de Montréal, 2015",
  booktabs = TRUE, valign = 't', row.names = FALSE)
```

::: {.bloc_attention .bloc_attention_png data-latex="{blocs/attention}"}
Intérêt des mesures de tendance centrale et types de distribution.
:::

### Les paramètres de position {#sect252}

Les paramètres de position permettent de diviser une distributions en _n_ parties égales.

* Les **quartiles** qui divisent une distribution en quatre parties (25%) :
  + Q1 (25%), soit le quartile inférieur ou premier quartile;
  + Q2 (50%), soit la médiane;
  + Q3 (75%), soit le quartile supérieur ou troisième quartile.
* Les **quintiles** qui divisent une distribution en cinq parties égales (20%).
* Les **déciles** (de D1 à D9) qui divisent une distribution en dix parties égales (10%).
* Les **centiles** (de C1 à C99) qui divisent une distribution en cent parties égales (1%).

En cartographie, les quartiles et les quintiles sont souvent utilisés pour discrétiser une variable quantitative (continue ou discrète) en quatre ou cinq classes et plus rarement, en huit ou dix classes. Avec les quartiles, les bornes des classes qui comprendront chacune 25% des untiés spatiales seront ainsi définies comme suit : [Min à Q1], [Q1 à Q2], [Q2 à Q3] et [Q3 à Max]. La méthode discrétisation selon les quartiles ou quintiles permet alors de repérer, en un coup d'œil, à quelle tranche de 25% ou 20% des données appartient chacune des unités spatiales. Cette méthode de discrétisation est aussi utile pour comparer plusieurs cartes et vérifier si deux phénomènes sont ou non colocalisés [@pumain1994]. En guise d'exemple, les pourcentages de personnes à faible revenu et de locataires par secteur de recensement ont clairement des distributions spatiales très semblables dans la région métropolitaine de Montréal en 2016 (figure \@ref(fig:figunivarie2)).



```{r figunivarie2, fig.align='center', echo=FALSE, include=identical(knitr:::pandoc_to(), 'html'), auto_pdf = TRUE, fig.cap="Exemples de cartographie avec une discrétisation selon les quantiles",  out.width='100%'}
knitr::include_graphics('images/univariee/figure2.jpg', dpi = NA)
```

Une lecture attentive des valeurs des centiles permet de repérer la présence de valeurs extrêmes voire aberrantes dans un jeu de données. Il n'est donc pas rare de les voir reportées dans un tableau de statistiques descriptives d'un article scientifique, et ce, afin de décrire succinctement les variables à l'étude. Par exemple, dans une étude récente comparant les niveaux d'exposition au bruit des cyclistes dans trois villes  [@2020_1], les auteurs reportent à la fois les valeurs moyennes et celles de plusieurs centiles. Globalement, la lecture des valeurs moyennes permet de constater que, sur la base des données collectées, Paris est bien plus bruyante que Montréal et Copenhague (73,4 dB(A) contre 70,7 et 68,4, tableau \@ref(tab:tableCentiles)). Compte tenu de l'échelle logarithmique du bruit et du taux de change de 3, la différence de 5 dB(A) entre les valeurs moyennes du bruit de Copenhague et de Paris peut être considérée comme une multiplication de l'énergie sonore par plus de 3. Pour Paris, l'analyse des quartiles montre que durant 25% du temps des trajets à vélo (plus de 63 heures de collecte), les participants ont été exposés à des niveaux de bruit soit inférieurs à 69,1 dB(A) (premier quartile), soit supérieurs à 74 dB(A). Quant à l'analyse des centiles, elle permet de constater que durant 5% et 10% du temps, les participants étaient exposés à des niveaux de bruit très élevés, dépassant 77 dB(A) (C90=76 et C90=77,2).

```{r tableCentiles, echo=FALSE, message=FALSE, warning=FALSE}
options(knitr.kable.NA = '')
df <- data.frame(
  Centiles = c("N","Moyenne de bruit","Centiles","1","5","10", "25 (premier quartile)", "50 (médiane)", "75 (troisième quartile)", "90", "95", "99"),
  C = c(6212,68.4,NA,57.5,59.1,60.3,62.7,66.0,69.2,71.9,73.3,76.5),
  M = c(4723,70.7,NA,59.2,61.1,62.3,64.5,67.7,71.0,73.7,75.2,78.9),
  P = c(3793,73.4,NA,62.3,65.0,66.5,69.1,71.6,74.0,76.0,77.2,81.0))

knitr::kable(df,
  format.args = list(decimal.mark = ",", big.mark = " "),   
  col.names = c("Statistiques","Copenhague", "Montréal","Paris"),
  caption = "Stastistiques descriptives de l'exposition au bruit des cyclistes par minute dans trois villes (dB(A), Laeq 1min)",
  booktabs = TRUE, valign = 't', row.names = FALSE)
```


### Les paramètres de dispersion {#sect253}
Cinq principales mesures de dispersion permettent d'évaluer la variabilité des valeurs d'une variable quantitative : l'étendue, l'écart interquartile, la variance, l'écart-type et le coefficient de variation. Notez d'emblée que cette dernière mesure ne s'applique pas à des variables d'intervalle (section \@ref(sect2122)).

* **L'étendue** ou est la différence entre les valeurs minimale et maximale d'une variable, soit l'intervalle de variation des valeurs dans laquelle elle a été mesurée. Il convient d'analyser avec prudence cette mesure puisqu'elle inclut dans son calcul des valeurs potentiellement extrêmes voire aberrantes (faibles ou fortes).

* **L'intervalle ou écart interquartile** est la différence entre les troisième et premier quartiles ($Q3 − Q1$). Il représente ainsi une mesure de la dispersion des valeurs de 50% des observations centrales de la distribution. Plus la valeur de l'écart interquartile est élevée, plus la dispersion des 50% des observations centrales est forte. Contrairement à l'étendue, cette mesure élimine l'influence des valeurs extrêmes puisqu'elle ne tient compte que des 25% des observations les plus faibles [Min à Q1] et des 25% observations les plus fortes [Q3 à Max]. Graphiquement, l'intervalle interquartile est représenté à l'aide d'une boîte à moustache (*boxplot* en anglais) : plus l'intervalle interquartile sera grand, plus la boîte sera allongée (figure \@ref(fig:figunivarie3))

```{r figunivarie3, fig.align='center', echo=FALSE, include=identical(knitr:::pandoc_to(), 'html'), auto_pdf = TRUE, fig.cap="Graphique en violon, boîte à moustache et intervalle interquartile",  out.width='40%'}
knitr::include_graphics('images/univariee/figure3.jpg', dpi = NA)
```

* **La variance** est la somme des déviations à la moyenne au carré (numérateur) divisée par le nombre d'observations pour une population ($\sigma^2$) ou divisée par le nombre d'observations moins une ($s^2$) pour un échantillon (eq. \@ref(eq:variance)). Puisque les déviations à la moyenne sont mises au carré, la valeur de variance (tout comme celle de l'écart-type) sera toujours positive. Plus sa valeur est élevée, plus les observations sont dispersées autour de la moyenne. La variance représente ainsi l'écart au carré moyen des observations à la moyenne. 

\begin{equation} 
\sigma^2=\frac{\sum_{i=1}^n (x_{i}-\mu)^2}{n} \text{ ou } s^2=\frac{\sum_{i=1}^n (x_{i}-\bar{x})^2}{n-1}
(\#eq:variance)
\end{equation}

* **L'écart-type** est la racine carrée de la variance (eq. \@ref(eq:ecartype)). Rappelez-vous que la variance est calculée à partir des déviations à la moyenne mises au carré. Étant donné que l'écart-type est la racine carré de la variance, il est donc évalué dans les mêmes unités que la variable, contrairement à la variance. Bien entendu, comme pour la variance, plus la valeur de l'écart-type est élevé, plus la distribution des observations autour de la moyenne est dispersée.

\begin{equation} 
\sigma=\sqrt{\sigma^2}=\sqrt{\frac{\sum_{i=1}^n (x_{i}-\mu)^2}{n}} \text{ ou } s=\sqrt{s^2}=\sqrt{\frac{\sum_{i=1}^n (x_{i}-\bar{x})^2}{n-1}}
(\#eq:ecartype)
\end{equation}

::: {.bloc_notes .bloc_notes_png data-latex="{blocs/notes}"}
Les formules des variances et des écart-types pour une population et un échantillon sont très similaires : seul le dénominateur change avec $n$ *versus* $n-1$ observations. Par conséquent, plus le nombre d'observations de votre jeu de données sera important, plus l'écart entre ces deux mesures de dispersion pour une population et une échantillon sera minime.

Comme dans la plupart des logiciels de statistique, les fonctions de base `var` et `sd` de ![](images/Rlogo.png) calculent la variance et l'écart-type pour un échantillon ($n-1$ au dénominateur). Si vous souhaitez les calculer pour une population, adaptez la syntaxe ci-dessous dans laquelle `df$var1` représente la variable intitulée `var1` présente dans un *dataframe* nommé `df`.

`var.p <- mean((df$var1 - mean(df$var1))^2)` 

`sd.p <- sqrt(mean((df$var1 - mean(df$var1))^2))` 
:::


* **Le coefficient de variation (CV)** est le rapport entre l'écart-type et la moyenne, représentant ainsi une standardisation de l'écart-type, ou en d'autres termes, une mesure de dispersion relative (eq. \@ref(eq:cv)). L'écart-type étant exprimé dans l'unité de mesure de la variable, il ne peut pas être utilisé pour comparer les dispersions de variables exprimées des unités de mesure différentes (par exemple, en pourcentage, en kilomètres, en dollars, etc.). Pour y remédier, on utilisera le coefficient de variation : une variable est plus dispersée qu'une autre si la valeur de son CV est plus élevée. Certains préfèreront multiplier la valeur du CV par 100 : l'écart-type est alors exprimée en pourcentage de la moyenne.


\begin{equation} 
CV=\frac{\sigma}{\mu} \text{ ou } CV=\frac{s^2}{\bar{x}}
(\#eq:cv)
\end{equation}


Illustrons comment calculer les cinq mesures de dispersion précédemment décrites à partir de valeurs fictives pour huit observations (colonne intitulée $x_i$ au tableau \@ref(tab:datavar)). Les différentes statistiques reportées dans ce tableau sont calculées comme suit :

* La **moyenne** est la somme divisée par le nombre d'observations, soit $248/8=31$.
* L'**étendue** est la différence entre les valeurs maximale et minimale, soit $40-22=30$.
* Les quartiles coupent la distribution en quatre parties égales. Avec huit observations triées par ordre croissant, **le premier quartile** est égale la valeur de la 2^e^ observation (soit 25), la **médiane** à celle de la 4^e^ (30), le **troisième quartile** à celle de la 6^e^ (35).
* **L'écart interquartile** est la différence entre Q3 et Q1, soit $35-25=10$.

* La seconde colonne du tableau est l'écart à la moyenne ($x_i-\bar{x}$), soit $22 - 31 = -9$ pour l'observation *1*; la somme de ces écarts est toujours égale à 0. La troisième colonne est cette déviation mise au carré ($(x_i-\bar{x})^2$), soit $-9^2 = 81$ toujours pour l'observation *1*. La somme de ces déviations à la moyenne au carré ($268$) représente le numérateur de la variance (eq. \@ref(eq:variance)). En divisant cette somme par le nombre d'observations, on obtient la **variance pour une population** ($268/8=33,5$) tandis que la **variance d'un échantillon** est égale à $268/(8-1)=38,29$.

* L'écart-type est la racine carrée de la variance (eq. \@ref(eq:ecartype)), soit $\sigma=\sqrt{33,5}=5,79$ et $s=\sqrt{38,29}=6,19$.

* Finalement, les valeurs des coefficients de variation (eq. \@ref(eq:cv)) sont de $5,79/31=0,19$ pour une population et $6,19/31=0,20$ pour un échantillon. 


```{r datavar, echo=FALSE, message=FALSE, warning=FALSE}
a <- c(22,25,27,30,32,35,37,40)
a <- sort(a)
n <- length(a)
df <- data.frame(
    id = as.character(c(1:n)),
    x = round(a,2),
    xi_mean = a - mean(a),
    numer = (a - mean(a))^2
)

df[n+1,1] <- "**Statistiques**"
n <- n+1
df[n+1,1] <- "N"
df[n+2,1] <- "Somme"
df[n+3,1] <- "Moyenne ($\\bar{x}$ ou $\\mu$)"
df[n+1,2] <- length(a)
df[n+2,2] <- sum(a)
df[n+2,4] <- sum(df$numer, na.rm = TRUE)
df[n+2,3] <- sum(df$xi_mean, na.rm = TRUE)

df[n+3,2] <- mean(a)
df[n+3,3] <- sum(df$xi_mean, na.rm = TRUE)/n
df[n+3,4] <- round(mean((a - mean(a))^2),2)
df[n+4,1] <- "Étendue"
df[n+4,2] <- max(a)-min(a)

df[n+5,1] <- "Premier quartile"
df[n+6,1] <- "Troisième quartile"
df[n+5,2] <- quantile(a, type = 1)[2]
df[n+6,2] <- quantile(a, type = 1)[4]

df[n+7,1] <- "Intervalle interquartile"
df[n+7,2] <- quantile(a, type = 1)[4]-quantile(a, type = 1)[2]

df[n+8,1] <- "Variance (population, $\\sigma^2$)"
df[n+9,1] <- "Écart-type (population, $\\sigma$)"
df[n+10,1] <- "Variance (échantillon, $s^2$)"
df[n+11,1] <- "Écart-type (échantillon, $s$)"
df[n+8,2] <- round(mean((a - mean(a))^2),2)
df[n+9,2] <- round(sqrt(mean((a - mean(a))^2)),2)
df[n+10,2] <- round(var(a),2)
df[n+11,2] <- round(sd(a),2)

df[n+12,1] <- "Coefficient de variation ($\\sigma / \\mu$)"
df[n+13,1] <- "Coefficient de variation ($s / \\bar{x}$)"

df[n+12,2] <- round(sqrt(mean((a - mean(a))^2))/mean(a),2)
df[n+13,2] <- round(sd(a)/mean(a),2)

opts <- options(knitr.kable.NA = "")
knitr::kable(df, 
  format.args = list(decimal.mark = ",", big.mark = " "),           
  col.names = c("Observation","$x_i$","$x_i-\\bar{x}$","$(x_i-\\bar{x})^2$"),
  caption = "Calcul des mesures de dispersion sur des données fictives",
  booktabs = TRUE, valign = 't', row.names = FALSE)
``` 

Le tableau \@ref(tab:datavar2) vise à démontrer à partir de trois variables comment certaines mesures de dispersion sont sensibles à l'unité de mesure et/ou aux valeurs extrêmes. 

Concernant **l'unité de mesure**, nous avons créé deux variables *A* et *B*, avec *B* étant simplement *A* multiplié par 10. Pour *A*, les valeurs de la moyenne, l'étendue et l'intervalle interquartile sont respectivement de 31, 18 et 10. Sans surprise, celles de B sont multipliées par 10 (310, 180, 100). La variance étant la moyenne des déviations à la moyenne au carré, elle est égale à 33,50 pour *A* et donc à $33,50\times10^2=3350$ pour *B*; l'écart-type de *B* est égal à celui de *A* multiplié par 10. Cela démontre que l'étendue, l'intervalle interquartile, la variance et l'écart-type sont des mesures de dispersion dépendantes de l'unité de mesure. Par contre, le coefficient de variation (CV) étant le rapport de l'écart-type avec la moyenne, il a la même valeur pour *A* et *B*, ce qui démontre que CV est bien une mesure de dispersion relative permettant de comparer des variables exprimées dans des unités de mesure différentes.

Concernant **la sensibilité aux valeurs extrêmes**, nous avons créé la variable *C* pour laquelle seule la huitième observation a une valeur différente (40 pour *A* et *105* pour B). Cette valeur de 105 pourrait être, soit une valeur extrême positive mesurée, soit une valeur aberrante (par exemple, si l'unité de mesure était un pourcentage variant de 0 à 100%). Cette valeur a un impact important sur la moyenne (31 contre 39,12) et l'étendue (18 contre 83) et corollairement sur la variance (33,50 contre 641,86), l'écart-type (5,79 contre 25,33) et le coefficient de variation (0,19 contre 0,65). Par contre, l'intervalle interquartile étant calculé sur 50% des observations centrales ($Q3-Q1$), il n'est pas affecté par cette valeur extrême.


```{r datavar2, echo=FALSE, message=FALSE, warning=FALSE}
a <- c(22,25,27,30,32,35,37,40)
c <- c(22,25,27,30,32,35,37,105)
b <- a*10
var.a <- round(mean((a - mean(a))^2),2)
var.b <- round(mean((b - mean(b))^2),2)
var.c <- round(mean((c - mean(c))^2),2)
sd.a <- round(sqrt(mean((a - mean(a))^2)),2)
sd.b <- round(sqrt(mean((b - mean(b))^2)),2)
sd.c <- round(sqrt(mean((c - mean(c))^2)),2)
a <- sort(a)
b <- sort(b)
c <- sort(c)

n <- length(a)
df <- data.frame(
  id = as.character(c(1:n)),
  A = round(a,2),
  B = round(b,2),
  C = round(c,2)
)

df[n+1,1] <- "**Statistiques**"
n <- n+1
df[n+1,1] <- "Moyenne ($\\mu$)"
df[n+2,1] <- "Étendue"
df[n+3,1] <- "Intervalle interquartile"
df[n+4,1] <- "Variance (population, $\\sigma^2$)"
df[n+5,1] <- "Écart-type (population, $\\sigma$)"
df[n+6,1] <- "Coefficient de variation ($\\sigma / \\mu$)"

df[n+1,2] <- mean(a)
df[n+2,2] <- max(a)-min(a)
df[n+3,2] <- quantile(a, type = 1)[4]-quantile(a, type = 1)[2]
df[n+4,2] <- round(var.a,2)
df[n+5,2] <- round(sd.a,2)
df[n+6,2] <- round(sd.a/mean(a),2)

df[n+1,3] <- mean(b)
df[n+2,3] <- max(b)-min(b)
df[n+3,3] <- quantile(b, type = 1)[4]-quantile(b, type = 1)[2]
df[n+4,3] <- round(var.b,2)
df[n+5,3] <- round(sd.b,2)
df[n+6,3] <- round(sd.b/mean(b),2)

df[n+1,4] <- round(mean(c),2)
df[n+2,4] <- max(c)-min(c)
df[n+3,4] <- quantile(c, type = 1)[4]-quantile(c, type = 1)[2]
df[n+4,4] <- round(var.c,2)
df[n+5,4] <- round(sd.c,2)
df[n+6,4] <- round(sd.c/mean(c),2)

opts <- options(knitr.kable.NA = "")
knitr::kable(df, 
  format.args = list(decimal.mark = ",", big.mark = " "),           
  col.names = c("Observation","A","B","C"),
  caption = "Illustration de la sensibilité des mesures de dispersion à l'unité de mesure et aux valeurs extrêmes",
  booktabs = TRUE, valign = 't', row.names = FALSE)
```



```{r resume, echo=FALSE, message=FALSE, warning=FALSE}
a <- c("Moyenne", "Étendue",
       "Intervalle interquartile",
       "Variance", "Écart-type", "Coefficient de variation")

b <- c("X","X","X","X","X","")
c <- c("X","X","","X","X","X")

df <- data.frame(
  Stat = a,
  Unite = b,
  Outlier = c
)

opts <- options(knitr.kable.NA = "")
knitr::kable(df, 
  col.names = c("Statistique","Unité de mesure","Valeurs extrêmes"),
  caption = "Résumé de la sensibilité de la moyenne et des mesures de dispersion",
  booktabs = TRUE, valign = 't', row.names = FALSE)
```


### Les paramètres de forme {#sect254}

#### Vérifier la normalité d'une variable quantitative

::: {.bloc_objectif .bloc_objectif_png data-latex="{blocs/objectif}"}
De nombreux méthodes statistiques qui seront abordées dans les chapitres suivants – entre autres la corrélation de Pearson, les test *t* et l'analyse de variance, les régressions simple et multiple – requiert que la variable continue suivent une **distribution normale** (nommée aussi **distribution gaussienne**).

Dans cette sous-section, nous décrirons trois démarches pour vérifier si la distribution d'une variables est normale : les coefficients d'asymétrie et d'applatissement (*skewness* et *kurtosis* en anglais), les graphiques (histogramme avec courbe normale, diagramme quantile-quantile), les tests de normalité (tests de Shapiro-Wilk, Kolmogorov-Smirnov et Jarque-Bera).
:::

##### Vérifier la normalité avec les coefficients d'asymétrie et d'applatissement

Une distribution est normale quand elle est symétrique et mésokurtique (figure \@ref(fig:figFormeDistr)).

```{r figFormeDistr, fig.align='center', echo=FALSE, include=identical(knitr:::pandoc_to(), 'html'), auto_pdf = TRUE, fig.cap="Formes d'une distribution et les coefficients d'asymétrie et d'aplatissement",  out.width='50%'}
knitr::include_graphics('images/univariee/FormeDistribution.jpg', dpi = NA)
```

**Une distribution est dite symétrique** quand la moyenne arithmétique est au centre de la distribution, c'est-dire que les observations sont bien réparties de part et d'autre la moyenne qui sera alors égale à la médiane et au mode (on utilisera uniquement le mode pour une variable discrète et non pour une variable continue). Pour évaluer l'asysmétrie, le coefficient d'assymétrie (*skewness* en anglais, eq. \@ref(eq:skewness)), habituellement utilisé, s'interprète comme suit (figure \@ref(fig:asymetrie)) :

* quand la valeur du *skewness* est négative, la **distribution est asymétrique négative**. La distribution est alors tirée à gauche par des valeurs extrêmes faibles, mais peu nombreuses. On emploie souvent l'expression la queue de distribution est tirée vers la gauche – La moyenne est alors inférieure à la médiane.
* quand la valeur du *skewness* est égale à 0, **la distribution est symétrique** (la médiane sera égale à la moyenne). Pour une variable discrète, les valeurs du mode, de la moyenne et de la médiane seront égales.
* quand la valeur du *skewness* est positive, la **distribution est symétrique positive**. La distribution est alors tirée à droite par des valeurs extrêmes fortes, mais peu nombreuses. On emploie souvent l'expression la queue de distribution est tirée vers la droit –. La moyenne est alors supérieure à la médiane. En sciences sociales, le revenu total des individus ou des ménages ont souvent des distributions asysmétriques positives : la moyenne est affectée par quelques observations avec des valeurs de revenu très élevées et est ainsi supérieure à la médiane. En études urbaines, la densité de population pour des unités géographiques d'une métropole donnée (secteur de recensement par exemple) a aussi souvent une distribution asymétrique positive : quelques secteurs de recensement au centre de la métropole caractérisés par des valeurs de densité très élevées tirent la distribution vers la droite.


\begin{equation} 
skew=\frac{n}{(n-1)(n-2)(n-3)}\sum_{i=1}^n\left(\frac{x_i-\bar{x}}{s}\right)^3
(\#eq:skewness)
\end{equation}

\begin{equation} 
kurt=\bigg\{\frac{n(n+1)}{(n-1)(n-2)(n-3)}\sum_{i=1}^n\left(\frac{x_i-\bar{x}}{s}\right)^4\bigg\}-\frac{3(n-1)^2}{(n-2)(n-3)}
(\#eq:kurtosis)
\end{equation}

```{r asymetrie, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center', fig.cap="Asymétrie d'une distribution", out.width='100%'}
library(moments)
library(ggplot2)
library(ggpubr)

# Générer des distributions asymétriques
df <- data.frame(
  Skewed_L = rbeta(1000,5,2)*1000,
  Skewed_R = rbeta(1000,2,5)*1000,
  Skewed_N = rbeta(1000,5,5)*1000
)

statsL <- c(mean(df$Skewed_L),median(df$Skewed_L),skewness(df$Skewed_L),kurtosis(df$Skewed_L))
statsR <- c(mean(df$Skewed_R),median(df$Skewed_R),skewness(df$Skewed_R),kurtosis(df$Skewed_R))
statsN <- c(mean(df$Skewed_N),median(df$Skewed_N),skewness(df$Skewed_N),kurtosis(df$Skewed_N))

CaptionL <- paste("Moyenne = ",  round(statsL[1],0), 
                  "\nMédiane = ",  round(statsL[2],0),  
                  "\nSkewness = ",  round(statsL[3],3), 
                  sep="")

CaptionR <- paste("Moyenne = ",  round(statsR[1],0), 
                  "\nMédiane = ",  round(statsR[2],0),  
                  "\nSkewness = ",  round(statsR[3],3), 
                  sep="")

CaptionN <- paste("Moyenne = ",  round(statsN[1],0), 
                  "\nMédiane = ",  round(statsN[2],0),  
                  "\nSkewness = ",  round(statsN[3],3), 
                  sep="")

Gl <- ggplot(data = df, mapping = aes(x=Skewed_L))+
      geom_histogram(color="white",fill="bisque3",aes(y=..density..))+
      stat_function(fun = dnorm, args = list(mean = mean(df$Skewed_L), sd = sd(df$Skewed_L)), color="black",size=1)+
      labs(title ="a. Asymétrie négative",
           subtitle = "Moyenne < Médiane",
           x="", 
           y="Densité",
           caption = CaptionL)+
      geom_vline(xintercept = statsL[1],color="cadetblue4", size=.8)+
      geom_vline(xintercept = statsL[2],color="coral4", size=.8)+
      theme(
      plot.title = element_text(hjust = 0.5,  size = 9, face = "bold"),
      plot.subtitle = element_text(hjust = 0.5,  size = 8, face = "plain"),
      plot.caption = element_text(hjust = 0.5,   size = 8, face = "plain")
      )
  
Gr <- ggplot(data = df, mapping = aes(x=Skewed_R))+
      geom_histogram(color="white",fill="bisque3",aes(y=..density..))+
      stat_function(fun = dnorm, args = list(mean = mean(df$Skewed_R), sd = sd(df$Skewed_R)), color="black",size=1)+
      labs(title ="b. Asymétrie positive",
           subtitle = "Moyenne > Médiane",
           x="", y="",
           caption = CaptionR)+
      geom_vline(xintercept = statsR[1],color="cadetblue4", size=.8)+
      geom_vline(xintercept = statsR[2],color="coral4", size=.8)+
      theme(
      plot.title = element_text(hjust = 0.5,  size = 9, face = "bold"),
      plot.subtitle = element_text(hjust = 0.5,  size = 8, face = "plain"),
      plot.caption = element_text(hjust = 0.5,   size = 8, face = "plain")
      )

Gn <- ggplot(data = df, mapping = aes(x=Skewed_N))+
      geom_histogram(color="white",fill="bisque3",aes(y=..density..))+
      stat_function(fun = dnorm, args = list(mean = mean(df$Skewed_N), sd = sd(df$Skewed_N)), color="black",size=1)+
      labs(title ="c. Asymétrie nulle", 
           subtitle = "Moy. et méd. très semblables",
           x="", y="",
           caption = CaptionN)+
      geom_vline(xintercept = statsN[1],color="cadetblue4", size=.8)+
      geom_vline(xintercept = statsN[2],color="coral4", size=.8)+
      theme(
      plot.title = element_text(hjust = 0.5,  size = 9, face = "bold"),
      plot.subtitle = element_text(hjust = 0.5,  size = 8, face = "plain"),
      plot.caption = element_text(hjust = 0.5,   size = 8, face = "plain")
      )

ggarrange(Gl, Gn, Gr, ncol = 3, nrow=1)
```


Kurtosis 
leptocurtique : small sd
Platykrutique : larger sd


### La transformation des variables {#sect255}

#### Les transformations visant à atteindre la normalité  {#sect2551}


#### Autres types de transformation  {#sect2552}

Les trois transformations les plus couramment utilisées sont :

* **La côte $z$** (*z score* en anglais) qui consiste à soustraire à chaque valeur sa moyenne (soit un centrage), puis à la diviser par son écart-type (soit une réduction) (eq. \@ref(eq:scorez)). Par conséquent, on parle aussi de variable centrée-réduite qui a comme propriétés intéressantes une moyenne égale à 0 et un écart-type égale à 1 (ainsi que la variance puisque 1^2^=1). Nous verrons que cette transformation est largement utilisée dans les méthodes de classification (REF PLUS TARD) et factorielles (REF PLUS TARD).

\begin{equation} 
z= \frac{x_i-\mu}{\sigma}
(\#eq:scorez)
\end{equation}

* **La transformation en rangs** qui consiste simplement à trier une variable en ordre croissant, puis à affecter le rang de chaque observation de 1 à $n$. Cette transformation est très utilisée quand la variable est très anormalement distribuée, notamment pour calculer le coefficient de corrélation de Speaman et certains tests non-paramétriques (RAPPEL SECTION).

* **La transformation sur une échelle de 0 à 1** (ou de 0 à 100) qui consiste à soustraite à chaque observation la valeur minimale et à diviser le tout par l'étendue (eq. \@ref(eq:t01))). 

\begin{equation} 
X_{\in\lbrack0-1\rbrack}= \frac{x_i-max}{max-min} \text{ ou } X_{\in\lbrack0-100\rbrack}= \frac{x_i-min}{max-min}\times100
(\#eq:t01)
\end{equation}


```{r AutresTransformation, echo=FALSE, message=FALSE, warning=FALSE}
a <- c(22,27,25,30,37,32,35,40)
b <- (a-mean(a))/sd(a)
d <- (a-min(a))/(max(a)-min(a))

df <- data.frame(
  id = as.character(c(1:length(a))),
  A = round(a,2),
  B = round(b,2),
  C = rank(a),
  D = round(d,2)
)

df[9,1] <- "Moyenne"
df[10,1] <- "Écart-type"
df[9,2] <- round(mean(a),2)
df[10,2] <- round(sd(a),2)
df[9,3] <- round(mean(b),2)
df[10,3] <- round(sd(b),2)

opts <- options(knitr.kable.NA = "")
knitr::kable(df, 
  format.args = list(decimal.mark = ",", big.mark = " "),           
  col.names = c("Observation","$x_i$","Côte $z$","Rang","0 à 1"),
  caption = "Illustration des trois tranformations",
  booktabs = TRUE, valign = 't', row.names = FALSE)
```


::: {.bloc_aller_loin .bloc_aller_loin_png data-latex="{blocs/aller_loin}"}
Ces trois transformations sont parfois utilisées pour générer un indice composite à partir de plusieurs variables ou encore dans une analyse de sensibilité avec les indices de Sobol [-@Sobol1993].
:::


### Mise en œuvre dans ![](images/Rlogo.png) {#sect256}

## Statistiques descriptives sur des variables qualitatives (PHILIPPE) {#sect26}


Tableau de fréquences
médiane uniquement pour des variables ordinales
https://www150.statcan.gc.ca/n1/edu/power-pouvoir/ch11/median-mediane/5214872-fra.htm#:~:text=La%20m%C3%A9diane%20(c'est%2D,les%20cinqui%C3%A8me%20et%20sixi%C3%A8me%20valeurs.

Mesure de tendance centrale pour une variable ordinale

https://fr.wikipedia.org/wiki/Indicateur_de_tendance_centrale#:~:text=Un%20article%20de%20Wikip%C3%A9dia%2C%20l,une%20variable%20quantitative%20ou%20ordinale.&text=Un%20indicateur%20de%20tendance%20centrale%20est%20toujours,les%20valeurs%20maximale%20et%20minimale.

## Statistiques descriptives sur des variables semi-quantitatives (PHILIPPE) {#sect27}

### TEST ET INFÉRENCE
La notion de bootstrap : 
concept de bootstrap et 

### LA NOTION DE VALEUR DE P ou la mettre
mesures sur populations complètes ou Échantillons

### Pour aller plus loin : les statistiques descriptives pondérées

## Statistiques descriptives sur des variables qualitatives
tableau de fréquences
